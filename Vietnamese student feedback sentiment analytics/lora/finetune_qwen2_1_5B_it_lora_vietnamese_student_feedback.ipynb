{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "id": "jifd1iT9PGTx"
      },
      "source": [
        "# Install library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZXhnT8XHPGTy",
        "outputId": "ece9fa1c-a7b0-424c-94f8-40acbfe422a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -q datasets==2.16.0\n",
        "!pip install -q bitsandbytes\n",
        "!pip install -q tiktoken\n",
        "!pip install -q peft\n",
        "!pip install -q trl\n",
        "!pip install -q transformers\n",
        "!pip install -q openpyxl\n",
        "!pip install -q pandas\n",
        "!pip install -q scikit-learn\n",
        "!pip install -q flash-attn\n",
        "#pip install -q transformers==4.38.1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_DSr9kKuPGTz"
      },
      "source": [
        "# Import library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eRGsO_RSPGTz"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
        "import torch\n",
        "from accelerate import PartialState\n",
        "from peft import LoraConfig, PeftModel, prepare_model_for_kbit_training, get_peft_model\n",
        "from trl import SFTTrainer\n",
        "from peft import prepare_model_for_kbit_training\n",
        "from transformers import TrainingArguments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I8nDYPC_PGT0"
      },
      "source": [
        "# Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZB8BnQPtPGT1"
      },
      "outputs": [],
      "source": [
        "modelpath = \"Qwen/Qwen2-1.5B-Instruct\"\n",
        "lr=2e-4      # learning rate\n",
        "bs=16            # batch size\n",
        "bs_eval=16      # batch size for evals\n",
        "ga_steps=1     # gradient acc. steps\n",
        "epochs=4\n",
        "max_length=128      # max. sample length with 24GB VRAM\n",
        "output_dir=\"out\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "718sAXQGPGT2"
      },
      "source": [
        "# Remove old model\n",
        "Because of limited storage, we can't save all models, we need to delete all models in cache by the following code:\n",
        "- rm -r out: delete out folder (because I save finetuned model in out folder), you can change folder name like (rm -r output_folder). If you doesn't have out folder, this commend do not thing.\n",
        "- all pretrained huggingface models will auto save in transformers.TRANSFORMERS_CACHE. I use shutil.rmtree to delete them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LMaJlkaQPGT2"
      },
      "outputs": [],
      "source": [
        "!rm -r out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X0m25NrbPGT2"
      },
      "outputs": [],
      "source": [
        "# from transformers import TRANSFORMERS_CACHE\n",
        "# print(TRANSFORMERS_CACHE)\n",
        "\n",
        "# import shutil\n",
        "# shutil.rmtree(TRANSFORMERS_CACHE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uEV431EcPGT2"
      },
      "source": [
        "# Create Dataset\n",
        "Download dataset from [kaggle synthetic-vietnamese-students-feedback-corpus](https://www.kaggle.com/datasets/toreleon/synthetic-vietnamese-students-feedback-corpus/data)\n",
        "\n",
        "We need convert DataFrame to json line (jsonl)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UIIM1H2MPGT3"
      },
      "outputs": [],
      "source": [
        "df_train = pd.read_csv(\"synthetic_train.csv\")\n",
        "df_test = pd.read_csv(\"synthetic_val.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DwDM2l7ZPGT3",
        "outputId": "4efbd1ed-93ee-4324-e5b1-0a31e03de343"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>topic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ƒê·ªôi ng≈© b·∫£o tr√¨ qu√° th∆∞a th·ªõt d·∫´n ƒë·∫øn kh√¥ng ƒë·∫£...</td>\n",
              "      <td>negative</td>\n",
              "      <td>facility</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The university's musical and artistic faciliti...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>facility</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Ph∆∞∆°ng ph√°p gi·∫£ng d·∫°y ph√π h·ª£p v·ªõi c√°c ƒë·ªëi t∆∞·ª£n...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>curriculum</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Ch∆∞∆°ng tr√¨nh h·ªçc gi√∫p t√¥i tr·ªü th√†nh m·ªôt chuy√™n...</td>\n",
              "      <td>positive</td>\n",
              "      <td>curriculum</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>T√¥i nghƒ© r·∫±ng ch∆∞∆°ng tr√¨nh ƒë√†o t·∫°o c√≥ th·ªÉ c√≥ t...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>curriculum</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            sentence sentiment       topic\n",
              "0  ƒê·ªôi ng≈© b·∫£o tr√¨ qu√° th∆∞a th·ªõt d·∫´n ƒë·∫øn kh√¥ng ƒë·∫£...  negative    facility\n",
              "1  The university's musical and artistic faciliti...   neutral    facility\n",
              "2  Ph∆∞∆°ng ph√°p gi·∫£ng d·∫°y ph√π h·ª£p v·ªõi c√°c ƒë·ªëi t∆∞·ª£n...   neutral  curriculum\n",
              "3  Ch∆∞∆°ng tr√¨nh h·ªçc gi√∫p t√¥i tr·ªü th√†nh m·ªôt chuy√™n...  positive  curriculum\n",
              "4  T√¥i nghƒ© r·∫±ng ch∆∞∆°ng tr√¨nh ƒë√†o t·∫°o c√≥ th·ªÉ c√≥ t...   neutral  curriculum"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KLH4IDfdPGT3",
        "outputId": "2b9c5143-ed1e-4a92-9c88-50d04aff4c30"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>topic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Ch·∫•t l∆∞·ª£ng v·∫≠t ch·∫•t k√©m.</td>\n",
              "      <td>negative</td>\n",
              "      <td>facility</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Ph·∫ßn m·ªÅm h·ªçc t·∫≠p qu√° kh√≥ s·ª≠ d·ª•ng, khi·∫øn sinh v...</td>\n",
              "      <td>negative</td>\n",
              "      <td>facility</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Tr∆∞·ªùng t√¥i thi·∫øu nh·ªØng ti·ªán √≠ch c∆° b·∫£n nh∆∞ m√°y...</td>\n",
              "      <td>negative</td>\n",
              "      <td>facility</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>C·∫ßn t·∫°o th√™m c√°c ho·∫°t ƒë·ªông g·∫Øn k·∫øt gi·ªØa sinh v...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>curriculum</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>H·ªç r·∫•t khoan dung v√† l∆∞·ª£ng gi√°c trong quan ƒëi·ªÉ...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>others</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            sentence sentiment       topic\n",
              "0                           Ch·∫•t l∆∞·ª£ng v·∫≠t ch·∫•t k√©m.  negative    facility\n",
              "1  Ph·∫ßn m·ªÅm h·ªçc t·∫≠p qu√° kh√≥ s·ª≠ d·ª•ng, khi·∫øn sinh v...  negative    facility\n",
              "2  Tr∆∞·ªùng t√¥i thi·∫øu nh·ªØng ti·ªán √≠ch c∆° b·∫£n nh∆∞ m√°y...  negative    facility\n",
              "3  C·∫ßn t·∫°o th√™m c√°c ho·∫°t ƒë·ªông g·∫Øn k·∫øt gi·ªØa sinh v...   neutral  curriculum\n",
              "4  H·ªç r·∫•t khoan dung v√† l∆∞·ª£ng gi√°c trong quan ƒëi·ªÉ...   neutral      others"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_test.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oyXxelgjPGT3",
        "outputId": "8ed56bdb-c983-49c6-8620-ab37f763e0d8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "sentiment\n",
              "neutral     2724\n",
              "negative    2711\n",
              "positive    2709\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train.sentiment.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XGUlksAQPGT3",
        "outputId": "d9b1f28e-a755-426f-9a75-64f357956164"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "sentiment\n",
              "negative    686\n",
              "positive    680\n",
              "neutral     670\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_test.sentiment.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BLEpYd_GPGT3"
      },
      "outputs": [],
      "source": [
        "df_train['len'] = df_train.sentence.apply(lambda x: len(str(x).split()))\n",
        "df_test['len'] = df_test.sentence.apply(lambda x: len(str(x).split()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YrCao-EoPGT4",
        "outputId": "38f2e4a9-2337-47eb-db62-7b1cb3ab3153"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "count    8144.000000\n",
              "mean       15.549730\n",
              "std         5.018764\n",
              "min         3.000000\n",
              "25%        12.000000\n",
              "50%        15.000000\n",
              "75%        18.000000\n",
              "max        43.000000\n",
              "Name: len, dtype: float64"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train['len'].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mPdvQ4k7PGT4",
        "outputId": "f649dce9-2db9-46b1-c905-b42f94780e96"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "count    2036.000000\n",
              "mean       15.694990\n",
              "std         5.185957\n",
              "min         2.000000\n",
              "25%        12.000000\n",
              "50%        15.000000\n",
              "75%        19.000000\n",
              "max        48.000000\n",
              "Name: len, dtype: float64"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_test['len'].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "97k5pedtPGT4"
      },
      "outputs": [],
      "source": [
        "with open('train.jsonl', 'w') as outfile:\n",
        "    for i, x in df_train.iterrows():\n",
        "        comment = x['sentence']\n",
        "        label = x['sentiment']\n",
        "        #label = 'yes' if label == 'relevance' else 'no'\n",
        "        data = {\n",
        "            \"input\": f'''The sentiment of this comment \"{comment}\" is''',\n",
        "            \"output\": f\"{label}\"\n",
        "        }\n",
        "        json.dump(data, outfile)\n",
        "        outfile.write('\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "be9hUtT3PGT4"
      },
      "outputs": [],
      "source": [
        "with open('test.jsonl', 'w') as outfile:\n",
        "    for i, x in df_test.iterrows():\n",
        "        comment = x['sentence']\n",
        "        label = x['sentiment']\n",
        "        #label = 'yes' if label == 'relevance' else 'no'\n",
        "        data = {\n",
        "            \"input\": f'''The sentiment of this comment \"{comment}\" is''',\n",
        "            \"output\": f\"{label}\"\n",
        "        }\n",
        "        json.dump(data, outfile)\n",
        "        outfile.write('\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "de351ba18a3247888d17c07e968db52b",
            "201c3c2c683142ba8299da789606d6f4"
          ]
        },
        "id": "FisUcprhPGT4",
        "outputId": "0aacc3ee-bab0-4d6b-b23f-c7e48ee9da34"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "de351ba18a3247888d17c07e968db52b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "201c3c2c683142ba8299da789606d6f4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating validation split: 0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "data_files = {\n",
        "    \"train\": \"train.jsonl\",\n",
        "    \"validation\": \"test.jsonl\",\n",
        "}\n",
        "\n",
        "dataset = load_dataset(\"json\", data_files=data_files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y3Z5DCCBPGT4",
        "outputId": "03b33efa-830f-4f45-840d-66d149820469"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['input', 'output'],\n",
              "        num_rows: 8144\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['input', 'output'],\n",
              "        num_rows: 2036\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JC0hjBlJPGT4"
      },
      "source": [
        "# Create prompt format\n",
        "Load tokenizer by AutoTokenizer.from_pretrained:\n",
        "- We need create and copy YOUR TOKEN from [huggingface](https://huggingface.co/settings/tokens)\n",
        "- We need use padding_side = 'right' because training library need padding_side = 'right' when training. You can use left padding but you need to make sure the library is not corrupted and check whether performance is affected by left padding!\n",
        "- If you have 1 prompt like \"test th·ª≠ m√¥ h√¨nh\" and want to tokenize it, just you tokenizer(prompt, return_tensors=\"pt\"). You can see output of tokenizer in cell below (output includes input_ids (list index of each token in prompt) and attention mask)\n",
        "- We can use tokenizer.batch_decode to see how tokenizer restore string from token tensor. You can see that it automatically adds the start token \"<bos>\" at the beginning of the string.\n",
        "- To train llm, we only need to pass 1 sentence to llm (including input and desired output) without specifying which is the input and which is the output.\n",
        "- I wrote the function formatting_prompts_func to convert input and output to prompt and tested this function, you can see below.\n",
        "- When predicting, remove the output part to let the model predict itself. See the predict section below later.\n",
        "- we only need to predict some next tokens like A. positive, and B. neutral. We don't care what the model says after sentiment. Then we do not need to add <eos token>. If you fine-tune the model with other tasks, maybe you need to add <eos token> at the end of the prompt:\n",
        "  - use tokenizer.eos_token, tokenizer.eos_token_id to see eos_token of your model and correspond id\n",
        "  - for ex: eos_token is \"<|im_end|>\". You need edit prompt like:\n",
        "    - '''...The correct answer is {output_}.''' --> '''...The correct answer is {output_}. <|im_end|>'''\n",
        "  - for ex: eos_token is \"end_token__\". You need edit prompt like:\n",
        "    - '''...The correct answer is {output_}.''' --> '''...The correct answer is {output_}. end_token__'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i54Bw_AUPGT4",
        "outputId": "b5450a40-4c07-4a94-a7b0-9b50eff46d90"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    modelpath,\n",
        "    padding_side=\"right\",\n",
        "    # add_eos_token=True,\n",
        "    # add_bos_token=True,\n",
        "    trust_remote_code=True,\n",
        "    token = 'YOUR TOKEN HERE'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tXBNZRWTPGT5",
        "outputId": "0c346207-9fb1-4897-923b-d998eca11ad7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_ids': tensor([[  1944, 131885, 130179, 128338]]), 'attention_mask': tensor([[1, 1, 1, 1]])}\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['test', ' th·ª≠', ' m√¥', ' h√¨nh']"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prompt = \"test th·ª≠ m√¥ h√¨nh\"\n",
        "tokens = tokenizer(prompt, return_tensors=\"pt\")\n",
        "print(tokens)\n",
        "tokenizer.batch_decode(tokenizer.encode(prompt))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OzXik36xPGT-"
      },
      "outputs": [],
      "source": [
        "def formatting_prompts_func(example):\n",
        "    output_texts = []\n",
        "    for i in range(len(example['input'])):\n",
        "        input_ = example['input'][i]\n",
        "        output_ = example['output'][i]\n",
        "        output_ = 'A. Positive' if output_ == 'positive' else 'B. Neutral' if output_ == 'neutral' else 'C. Negative'\n",
        "        #text = f\"### Question: {input__}\\n ### Answer: {example['output'][i]}\"\n",
        "        text = f'''{input_}\n",
        "A. Positive\n",
        "B. Neutral\n",
        "C. Negative\n",
        "\n",
        "The correct answer is {output_}.'''\n",
        "\n",
        "        output_texts.append(text)\n",
        "    return output_texts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rIzL2cztPGT-",
        "outputId": "c914982d-7a0a-49cf-97c6-c7fddc4e7477"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('The sentiment of this comment \"Ch·∫•t l∆∞·ª£ng v·∫≠t ch·∫•t k√©m.\" is', 'negative')"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset[\"validation\"]['input'][0], dataset[\"validation\"]['output'][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ruFC5SQ0PGT-",
        "outputId": "20ea62d2-3501-4105-bf12-860c311d25fe"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['The sentiment of this comment \"Ch·∫•t l∆∞·ª£ng v·∫≠t ch·∫•t k√©m.\" is\\nA. Positive\\nB. Neutral\\nC. Negative\\n\\nThe correct answer is C. Negative.']"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "formatting_prompts_func({'input': [dataset[\"validation\"]['input'][0]],\n",
        "                         'output': [dataset[\"validation\"]['output'][0]]})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hJcWuzaTPGT-",
        "outputId": "5b5c102d-7e54-463a-9898-605d4be15b01"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The sentiment of this comment \"Ch·∫•t l∆∞·ª£ng v·∫≠t ch·∫•t k√©m.\" is\n",
            "A. Positive\n",
            "B. Neutral\n",
            "C. Negative\n",
            "\n",
            "The correct answer is C. Negative.\n"
          ]
        }
      ],
      "source": [
        "print(formatting_prompts_func({'input': [dataset[\"validation\"]['input'][0]],\n",
        "                         'output': [dataset[\"validation\"]['output'][0]]})[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p7tD48VgPGT_"
      },
      "source": [
        "# Create model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l1szreiBPGT_"
      },
      "source": [
        "## Load model\n",
        "We use AutoModelForCausalLM.from_pretrained to load model:\n",
        "- device_map = 'auto': auto active gpu.\n",
        "- torch_dtype: use bfloat16, if your gpu don't support bfloat16, set it to float32\n",
        "- attn_implementation: you can use 'flash_attention_2', if you meet bug, maybe your gpu doesn't support it, you need delete this line.\n",
        "- token: you huggingface token like tokenizer above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6GRQc8trPGT_"
      },
      "outputs": [],
      "source": [
        "# bnb_config = BitsAndBytesConfig(\n",
        "#     load_in_4bit=True,\n",
        "#     bnb_4bit_use_double_quant=True,\n",
        "#     bnb_4bit_quant_type=\"nf4\",\n",
        "#     bnb_4bit_compute_dtype=torch.bfloat16,\n",
        "# )\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    modelpath,\n",
        "    device_map=\"auto\",\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    #torch_dtype=torch.float32,\n",
        "    #quantization_config=bnb_config,\n",
        "    attn_implementation=\"flash_attention_2\",\n",
        "    trust_remote_code=True,\n",
        "    token = 'YOUR TOKEN HERE'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s9HUMTsNPGUA",
        "outputId": "32bd4fad-5dd8-4d8e-8412-5cf566c91bf6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Qwen2ForCausalLM(\n",
              "  (model): Qwen2Model(\n",
              "    (embed_tokens): Embedding(151936, 1536)\n",
              "    (layers): ModuleList(\n",
              "      (0-27): 28 x Qwen2DecoderLayer(\n",
              "        (self_attn): Qwen2FlashAttention2(\n",
              "          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
              "          (k_proj): Linear(in_features=1536, out_features=256, bias=True)\n",
              "          (v_proj): Linear(in_features=1536, out_features=256, bias=True)\n",
              "          (o_proj): Linear(in_features=1536, out_features=1536, bias=False)\n",
              "          (rotary_emb): Qwen2RotaryEmbedding()\n",
              "        )\n",
              "        (mlp): Qwen2MLP(\n",
              "          (gate_proj): Linear(in_features=1536, out_features=8960, bias=False)\n",
              "          (up_proj): Linear(in_features=1536, out_features=8960, bias=False)\n",
              "          (down_proj): Linear(in_features=8960, out_features=1536, bias=False)\n",
              "          (act_fn): SiLU()\n",
              "        )\n",
              "        (input_layernorm): Qwen2RMSNorm()\n",
              "        (post_attention_layernorm): Qwen2RMSNorm()\n",
              "      )\n",
              "    )\n",
              "    (norm): Qwen2RMSNorm()\n",
              "  )\n",
              "  (lm_head): Linear(in_features=1536, out_features=151936, bias=False)\n",
              ")"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5u1vDZs2PGUA"
      },
      "source": [
        "## Create peft\n",
        "For lora training, we need create LoraConfig:\n",
        "  - lora_alpha, r, dropout is basic hyperarameter.\n",
        "  - almost LLM use bias = 'none' when finetune then we set is to None\n",
        "  - target_modules are list of layer we want to finetune, I set it to 'all-linear', then all linear layers will be finetuned. If you just finetune some layers like q_proj, k_proj, you can pass list ['q_proj', 'k_proj'].\n",
        "  - modules_to_save is other layers we want to finetune (but don't use lora), in my experience, finetune all embedding layers will make model work betters than I set modules_to_save as list of all embedding layers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-0qjr-a9PGUA"
      },
      "outputs": [],
      "source": [
        "#model.print_trainable_parameters()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s6PerdANPGUA"
      },
      "outputs": [],
      "source": [
        "peft_config = LoraConfig(\n",
        "    lora_alpha=32,\n",
        "    lora_dropout=0.1,\n",
        "    r=8,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\",\n",
        "    target_modules = 'all-linear',\n",
        "#     target_modules=[\"q_proj\",\n",
        "#         \"k_proj\",\n",
        "#         \"v_proj\",\n",
        "#         \"o_proj\",\n",
        "#         \"gate_proj\",\n",
        "#         \"up_proj\",\n",
        "#         \"down_proj\",\n",
        "#         \"lm_head\",],\n",
        "    modules_to_save=[\"embed_tokens\", \"rotary_emb\"]\n",
        "                     #\"input_layernorm\", \"post_attention_layernorm\", \"norm\"]\n",
        ")\n",
        "model = get_peft_model(model, peft_config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sKruJfQmPGUA"
      },
      "outputs": [],
      "source": [
        "#lora_model.print_trainable_parameters()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f2HHDkOYPGUA"
      },
      "outputs": [],
      "source": [
        "#lora_model.print_trainable_parameters() #\"embed_tokens\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Akzyq5daPGUB",
        "outputId": "946e9c37-670e-4789-b816-341c85b87f1d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trainable params: 242,606,080 || all params: 1,786,320,384 || trainable%: 13.5813\n"
          ]
        }
      ],
      "source": [
        "model.print_trainable_parameters() #"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Eval model before training\n",
        "We use create_prompt function to generate prompt (without output), our model will predict output. We will eval model before finetune. You can see some predict below.\n",
        "\n",
        "You can see that pretrained model has poor performance"
      ],
      "metadata": {
        "id": "4-fDJHnSPWKv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dj-VeOXoPGUB",
        "outputId": "d3df635a-c8e3-4712-b366-498911cc2295"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:540: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:545: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:562: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.\n",
            "  warnings.warn(\n",
            "The attention mask is not set and cannot be inferred from input because pad token is same as eos token.As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The sentiment of this comment: \"m√≥n ƒÉn r·∫•t ngon\" is\n",
            "A. Positive\n",
            "B. Neutral\n",
            "C. Negative\n",
            "\n",
            "The correct answer is\n",
            "The sentiment of this comment: \"m√≥n ƒÉn r·∫•t ngon\" is\n",
            "A. Positive\n",
            "B. Neutral\n",
            "C. Negative\n",
            "\n",
            "The correct answer is A. Positive.\n",
            "\n",
            "The phrase \"m√≥n ƒÉn r·∫•t ngon\" translates to \"delicious food\" in English, which indicates a positive sentiment towards the food being described. The use of \"kh√¥ng\" (not) at the end of the\n"
          ]
        }
      ],
      "source": [
        "def create_prompt(input_, output_):\n",
        "    output_ = 'A. Positive' if output_ == 'positive' else 'B. Neutral' if output_ == 'neutral' else 'C. Negative'\n",
        "        #text = f\"### Question: {input__}\\n ### Answer: {example['output'][i]}\"\n",
        "    text = f'''{input_}\n",
        "A. Positive\n",
        "B. Neutral\n",
        "C. Negative\n",
        "\n",
        "The correct answer is'''\n",
        "\n",
        "    return text\n",
        "\n",
        "sentence = 'm√≥n ƒÉn r·∫•t ngon'\n",
        "input_ = f'''The sentiment of this comment: \"{sentence}\" is'''\n",
        "prompt = create_prompt(input_, \"\")\n",
        "print(prompt)\n",
        "\n",
        "inputs = torch.tensor([tokenizer.encode(prompt)])\n",
        "\n",
        "tokens = model.generate(\n",
        "    inputs.to(model.device),\n",
        "    max_new_tokens=50,\n",
        "    temperature=0.1,\n",
        "    do_sample=False\n",
        ")\n",
        "print(tokenizer.decode(tokens[0], skip_special_tokens=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dS4Zt7UKPGUB",
        "outputId": "a8c44934-d79e-410d-f717-3f04b88bcee2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 100.0 0:00:00.121622 0:00:00.121624\n",
            "100 69.3069306930693 0:00:12.179419 0:00:00.120588\n",
            "200 70.64676616915423 0:00:24.347871 0:00:00.121134\n",
            "300 67.77408637873754 0:00:36.492047 0:00:00.121236\n",
            "400 68.5785536159601 0:00:48.678283 0:00:00.121392\n",
            "500 69.26147704590818 0:01:00.780316 0:00:00.121318\n",
            "600 67.55407653910149 0:01:12.851168 0:00:00.121217\n",
            "700 66.76176890156918 0:01:24.998305 0:00:00.121253\n",
            "800 67.41573033707866 0:01:37.215684 0:00:00.121368\n",
            "900 66.48168701442842 0:01:49.254118 0:00:00.121259\n",
            "1000 66.53346653346654 0:02:01.415417 0:00:00.121294\n",
            "1100 66.03088101725703 0:02:13.598444 0:00:00.121343\n",
            "1200 65.69525395503747 0:02:25.695514 0:00:00.121312\n",
            "1300 66.10299769408148 0:02:37.724233 0:00:00.121233\n",
            "1400 66.38115631691649 0:02:49.795400 0:00:00.121196\n",
            "1500 66.35576282478348 0:03:01.936345 0:00:00.121210\n",
            "1600 66.70830730793254 0:03:14.046403 0:00:00.121203\n",
            "1700 66.84303350970018 0:03:26.051836 0:00:00.121136\n",
            "1800 67.01832315380344 0:03:38.173664 0:00:00.121140\n",
            "1900 66.964755391899 0:03:50.214584 0:00:00.121102\n",
            "2000 66.96651674162919 0:04:02.355218 0:00:00.121117\n"
          ]
        }
      ],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "start = datetime.now()\n",
        "\n",
        "prediction = []\n",
        "response = []\n",
        "accuracy = []\n",
        "labels = []\n",
        "\n",
        "for i, x in df_test.iterrows():\n",
        "    sentence = x['sentence']\n",
        "    label = x['sentiment']\n",
        "    input_ = f'''The sentiment of this comment: \"{sentence}\" is'''\n",
        "    prompt = create_prompt(input_, label)\n",
        "\n",
        "    inputs = tokenizer.encode(\n",
        "        prompt,\n",
        "        # add_generation_prompt=True,\n",
        "        return_tensors='pt'\n",
        "    )\n",
        "\n",
        "    tokens = model.generate(\n",
        "        inputs.to(model.device),\n",
        "        max_new_tokens=3,\n",
        "        temperature=0.1,\n",
        "        do_sample=False,\n",
        "        pad_token_id=tokenizer.eos_token_id\n",
        "    )\n",
        "    #break\n",
        "\n",
        "    answer = tokenizer.decode(tokens[0], skip_special_tokens=False).split(\"The correct answer is \")[-1]\n",
        "    answer = 'positive' if 'positive' in answer.lower() else 'negative' if 'negative' in answer.lower() else 'neutral'\n",
        "    prediction.append(answer.lower())\n",
        "    response.append(tokenizer.decode(tokens[0], skip_special_tokens=False))\n",
        "\n",
        "    accuracy.append(prediction[-1] == label)\n",
        "    labels.append(label)\n",
        "\n",
        "    if i % 100 == 0:\n",
        "        print(i, np.array(accuracy).sum()/len(prediction)*100, datetime.now() - start, (datetime.now() - start)/len(prediction))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OCU5jNfRPGUB",
        "outputId": "59c805ae-42d5-42ad-fff0-371e8fea1c7f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative     0.9503    0.9752    0.9626       686\n",
            "     neutral     0.7647    0.0194    0.0378       670\n",
            "    positive     0.5163    0.9985    0.6807       680\n",
            "\n",
            "    accuracy                         0.6685      2036\n",
            "   macro avg     0.7438    0.6644    0.5604      2036\n",
            "weighted avg     0.7443    0.6685    0.5641      2036\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report, f1_score\n",
        "import sklearn\n",
        "\n",
        "print(sklearn.metrics.classification_report(labels, prediction, digits=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aba-trW_PGUB",
        "outputId": "6685f3ca-a512-4034-b6a5-9902d3904889"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The sentiment of this comment: \"The facilities of the university are versatile and helpful.\" is\n",
            "A. Positive\n",
            "B. Neutral\n",
            "C. Negative\n",
            "\n",
            "The correct answer is A. Positive\n",
            "\n",
            "\n",
            "The sentiment of this comment: \"M·∫•y b·∫°n ƒë√≥ hay ƒë√≤i h·ªèi nh∆∞ng kh√¥ng bao gi·ªù gi√∫p ƒë·ª° ng∆∞·ªùi kh√°c.\" is\n",
            "A. Positive\n",
            "B. Neutral\n",
            "C. Negative\n",
            "\n",
            "The correct answer is C. Negative\n",
            "\n",
            "\n",
            "The sentiment of this comment: \"C·∫≠u ·∫•y r·∫•t c√≥ k·ªπ nƒÉng v·ªÅ s√°ng t·∫°o v√† ngh·ªá thu·∫≠t.\" is\n",
            "A. Positive\n",
            "B. Neutral\n",
            "C. Negative\n",
            "\n",
            "The correct answer is A. Positive\n",
            "\n",
            "\n",
            "The sentiment of this comment: \"Gi·∫£ng vi√™n n√†y kh√¥ng nh√†m ch√°n.\" is\n",
            "A. Positive\n",
            "B. Neutral\n",
            "C. Negative\n",
            "\n",
            "The correct answer is A. Positive\n",
            "\n",
            "\n",
            "The sentiment of this comment: \"Anh ta l√† m·ªôt ng∆∞·ªùi r·∫•t t·ªâ m·ªâ v√† c·∫©n th·∫≠n.\" is\n",
            "A. Positive\n",
            "B. Neutral\n",
            "C. Negative\n",
            "\n",
            "The correct answer is A. Positive\n",
            "\n",
            "\n",
            "The sentiment of this comment: \"Gi√°o vi√™n ƒë∆∞a ra c√°c ph∆∞∆°ng ti·ªán h·ªó tr·ª£ gi·∫£ng d·∫°y r·∫•t t·ªët v√† hi·ªáu qu·∫£.\" is\n",
            "A. Positive\n",
            "B. Neutral\n",
            "C. Negative\n",
            "\n",
            "The correct answer is A. Positive\n",
            "\n",
            "\n",
            "The sentiment of this comment: \"The university's computer facilities are up-to-date and well-maintained.\" is\n",
            "A. Positive\n",
            "B. Neutral\n",
            "C. Negative\n",
            "\n",
            "The correct answer is A. Positive\n",
            "\n",
            "\n",
            "The sentiment of this comment: \"Thi·∫øu t√≠nh linh ho·∫°t trong h√¨nh th·ª©c gi·∫£ng d·∫°y v√† ƒë√°nh gi√° k·∫øt qu·∫£ h·ªçc t·∫≠p.\" is\n",
            "A. Positive\n",
            "B. Neutral\n",
            "C. Negative\n",
            "\n",
            "The correct answer is C. Negative\n",
            "\n",
            "\n",
            "The sentiment of this comment: \"C√¥ ·∫•y r·∫•t s·∫Øc s·∫£o v√† c√≥ kh·∫£ nƒÉng ph√¢n t√≠ch chi ti·∫øt r·∫•t t·ªët.\" is\n",
            "A. Positive\n",
            "B. Neutral\n",
            "C. Negative\n",
            "\n",
            "The correct answer is A. Positive\n",
            "\n",
            "\n",
            "The sentiment of this comment: \"Anh ·∫•y c√≥ t√†i nƒÉng v·ªÅ √¢m nh·∫°c v√† lu√¥n t√¨m c√°ch t·∫°o ra c√°c b·∫£n nh·∫°c m·ªõi, gi√∫p nh√≥m th√™m ho√†n h·∫£o v√† ƒëa d·∫°ng h∆°n.\" is\n",
            "A. Positive\n",
            "B. Neutral\n",
            "C. Negative\n",
            "\n",
            "The correct answer is A. Positive\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for x in response[-10:]:\n",
        "    print(x)\n",
        "    print(\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7NgbLBSDPGUC"
      },
      "source": [
        "## Create TrainingArguments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FKAMMwZIPGUC",
        "outputId": "dc70373a-65f2-4685-d79b-034255ef8fc0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "509\n"
          ]
        }
      ],
      "source": [
        "print(len(df_train)//bs//ga_steps*epochs//4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ova_IHLPGUC",
        "outputId": "3908ad0d-8739-4b4d-97af-6540007290dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "509\n"
          ]
        }
      ],
      "source": [
        "save_step = len(df_train)//bs//ga_steps*epochs//4\n",
        "print(save_step)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uwFM7bkuPGUC",
        "outputId": "310078d1-27a0-4448-9916-96b208ad8d29"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "training_arguments = TrainingArguments(\n",
        "    output_dir=output_dir,\n",
        "    num_train_epochs=epochs,\n",
        "    per_device_train_batch_size=bs,\n",
        "    per_device_eval_batch_size=bs_eval,\n",
        "    evaluation_strategy=\"steps\",\n",
        "    eval_steps=save_step,\n",
        "    gradient_accumulation_steps=ga_steps,\n",
        "    optim=\"paged_adamw_32bit\",\n",
        "    save_steps=save_step,\n",
        "    save_strategy=\"steps\",\n",
        "    logging_steps=save_step,\n",
        "    learning_rate=lr,\n",
        "    weight_decay=0.001,\n",
        "    fp16=False,\n",
        "    bf16=True,\n",
        "    max_grad_norm=0.3,\n",
        "    max_steps=-1,\n",
        "    warmup_ratio=0.03,\n",
        "    group_by_length=True,\n",
        "    lr_scheduler_type=\"constant\",\n",
        "    report_to=\"none\",\n",
        "    save_total_limit=1,\n",
        "    #load_best_model_at_end=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J3jp3IhOPGUC"
      },
      "source": [
        "## Create trainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "f61915c391954991aae9fdb21246eee3",
            "184b7048ee1a44e7b7697d1667270bd6"
          ]
        },
        "id": "irqNA3TQPGUC",
        "outputId": "3da89a79-f0f8-4b64-dba3-2bc4367d3dc6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': max_seq_length. Will not be supported from version '1.0.0'.\n",
            "\n",
            "Deprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n",
            "  warnings.warn(message, FutureWarning)\n",
            "/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1961: FutureWarning: `--push_to_hub_token` is deprecated and will be removed in version 5 of ü§ó Transformers. Use `--hub_token` instead.\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:269: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f61915c391954991aae9fdb21246eee3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/8144 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "184b7048ee1a44e7b7697d1667270bd6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/2036 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
          ]
        }
      ],
      "source": [
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    train_dataset=dataset[\"train\"],\n",
        "    eval_dataset=dataset[\"validation\"],\n",
        "    peft_config=peft_config,\n",
        "    max_seq_length= 128,\n",
        "    #dataset_text_field=[\"input\", \"output\"],\n",
        "    tokenizer=tokenizer,\n",
        "    args=training_arguments,\n",
        "    packing= False,\n",
        "    formatting_func = formatting_prompts_func,\n",
        "    #data_collator=collator\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GUtcItlpPGUC"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MAgMFmqVPGUC",
        "outputId": "d5c773d1-7884-4a9e-ab3d-5fd28bd04f61"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2036' max='2036' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2036/2036 06:28, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>509</td>\n",
              "      <td>0.783000</td>\n",
              "      <td>0.742862</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1018</td>\n",
              "      <td>0.672800</td>\n",
              "      <td>0.740708</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1527</td>\n",
              "      <td>0.600800</td>\n",
              "      <td>0.759789</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2036</td>\n",
              "      <td>0.530600</td>\n",
              "      <td>0.793977</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=2036, training_loss=0.6467708295361232, metrics={'train_runtime': 389.3988, 'train_samples_per_second': 83.657, 'train_steps_per_second': 5.229, 'total_flos': 1.2091384561287168e+16, 'train_loss': 0.6467708295361232, 'epoch': 4.0})"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fpNRsTahPGUD"
      },
      "source": [
        "# Eval\n",
        "- If you save the model to the output_dir folder, the training code above will automatically save the model to output_dir/checkpoint-{save_step} (in my case: out/checkpoint-2036). We will load the model from this folder:\n",
        "  - I calculate _id = save_step * num_epoch = 509 * 4 = 2036\n",
        "  - My model will saved at \"{output_dir}/checkpoint-{_id}\"\n",
        "- I use del model, gc.collect() and torch.cuda.empty_cache() to release trained model (save gpu memory).\n",
        "- We use PeftConfig.from_pretrained to lead peft config (this is the same as peft config at training)\n",
        "- we load pretrained model like before.\n",
        "- We load the tokenizer in this folder by passing the saved folder to AutoTokenizer.from_pretrained()\n",
        "- We use PeftModel.from_pretrained(model, peft_model_id) to merge pre-trained model with finetuned lora model (note that when we use peft lora, training code only saves lora model, this saves our storage and saving time)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eZ8TEezZPGUD",
        "outputId": "4099a534-6e6d-4d8b-d4e7-c13e208c3a82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "509\n"
          ]
        }
      ],
      "source": [
        "save_step = len(df_train)//bs//ga_steps*epochs//4\n",
        "print(save_step)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YbRGBPfNPGUD"
      },
      "outputs": [],
      "source": [
        "import gc\n",
        "\n",
        "del model\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YpcEuTa6PGUD",
        "outputId": "5cf78ef7-92a2-423c-85a0-e018d1a3c314"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ],
      "source": [
        "from peft import PeftModel, PeftConfig\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import torch\n",
        "\n",
        "_id = save_step*4\n",
        "\n",
        "peft_model_id = f\"{output_dir}/checkpoint-{_id}\"\n",
        "\n",
        "config = PeftConfig.from_pretrained(peft_model_id)\n",
        "\n",
        "# bnb_config = BitsAndBytesConfig(\n",
        "#     load_in_4bit=True,\n",
        "#     bnb_4bit_use_double_quant=False,\n",
        "#     bnb_4bit_quant_type=\"nf4\",\n",
        "#     bnb_4bit_compute_dtype=torch.float16,\n",
        "# )\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    modelpath,\n",
        "    device_map=\"auto\",\n",
        "    #torch_dtype=torch.float16,\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    #quantization_config=bnb_config,\n",
        "    attn_implementation=\"flash_attention_2\",\n",
        "    trust_remote_code=True,\n",
        "    token = 'YOUR TOKEN HERE'\n",
        ")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(f\"{output_dir}/checkpoint-{_id}\",\n",
        "                                          trust_remote_code=True,\n",
        "                                          padding_side='left',\n",
        "                                          token='YOUR TOKEN HERE')\n",
        "\n",
        "# Load the Lora model\n",
        "model = PeftModel.from_pretrained(model, peft_model_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pRC2RWJSPGUD"
      },
      "outputs": [],
      "source": [
        "def create_prompt(input_, output_):\n",
        "    output_ = 'A. Positive' if output_ == 'positive' else 'B. Neutral' if output_ == 'neutral' else 'C. Negative'\n",
        "        #text = f\"### Question: {input__}\\n ### Answer: {example['output'][i]}\"\n",
        "    text = f'''{input_}\n",
        "A. Positive\n",
        "B. Neutral\n",
        "C. Negative\n",
        "\n",
        "The correct answer is'''\n",
        "\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ro6waIBOPGUD",
        "outputId": "6621d59d-907c-4446-c17c-997d75adca43"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The sentiment of this comment: \"m√≥n ƒÉn r·∫•t ngon\" is\n",
            "A. Positive\n",
            "B. Neutral\n",
            "C. Negative\n",
            "\n",
            "The correct answer is\n"
          ]
        }
      ],
      "source": [
        "sentence = 'm√≥n ƒÉn r·∫•t ngon'\n",
        "input_ = f'''The sentiment of this comment: \"{sentence}\" is'''\n",
        "prompt = create_prompt(input_, \"\")\n",
        "print(prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cGe-gk41PGUD",
        "outputId": "4e89abda-3298-4480-8613-a7245eb29677"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[   785,  25975,    315,    419,   3980,     25,    330,     76,   3165,\n",
              "         128442, 128323,   7777,    263,      1,    374,    198,     32,     13,\n",
              "          43903,    198,     33,     13,  58694,    198,     34,     13,  50857,\n",
              "            271,    785,   4396,   4226,    374]])"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "inputs = torch.tensor([tokenizer.encode(prompt)])\n",
        "inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V6hMhnB0PGUE"
      },
      "outputs": [],
      "source": [
        "tokens = model.generate(\n",
        "    inputs.to(model.device),\n",
        "    max_new_tokens=50,\n",
        "    temperature=0.1,\n",
        "    do_sample=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "obpJUme8PGUE",
        "outputId": "2c1d765a-1615-4cd3-8f4d-f659337c95ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The sentiment of this comment: \"m√≥n ƒÉn r·∫•t ngon\" is\n",
            "A. Positive\n",
            "B. Neutral\n",
            "C. Negative\n",
            "\n",
            "The correct answer is B. Neutral. The comment \"m√¥n ƒÉn r·∫•t ngon\" is a positive comment on the food served in the cafeteria. However, it does not provide any information about the quality of the food itself. Therefore, it cannot be classified as either\n"
          ]
        }
      ],
      "source": [
        "print(tokenizer.decode(tokens[0], skip_special_tokens=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k_ngE17PPGUE",
        "outputId": "e0d92411-d366-454c-f5d9-6277bcdb68a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The sentiment of this comment: \"m√≥n ƒÉn r·∫•t ngon\" is\n",
            "A. Positive\n",
            "B. Neutral\n",
            "C. Negative\n",
            "\n",
            "The correct answer is B. Neutral\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:540: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:545: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:562: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "tokens = model.generate(\n",
        "    inputs.to(model.device),\n",
        "    max_new_tokens=3,\n",
        "    temperature=0.1,\n",
        "    do_sample=False\n",
        ")\n",
        "print(tokenizer.decode(tokens[0], skip_special_tokens=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_zooN6vFPGUE",
        "outputId": "38b6399d-baaf-4576-a4c3-795d8fbdd0a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 100.0 0:00:00.117085 0:00:00.117088\n",
            "100 87.12871287128714 0:00:11.459762 0:00:00.113463\n",
            "200 86.06965174129353 0:00:22.732505 0:00:00.113097\n",
            "300 87.37541528239203 0:00:34.022894 0:00:00.113033\n",
            "400 85.53615960099751 0:00:45.343768 0:00:00.113077\n",
            "500 85.82834331337325 0:00:56.750492 0:00:00.113274\n",
            "600 86.02329450915141 0:01:08.133723 0:00:00.113367\n",
            "700 85.73466476462197 0:01:19.426894 0:00:00.113305\n",
            "800 86.14232209737828 0:01:30.704837 0:00:00.113240\n",
            "900 86.12652608213097 0:01:42.046285 0:00:00.113259\n",
            "1000 86.21378621378622 0:01:53.524557 0:00:00.113411\n",
            "1100 86.28519527702089 0:02:04.847799 0:00:00.113395\n",
            "1200 85.34554537885096 0:02:16.278358 0:00:00.113471\n",
            "1300 85.54957724827055 0:02:27.701936 0:00:00.113530\n",
            "1400 85.58172733761599 0:02:39.057269 0:00:00.113531\n",
            "1500 85.27648234510326 0:02:50.385303 0:00:00.113515\n",
            "1600 85.32167395377888 0:03:01.627965 0:00:00.113447\n",
            "1700 85.71428571428571 0:03:12.845191 0:00:00.113372\n",
            "1800 85.8411993337035 0:03:24.085562 0:00:00.113318\n",
            "1900 85.63913729615992 0:03:35.337574 0:00:00.113276\n",
            "2000 85.6071964017991 0:03:46.673662 0:00:00.113280\n"
          ]
        }
      ],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "start = datetime.now()\n",
        "\n",
        "prediction = []\n",
        "response = []\n",
        "accuracy = []\n",
        "labels = []\n",
        "\n",
        "for i, x in df_test.iterrows():\n",
        "    sentence = x['sentence']\n",
        "    label = x['sentiment']\n",
        "    input_ = f'''The sentiment of this comment: \"{sentence}\" is'''\n",
        "    prompt = create_prompt(input_, label)\n",
        "\n",
        "    inputs = tokenizer.encode(\n",
        "        prompt,\n",
        "        # add_generation_prompt=True,\n",
        "        return_tensors='pt'\n",
        "    )\n",
        "\n",
        "    tokens = model.generate(\n",
        "        inputs.to(model.device),\n",
        "        max_new_tokens=3,\n",
        "        temperature=0.1,\n",
        "        do_sample=False,\n",
        "        pad_token_id=tokenizer.eos_token_id\n",
        "    )\n",
        "    #break\n",
        "\n",
        "    answer = tokenizer.decode(tokens[0], skip_special_tokens=False).split(\"The correct answer is \")[-1]\n",
        "    answer = 'positive' if 'positive' in answer.lower() else 'negative' if 'negative' in answer.lower() else 'neutral'\n",
        "    prediction.append(answer.lower())\n",
        "    response.append(tokenizer.decode(tokens[0], skip_special_tokens=False))\n",
        "\n",
        "    accuracy.append(prediction[-1] == label)\n",
        "    labels.append(label)\n",
        "\n",
        "    if i % 100 == 0:\n",
        "        print(i, np.array(accuracy).sum()/len(prediction)*100, datetime.now() - start, (datetime.now() - start)/len(prediction))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "45S3wNIDPGUE",
        "outputId": "87c6bb02-5f1b-4042-b075-5fcbdca96c9e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative     0.9714    0.9913    0.9812       686\n",
            "     neutral     0.7972    0.7567    0.7764       670\n",
            "    positive     0.7914    0.8147    0.8029       680\n",
            "\n",
            "    accuracy                         0.8551      2036\n",
            "   macro avg     0.8533    0.8542    0.8535      2036\n",
            "weighted avg     0.8540    0.8551    0.8543      2036\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report, f1_score\n",
        "import sklearn\n",
        "\n",
        "print(sklearn.metrics.classification_report(labels, prediction, digits=4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7k1jQSOxPGUE"
      },
      "source": [
        "# Check results\n",
        "- I print all sentences have wrong prediction and see that almost cases is bug.\n",
        "- Conclusion, dataset is not clean than finetune LLM can't better than finetune roberta (~89..90%), because roberta will overfit even in test dataset.\n",
        "- In additionally, when I print example: \"m√≥n ƒÉn n√†y r·∫•t ngon\", we can see that model before finetune work better. Model after finetune only think about school (because finetune dataset is about school) and it don't know about food review. Than I think we only need finetune for special cases and finetune dataset need be clean and large enough."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mbpht-nmPGUE"
      },
      "outputs": [],
      "source": [
        "df_test['predict'] = prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8LgfIEmoPGUF",
        "outputId": "b0240db8-5d57-4022-881b-36afffa07884"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Gi·∫£ng vi√™n lu√¥n ƒë·ªìng h√†nh v·ªõi sinh vi√™n tr√™n qu√° tr√¨nh h·ªçc t·∫≠p. positive neutral\n",
            "T√¥i c√≥ th·ªÉ ·ª©ng d·ª•ng c√°c ki·∫øn th·ª©c c√≥ ƒë∆∞·ª£c t·ª´ ch∆∞∆°ng tr√¨nh ƒë√†o t·∫°o v√†o c√¥ng vi·ªác c·ªßa m√¨nh. neutral positive\n",
            "Gi·∫£ng vi√™n r·∫•t t√†i nƒÉng v√† c√≥ nhi·ªÅu kinh nghi·ªám trong c√¥ng t√°c gi·∫£ng d·∫°y. positive neutral\n",
            "ƒê∆∞·ª£c h·ªçc t·∫≠p v·ªõi c√°c gi√°o vi√™n gi√†u kinh nghi·ªám v√† th·ª±c ti·ªÖn. positive neutral\n",
            "Nh√† h√†ng v√† c√°c c·ª≠a h√†ng ti·ªán l·ª£i ·ªü g·∫ßn tr∆∞·ªùng r·∫•t ƒëa d·∫°ng v√† phong ph√∫. neutral positive\n",
            "Ch·ªã ·∫•y r·∫•t gi·ªèi qu·∫£n l√Ω th·ªùi gian v√† lu√¥n ho√†n th√†nh c√¥ng vi·ªác ƒë√∫ng ti·∫øn ƒë·ªô. positive neutral\n",
            "Anh ·∫•y c√≥ m·ªôt t·∫ßm nh√¨n ƒë·ªânh cao v√† kh·∫£ nƒÉng gi·∫£i quy·∫øt v·∫•n ƒë·ªÅ t·ªët. positive neutral\n",
            "C√°c c·ª≠a h√†ng ti·ªán l·ª£i g·∫ßn ƒë√≥ th∆∞·ªùng xuy√™n ƒë∆∞·ª£c m·ªü c·ª≠a cho sinh vi√™n. negative neutral\n",
            "Tr∆∞·ªùng ƒë·∫°i h·ªçc n√†y ƒë√≥ng g√≥p m·ªôt ph·∫ßn quan tr·ªçng trong vi·ªác ph√°t tri·ªÉn kinh t·∫ø v√† x√£ h·ªôi ƒë·ªãa ph∆∞∆°ng. positive neutral\n",
            "C√≥ nhi·ªÅu ho·∫°t ƒë·ªông ngo·∫°i kh√≥a v√† phong ph√∫ cho sinh vi√™n. neutral positive\n",
            "Khu v·ª±c ƒë·∫∑t m√°y b√°n th·ª©c u·ªëng r·∫•t ti·ªán l·ª£i cho sinh vi√™n. neutral positive\n",
            "Ch∆∞∆°ng tr√¨nh h·ªçc gi√∫p t√¥i c·∫£m th·∫•y m√¨nh c√≥ m·ª•c ti√™u r√µ r√†ng h∆°n. neutral positive\n",
            "Ph√≤ng h·ªçc ƒë∆∞·ª£c trang b·ªã ƒë·∫ßy ƒë·ªß ti·ªán nghi gi√∫p sinh vi√™n lu√¥n d·ªÖ d√†ng ti·∫øp c·∫≠n t√†i li·ªáu v√† th√¥ng tin li√™n quan. positive neutral\n",
            "Th·∫ßy d·∫°y r·∫•t chuy√™n nghi·ªáp v√† nhi·ªát t√¨nh. neutral positive\n",
            "ƒê·∫°i h·ªçc n√†y c√≥ nhi·ªÅu h·ªôi th·∫£o v√† kh√≥a t·∫≠p hu·∫•n gi√∫p sinh vi√™n trau d·ªìi ki·∫øn th·ª©c v√† k·ªπ nƒÉng. neutral positive\n",
            "C√°c ph√≤ng th√≠ nghi·ªám ƒë∆∞·ª£c trang b·ªã ƒë·∫ßy ƒë·ªß c√°c thi·∫øt b·ªã c·∫ßn thi·∫øt. positive neutral\n",
            "Khu v·ª±c h·ªçc t·∫≠p t·∫°i th∆∞ vi·ªán r·∫•t y√™n tƒ©nh v√† tho·∫£i m√°i. neutral positive\n",
            "Th·∫ßy/c√¥ ƒë√°nh gi√° v√† ƒë·ªÅ xu·∫•t nh·ªØng √Ω ki·∫øn x√¢y d·ª±ng t√≠ch c·ª±c gi√∫p sinh vi√™n ph√°t tri·ªÉn h∆°n. neutral positive\n",
            "Gi·∫£ng vi√™n r·∫•t ch√¢n th√†nh v√† nhi·ªát t√¨nh. neutral positive\n",
            "H·ªá th·ªëng th∆∞ vi·ªán v√† t√†i nguy√™n h·ªçc t·∫≠p r·∫•t ƒë·∫ßy ƒë·ªß v√† ti·ªán l·ª£i. positive neutral\n",
            "Ch∆∞∆°ng tr√¨nh ƒë√†o t·∫°o c√≥ nhi·ªÅu t√≠nh ·ª©ng d·ª•ng gi√∫p sinh vi√™n t·ª± tin v√† th√†nh c√¥ng trong c√¥ng vi·ªác. neutral positive\n",
            "Tr∆∞·ªùng c·∫ßn c√≥ ch√≠nh s√°ch h·ªó tr·ª£ chi ph√≠ h·ªçc t·∫≠p ph√π h·ª£p cho sinh vi√™n. neutral negative\n",
            "Th·∫ßy cho h·ªçc sinh m·ªôt c√°i nh√¨n t·ªïng quan v·ªÅ chuy√™n ng√†nh c·ªßa m√¨nh. neutral positive\n",
            "C√°c ph√≤ng h·ªçc ƒë∆∞·ª£c trang b·ªã ƒë·∫ßy ƒë·ªß ti·ªán nghi v√† thi·∫øt b·ªã. positive neutral\n",
            "Ch∆∞∆°ng tr√¨nh ƒë√†o t·∫°o r·∫•t ƒëa d·∫°ng v·ªÅ c·∫£ n·ªôi dung l·∫´n h√¨nh th·ª©c ƒë√†o t·∫°o. neutral positive\n",
            "Tr∆∞·ªùng ƒë·∫°i h·ªçc cung c·∫•p nhi·ªÅu ch∆∞∆°ng tr√¨nh h·ªçc b·ªïng h·ªó tr·ª£ cho sinh vi√™n kh√≥ khƒÉn kinh t·∫ø. neutral positive\n",
            "C√°c d·ªãch v·ª• b·∫£o v·ªá trong tr∆∞·ªùng r·∫•t chuy√™n nghi·ªáp v√† ƒë·∫£m b·∫£o an to√†n cho sinh vi√™n. positive neutral\n",
            "Khu v·ª±c s·ªëng ƒë·ªông c·ªßa tr∆∞·ªùng r·∫•t th√∫ v·ªã cho sinh vi√™n. positive neutral\n",
            "Gi·∫£ng vi√™n r·∫•t am hi·ªÉu v√† t·ª´ng b∆∞·ªõc h∆∞·ªõng d·∫´n sinh vi√™n ƒëi ƒë·∫øn th√†nh c√¥ng. positive neutral\n",
            "Th·∫ßy gi·∫£i th√≠ch c·∫∑n k·∫Ω v√† d·ªÖ hi·ªÉu. neutral positive\n",
            "Th·∫ßy c√¥ gi·∫£ng d·∫°y ƒë·ªÅu r·∫•t nhi·ªát t√¨nh v√† c√≥ kinh nghi·ªám trong lƒ©nh v·ª±c ƒëang gi·∫£ng d·∫°y. neutral positive\n",
            "C√≥ r·∫•t nhi·ªÅu ph√≤ng h·ªçc t·∫°i tr∆∞·ªùng ƒë·ªÉ sinh vi√™n c√≥ th·ªÉ l·ª±a ch·ªçn v√† s·ª≠ d·ª•ng. neutral positive\n",
            "T√¥i r·∫•t ·∫•n t∆∞·ª£ng v·ªõi s·ª± trang tr√≠ trong tr∆∞·ªùng, ch√∫ng t·∫°o c·∫£m gi√°c tho·∫£i m√°i v√† th∆∞ gi√£n cho sinh vi√™n. positive neutral\n",
            "C√¥ ·∫•y lu√¥n s·∫µn s√†ng gi√∫p ƒë·ª° v√† h·ªó tr·ª£ ng∆∞·ªùi kh√°c. positive neutral\n",
            "Tr∆∞·ªùng c√≥ h·ªá th·ªëng th√¥ng tin qu·∫£n l√Ω hi·ªán ƒë·∫°i v√† ƒë√°p ·ª©ng ƒë∆∞·ª£c c√°c y√™u c·∫ßu c·ªßa sinh vi√™n. positive neutral\n",
            "Gi·∫£ng vi√™n ƒë∆∞a ra nh·ªØng c√¢u h·ªèi th√∫ v·ªã v√† kh√≥ gi·∫£i quy·∫øt, gi√∫p sinh vi√™n r√®n luy·ªán k·ªπ nƒÉng suy lu·∫≠n v√† ph√¢n t√≠ch. positive neutral\n",
            "Th·∫ßy lu√¥n khuy·∫øn kh√≠ch t√¥i c·∫£i thi·ªán kh·∫£ nƒÉng t·ªï ch·ª©c th·ªùi gian v√† ho√†n th√†nh nhi·ªám v·ª•. neutral positive\n",
            "Khu v·ª±c ƒÉn u·ªëng c·ªßa tr∆∞·ªùng c√≥ nhi·ªÅu m√≥n ƒÉn ngon v√† ƒëa d·∫°ng. neutral positive\n",
            "B·∫°n c·ªßa em l√† ng∆∞·ªùi d·ªÖ th∆∞∆°ng v√† tr·∫ª trung. positive neutral\n",
            "M√¥n h·ªçc ƒë·∫ßy ƒë·ªß v√† b√°m s√°t v·ªõi th·ª±c ti·ªÖn, gi√∫p sinh vi√™n n·∫Øm v·ªØng ki·∫øn th·ª©c chuy√™n ng√†nh. neutral positive\n",
            "Ch·ªã ·∫•y l√† ng∆∞·ªùi th·∫≠t s·ª± t·∫≠n t√¢m v√† d√†nh tr·ªçn t√¢m huy·∫øt cho c√¥ng vi·ªác. positive neutral\n",
            "Gi√°o vi√™n c·ªßa t√¥i d·∫°y l√≠ thuy·∫øt v√† th·ª±c h√†nh v·ªÅ quy·ªÅn s·ªü h·ªØu tr√≠ tu·ªá v√† b·∫£o v·ªá nh√£n hi·ªáu. neutral positive\n",
            "Ch∆∞∆°ng tr√¨nh ƒë√†o t·∫°o gi√∫p t√¥i ph√°t tri·ªÉn m·ªëi quan h·ªá v·ªõi c√°c sinh vi√™n kh√°c v√† c√°c gi·∫£ng vi√™n. neutral positive\n",
            "T√¥i r·∫•t th√≠ch nh·ªØng khu v·ª±c xanh trong tr∆∞·ªùng, ch√∫ng t·∫°o c·∫£m gi√°c tho·∫£i m√°i v√† g·∫ßn g≈©i v·ªõi thi√™n nhi√™n. positive neutral\n",
            "N√†ng c√≥ s·ª± t·∫≠p trung cao ƒë·ªô v√† lu√¥n ƒë·∫°t ƒë∆∞·ª£c nh·ªØng th√†nh t√≠ch t·ªët. positive neutral\n",
            "Ph√≤ng h·ªçc ƒë∆∞·ª£c b·ªë tr√≠ nhi·ªÅu √°nh s√°ng t·ª± nhi√™n gi√∫p sinh vi√™n ti·∫øt ki·ªám ƒë∆∞·ª£c ƒëi·ªán trong qu√° tr√¨nh h·ªçc t·∫≠p. neutral positive\n",
            "C√°c khu v·ª±c sinh ho·∫°t c·ªßa tr∆∞·ªùng c·∫ßn ƒë∆∞·ª£c x√¢y d·ª±ng l·∫°i ƒë·ªÉ ƒë√°p ·ª©ng nhu c·∫ßu c·ªßa sinh vi√™n. negative neutral\n",
            "T√¥i r·∫•t ƒë√°nh gi√° cao s·ª± chu·∫©n b·ªã v√† b·ªë tr√≠ c·ªßa c√°c m√¥n h·ªçc trong ch∆∞∆°ng tr√¨nh. neutral positive\n",
            "Anh ·∫•y l√† m·ªôt ng∆∞·ªùi h·ªçc nhanh v√† c√≥ kh·∫£ nƒÉng t√¨m ki·∫øm th√¥ng tin m·ªôt c√°ch hi·ªáu qu·∫£. positive neutral\n",
            "Th∆∞ vi·ªán ƒë·∫ßy ƒë·ªß s√°ch v·ªü c·∫ßn thi·∫øt. neutral positive\n",
            "T√¥i r·∫•t th√≠ch k·∫øt h·ª£p c·ªßa m·ªôt s·ªë m√¥n h·ªçc c∆° b·∫£n v√† nh·ªØng ch·ªß ƒë·ªÅ th√∫ v·ªã v√† l·∫° l·∫´m. neutral positive\n",
            "C√°c m√¥n h·ªçc gi√∫p sinh vi√™n ph√°t tri·ªÉn t∆∞ duy ph·∫£n bi·ªán v√† ƒë·ªôc l·∫≠p trong t∆∞ duy. neutral positive\n",
            "Anh ta l√† m·ªôt ng∆∞·ªùi ƒë√°ng tin c·∫≠y v√† lu√¥n gi·ªØ l·ªùi h·ª©a c·ªßa m√¨nh. positive neutral\n",
            "Anh ·∫•y r·∫•t th·∫•u hi·ªÉu v√† gi√∫p ƒë·ª° nh·ªØng ng∆∞·ªùi g·∫∑p kh√≥ khƒÉn. positive neutral\n",
            "Gi·∫£ng vi√™n c√≥ th·ªÉ s·ª≠ d·ª•ng nhi·ªÅu ph∆∞∆°ng ph√°p gi·∫£ng d·∫°y kh√°c nhau ƒë·ªÉ thu h√∫t sinh vi√™n h·ªçc t·∫≠p. neutral positive\n",
            "Th·∫ßy gi√∫p ƒë·ª° sinh vi√™n ƒë·ªãnh h∆∞·ªõng ngh·ªÅ nghi·ªáp v√† ph√°t tri·ªÉn b·∫£n th√¢n. positive neutral\n",
            "C√°c ph√≤ng h·ªçc ƒë∆∞·ª£c trang b·ªã ƒë·∫ßy ƒë·ªß v·∫≠t d·ª•ng v√† thi·∫øt b·ªã ƒë·ªÉ ƒë√°p ·ª©ng nhu c·∫ßu h·ªçc t·∫≠p. positive neutral\n",
            "C√¥ ·∫•y lu√¥n t·ªè ra th√¢n thi·ªán v√† t·∫°o ra kh√¥ng kh√≠ l√†m vi·ªác t·ªët trong nh√≥m. positive neutral\n",
            "T√¥i r·∫•t th√≠ch l·ªëi thi·∫øt k·∫ø v√† trang tr√≠ c·ªßa tr∆∞·ªùng, n√≥ c·ª±c k·ª≥ ·∫•n t∆∞·ª£ng v√† s√°ng t·∫°o. positive neutral\n",
            "L·ªõp h·ªçc ƒë∆∞·ª£c ƒë∆∞a ra m·ªôt c√°ch sinh ƒë·ªông, h·∫•p d·∫´n v√† ƒë·∫ßy ƒë·ªß ki·∫øn th·ª©c chuy√™n m√¥n. positive neutral\n",
            "Th·∫ßy cung c·∫•p cho ch√∫ng t√¥i nhi·ªÅu t√†i li·ªáu v√† b√†i gi·∫£ng h·ªØu √≠ch. neutral positive\n",
            "Em th·∫•y b·∫°n c·ªßa m√¨nh r·∫•t nhanh nh·∫πn v√† chƒÉm ch·ªâ h·ªçc. positive neutral\n",
            "Khu v·ª±c sinh ho·∫°t c·ªßa sinh vi√™n ƒë∆∞·ª£c qu·∫£n l√Ω t·ªët, an ninh. neutral positive\n",
            "C∆° h·ªôi ƒë·ªÉ th·ª±c t·∫≠p trong m·ªôt m√¥i tr∆∞·ªùng th·ª±c t·∫ø. neutral positive\n",
            "Ch∆∞∆°ng tr√¨nh h·ªçc r·∫•t th√∫ v·ªã v√† ƒëa d·∫°ng. neutral positive\n",
            "ƒê·ªôi ng≈© gi·∫£ng vi√™n chuy√™n nghi·ªáp v√† th√¢n thi·ªán. neutral positive\n",
            "Th·∫ßy gi·∫£ng d·∫°y r·∫•t chu ƒë√°o v√† chuy√™n nghi·ªáp. neutral positive\n",
            "Gi√°o vi√™n r·∫•t nhi·ªát t√¨nh v√† gi√∫p ƒë·ª° sinh vi√™n trong qu√° tr√¨nh h·ªçc t·∫≠p. positive neutral\n",
            "B·∫°n c·ªßa t√¥i l√† ng∆∞·ªùi r·∫•t duy√™n d√°ng v√† s√†nh ƒëi·ªáu. positive neutral\n",
            "M√¥n h·ªçc trong ch∆∞∆°ng tr√¨nh ƒë√†o t·∫°o ƒë∆∞·ª£c gi·∫£ng d·∫°y b·ªüi nh·ªØng gi√°o vi√™n gi·ªèi v√† c√≥ chuy√™n m√¥n cao. positive neutral\n",
            "Tr∆∞·ªùng cung c·∫•p nhi·ªÅu ƒëi·ªán tho·∫°i c√¥ng c·ªông t·∫°i khu√¥n vi√™n. negative neutral\n",
            "Anh ·∫•y l√† m·ªôt ng∆∞·ªùi h·ªçc t·∫≠p t√≠ch c·ª±c v√† ƒëam m√™ trong vi·ªác t√¨m hi·ªÉu ki·∫øn th·ª©c m·ªõi. positive neutral\n",
            "Th·∫ßy lu√¥n ƒë∆∞a ra nh·ªØng v√≠ d·ª• c·ª• th·ªÉ v√† minh ho·∫° ƒë·ªÉ gi√∫p sinh vi√™n hi·ªÉu b√†i t·∫≠p. neutral positive\n",
            "Anh ·∫•y lu√¥n c√≥ nh·ªØng √Ω t∆∞·ªüng kh√°c bi·ªát v·ªõi nh·ªØng ng∆∞·ªùi kh√°c trong nh√≥m. positive negative\n",
            "Th·∫ßy l√† m·ªôt gi·∫£ng vi√™n r·∫•t gi·ªèi trong vi·ªác truy·ªÅn ƒë·∫°t ki·∫øn th·ª©c v√† k·ªπ nƒÉng cho sinh vi√™n. positive neutral\n",
            "B·∫°n c·ªßa t√¥i r·∫•t chƒÉm ch·ªâ v√† lu√¥n ƒë√∫ng gi·ªù. positive neutral\n",
            "Nh·ªØng b√†i ki·ªÉm tra v√† ƒë√°nh gi√° ƒë·∫ßy th·ª≠ th√°ch trong ch∆∞∆°ng tr√¨nh ƒë√†o t·∫°o gi√∫p t√¥i tr·ªü n√™n chuy√™n nghi·ªáp h∆°n. neutral positive\n",
            "C√¥ ·∫•y r·∫•t nƒÉng ƒë·ªông v√† th√¢n thi·ªán ƒë·ªëi v·ªõi m·ªçi ng∆∞·ªùi trong l·ªõp. positive neutral\n",
            "Anh ·∫•y l√† m·ªôt ng∆∞·ªùi gi·ªèi v·ªÅ c√¥ng ngh·ªá v√† c√≥ kh·∫£ nƒÉng gi·∫£i quy·∫øt v·∫•n ƒë·ªÅ k·ªπ thu·∫≠t. positive neutral\n",
            "S·ªë l∆∞·ª£ng gi√°o vi√™n n∆∞·ªõc ngo√†i ƒë∆∞·ª£c gi·∫£ng d·∫°y trong ch∆∞∆°ng tr√¨nh ƒë√†o t·∫°o l√† r·∫•t √≠t. negative neutral\n",
            "Ch∆∞∆°ng tr√¨nh ƒë√†o t·∫°o gi√∫p t√¥i trang b·ªã nh·ªØng k·ªπ nƒÉng m·ªÅm c·∫ßn thi·∫øt ƒë·ªÉ th√†nh c√¥ng trong t∆∞∆°ng lai. positive neutral\n",
            "C√°c khu v·ª±c ti·∫øp kh√°ch c·ªßa tr∆∞·ªùng ƒë∆∞·ª£c b·ªë tr√≠ th√¥ng tho√°ng v√† chuy√™n nghi·ªáp. neutral positive\n",
            "C√¥ng ngh·ªá v√† trang thi·∫øt b·ªã c·ªßa ƒë·∫°i h·ªçc t·ªët h∆°n so v·ªõi nhi·ªÅu tr∆∞·ªùng kh√°c. positive neutral\n",
            "Gi·∫£ng vi√™n n√†y d·∫°y r·∫•t t·ªët v√† truy·ªÅn c·∫£m h·ª©ng cho h·ªçc sinh. neutral positive\n",
            "Gi·∫£ng vi√™n n√†y bi·∫øt c√°ch t·∫°o ra m·ªôt s·ª± c·∫ßn th√°m nh√¨n m·∫°nh m·∫Ω v√† ƒë√°ng ch√∫ √Ω trong b√†i gi·∫£ng c·ªßa m√¨nh. positive neutral\n",
            "Th·∫ßy t·∫°o ra m√¥i tr∆∞·ªùng h·ªçc t·∫≠p vui v·∫ª v√† ·∫•m c√∫ng. positive neutral\n",
            "Tr∆∞·ªùng lu√¥n gi·ªØ g√¨n s·∫°ch s·∫Ω v√† d·ªÖ d√†ng b·∫£o tr√¨ h∆°n nh·ªù v√†o c√°c thi·∫øt b·ªã trang tr√≠ v√† c∆° s·ªü v·∫≠t ch·∫•t. positive neutral\n",
            "ƒêi·ªÉm y·∫øu c·ªßa ch∆∞∆°ng tr√¨nh l√† thi·∫øu s·ª± khuy·∫øn kh√≠ch v√† h·ªó tr·ª£ cho sinh vi√™n t·ª± h·ªçc. negative neutral\n",
            "Th·∫ßy khuy·∫øn kh√≠ch sinh vi√™n nghi√™n c·ª©u v√† kh√°m ph√° nh·ªØng th·ª© m·ªõi trong lƒ©nh v·ª±c c·ªßa m√¨nh. neutral positive\n",
            "ƒê·ªôi ng≈© k·ªπ thu·∫≠t c·ªßa tr∆∞·ªùng lu√¥n c√≥ m·∫∑t ƒë·ªÉ gi√∫p ƒë·ª° v√† gi·∫£i quy·∫øt c√°c v·∫•n ƒë·ªÅ k·ªπ thu·∫≠t cho sinh vi√™n. positive neutral\n",
            "ƒê·ªôi ng≈© nh√¢n vi√™n c·ªßa tr∆∞·ªùng r·∫•t th√¢n thi·ªán v√† h·ªó tr·ª£ t·∫≠n t√¨nh. neutral positive\n",
            "Ch∆∞∆°ng tr√¨nh gi·∫£ng d·∫°y r·∫•t ph√π h·ª£p v·ªõi nhu c·∫ßu c·ªßa sinh vi√™n. neutral positive\n",
            "Th·∫ßy c√¥ ƒë·ªÅ cao c√°c tr·∫ª em tr√™n h·∫øt v√† mang ƒë·∫øn cho ch√∫ng ta m·ªôt m√¥i tr∆∞·ªùng h·ªçc t·∫≠p khuy·∫øn kh√≠ch v√† th√¢n thi·ªán. positive neutral\n",
            "Khu v·ª±c cho sinh vi√™n t·ª± h·ªçc kh√° tho·∫£i m√°i v√† ti·ªán nghi. neutral positive\n",
            "C√°c khu v·ª±c ƒë·∫∑t t·ªß h·ªì s∆° c·ªßa tr∆∞·ªùng ƒë∆∞·ª£c b·∫£o qu·∫£n an to√†n v√† ch√≠n chu. neutral positive\n",
            "T√¥i c·∫£m th·∫•y r·∫•t ·∫•m √°p v√† tho·∫£i m√°i khi s·ª≠ d·ª•ng ph√≤ng sinh ho·∫°t chung. positive neutral\n",
            "Gi·∫£ng vi√™n c·∫≠p nh·∫≠t th√¥ng tin nhanh ch√≥ng v√† c√≥ hi·ªÉu bi·∫øt s√¢u v·ªÅ th·ª±c t·∫ø c·ªßa ng√†nh h·ªçc. positive neutral\n",
            "B·∫°n c·ªßa t√¥i r·∫•t y√™u th√≠ch nh·ªØng tr·∫£i nghi·ªám m·ªõi. positive neutral\n",
            "Kh√¥ng gian n·ªôi th·∫•t c·ªßa ph√≤ng h·ªçc r·∫•t t·ªët, ƒë∆∞·ª£c thi·∫øt k·∫ø ƒë·ªÉ gi√∫p tƒÉng s·ª± t·∫≠p trung c·ªßa sinh vi√™n. positive neutral\n",
            "T√¥i c·∫£m th·∫•y r·∫•t c·∫£m k√≠ch v√¨ gi·∫£ng vi√™n c·ªßa m√¨nh lu√¥n s·∫µn s√†ng gi√∫p ƒë·ª° sinh vi√™n trong b·∫•t c·ª© l√∫c n√†o. positive neutral\n",
            "T√¥i r·∫•t h√†i l√≤ng v·ªõi c√°c ph√≤ng h·ªçc ·ªü ƒë√¢y. positive neutral\n",
            "Gi√∫p sinh vi√™n n·∫Øm b·∫Øt ƒë∆∞·ª£c nh·ªØng quy t·∫Øc v√† ƒë·∫°o ƒë·ª©c trong ng√†nh. neutral positive\n",
            "H·ªçc t·∫°i ƒë√¢y ƒë√≤i h·ªèi t√¥i t√≠nh k·ª∑ lu·∫≠t v√† s·ª± ƒë√≥ng g√≥p s√°ng t·∫°o. neutral positive\n",
            "T√¥i h√†i l√≤ng v·ªõi ch∆∞∆°ng tr√¨nh ƒë√†o t·∫°o v√¨ ƒë√£ gi√∫p t√¥i hi·ªÉu r√µ h∆°n v·ªÅ c√°c ph∆∞∆°ng th·ª©c h·ªçc t·∫≠p kh√°c nhau. neutral positive\n",
            "Th√¥ng tin tr∆∞·ªùng ƒë∆∞·ª£c ƒëƒÉng t·∫£i ƒë·∫ßy ƒë·ªß v√† chi ti·∫øt. neutral positive\n",
            "C√°c h·ªôi tr∆∞·ªùng ƒë·ªÅu r·ªông r√£i v√† ƒë∆∞·ª£c trang b·ªã nh·ªØng trang thi·∫øt b·ªã hi·ªán ƒë·∫°i. positive neutral\n",
            "Gi√°o tr√¨nh ƒë∆∞·ª£c c·∫≠p nh·∫≠t th∆∞·ªùng xuy√™n v√† ph√π h·ª£p v·ªõi ch∆∞∆°ng tr√¨nh h·ªçc c·ªßa tr∆∞·ªùng. neutral positive\n",
            "C√°c ph√≤ng th√≠ nghi·ªám c·ªßa tr∆∞·ªùng ƒë∆∞·ª£c trang b·ªã ƒë·∫ßy ƒë·ªß thi·∫øt b·ªã v√† c√¥ng ngh·ªá hi·ªán ƒë·∫°i. positive neutral\n",
            "T√¥i th·∫≠t s·ª± ƒë√°nh gi√° cao c∆° s·ªü v·∫≠t ch·∫•t c·ªßa tr∆∞·ªùng, n√≥ ƒë√°p ·ª©ng t·ªët nhu c·∫ßu h·ªçc t·∫≠p v√† gi·∫£i tr√≠ c·ªßa sinh vi√™n. positive neutral\n",
            "T√¥i c·∫£m th·∫•y h·ªçc ph√≠ h·ª£p l√≠ v·ªõi ch·∫•t l∆∞·ª£ng ƒë√†o t·∫°o c·ªßa tr∆∞·ªùng. neutral positive\n",
            "M√¥n h·ªçc t·∫≠p trung v√†o vi·ªác th·ª±c h√†nh v√† ·ª©ng d·ª•ng ki·∫øn th·ª©c v√†o th·ª±c t·∫ø. positive neutral\n",
            "C√°c khu v·ª±c l∆∞u tr√∫ c·ªßa tr∆∞·ªùng ƒë∆∞·ª£c trang b·ªã ƒë·∫ßy ƒë·ªß ti·ªán nghi ƒë·ªÉ ƒë·∫£m b·∫£o s·ª± tho·∫£i m√°i cho sinh vi√™n. positive neutral\n",
            "C√¥ ·∫•y lu√¥n ƒë·∫∑t m·ª•c ti√™u cao v√† c·ªë g·∫Øng ƒë·ªÉ ƒë·∫°t ƒë∆∞·ª£c ch√∫ng. positive neutral\n",
            "Tr∆∞·ªùng c√≥ nhi·ªÅu ch∆∞∆°ng tr√¨nh h·ªó tr·ª£ cho sinh vi√™n ƒë·∫°t th√†nh t√≠ch cao. neutral positive\n",
            "Th·∫ßy ƒë√£ gi√∫p t√¥i c√≥ ƒë∆∞·ª£c nhi·ªÅu ki·∫øn th·ª©c quan tr·ªçng v√† k·ªπ nƒÉng c·∫ßn thi·∫øt trong c√¥ng vi·ªác. positive neutral\n",
            "Th∆∞ vi·ªán c·ªßa tr∆∞·ªùng c√≥ c√°c ph√≤ng ƒë·ªçc s√°ch ri√™ng, gi√∫p t√¥i t·∫≠p trung h∆°n trong vi·ªác t√¨m ki·∫øm t√†i li·ªáu. neutral positive\n",
            "Th·∫ßy l√† m·ªôt gi·∫£ng vi√™n r·∫•t tr·∫ª tu·ªïi nh∆∞ng ƒë√£ c√≥ nhi·ªÅu kinh nghi·ªám gi·∫£ng d·∫°y. positive neutral\n",
            "C√°c gi·∫£ng vi√™n r·∫•t t·∫≠n t√¢m v√† nhi·ªát t√¨nh trong vi·ªác gi·∫£ng d·∫°y. neutral positive\n",
            "T√¥i th·∫•y ch∆∞∆°ng tr√¨nh h·ªçc c·ªßa tr∆∞·ªùng r·∫•t thu h√∫t v√† ƒëem l·∫°i nhi·ªÅu gi√° tr·ªã cho sinh vi√™n. positive neutral\n",
            "Gi·∫£ng vi√™n c·ªßa t√¥i n√≥i r·∫•t r√µ v√† d·ªÖ nghe, ƒëi·ªÅu n√†y gi√∫p t√¥i hi·ªÉu ƒë∆∞·ª£c m√¥n h·ªçc c·ªßa m√¨nh nhanh h∆°n. positive neutral\n",
            "C∆° s·ªü v·∫≠t ch·∫•t ƒë·∫ßy ƒë·ªß, ti√™n ti·∫øn. neutral positive\n",
            "Ph√≤ng t·∫≠p gym t·ªët v√† ƒë·∫ßy ƒë·ªß d·ª•ng c·ª•. neutral positive\n",
            "Gi·∫£ng vi√™n n√†y l√† m·ªôt ng∆∞·ªùi r·∫•t ki√™n nh·∫´n v√† quan t√¢m ƒë·∫øn s·ª± ti·∫øn b·ªô c·ªßa h·ªçc sinh. positive neutral\n",
            "Khu v·ª±c khu√¢n vi√™n quanh tr∆∞·ªùng xanh t∆∞∆°i, nh·ªØng tin t·ª©c, th√¥ng b√°o c·ªßa tr∆∞·ªùng ƒë∆∞·ª£c ph√°t tr·ª±c ti·∫øp, r√µ r√†ng, d·ªÖ ti·∫øp c·∫≠n. positive neutral\n",
            "B√†i gi·∫£ng r·∫•t r√µ r√†ng v√† d·ªÖ hi·ªÉu. neutral positive\n",
            "C√¥ b·∫°n n√†y r·∫•t hi·ªÅn l√†nh v√† t·ªët b·ª•ng. positive neutral\n",
            "C√≥ m·ªôt s·ªë m√¥n h·ªçc trong ch∆∞∆°ng tr√¨nh ƒë√†o t·∫°o kh√¥ng ph√π h·ª£p v·ªõi nhu c·∫ßu c·ªßa sinh vi√™n v√† th·ªã tr∆∞·ªùng lao ƒë·ªông negative neutral\n",
            "Ch∆∞∆°ng tr√¨nh ƒë√†o t·∫°o r·∫•t ƒëa d·∫°ng v√† ƒë·∫ßy ƒë·ªß, gi√∫p sinh vi√™n c√≥ th·ªÉ n·∫Øm b·∫Øt ƒë∆∞·ª£c nhi·ªÅu ki·∫øn th·ª©c kh√°c nhau. neutral positive\n",
            "Gi·ªù h·ªçc c·ªßa th·∫ßy r·∫•t hi·ªáu qu·∫£ v√† c·∫•u tr√∫c. neutral positive\n",
            "Nh·ªØng b√†i gi·∫£ng c·ªßa gi√°o vi√™n r·∫•t chi ti·∫øt v√† ƒë·∫ßy ƒë·ªß th√¥ng tin. neutral positive\n",
            "C√≥ nh·ªØng b·∫°n kh√° t√†n nh·∫´n v√† th∆∞·ªùng ƒë∆∞a ra c√°c √Ω ki·∫øn kh√¥ng c·∫ßn thi·∫øt trong l·ªõp h·ªçc. negative neutral\n",
            "Ch∆∞∆°ng tr√¨nh h·ªçc c·ªßa tr∆∞·ªùng ƒë·∫∑t nhi·ªÅu gi√° tr·ªã v√†o ƒë·∫°o ƒë·ª©c, tinh th·∫ßn v√† gi√° tr·ªã con ng∆∞·ªùi. positive neutral\n",
            "Gi·∫£ng vi√™n n√†y lu√¥n h∆∞·ªõng d·∫´n sinh vi√™n ƒë√∫ng h∆∞·ªõng v√† gi·∫£i ƒë√°p m·ªçi th·∫Øc m·∫Øc v·ªÅ ch·ªß ƒë·ªÅ. positive neutral\n",
            "Th·∫ßy lu√¥n c·∫≠p nh·∫≠t ki·∫øn th·ª©c m·ªõi nh·∫•t ƒë·ªÉ gi·∫£ng d·∫°y cho sinh vi√™n. positive neutral\n",
            "Gi·∫£ng vi√™n r·∫•t tinh t·∫ø khi ƒë∆∞a ra c√°c b√†i gi·∫£ng s√¢u s·∫Øc. neutral positive\n",
            "Ch∆∞∆°ng tr√¨nh gi·∫£ng d·∫°y k·∫øt h·ª£p gi·ªØa l√Ω thuy·∫øt v√† th·ª±c h√†nh t·ªët. neutral positive\n",
            "Th·∫ßy ƒë∆∞a ra nh·ªØng t√†i li·ªáu v√† th√≠ nghi·ªám th·ª±c t·∫ø ƒë·ªÉ gi√∫p h·ªçc sinh h·ªçc t·∫≠p t·ªët h∆°n. neutral positive\n",
            "Gi·∫£ng vi√™n n√†y quan t√¢m ƒë·∫øn s·ª± ti·∫øn b·ªô c·ªßa h·ªçc sinh v√† s·∫µn s√†ng gi·∫£i ƒë√°p m·ªçi th·∫Øc m·∫Øc c·ªßa h·ªç. positive neutral\n",
            "Gi·∫£ng vi√™n r·∫•t d·ªÖ ti·∫øp c·∫≠n v√† th√¢n thi·ªán, d·ªÖ t·∫°o ƒë∆∞·ª£c m√¥i tr∆∞·ªùng h·ªçc t·∫≠p t√≠ch c·ª±c. positive neutral\n",
            "Gi·∫£ng vi√™n r·∫•t th√¢n thi·ªán v√† d·ªÖ g·∫ßn v·ªõi sinh vi√™n. positive neutral\n",
            "Anh ta l√† ng∆∞·ªùi r·∫•t nƒÉng ƒë·ªông v√† lu√¥n t·∫°o ƒë·ªông l·ª±c cho ng∆∞·ªùi kh√°c. positive neutral\n",
            "Ch∆∞∆°ng tr√¨nh ƒë√†o t·∫°o cung c·∫•p cho t√¥i nh·ªØng ki·∫øn th·ª©c v√† kƒ© nƒÉng c·∫ßn thi·∫øt ƒë·ªÉ tr·ªü th√†nh m·ªôt c·ª±u sinh vi√™n th√†nh c√¥ng. neutral positive\n",
            "C√°c ho·∫°t ƒë·ªông ƒë·ªëi ngo·∫°i c·ªßa tr∆∞·ªùng ƒëa d·∫°ng v√† h·∫•p d·∫´n cho sinh vi√™n. neutral positive\n",
            "Gi·∫£ng ƒë∆∞·ªùng r·ªông r√£i v√† s·∫°ch s·∫Ω. neutral positive\n",
            "C√¥ gi√°o c·ªßa t√¥i l√† ng∆∞·ªùi r·∫•t th√¥ng th√°i v√† gi√†u kinh nghi·ªám. positive neutral\n",
            "Gi·∫£ng vi√™n c√≥ k·ªπ nƒÉng gi·∫£ng d·∫°y t·ªët, gi√∫p sinh vi√™n t·ª± tin v√† hi·ªÉu r√µ h∆°n v·ªÅ ch·ªß ƒë·ªÅ. positive neutral\n",
            "ƒê·∫°i h·ªçc t√¥i c√≥ nhi·ªÅu c√¥ng tr√¨nh ki·∫øn tr√∫c ƒë·∫πp v√† ·∫•n t∆∞·ª£ng. positive neutral\n",
            "C√°c khu v·ª±c ph·ª•c v·ª• sinh vi√™n ƒë∆∞·ª£c ph·ªß s√≥ng wifi gi√∫p cho sinh vi√™n c√≥ th·ªÉ ra ngo√†i ƒë·ªÉ h·ªçc t·∫≠p ho·∫∑c gi·∫£i tr√≠. neutral positive\n",
            "Gi·∫£ng vi√™n r·∫•t th√¥ng minh v√† c√≥ ki·∫øn th·ª©c s√¢u r·ªông. positive neutral\n",
            "T√¥i c·∫£m th·∫•y gi·∫£ng vi√™n n√†y lu√¥n ƒë·∫∑t s·ª± c·∫ßn thƒÉm d√≤ tr∆∞·ªõc khi ƒë∆∞a ra quy·∫øt ƒë·ªãnh trong b√†i gi·∫£ng. negative neutral\n",
            "Anh ·∫•y lu√¥n ƒë·∫∑t c√°c m·ª•c ti√™u v√† ho√†n th√†nh ch√∫ng m·ªôt c√°ch t·ªët ƒë·∫πp. positive neutral\n",
            "Anh ·∫•y l√† m·ªôt ng∆∞·ªùi r·∫•t ƒë√°ng tin c·∫≠y, lu√¥n lu√¥n gi·ªØ l·ªùi h·ª©a. positive neutral\n",
            "M√¥n h·ªçc c√≥ s·ª©c h·∫•p d·∫´n cao, t·∫°o ƒë·ªông l·ª±c cho sinh vi√™n h·ªçc t·∫≠p. positive neutral\n",
            "Th·∫ßy d·∫°y r·∫•t th√¥ng minh v√† t·∫≠p trung v√†o vi·ªác gi·∫£ng d·∫°y cho h·ªçc sinh hi·ªÉu b√†i h·ªçc. neutral positive\n",
            "Gi√°o vi√™n c·ªßa t√¥i h∆∞·ªõng d·∫´n sinh vi√™n th·ª±c hi·ªán c√°c nghi√™n c·ª©u th·ªã tr∆∞·ªùng v√† ƒë√°nh gi√° s·∫£n ph·∫©m. neutral positive\n",
            "Th∆∞ vi·ªán tr∆∞·ªùng c√≥ nhi·ªÅu ch·ªß ƒë·ªÅ kh√°c nhau gi√∫p sinh vi√™n t√¨m ƒë∆∞·ª£c ngu·ªìn t√†i li·ªáu ph√π h·ª£p v·ªõi nhu c·∫ßu h·ªçc t·∫≠p c·ªßa m√¨nh. neutral positive\n",
            "T√¥i r·∫•t h√†i l√≤ng v·ªõi c√°c d·ªãch v·ª• h·ªó tr·ª£ c·ªßa tr∆∞·ªùng, ƒë·∫∑c bi·ªát l√† c√°c d·ªãch v·ª• t∆∞ v·∫•n v√† t√†i ch√≠nh. positive neutral\n",
            "Anh ta c√≥ t√≠nh c√°ch ƒëi·ªÅm ƒë·∫°m v√† kh√¥ng bao gi·ªù ho·∫£ng lo·∫°n. neutral positive\n",
            "C√°c ho·∫°t ƒë·ªông ngo·∫°i kh√≥a c·ªßa tr∆∞·ªùng ƒëa d·∫°ng v√† h·∫•p d·∫´n cho ng∆∞·ªùi tham gia. neutral positive\n",
            "Th·∫ßy l√† ng∆∞·ªùi gi·∫£ng d·∫°y gi·ªèi nh·∫•t m√† t√¥i t·ª´ng g·∫∑p. positive neutral\n",
            "Tr∆∞·ªùng cung c·∫•p ƒë·∫ßy ƒë·ªß c√°c th√¥ng tin v√† t√†i li·ªáu cho sinh vi√™n ƒë·ªÉ gi√∫p t√¥i h·ªçc t·∫≠p m·ªôt c√°ch hi·ªáu qu·∫£. neutral positive\n",
            "Tr∆∞·ªùng c√≥ cung c·∫•p wifi mi·ªÖn ph√≠ cho sinh vi√™n, gi√∫p c√°c em ti·ªán l·ª£i h∆°n trong vi·ªác truy c·∫≠p internet. positive neutral\n",
            "C√¥ ·∫•y c√≥ kh·∫£ nƒÉng n·∫Øm b·∫Øt ƒë∆∞·ª£c √Ω t∆∞·ªüng m·ªõi v√† th√∫c ƒë·∫©y c√°c ho·∫°t ƒë·ªông t·∫°o √Ω t∆∞·ªüng s√°ng t·∫°o. positive neutral\n",
            "C√≥ r·∫•t nhi·ªÅu c∆° h·ªôi ƒë·ªÉ b·∫°n ph√°t tri·ªÉn nƒÉng l·ª±c kh√¥ng ch·ªâ trong l·ªõp h·ªçc m√† c√≤n ngo√†i ƒë·ªùi th·ª±c. positive neutral\n",
            "Khu v·ª±c ng·ªìi ch·ªù ƒë·ª£i ƒë∆∞·ª£c trang b·ªã ƒë·∫ßy ƒë·ªß gh·∫ø v√† trang thi·∫øt b·ªã gi√∫p sinh vi√™n ch·ªù ƒë·ª£i m·ªôt c√°ch tho·∫£i m√°i. positive neutral\n",
            "Gi·∫£ng vi√™n d·∫°y r·∫•t c√≥ t√¢m, t·∫≠n t√¨nh gi√∫p ƒë·ª° sinh vi√™n khi c·∫ßn. positive neutral\n",
            "C√¥ b·∫°n n√†y l√† m·ªôt gi·∫£ng vi√™n tuy·ªát v·ªùi, lu√¥n h·ªó tr·ª£ v√† gi√∫p ƒë·ª° sinh vi√™n. positive neutral\n",
            "T√¥i r·∫•t th√≠ch c√°ch m√† ch∆∞∆°ng tr√¨nh ƒë√†o t·∫°o ƒë∆∞·ª£c t·ªï ch·ª©c v√† qu·∫£n l√Ω. positive neutral\n",
            "Ch∆∞∆°ng tr√¨nh ti√™n ti·∫øn ch∆∞a ƒë∆∞·ª£c tri·ªÉn khai r·ªông r√£i cho sinh vi√™n. negative neutral\n",
            "H·ªá th·ªëng wifi mi·ªÖn ph√≠ s·ª≠ d·ª•ng thu·∫≠n ti·ªán. positive neutral\n",
            "C√¥ ·∫•y l√† m·ªôt ng∆∞·ªùi r·∫•t gi·ªèi trong vi·ªác gi·∫£ng d·∫°y v√† r·∫•t nhi·ªát t√¨nh. positive neutral\n",
            "Anh ·∫•y l√† m·ªôt ng∆∞·ªùi c√≥ kh·∫£ nƒÉng truy·ªÅn c·∫£m h·ª©ng v√† ƒë·ªông vi√™n ng∆∞·ªùi kh√°c. positive neutral\n",
            "K√Ω t√∫c x√° c·ªßa tr∆∞·ªùng r·∫•t ti·ªán nghi v√† s·∫°ch s·∫Ω. positive neutral\n",
            "C√¥ n√†y l√† ng∆∞·ªùi r·∫•t chuy√™n nghi·ªáp v√† c√≥ kinh nghi·ªám gi·∫£ng d·∫°y l√¢u nƒÉm. positive neutral\n",
            "N∆°i ƒë√¢y c√≥ nhi·ªÅu ph√≤ng th√≠ nghi·ªám v√† trang thi·∫øt b·ªã c·∫ßn thi·∫øt ƒë·ªÉ h·ªó tr·ª£ h·ªçc vi√™n. positive neutral\n",
            "Ch∆∞∆°ng tr√¨nh h·ªçc t·∫≠p ƒë√°p ·ª©ng ƒë∆∞·ª£c nh·ªØng y√™u c·∫ßu c·ªßa ngh·ªÅ nghi·ªáp. neutral positive\n",
            "Sinh vi√™n ƒë∆∞·ª£c h·ªó tr·ª£ t√¨m ki·∫øm vi·ªác l√†m sau khi t·ªët nghi·ªáp. neutral positive\n",
            "C√≥ nhi·ªÅu v·∫•n ƒë·ªÅ v·ªÅ thi·∫øt b·ªã v√† h·ªá th·ªëng m·∫°ng trong c√°c ph√≤ng h·ªçc. negative neutral\n",
            "B·∫°n c·ªßa t√¥i l√† ng∆∞·ªùi r·∫•t nƒÉng ƒë·ªông v√† lu√¥n c√≥ nh·ªØng √Ω t∆∞·ªüng m·ªõi l·∫°. positive neutral\n",
            "Tr∆∞·ªùng ƒë·∫°i h·ªçc n√†y l√† n∆°i l√Ω t∆∞·ªüng ƒë·ªÉ giao l∆∞u v√† k·∫øt n·ªëi v·ªõi nh·ªØng ng∆∞·ªùi b·∫°n m·ªõi. positive neutral\n",
            "Tr∆∞·ªùng h·ªó tr·ª£ sinh vi√™n ƒëƒÉng k√Ω tham gia c√°c k·ª≥ thi ch·ª©ng ch·ªâ v√† ƒë√†o t·∫°o kh√°c. neutral positive\n",
            "C∆° s·ªü v·∫≠t ch·∫•t t·∫°i ƒë·∫°i h·ªçc n√†y ƒë√°p ·ª©ng t·ªët nhu c·∫ßu h·ªçc t·∫≠p c·ªßa sinh vi√™n. neutral positive\n",
            "M√¥n h·ªçc kh√¥ng ph√π h·ª£p v·ªõi chuy√™n ng√†nh c·ª• th·ªÉ v√† ƒë·ªô kh√≥ qu√° cao. negative neutral\n",
            "ƒê·ªìng nghi·ªáp c·ªßa t√¥i r·∫•t h·ªó tr·ª£ v√† ƒë·ªìng c·∫£m. neutral positive\n",
            "Anh ·∫•y c√≥ tr√≠ th√¥ng minh s√°ng su·ªët v√† s·ª± nghi·ªáp c·ªßa anh ·∫•y tuy·ªát v·ªùi. positive neutral\n",
            "Kh·∫£ nƒÉng c·∫£i thi·ªán k·ªπ nƒÉng d·ª± √°n v√† k·ªπ nƒÉng gi·∫£i quy·∫øt v·∫•n ƒë·ªÅ. positive neutral\n",
            "S·ª± ƒëa d·∫°ng c·ªßa ch∆∞∆°ng tr√¨nh ƒë√†o t·∫°o gi√∫p tƒÉng t√≠nh linh ho·∫°t cho sinh vi√™n. neutral positive\n",
            "Th·∫ßy c√≥ kh·∫£ nƒÉng d·∫°y h·ªçc ƒëa d·∫°ng ƒë·ªÉ ph√π h·ª£p v·ªõi c√°c h·ªçc sinh c√≥ n·ªÅn t·∫£ng k√©m. neutral positive\n",
            "Th·∫ßy th∆∞·ªùng t·∫°o ra c√°c ho·∫°t ƒë·ªông nh√≥m ƒë·ªÉ tƒÉng c∆∞·ªùng t∆∞∆°ng t√°c gi·ªØa h·ªçc vi√™n v√† h·ªçc vi√™n. neutral positive\n",
            "Th·∫ßy c√≥ ph·∫ßn n√†o gi·ªëng nh∆∞ ng∆∞·ªùi b·∫°n ƒë·ªìng h√†nh trong h√†nh tr√¨nh h·ªçc t·∫≠p c·ªßa sinh vi√™n. positive neutral\n",
            "Anh ·∫•y l√† m·ªôt ng∆∞·ªùi r·∫•t t·∫≠n t√¢m v·ªõi c√¥ng vi·ªác v√† gia ƒë√¨nh. neutral positive\n",
            "Gi·∫£ng vi√™n r·∫•t th√¥ng minh v√† am hi·ªÉu chuy√™n ng√†nh. positive neutral\n",
            "C√°c ph√≤ng h·ªçc v√† ph√≤ng th√≠ nghi·ªám trong tr∆∞·ªùng ƒë∆∞·ª£c trang b·ªã ƒë·∫ßy ƒë·ªß thi·∫øt b·ªã ƒë·ªÉ ƒë·∫£m b·∫£o ch·∫•t l∆∞·ª£ng h·ªçc t·∫≠p. positive neutral\n",
            "Th·∫ßy c√¥ gi·∫£ng d·∫°y ƒë·ªÅu r·∫•t h√≤a nh√£ v√† th√¢n thi·ªán, gi√∫p t√¥i c·∫£m th·∫•y tho·∫£i m√°i h∆°n trong l·ªõp h·ªçc. neutral positive\n",
            "Gi·∫£ng vi√™n n√†y th∆∞·ªùng ƒë·ªìng √Ω v·ªõi √Ω ki·∫øn c·ªßa nh·ªØng sinh vi√™n gi√†u kinh nghi·ªám. neutral negative\n",
            "C√°c d·ªãch v·ª• th∆∞ vi·ªán c·ªßa tr∆∞·ªùng r·∫•t t·ªët v√† ƒë∆∞·ª£c c·∫≠p nh·∫≠t th∆∞·ªùng xuy√™n. positive neutral\n",
            "Gi·∫£ng vi√™n r·∫•t trung th√†nh v·ªõi vai tr√≤ c·ªßa m√¨nh v√† gi·∫£ng d·∫°y r·∫•t ch√≠nh x√°c. neutral positive\n",
            "H·ªçc ph√≠ r·∫•t h·ª£p l√Ω v√† ph√π h·ª£p v·ªõi nhu c·∫ßu c·ªßa sinh vi√™n. neutral positive\n",
            "T√¥i c·∫£m th·∫•y gi·∫£ng vi√™n c·ªßa m√¨nh kh√¥ng th·ª±c s·ª± nhi·ªát t√¨nh v√† h√†o h·ª©ng trong qu√° tr√¨nh gi·∫£ng d·∫°y. negative neutral\n",
            "Gi·∫£ng vi√™n n√†y lu√¥n ƒë∆∞a ra c√°c v√≠ d·ª• kh√≥ nh·∫±n ƒë·ªÉ h·ªçc sinh hi·ªÉu. neutral negative\n",
            "Gi·∫£ng vi√™n d·∫°y r·∫•t ch·∫•t l∆∞·ª£ng v√† hi·ªáu qu·∫£. neutral positive\n",
            "H·ªó tr·ª£ sinh vi√™n ngay t·ª´ giai ƒëo·∫°n ƒë·∫ßu v√†o. neutral positive\n",
            "Ch∆∞∆°ng tr√¨nh ƒë√†o t·∫°o r·∫•t chuy√™n nghi·ªáp. neutral positive\n",
            "Sau khi t·ªët nghi·ªáp, sinh vi√™n c√≥ th·ªÉ c√≥ nhi·ªÅu c∆° h·ªôi vi·ªác l√†m t·ªët trong lƒ©nh v·ª±c c·ªßa m√¨nh. neutral positive\n",
            "T√¥i mong ƒë·ª£i gi·∫£ng vi√™n s·∫Ω s·ª≠a ngay l·∫≠p t·ª©c nh·ªØng sai s√≥t trong b√†i gi·∫£ng ƒë·ªÉ tr√°nh nh·∫ßm l·∫´n. negative neutral\n",
            "Th·∫ßy l√† m·ªôt ng∆∞·ªùi d·∫°y r·∫•t nhi·ªát t√¨nh v√† s√°ng t·∫°o. neutral positive\n",
            "Kh√¥ng gi·ªõi h·∫°n v·ªÅ th·ªùi gian h·ªçc t·∫≠p. neutral positive\n",
            "C√°c ph√≤ng h·ªçc ƒë∆∞·ª£c c·∫£i t·∫°o ƒë·ªãnh k·ª≥ ƒë·ªÉ ƒë√°p ·ª©ng nhu c·∫ßu h·ªçc t·∫≠p c·ªßa sinh vi√™n. neutral positive\n",
            "T√¥i c·∫£m th·∫•y ki·∫øn th·ª©c ƒë∆∞·ª£c truy·ªÅn ƒë·∫°t s√¢u s·∫Øc v√† c√≥ t√≠nh ·ª©ng d·ª•ng cao. positive neutral\n",
            "B·∫°n c·ªßa t√¥i r·∫•t t·ªâ m·ªâ v√† l∆∞u √Ω ƒë·∫øn chi ti·∫øt. positive neutral\n",
            "Ch∆∞∆°ng tr√¨nh h·ªçc ph√π h·ª£p v·ªõi y√™u c·∫ßu c·ªßa th·ªã tr∆∞·ªùng v√† ƒë√°p ·ª©ng ƒë∆∞·ª£c nhu c·∫ßu c·ªßa h·ªçc vi√™n. neutral positive\n",
            "Khu√¥n vi√™n tr∆∞·ªùng r·ªông l·ªõn v√† ƒë∆∞·ª£c b·ªë tr√≠ h·ª£p l√≠. neutral positive\n",
            "Tr∆∞·ªùng c√≥ c√°c ch∆∞∆°ng tr√¨nh h·ªçc b·ªïng v√† t√†i tr·ª£ gi√∫p ƒë·ª° nh·ªØng sinh vi√™n c√≥ th√†nh t√≠ch h·ªçc t·∫≠p cao. positive neutral\n",
            "C√°c cƒÉn tin ·ªü ƒë√¢y r·∫•t ngon v√† gi√° c·∫£ ph·∫£i chƒÉng. positive neutral\n",
            "H·ªçc ph√≠ ƒë∆∞·ª£c chia theo c√°c k·ª≥ h·ªçc, gi√∫p sinh vi√™n d·ªÖ d√†ng to√†n t√¢m to√†n √Ω v·ªõi t·ª´ng k·ª≥ h·ªçc. neutral positive\n",
            "T√¥i c·∫£m th·∫•y ch∆∞∆°ng tr√¨nh h·ªçc kh√¥ng th·ª±c s·ª± ƒë√°p ·ª©ng ƒë∆∞·ª£c nhu c·∫ßu ng√†nh ngh·ªÅ hi·ªán t·∫°i. neutral negative\n",
            "H·ªçc ph√≠ ƒë∆∞·ª£c gi·∫£m gi√° cho nh·ªØng sinh vi√™n ƒëƒÉng k√Ω s·ªõm. neutral positive\n",
            "Gi·∫£ng vi√™n n√†y qu√° ƒë√≤i h·ªèi cao v·ªÅ ƒëi·ªÉm s·ªë v√† ƒë√¥i khi l√†m kh√≥ h·ªçc sinh. negative neutral\n",
            "T√¥i r·∫•t y√™u th√≠ch kh√¥ng gian c·ªßa th∆∞ vi·ªán v√† c√°c d·ªãch v·ª• b·ªï tr·ª£ t·∫°i ƒë√¢y. positive neutral\n",
            "Th·∫ßy r·∫•t trung th·ª±c v√† ch√≠nh tr·ª±c trong gi·∫£ng d·∫°y. neutral positive\n",
            "Ch∆∞∆°ng tr√¨nh h·ªçc r·∫•t linh ho·∫°t v√† c√≥ th·ªÉ ph√π h·ª£p v·ªõi nhu c·∫ßu c·ªßa t·ª´ng sinh vi√™n. neutral positive\n",
            "Gi·∫£ng vi√™n n√†y kh√¥ng gi√∫p ƒë∆∞·ª£c h·ªçc sinh ƒë·∫°t ƒë∆∞·ª£c nh·ªØng m·ª•c ti√™u c·ªßa h·ªç. negative neutral\n",
            "K√Ω t√∫c x√° c·ªßa tr∆∞·ªùng c√≥ c√°c d·ªãch v·ª• ti·ªán √≠ch nh∆∞ t·∫≠p gym v√† qu·∫ßy c√† ph√™. neutral positive\n",
            "Tr∆∞·ªùng ƒë·∫∑t nhi·ªÅu ∆∞u ti√™n cho s·ª± ph√°t tri·ªÉn to√†n di·ªán c·ªßa sinh vi√™n. positive neutral\n",
            "C√°c gi·∫£ng vi√™n c·ªßa tr∆∞·ªùng r·∫•t c√≥ kinh nghi·ªám v√† gi·ªèi chuy√™n m√¥n. neutral positive\n",
            "ƒê·ªôi ng≈© nh√¢n vi√™n ·ªü ƒë√¢y lu√¥n h·ªó tr·ª£ v√† ƒë√°p ·ª©ng m·ªçi nhu c·∫ßu c·ªßa sinh vi√™n. positive neutral\n",
            "T√¥i ƒë√£ ƒë∆∞·ª£c trang b·ªã ƒë·∫ßy ƒë·ªß c√°c t√†i li·ªáu th∆∞ vi·ªán c·∫ßn thi·∫øt ƒë·ªÉ h·ªçc t·∫≠p v√† l√†m b√†i t·∫≠p. positive neutral\n",
            "Ph√≤ng th√≠ nghi·ªám ·ªü tr∆∞·ªùng ƒë∆∞·ª£c trang b·ªã ƒë·∫ßy ƒë·ªß thi·∫øt b·ªã v√† m√°y m√≥c. positive neutral\n",
            "Gi·∫£ng vi√™n n√†y bi·∫øt c√°ch t·∫°o ra m·ªôt s·ª± t∆∞∆°ng t√°c t√≠ch c·ª±c l√†m cho b√†i gi·∫£ng c·ªßa m√¨nh tr·ªü n√™n ƒë·∫ßy h·ª©ng th√∫. positive neutral\n",
            "ƒê·ªôi ng≈© gi√°o vi√™n c√≥ nhi·ªÅu tri th·ª©c v√† kinh nghi·ªám gi√∫p sinh vi√™n n·∫Øm v·ªØng ki·∫øn th·ª©c chuy√™n m√¥n. neutral positive\n",
            "C√°c ph√≤ng h·ªçc ƒë∆∞·ª£c ƒë√°nh gi√° l√† kh√¥ng gian r·ªông r√£i v√† tho·∫£i m√°i. neutral positive\n",
            "Tr∆∞·ªùng ƒë·∫°i h·ªçc n√†y lu√¥n gi·ªØ v·ªá sinh v√† s·ª≠a ch·ªØa t·ªët h·ªá th·ªëng c∆° s·ªü v·∫≠t ch·∫•t. positive neutral\n",
            "Nh·ªØng ki·∫øn th·ª©c t√¥i h·ªçc ƒë∆∞·ª£c trong ch∆∞∆°ng tr√¨nh h·ªçc r·∫•t b·ªï √≠ch cho c√¥ng vi·ªác c·ªßa t√¥i sau n√†y. positive neutral\n",
            "Th·∫ßy c√¥ lu√¥n g·∫ßn g≈©i v√† d·ªÖ ti·∫øp c·∫≠n v·ªõi c√°c sinh vi√™n. positive neutral\n",
            "B·∫°n c·ªßa t√¥i r·∫•t c·ªüi m·ªü v√† d·ªÖ th∆∞∆°ng v·ªõi m·ªçi ng∆∞·ªùi. positive neutral\n",
            "C√°c ho·∫°t ƒë·ªông gi√°o d·ª•c kh√° ƒëa d·∫°ng v√† phong ph√∫. neutral positive\n",
            "C√°c b√†i ki·ªÉm tra ƒë∆∞·ª£c thi·∫øt k·∫ø t·ªët v√† c√¥ng b·∫±ng. neutral positive\n",
            "Th·∫ßy lu√¥n d·∫°y sinh vi√™n c√°ch t∆∞ duy v√† ph√°t tri·ªÉn k·ªπ nƒÉng. positive neutral\n",
            "C∆° s·ªü v·∫≠t ch·∫•t t·ªët v√† ƒë∆∞·ª£c c·∫≠p nh·∫≠t li√™n t·ª•c. neutral positive\n",
            "T·∫•t c·∫£ sinh vi√™n ƒë∆∞·ª£c ƒë√≥n ti·∫øp v·ªõi c√°ch th·ª©c tr·ªã nh·∫π nh√†ng v√† d·ªÖ d√†ng. positive neutral\n",
            "C√°c c∆° s·ªü v·∫≠t ch·∫•t trong tr∆∞·ªùng r·∫•t phong ph√∫ v√† ƒë√°p ·ª©ng t·ªët nhu c·∫ßu sinh vi√™n. positive neutral\n",
            "Gi·∫£ng vi√™n n√†y ƒë√¥i l√∫c qu√™n chuy·ªán ch√≠nh ƒë·ªÉ gi·∫£i th√≠ch nh·ªØng chi ti·∫øt kh√¥ng quan tr·ªçng. negative neutral\n",
            "L·ªõp h·ªçc ƒë∆∞·ª£c t·ªï ch·ª©c khoa h·ªçc, h·ªó tr·ª£ sinh vi√™n kh√¥ng ch·ªâ gi√∫p h·ªçc m√† c√≤n gi√∫p sinh vi√™n r√®n luy·ªán k·ªπ nƒÉng qu·∫£n l√Ω th·ªùi gian. positive neutral\n",
            "Gi·∫£ng vi√™n r·∫•t th√¢n thi·ªán v√† c√≥ t∆∞ duy ph·∫£n bi·ªán cao. neutral positive\n",
            "Tr∆∞·ªùng ƒë∆∞·ª£c trang b·ªã ƒë·∫ßy ƒë·ªß thi·∫øt b·ªã th√¥ng tin li√™n l·∫°c gi·ªØa sinh vi√™n v√† gi·∫£ng vi√™n. positive neutral\n",
            "C√°c gi·∫£ng vi√™n ƒë·ªÅu r·∫•t am hi·ªÉu trong lƒ©nh v·ª±c c·ªßa m√¨nh. neutral positive\n",
            "Ng∆∞·ªùi n√†y l√† ng∆∞·ªùi r·∫•t nƒÉng ƒë·ªông v√† lu√¥n t√¨m c√°ch t·∫°o s·ª± kh√°c bi·ªát. positive neutral\n",
            "Gi√°o tr√¨nh r·∫•t th√∫ v·ªã v√† ƒë·ªôc ƒë√°o, gi√∫p t√¥i h·ªçc ƒë∆∞·ª£c nhi·ªÅu th·ª© m·ªõi l·∫°. positive neutral\n",
            "Khu√¥n vi√™n ƒë·∫•t n·ªÅn r·ªông r√£i v√† kh√° y√™n tƒ©nh. neutral positive\n",
            "Th·∫ßy gi√∫p ch√∫ng t√¥i hi·ªÉu r√µ h∆°n v·ªÅ t·∫ßm quan tr·ªçng c·ªßa vi·ªác h·ªçc t·∫≠p. neutral positive\n",
            "Gi√°o vi√™n r·∫•t nhi·ªát t√¨nh v√† c√≥ tr√°ch nhi·ªám trong qu√° tr√¨nh gi·∫£ng d·∫°y. positive neutral\n",
            "Th·∫ßy d·∫°y r·∫•t c·∫©n th·∫≠n v√† t·ªâ m·ªâ, lu√¥n ch√∫ √Ω t·ª´ng chi ti·∫øt. positive neutral\n",
            "Th·∫ßy truy·ªÅn c·∫£m h·ª©ng v√† ƒë·ªông vi√™n c√°c sinh vi√™n c√≥ ho√†n c·∫£nh kh√≥ khƒÉn. positive neutral\n",
            "C√¥ ·∫•y r·∫•t tho·∫£i m√°i v√† t·ª± tin trong giao ti·∫øp ƒëa d·∫°ng v·ªõi ng∆∞·ªùi kh√°c gi·ªõi. positive neutral\n",
            "T√¥i r·∫•t th√≠ch c√°ch m√† tr∆∞·ªùng ƒë∆∞a c√°c l·ªõp h·ªçc v√† nghi√™n c·ª©u ra kh·ªèi l·ªõp h·ªçc. neutral positive\n",
            "H·ªá th·ªëng gi√°o tr√¨nh h·ªó tr·ª£ c√°c sinh vi√™n c√≥ th·ªÉ ti·∫øp c·∫≠n v√† t√¨m hi·ªÉu v·ªÅ ng√†nh ngh·ªÅ c·ªßa m√¨nh m·ªôt c√°ch hi·ªáu qu·∫£. positive neutral\n",
            "Anh ·∫•y c√≥ tinh th·∫ßn l·∫°c quan v√† lu√¥n gi·ªØ v·ªØng ni·ªÅm tin v√†o b·∫£n th√¢n. positive neutral\n",
            "S·ª± ƒëa d·∫°ng v·ªÅ c√°c m√¥n h·ªçc gi√∫p m√¨nh l·ª±a ch·ªçn v√† c·∫≠p nh·∫≠t ki·∫øn th·ª©c m·ªõi. neutral positive\n",
            "Gi·∫£ng vi√™n n√†y ƒë∆∞a ra c√°c v√≠ d·ª• r·∫•t th·ª±c t·∫ø v√† h·ªØu √≠ch ƒë·ªÉ gi√∫p t√¥i hi·ªÉu b√†i h·ªçc. neutral positive\n",
            "Gi·∫£ng vi√™n n√†y r·∫•t th√≠ch h·ª£p trong vi·ªác gi·∫£ng d·∫°y cho h·ªçc sinh ƒëam m√™ chuy√™n m√¥n n√†y. positive neutral\n",
            "The dorms offer basic amenities for living on campus. negative neutral\n",
            "Gi·∫£ng vi√™n r·∫•t th√¢n thi·ªán v√† t·∫°o kh√¥ng kh√≠ h·ªçc t·∫≠p t√≠ch c·ª±c cho sinh vi√™n. positive neutral\n",
            "Gi√°o vi√™n lu√¥n gi·∫£i ƒë√°p th·∫Øc m·∫Øc c·ªßa sinh vi√™n r√µ r√†ng v√† chi ti·∫øt. positive neutral\n",
            "C√¥ ·∫•y c√≥ t√†i giao ti·∫øp t·ªët v√† th√¢n thi·ªán v·ªõi nh·ªØng ng∆∞·ªùi xung quanh. positive neutral\n",
            "T√¥i r·∫•t h√†i l√≤ng v·ªõi ch∆∞∆°ng tr√¨nh h·ªçc n∆°i ƒë√¢y. positive neutral\n",
            "T√¥i th·∫•y h·ªçc t·∫≠p t·∫°i ƒë√¢y c·ª±c k√¨ h·ªØu √≠ch cho t∆∞∆°ng lai. neutral positive\n",
            "B·∫°n c·ªßa em l√† ng∆∞·ªùi r·∫•t c√° t√≠nh v√† kh√¥ng s·ª£ th·ªÉ hi·ªán b·∫£n th√¢n. positive neutral\n",
            "C√¥ ·∫•y c√≥ phong c√°ch d·∫°y h·ªçc v√¥ c√πng s√°ng t·∫°o v√† th√∫ v·ªã. positive neutral\n",
            "Anh ta lu√¥n c√≥ tinh th·∫ßn h·ªçc h·ªèi v√† m·ªü ƒë·∫ßu v·ªõi nh·ªØng ki·∫øn th·ª©c m·ªõi. positive neutral\n",
            "C√°c bu·ªïi h·ªçc ƒë∆∞·ª£c t·ªï ch·ª©c ch·∫∑t ch·∫Ω v√† c√≥ s·ª± chu·∫©n b·ªã k·ªπ l∆∞·ª°ng. neutral positive\n",
            "Gi·∫£ng vi√™n r·∫•t l·∫°c quan v√† ƒë√°ng k√≠nh. neutral positive\n",
            "T√¥i r·∫•t th√≠ch khu√¥n vi√™n ƒë·∫πp c·ªßa tr∆∞·ªùng. neutral positive\n",
            "Gi·∫£ng vi√™n d·∫°y r·∫•t hay v√† d·ªÖ hi·ªÉu. neutral positive\n",
            "T√¥i kh√¥ng th·ªÉ t∆∞·ªüng t∆∞·ª£ng ƒë∆∞·ª£c m√¥i tr∆∞·ªùng h·ªçc t·∫≠p s·∫Ω nh∆∞ th·∫ø n·∫øu kh√¥ng c√≥ th·∫ßy/c√¥. negative positive\n",
            "Anh ·∫•y r·∫•t ti·∫øp thu ƒë∆∞·ª£c nh·ªØng ki·∫øn th·ª©c m·ªõi m·ªôt c√°ch nhanh ch√≥ng. positive neutral\n",
            "Gi·∫£ng vi√™n kh√¥ng th∆∞·ªùng xuy√™n li√™n h·ªá v·ªõi sinh vi√™n sau khi h·ªç k·∫øt th√∫c m√¥n h·ªçc. negative neutral\n",
            "C√≥ r·∫•t nhi·ªÅu b·∫°n h·ªçc t·ªët v√† t√≠ch c·ª±c tham gia v√†o c√°c ho·∫°t ƒë·ªông c·ªßa tr∆∞·ªùng. positive neutral\n",
            "Anh ta l√† m·ªôt gi·∫£ng vi√™n r·∫•t t·∫≠n t√¢m v√† s√°ng t·∫°o. neutral positive\n",
            "Ph√≤ng gi√°o vi√™n ƒë·ªß ti·ªán nghi, tho·∫£i m√°i. neutral positive\n",
            "Ch∆∞∆°ng tr√¨nh h·ªçc c·ªßa tr∆∞·ªùng gi√∫p t√¥i c√≥ c∆° h·ªôi h·ªçc t·∫≠p v√† nghi√™n c·ª©u v·ªõi nh·ªØng gi·∫£ng vi√™n h√†ng ƒë·∫ßu trong ng√†nh c·ªßa m√¨nh. positive neutral\n",
            "C·∫≠u b·∫°n n√†y r·∫•t th√¢n thi·ªán v√† h√≤a ƒë·ªìng. neutral positive\n",
            "Gi·∫£ng vi√™n r·∫•t ƒë√°ng k√≠nh v√† ƒë∆∞·ª£c sinh vi√™n y√™u m·∫øn ƒë·∫∑c bi·ªát. positive neutral\n",
            "Th·∫ßy r·∫•t nƒÉng ƒë·ªông, gi√∫p sinh vi√™n t·∫≠p trung v√†o h·ªçc t·∫≠p m·ªôt c√°ch hi·ªáu qu·∫£. positive neutral\n",
            "Ch·∫•t l∆∞·ª£ng gi·∫£ng d·∫°y c·ªßa tr∆∞·ªùng t√¥i r·∫•t t·ªët trong ƒë√≥ gi√°o vi√™n l√† m·ªôt ph·∫ßn quan tr·ªçng. neutral positive\n",
            "Gi·∫£ng vi√™n mang l·∫°i kinh nghi·ªám th·ª±c t·∫ø cho h·ªçc sinh. neutral positive\n",
            "H·ªá th·ªëng r·∫°p chi·∫øu phim v√† trung t√¢m gi·∫£i tr√≠ n√¢ng cao sinh ho·∫°t vƒÉn h√≥a cho sinh vi√™n. positive neutral\n",
            "Ph∆∞∆°ng ph√°p d·∫°y h·ªçc thi·∫øt th·ª±c v√† c√≥ t√≠nh ·ª©ng d·ª•ng cao. neutral positive\n",
            "Nhi·ªÅu b·∫°n x·ª≠ l√Ω t√¨nh hu·ªëng kh√≥ khƒÉn m·ªôt c√°ch th√¥ng minh v√† kh√©o l√©o trong l·ªõp h·ªçc. positive neutral\n",
            "Nh√¢n vi√™n ph·ª•c v·ª• tr∆∞·ªùng lu√¥n s√°ng su·ªët, vui v·∫ª, nhi·ªát t√¨nh h·ªó tr·ª£ sinh vi√™n m·ªçi khi c·∫ßn thi·∫øt positive neutral\n",
            "T√†i li·ªáu h·ªçc t·∫≠p nhi·ªát t√¨nh v√† ƒë·∫ßy tr·∫£i nghi·ªám th·ª±c t·∫ø. positive neutral\n",
            "C√°c b√†i h·ªçc ƒë∆∞·ª£c thi·∫øt k·∫ø t·ªëi ∆∞u cho vi·ªác h·ªçc tr·ª±c tuy·∫øn. neutral positive\n",
            "C√°c khu v·ª±c c·∫•m h√∫t thu·ªëc ƒë∆∞·ª£c thi·∫øt k·∫ø v√† b·ªë tr√≠ ƒë·ªÉ ƒë·∫£m b·∫£o kh√¥ng kh√≠ trong l√†nh. neutral positive\n",
            "T√¥i c·∫£m th·∫•y r·∫•t ti·∫øc khi th·ªùi gian h·ªçc t·∫≠p t·∫°i tr∆∞·ªùng c·ªßa t√¥i k·∫øt th√∫c. negative positive\n",
            "Th·∫ßy gi√°o c·ªßa t√¥i r·∫•t t·ª± tin v√† gi·ªèi giang trong gi·∫£ng d·∫°y. neutral positive\n",
            "Gi·∫£ng vi√™n n√†y kh√¥ng nh√†m ch√°n. neutral negative\n"
          ]
        }
      ],
      "source": [
        "for i, row in df_test.iterrows():\n",
        "    if row['predict'] != row['sentiment']:\n",
        "        print(row['sentence'], row['predict'], row['sentiment'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gsbdBoj5PGUF"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HKQEmM61PGUF"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "datasetId": 3052448,
          "sourceId": 5245967,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30733,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
