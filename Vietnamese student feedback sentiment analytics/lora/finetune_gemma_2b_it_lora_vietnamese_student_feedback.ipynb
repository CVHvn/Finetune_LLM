{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "id": "TP6MkkhPF9EB"
      },
      "source": [
        "# Install library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zz_a2lxZF9EC",
        "outputId": "31462c02-a63b-41a0-bb04-12f32a2bd2c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -q datasets==2.16.0\n",
        "!pip install -q bitsandbytes\n",
        "!pip install -q tiktoken\n",
        "!pip install -q peft\n",
        "!pip install -q trl\n",
        "!pip install -q transformers\n",
        "!pip install -q openpyxl\n",
        "!pip install -q pandas\n",
        "!pip install -q scikit-learn\n",
        "!pip install -q flash-attn\n",
        "#pip install -q transformers==4.38.1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfiZcOyeF9ED"
      },
      "source": [
        "# Import library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6zY5GCP8F9ED"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
        "import torch\n",
        "from accelerate import PartialState\n",
        "from peft import LoraConfig, PeftModel, prepare_model_for_kbit_training, get_peft_model\n",
        "from trl import SFTTrainer\n",
        "from peft import prepare_model_for_kbit_training\n",
        "from transformers import TrainingArguments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9XY7J86nF9ED"
      },
      "source": [
        "# Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M-c_BuMHF9EE"
      },
      "outputs": [],
      "source": [
        "modelpath = \"google/gemma-2b-it\"\n",
        "lr=2e-4      # learning rate\n",
        "bs=16            # batch size\n",
        "bs_eval=16      # batch size for evals\n",
        "ga_steps=1     # gradient acc. steps\n",
        "epochs=4\n",
        "max_length=128      # max. sample length with 24GB VRAM\n",
        "output_dir=\"out\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4KxZlpCuF9EE"
      },
      "source": [
        "# Remove old model\n",
        "Because of limited storage, we can't save all models, we need to delete all models in cache by the following code:\n",
        "- rm -r out: delete out folder (because I save finetuned model in out folder), you can change folder name like (rm -r output_folder). If you doesn't have out folder, this commend do not thing.\n",
        "- all pretrained huggingface models will auto save in transformers.TRANSFORMERS_CACHE. I use shutil.rmtree to delete them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D4nrOdEcF9EE"
      },
      "outputs": [],
      "source": [
        "!rm -r out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B5-tHE7yF9EE"
      },
      "outputs": [],
      "source": [
        "# from transformers import TRANSFORMERS_CACHE\n",
        "# print(TRANSFORMERS_CACHE)\n",
        "\n",
        "# import shutil\n",
        "# shutil.rmtree(TRANSFORMERS_CACHE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CIt6-OC1F9EE"
      },
      "source": [
        "# Create Dataset\n",
        "Download dataset from [kaggle synthetic-vietnamese-students-feedback-corpus](https://www.kaggle.com/datasets/toreleon/synthetic-vietnamese-students-feedback-corpus/data)\n",
        "\n",
        "We need convert DataFrame to json line (jsonl)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZuEPdF7KF9EE"
      },
      "outputs": [],
      "source": [
        "df_train = pd.read_csv(\"synthetic_train.csv\")\n",
        "df_test = pd.read_csv(\"synthetic_val.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "myfqE7a0F9EE",
        "outputId": "b088658e-d588-401e-de73-6f2a7f23fa02"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>topic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ƒê·ªôi ng≈© b·∫£o tr√¨ qu√° th∆∞a th·ªõt d·∫´n ƒë·∫øn kh√¥ng ƒë·∫£...</td>\n",
              "      <td>negative</td>\n",
              "      <td>facility</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The university's musical and artistic faciliti...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>facility</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Ph∆∞∆°ng ph√°p gi·∫£ng d·∫°y ph√π h·ª£p v·ªõi c√°c ƒë·ªëi t∆∞·ª£n...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>curriculum</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Ch∆∞∆°ng tr√¨nh h·ªçc gi√∫p t√¥i tr·ªü th√†nh m·ªôt chuy√™n...</td>\n",
              "      <td>positive</td>\n",
              "      <td>curriculum</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>T√¥i nghƒ© r·∫±ng ch∆∞∆°ng tr√¨nh ƒë√†o t·∫°o c√≥ th·ªÉ c√≥ t...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>curriculum</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            sentence sentiment       topic\n",
              "0  ƒê·ªôi ng≈© b·∫£o tr√¨ qu√° th∆∞a th·ªõt d·∫´n ƒë·∫øn kh√¥ng ƒë·∫£...  negative    facility\n",
              "1  The university's musical and artistic faciliti...   neutral    facility\n",
              "2  Ph∆∞∆°ng ph√°p gi·∫£ng d·∫°y ph√π h·ª£p v·ªõi c√°c ƒë·ªëi t∆∞·ª£n...   neutral  curriculum\n",
              "3  Ch∆∞∆°ng tr√¨nh h·ªçc gi√∫p t√¥i tr·ªü th√†nh m·ªôt chuy√™n...  positive  curriculum\n",
              "4  T√¥i nghƒ© r·∫±ng ch∆∞∆°ng tr√¨nh ƒë√†o t·∫°o c√≥ th·ªÉ c√≥ t...   neutral  curriculum"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7sDKtj_mF9EF",
        "outputId": "1a143b5a-6621-4ec1-97b2-a4eff657d375"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>topic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Ch·∫•t l∆∞·ª£ng v·∫≠t ch·∫•t k√©m.</td>\n",
              "      <td>negative</td>\n",
              "      <td>facility</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Ph·∫ßn m·ªÅm h·ªçc t·∫≠p qu√° kh√≥ s·ª≠ d·ª•ng, khi·∫øn sinh v...</td>\n",
              "      <td>negative</td>\n",
              "      <td>facility</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Tr∆∞·ªùng t√¥i thi·∫øu nh·ªØng ti·ªán √≠ch c∆° b·∫£n nh∆∞ m√°y...</td>\n",
              "      <td>negative</td>\n",
              "      <td>facility</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>C·∫ßn t·∫°o th√™m c√°c ho·∫°t ƒë·ªông g·∫Øn k·∫øt gi·ªØa sinh v...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>curriculum</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>H·ªç r·∫•t khoan dung v√† l∆∞·ª£ng gi√°c trong quan ƒëi·ªÉ...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>others</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            sentence sentiment       topic\n",
              "0                           Ch·∫•t l∆∞·ª£ng v·∫≠t ch·∫•t k√©m.  negative    facility\n",
              "1  Ph·∫ßn m·ªÅm h·ªçc t·∫≠p qu√° kh√≥ s·ª≠ d·ª•ng, khi·∫øn sinh v...  negative    facility\n",
              "2  Tr∆∞·ªùng t√¥i thi·∫øu nh·ªØng ti·ªán √≠ch c∆° b·∫£n nh∆∞ m√°y...  negative    facility\n",
              "3  C·∫ßn t·∫°o th√™m c√°c ho·∫°t ƒë·ªông g·∫Øn k·∫øt gi·ªØa sinh v...   neutral  curriculum\n",
              "4  H·ªç r·∫•t khoan dung v√† l∆∞·ª£ng gi√°c trong quan ƒëi·ªÉ...   neutral      others"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_test.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ggfs4xIpF9EF",
        "outputId": "c3389b78-5a9d-4c85-eb93-94c679f42ce4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "sentiment\n",
              "neutral     2724\n",
              "negative    2711\n",
              "positive    2709\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train.sentiment.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KKtxI7qZF9EF",
        "outputId": "5a4809bd-13b7-4f12-f608-72a75092fe65"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "sentiment\n",
              "negative    686\n",
              "positive    680\n",
              "neutral     670\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_test.sentiment.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9kGaFCipF9EF"
      },
      "outputs": [],
      "source": [
        "df_train['len'] = df_train.sentence.apply(lambda x: len(str(x).split()))\n",
        "df_test['len'] = df_test.sentence.apply(lambda x: len(str(x).split()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lNe_CCuoF9EF",
        "outputId": "a2c19a41-3f3e-42c8-aed0-797903df3a0c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "count    8144.000000\n",
              "mean       15.549730\n",
              "std         5.018764\n",
              "min         3.000000\n",
              "25%        12.000000\n",
              "50%        15.000000\n",
              "75%        18.000000\n",
              "max        43.000000\n",
              "Name: len, dtype: float64"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train['len'].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dEKPQdnwF9EF",
        "outputId": "50221011-8b24-4114-c03f-53c4b09ebf82"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "count    2036.000000\n",
              "mean       15.694990\n",
              "std         5.185957\n",
              "min         2.000000\n",
              "25%        12.000000\n",
              "50%        15.000000\n",
              "75%        19.000000\n",
              "max        48.000000\n",
              "Name: len, dtype: float64"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_test['len'].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aJtrxYDQF9EF"
      },
      "outputs": [],
      "source": [
        "with open('train.jsonl', 'w') as outfile:\n",
        "    for i, x in df_train.iterrows():\n",
        "        comment = x['sentence']\n",
        "        label = x['sentiment']\n",
        "        #label = 'yes' if label == 'relevance' else 'no'\n",
        "        data = {\n",
        "            \"input\": f'''The sentiment of this comment \"{comment}\" is''',\n",
        "            \"output\": f\"{label}\"\n",
        "        }\n",
        "        json.dump(data, outfile)\n",
        "        outfile.write('\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "liXQmSOjF9EF"
      },
      "outputs": [],
      "source": [
        "with open('test.jsonl', 'w') as outfile:\n",
        "    for i, x in df_test.iterrows():\n",
        "        comment = x['sentence']\n",
        "        label = x['sentiment']\n",
        "        #label = 'yes' if label == 'relevance' else 'no'\n",
        "        data = {\n",
        "            \"input\": f'''The sentiment of this comment \"{comment}\" is''',\n",
        "            \"output\": f\"{label}\"\n",
        "        }\n",
        "        json.dump(data, outfile)\n",
        "        outfile.write('\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "297b49ea242742dc82e100bb4b6cd1fc",
            "61f99783c8e34f1b87d9ec99e62d3c4a"
          ]
        },
        "id": "Xtm__4Z5F9EG",
        "outputId": "5c26ea9f-adb1-467b-c5f8-3d3d8b26a3c0"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "297b49ea242742dc82e100bb4b6cd1fc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "61f99783c8e34f1b87d9ec99e62d3c4a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating validation split: 0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "data_files = {\n",
        "    \"train\": \"train.jsonl\",\n",
        "    \"validation\": \"test.jsonl\",\n",
        "}\n",
        "\n",
        "dataset = load_dataset(\"json\", data_files=data_files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yYsbZf0pF9EG",
        "outputId": "df0a13c0-17f9-40ab-f04b-4e91731cef9e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['input', 'output'],\n",
              "        num_rows: 8144\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['input', 'output'],\n",
              "        num_rows: 2036\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xg_LF0eF9EG"
      },
      "source": [
        "# Create prompt format\n",
        "Load tokenizer by AutoTokenizer.from_pretrained:\n",
        "- We need create and copy YOUR TOKEN from [huggingface](https://huggingface.co/settings/tokens)\n",
        "- We need use padding_side = 'right' because training library need padding_side = 'right' when training. You can use left padding but you need to make sure the library is not corrupted and check whether performance is affected by left padding!\n",
        "- If you have 1 prompt like \"test th·ª≠ m√¥ h√¨nh\" and want to tokenize it, just you tokenizer(prompt, return_tensors=\"pt\"). You can see output of tokenizer in cell below (output includes input_ids (list index of each token in prompt) and attention mask)\n",
        "- We can use tokenizer.batch_decode to see how tokenizer restore string from token tensor. You can see that it automatically adds the start token \"<bos>\" at the beginning of the string.\n",
        "- To train llm, we only need to pass 1 sentence to llm (including input and desired output) without specifying which is the input and which is the output.\n",
        "- I wrote the function formatting_prompts_func to convert input and output to prompt and tested this function, you can see below.\n",
        "- When predicting, remove the output part to let the model predict itself. See the predict section below later.\n",
        "- we only need to predict some next tokens like A. positive, and B. neutral. We don't care what the model says after sentiment. Then we do not need to add <eos token>. If you fine-tune the model with other tasks, maybe you need to add <eos token> at the end of the prompt:\n",
        "  - use tokenizer.eos_token, tokenizer.eos_token_id to see eos_token of your model and correspond id\n",
        "  - for ex: eos_token is \"<|im_end|>\". You need edit prompt like:\n",
        "    - '''...The correct answer is {output_}.''' --> '''...The correct answer is {output_}. <|im_end|>'''\n",
        "  - for ex: eos_token is \"end_token__\". You need edit prompt like:\n",
        "    - '''...The correct answer is {output_}.''' --> '''...The correct answer is {output_}. end_token__'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MvYtxMXeF9EG"
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    modelpath,\n",
        "    padding_side=\"right\",\n",
        "    # add_eos_token=True,\n",
        "    # add_bos_token=True,\n",
        "    trust_remote_code=True,\n",
        "    token = 'YOUR TOKEN HERE'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cp5tAQMoF9EG",
        "outputId": "bae29acf-ff25-4e97-b3b6-68fa7beaf323"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_ids': tensor([[     2,   2195, 101869,  34580,  15885]]), 'attention_mask': tensor([[1, 1, 1, 1, 1]])}\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['<bos>', 'test', ' th·ª≠', ' m√¥', ' h√¨nh']"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prompt = \"test th·ª≠ m√¥ h√¨nh\"\n",
        "tokens = tokenizer(prompt, return_tensors=\"pt\")\n",
        "print(tokens)\n",
        "tokenizer.batch_decode(tokenizer.encode(prompt))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0gLI7G1wF9EM"
      },
      "outputs": [],
      "source": [
        "def formatting_prompts_func(example):\n",
        "    output_texts = []\n",
        "    for i in range(len(example['input'])):\n",
        "        input_ = example['input'][i]\n",
        "        output_ = example['output'][i]\n",
        "        output_ = 'A. Positive' if output_ == 'positive' else 'B. Neutral' if output_ == 'neutral' else 'C. Negative'\n",
        "        #text = f\"### Question: {input__}\\n ### Answer: {example['output'][i]}\"\n",
        "        text = f'''{input_}\n",
        "A. Positive\n",
        "B. Neutral\n",
        "C. Negative\n",
        "\n",
        "The correct answer is {output_}.'''\n",
        "\n",
        "        output_texts.append(text)\n",
        "    return output_texts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9p9JjPqZF9EM",
        "outputId": "5d9518d8-99f1-46db-8e71-29785c2aad58"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('The sentiment of this comment \"Ch·∫•t l∆∞·ª£ng v·∫≠t ch·∫•t k√©m.\" is', 'negative')"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset[\"validation\"]['input'][0], dataset[\"validation\"]['output'][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pbAKL4CdF9EM",
        "outputId": "5807be19-7100-4e00-f420-9b4c77dee03a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['The sentiment of this comment \"Ch·∫•t l∆∞·ª£ng v·∫≠t ch·∫•t k√©m.\" is\\nA. Positive\\nB. Neutral\\nC. Negative\\n\\nThe correct answer is C. Negative.']"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "formatting_prompts_func({'input': [dataset[\"validation\"]['input'][0]],\n",
        "                         'output': [dataset[\"validation\"]['output'][0]]})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6SWaa2zOF9EM",
        "outputId": "0617c691-4b97-4f3c-dd5f-9de4f9b50cdc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The sentiment of this comment \"Ch·∫•t l∆∞·ª£ng v·∫≠t ch·∫•t k√©m.\" is\n",
            "A. Positive\n",
            "B. Neutral\n",
            "C. Negative\n",
            "\n",
            "The correct answer is C. Negative.\n"
          ]
        }
      ],
      "source": [
        "print(formatting_prompts_func({'input': [dataset[\"validation\"]['input'][0]],\n",
        "                         'output': [dataset[\"validation\"]['output'][0]]})[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c_m9AbVkF9EM"
      },
      "source": [
        "# Create model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FrWOQj4jF9EM"
      },
      "source": [
        "## Load model\n",
        "We use AutoModelForCausalLM.from_pretrained to load model:\n",
        "- device_map = 'auto': auto active gpu.\n",
        "- torch_dtype: use bfloat16, if your gpu don't support bfloat16, set it to float32\n",
        "- attn_implementation: you can use 'flash_attention_2', if you meet bug, maybe your gpu doesn't support it, you need delete this line.\n",
        "- token: you huggingface token like tokenizer above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "17280e5e90da49998e753ba8668d6140"
          ]
        },
        "id": "jkU4hYXQF9EM",
        "outputId": "3ecda878-abcc-4bef-b1bb-1e5f45354408"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`config.hidden_act` is ignored, you should use `config.hidden_activation` instead.\n",
            "Gemma's activation function will be set to `gelu_pytorch_tanh`. Please, use\n",
            "`config.hidden_activation` if you want to override this behaviour.\n",
            "See https://github.com/huggingface/transformers/pull/29402 for more details.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "17280e5e90da49998e753ba8668d6140",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# bnb_config = BitsAndBytesConfig(\n",
        "#     load_in_4bit=True,\n",
        "#     bnb_4bit_use_double_quant=True,\n",
        "#     bnb_4bit_quant_type=\"nf4\",\n",
        "#     bnb_4bit_compute_dtype=torch.bfloat16,\n",
        "# )\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    modelpath,\n",
        "    device_map=\"auto\",\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    #torch_dtype=torch.float32,\n",
        "    #quantization_config=bnb_config,\n",
        "    attn_implementation=\"flash_attention_2\",\n",
        "    trust_remote_code=True,\n",
        "    token = 'YOUR TOKEN HERE'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0gRkkRIZF9EN",
        "outputId": "58b73bb7-4e0d-4ec3-8d31-be19a2bbe325"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "GemmaForCausalLM(\n",
              "  (model): GemmaModel(\n",
              "    (embed_tokens): Embedding(256000, 2048, padding_idx=0)\n",
              "    (layers): ModuleList(\n",
              "      (0-17): 18 x GemmaDecoderLayer(\n",
              "        (self_attn): GemmaFlashAttention2(\n",
              "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
              "          (k_proj): Linear(in_features=2048, out_features=256, bias=False)\n",
              "          (v_proj): Linear(in_features=2048, out_features=256, bias=False)\n",
              "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
              "          (rotary_emb): GemmaRotaryEmbedding()\n",
              "        )\n",
              "        (mlp): GemmaMLP(\n",
              "          (gate_proj): Linear(in_features=2048, out_features=16384, bias=False)\n",
              "          (up_proj): Linear(in_features=2048, out_features=16384, bias=False)\n",
              "          (down_proj): Linear(in_features=16384, out_features=2048, bias=False)\n",
              "          (act_fn): PytorchGELUTanh()\n",
              "        )\n",
              "        (input_layernorm): GemmaRMSNorm()\n",
              "        (post_attention_layernorm): GemmaRMSNorm()\n",
              "      )\n",
              "    )\n",
              "    (norm): GemmaRMSNorm()\n",
              "  )\n",
              "  (lm_head): Linear(in_features=2048, out_features=256000, bias=False)\n",
              ")"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D06AoNalF9EN"
      },
      "source": [
        "## Eval model before training\n",
        "We use create_prompt function to generate prompt (without output), our model will predict output. We will eval model before finetune. You can see some predict below.\n",
        "\n",
        "You can see that pretrained model has poor performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wspTleOHF9EN",
        "outputId": "2215b064-d621-41c7-98f9-82e746696b11"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The sentiment of this comment: \"m√≥n ƒÉn r·∫•t ngon\" is\n",
            "A. Positive\n",
            "B. Neutral\n",
            "C. Negative\n",
            "\n",
            "The correct answer is\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:540: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<bos>The sentiment of this comment: \"m√≥n ƒÉn r·∫•t ngon\" is\n",
            "A. Positive\n",
            "B. Neutral\n",
            "C. Negative\n",
            "\n",
            "The correct answer is A. Positive.\n",
            "\n",
            "\"Mon ƒÉn r·∫•t ngon\" means \"I eat very well\". It is a positive sentiment.<eos>\n"
          ]
        }
      ],
      "source": [
        "def create_prompt(input_, output_):\n",
        "    output_ = 'A. Positive' if output_ == 'positive' else 'B. Neutral' if output_ == 'neutral' else 'C. Negative'\n",
        "        #text = f\"### Question: {input__}\\n ### Answer: {example['output'][i]}\"\n",
        "    text = f'''{input_}\n",
        "A. Positive\n",
        "B. Neutral\n",
        "C. Negative\n",
        "\n",
        "The correct answer is'''\n",
        "\n",
        "    return text\n",
        "\n",
        "sentence = 'm√≥n ƒÉn r·∫•t ngon'\n",
        "input_ = f'''The sentiment of this comment: \"{sentence}\" is'''\n",
        "prompt = create_prompt(input_, \"\")\n",
        "print(prompt)\n",
        "\n",
        "inputs = torch.tensor([tokenizer.encode(prompt)])\n",
        "\n",
        "tokens = model.generate(\n",
        "    inputs.to(model.device),\n",
        "    max_new_tokens=50,\n",
        "    temperature=0.1,\n",
        "    do_sample=False\n",
        ")\n",
        "print(tokenizer.decode(tokens[0], skip_special_tokens=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OvxBMiPuF9EN",
        "outputId": "57a1fedf-8199-4051-d77b-c05bab08e707"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask is not set and cannot be inferred from input because pad token is same as eos token.As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 100.0 0:00:00.047259 0:00:00.047261\n",
            "100 64.35643564356435 0:00:04.590000 0:00:00.045446\n",
            "200 66.16915422885572 0:00:09.125947 0:00:00.045403\n",
            "300 64.11960132890366 0:00:13.633852 0:00:00.045295\n",
            "400 65.33665835411472 0:00:18.165904 0:00:00.045302\n",
            "500 66.06786427145708 0:00:22.669066 0:00:00.045248\n",
            "600 64.39267886855241 0:00:27.198225 0:00:00.045255\n",
            "700 63.48074179743224 0:00:31.708645 0:00:00.045233\n",
            "800 64.41947565543072 0:00:36.240826 0:00:00.045244\n",
            "900 63.374028856825745 0:00:40.769665 0:00:00.045249\n",
            "1000 63.536463536463536 0:00:45.290881 0:00:00.045246\n",
            "1100 63.03360581289736 0:00:49.851445 0:00:00.045278\n",
            "1200 62.614487926727726 0:00:54.371535 0:00:00.045272\n",
            "1300 63.02843966179862 0:00:58.902764 0:00:00.045275\n",
            "1400 63.097787294789434 0:01:03.420205 0:00:00.045268\n",
            "1500 63.35776149233844 0:01:07.989346 0:00:00.045296\n",
            "1600 63.772642098688316 0:01:12.526595 0:00:00.045301\n",
            "1700 63.72721928277484 0:01:17.058861 0:00:00.045302\n",
            "1800 63.90893947806774 0:01:21.597925 0:00:00.045307\n",
            "1900 63.913729615991585 0:01:26.161601 0:00:00.045324\n",
            "2000 63.618190904547724 0:01:30.691721 0:00:00.045323\n"
          ]
        }
      ],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "start = datetime.now()\n",
        "\n",
        "prediction = []\n",
        "response = []\n",
        "accuracy = []\n",
        "labels = []\n",
        "\n",
        "for i, x in df_test.iterrows():\n",
        "    sentence = x['sentence']\n",
        "    label = x['sentiment']\n",
        "    input_ = f'''The sentiment of this comment: \"{sentence}\" is'''\n",
        "    prompt = create_prompt(input_, label)\n",
        "\n",
        "    inputs = tokenizer.encode(\n",
        "        prompt,\n",
        "        # add_generation_prompt=True,\n",
        "        return_tensors='pt'\n",
        "    )\n",
        "\n",
        "    tokens = model.generate(\n",
        "        inputs.to(model.device),\n",
        "        max_new_tokens=3,\n",
        "        temperature=0.1,\n",
        "        do_sample=False,\n",
        "        pad_token_id=tokenizer.eos_token_id\n",
        "    )\n",
        "    #break\n",
        "\n",
        "    answer = tokenizer.decode(tokens[0], skip_special_tokens=False).split(\"The correct answer is \")[-1]\n",
        "    answer = 'positive' if 'positive' in answer.lower() else 'negative' if 'negative' in answer.lower() else 'neutral'\n",
        "    prediction.append(answer.lower())\n",
        "    response.append(tokenizer.decode(tokens[0], skip_special_tokens=False))\n",
        "\n",
        "    accuracy.append(prediction[-1] == label)\n",
        "    labels.append(label)\n",
        "\n",
        "    if i % 100 == 0:\n",
        "        print(i, np.array(accuracy).sum()/len(prediction)*100, datetime.now() - start, (datetime.now() - start)/len(prediction))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TnsyjHSWF9EN",
        "outputId": "a9aa4e2e-18ff-4dcb-d4a0-b893c9afb98f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative     0.9655    0.8965    0.9297       686\n",
            "     neutral     0.0000    0.0000    0.0000       670\n",
            "    positive     0.4853    0.9985    0.6532       680\n",
            "\n",
            "    accuracy                         0.6356      2036\n",
            "   macro avg     0.4836    0.6317    0.5276      2036\n",
            "weighted avg     0.4874    0.6356    0.5314      2036\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report, f1_score\n",
        "import sklearn\n",
        "\n",
        "print(sklearn.metrics.classification_report(labels, prediction, digits=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DZMeckPTF9EN",
        "outputId": "246a6de4-2230-45af-8a52-0ccd69cb2656"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<bos>The sentiment of this comment: \"The facilities of the university are versatile and helpful.\" is\n",
            "A. Positive\n",
            "B. Neutral\n",
            "C. Negative\n",
            "\n",
            "The correct answer is A. Positive\n",
            "\n",
            "\n",
            "<bos>The sentiment of this comment: \"M·∫•y b·∫°n ƒë√≥ hay ƒë√≤i h·ªèi nh∆∞ng kh√¥ng bao gi·ªù gi√∫p ƒë·ª° ng∆∞·ªùi kh√°c.\" is\n",
            "A. Positive\n",
            "B. Neutral\n",
            "C. Negative\n",
            "\n",
            "The correct answer is C. Negative\n",
            "\n",
            "\n",
            "<bos>The sentiment of this comment: \"C·∫≠u ·∫•y r·∫•t c√≥ k·ªπ nƒÉng v·ªÅ s√°ng t·∫°o v√† ngh·ªá thu·∫≠t.\" is\n",
            "A. Positive\n",
            "B. Neutral\n",
            "C. Negative\n",
            "\n",
            "The correct answer is A. Positive\n",
            "\n",
            "\n",
            "<bos>The sentiment of this comment: \"Gi·∫£ng vi√™n n√†y kh√¥ng nh√†m ch√°n.\" is\n",
            "A. Positive\n",
            "B. Neutral\n",
            "C. Negative\n",
            "\n",
            "The correct answer is A. Positive\n",
            "\n",
            "\n",
            "<bos>The sentiment of this comment: \"Anh ta l√† m·ªôt ng∆∞·ªùi r·∫•t t·ªâ m·ªâ v√† c·∫©n th·∫≠n.\" is\n",
            "A. Positive\n",
            "B. Neutral\n",
            "C. Negative\n",
            "\n",
            "The correct answer is A. Positive\n",
            "\n",
            "\n",
            "<bos>The sentiment of this comment: \"Gi√°o vi√™n ƒë∆∞a ra c√°c ph∆∞∆°ng ti·ªán h·ªó tr·ª£ gi·∫£ng d·∫°y r·∫•t t·ªët v√† hi·ªáu qu·∫£.\" is\n",
            "A. Positive\n",
            "B. Neutral\n",
            "C. Negative\n",
            "\n",
            "The correct answer is A. Positive\n",
            "\n",
            "\n",
            "<bos>The sentiment of this comment: \"The university's computer facilities are up-to-date and well-maintained.\" is\n",
            "A. Positive\n",
            "B. Neutral\n",
            "C. Negative\n",
            "\n",
            "The correct answer is A. Positive\n",
            "\n",
            "\n",
            "<bos>The sentiment of this comment: \"Thi·∫øu t√≠nh linh ho·∫°t trong h√¨nh th·ª©c gi·∫£ng d·∫°y v√† ƒë√°nh gi√° k·∫øt qu·∫£ h·ªçc t·∫≠p.\" is\n",
            "A. Positive\n",
            "B. Neutral\n",
            "C. Negative\n",
            "\n",
            "The correct answer is C. Negative\n",
            "\n",
            "\n",
            "<bos>The sentiment of this comment: \"C√¥ ·∫•y r·∫•t s·∫Øc s·∫£o v√† c√≥ kh·∫£ nƒÉng ph√¢n t√≠ch chi ti·∫øt r·∫•t t·ªët.\" is\n",
            "A. Positive\n",
            "B. Neutral\n",
            "C. Negative\n",
            "\n",
            "The correct answer is A. Positive\n",
            "\n",
            "\n",
            "<bos>The sentiment of this comment: \"Anh ·∫•y c√≥ t√†i nƒÉng v·ªÅ √¢m nh·∫°c v√† lu√¥n t√¨m c√°ch t·∫°o ra c√°c b·∫£n nh·∫°c m·ªõi, gi√∫p nh√≥m th√™m ho√†n h·∫£o v√† ƒëa d·∫°ng h∆°n.\" is\n",
            "A. Positive\n",
            "B. Neutral\n",
            "C. Negative\n",
            "\n",
            "The correct answer is A. Positive\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for x in response[-10:]:\n",
        "    print(x)\n",
        "    print(\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create peft\n",
        "For lora training, we need create LoraConfig:\n",
        "  - lora_alpha, r, dropout is basic hyperarameter.\n",
        "  - almost LLM use bias = 'none' when finetune then we set is to None\n",
        "  - target_modules are list of layer we want to finetune, I set it to 'all-linear', then all linear layers will be finetuned. If you just finetune some layers like q_proj, k_proj, you can pass list ['q_proj', 'k_proj'].\n",
        "  - modules_to_save is other layers we want to finetune (but don't use lora), in my experience, finetune all embedding layers will make model work betters than I set modules_to_save as list of all embedding layers."
      ],
      "metadata": {
        "id": "EKu2eyWTGWLy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "plUNi-7XF9EQ",
        "outputId": "25984267-3dac-42e4-8978-08019b99e3de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trainable params: 534,093,824 || all params: 3,040,266,240 || trainable%: 17.5673\n"
          ]
        }
      ],
      "source": [
        "peft_config = LoraConfig(\n",
        "    lora_alpha=32,\n",
        "    lora_dropout=0.1,\n",
        "    r=8,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\",\n",
        "    target_modules = 'all-linear',\n",
        "#     target_modules=[\"q_proj\",\n",
        "#         \"k_proj\",\n",
        "#         \"v_proj\",\n",
        "#         \"o_proj\",\n",
        "#         \"gate_proj\",\n",
        "#         \"up_proj\",\n",
        "#         \"down_proj\",\n",
        "#         \"lm_head\",],\n",
        "    modules_to_save=[\"embed_tokens\", \"rotary_emb\"]\n",
        "                     #\"input_layernorm\", \"post_attention_layernorm\", \"norm\"]\n",
        ")\n",
        "model = get_peft_model(model, peft_config)\n",
        "\n",
        "model.print_trainable_parameters() #"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CueNJeQwF9EQ"
      },
      "source": [
        "## Create TrainingArguments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-_c3uow7F9EQ",
        "outputId": "13b3ae9e-2a1b-473d-e6a0-ac3fc6fd7805"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "509\n"
          ]
        }
      ],
      "source": [
        "print(len(df_train)//bs//ga_steps*epochs//4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HHH7g29jF9EQ",
        "outputId": "86c51951-2fe2-4939-aab5-85995ced8136"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "509\n"
          ]
        }
      ],
      "source": [
        "save_step = len(df_train)//bs//ga_steps*epochs//4\n",
        "print(save_step)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zCgiOctoF9EQ",
        "outputId": "1d87998c-ee52-418c-9b12-92a97664b9a9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "training_arguments = TrainingArguments(\n",
        "    output_dir=output_dir,\n",
        "    num_train_epochs=epochs,\n",
        "    per_device_train_batch_size=bs,\n",
        "    per_device_eval_batch_size=bs_eval,\n",
        "    evaluation_strategy=\"steps\",\n",
        "    eval_steps=save_step,\n",
        "    gradient_accumulation_steps=ga_steps,\n",
        "    optim=\"paged_adamw_32bit\",\n",
        "    save_steps=save_step,\n",
        "    save_strategy=\"steps\",\n",
        "    logging_steps=save_step,\n",
        "    learning_rate=lr,\n",
        "    weight_decay=0.001,\n",
        "    fp16=False,\n",
        "    bf16=True,\n",
        "    max_grad_norm=0.3,\n",
        "    max_steps=-1,\n",
        "    warmup_ratio=0.03,\n",
        "    group_by_length=True,\n",
        "    lr_scheduler_type=\"constant\",\n",
        "    report_to=\"none\",\n",
        "    save_total_limit=1,\n",
        "    #load_best_model_at_end=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GObHcjYPF9ER"
      },
      "source": [
        "## Create trainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "4341f52d24c84111a93f9f8b9ea522c5",
            "c7a1e75230a446d68bbd927689aa97e0"
          ]
        },
        "id": "22V_au7BF9ER",
        "outputId": "b59980f7-e7fb-42db-dcd6-396ccc04e4d3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': max_seq_length. Will not be supported from version '1.0.0'.\n",
            "\n",
            "Deprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n",
            "  warnings.warn(message, FutureWarning)\n",
            "/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1961: FutureWarning: `--push_to_hub_token` is deprecated and will be removed in version 5 of ü§ó Transformers. Use `--hub_token` instead.\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:269: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4341f52d24c84111a93f9f8b9ea522c5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/8144 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c7a1e75230a446d68bbd927689aa97e0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/2036 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
          ]
        }
      ],
      "source": [
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    train_dataset=dataset[\"train\"],\n",
        "    eval_dataset=dataset[\"validation\"],\n",
        "    peft_config=peft_config,\n",
        "    max_seq_length= 128,\n",
        "    #dataset_text_field=[\"input\", \"output\"],\n",
        "    tokenizer=tokenizer,\n",
        "    args=training_arguments,\n",
        "    packing= False,\n",
        "    formatting_func = formatting_prompts_func,\n",
        "    #data_collator=collator\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F2jx6WerF9ER"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "swG3nyB7F9ER",
        "outputId": "d5a830e1-516f-4258-8dce-4f9bcbb022e1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2036' max='2036' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2036/2036 05:57, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>509</td>\n",
              "      <td>0.832000</td>\n",
              "      <td>0.772138</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1018</td>\n",
              "      <td>0.677500</td>\n",
              "      <td>0.775478</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1527</td>\n",
              "      <td>0.582000</td>\n",
              "      <td>0.793018</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2036</td>\n",
              "      <td>0.504100</td>\n",
              "      <td>0.853091</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/peft/utils/other.py:611: UserWarning: Unable to fetch remote file due to the following error 401 Client Error. (Request ID: Root=1-667e8d36-380122221f182e823e1292f9;2bd0cb3c-f2d7-4c49-b219-64abfc82e02d)\n",
            "\n",
            "Cannot access gated repo for url https://huggingface.co/google/gemma-2b-it/resolve/main/config.json.\n",
            "Access to model google/gemma-2b-it is restricted. You must be authenticated to access it. - silently ignoring the lookup for the file config.json in google/gemma-2b-it.\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:195: UserWarning: Could not find a config file in google/gemma-2b-it - will assume that the vocabulary was not modified.\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/peft/utils/other.py:611: UserWarning: Unable to fetch remote file due to the following error 401 Client Error. (Request ID: Root=1-667e8d90-652e315637ea219426a28e88;ebab7078-dd18-4af3-99e0-5e95edd430e6)\n",
            "\n",
            "Cannot access gated repo for url https://huggingface.co/google/gemma-2b-it/resolve/main/config.json.\n",
            "Access to model google/gemma-2b-it is restricted. You must be authenticated to access it. - silently ignoring the lookup for the file config.json in google/gemma-2b-it.\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:195: UserWarning: Could not find a config file in google/gemma-2b-it - will assume that the vocabulary was not modified.\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/peft/utils/other.py:611: UserWarning: Unable to fetch remote file due to the following error 401 Client Error. (Request ID: Root=1-667e8de9-2dbdca5c506bb8ab7728e249;5614ef23-e30a-4af2-8e3d-f1ee45935e25)\n",
            "\n",
            "Cannot access gated repo for url https://huggingface.co/google/gemma-2b-it/resolve/main/config.json.\n",
            "Access to model google/gemma-2b-it is restricted. You must be authenticated to access it. - silently ignoring the lookup for the file config.json in google/gemma-2b-it.\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:195: UserWarning: Could not find a config file in google/gemma-2b-it - will assume that the vocabulary was not modified.\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/peft/utils/other.py:611: UserWarning: Unable to fetch remote file due to the following error 401 Client Error. (Request ID: Root=1-667e8e43-79398f1548ab26e322b3aec8;b19410b6-8b70-4aa1-b129-8d4d6fc78748)\n",
            "\n",
            "Cannot access gated repo for url https://huggingface.co/google/gemma-2b-it/resolve/main/config.json.\n",
            "Access to model google/gemma-2b-it is restricted. You must be authenticated to access it. - silently ignoring the lookup for the file config.json in google/gemma-2b-it.\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:195: UserWarning: Could not find a config file in google/gemma-2b-it - will assume that the vocabulary was not modified.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=2036, training_loss=0.6488756730654853, metrics={'train_runtime': 358.2137, 'train_samples_per_second': 90.94, 'train_steps_per_second': 5.684, 'total_flos': 1.834279790247936e+16, 'train_loss': 0.6488756730654853, 'epoch': 4.0})"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-COENdjF9ER"
      },
      "source": [
        "# Eval\n",
        "- If you save the model to the output_dir folder, the training code above will automatically save the model to output_dir/checkpoint-{save_step} (in my case: out/checkpoint-2036). We will load the model from this folder:\n",
        "  - I calculate _id = save_step * num_epoch = 509 * 4 = 2036\n",
        "  - My model will saved at \"{output_dir}/checkpoint-{_id}\"\n",
        "- I use del model, gc.collect() and torch.cuda.empty_cache() to release trained model (save gpu memory).\n",
        "- We use PeftConfig.from_pretrained to lead peft config (this is the same as peft config at training)\n",
        "- we load pretrained model like before.\n",
        "- We load the tokenizer in this folder by passing the saved folder to AutoTokenizer.from_pretrained()\n",
        "- We use PeftModel.from_pretrained(model, peft_model_id) to merge pre-trained model with finetuned lora model (note that when we use peft lora, training code only saves lora model, this saves our storage and saving time)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tirP5esFF9ER",
        "outputId": "39b4e6e6-3470-4845-86c5-d946e460ebb3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "509\n"
          ]
        }
      ],
      "source": [
        "save_step = len(df_train)//bs//ga_steps*epochs//4\n",
        "print(save_step)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iCevflvsF9ER"
      },
      "outputs": [],
      "source": [
        "import gc\n",
        "\n",
        "del model\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "fde38881ac8b4035b0e95755374f4479"
          ]
        },
        "id": "ZkOKYKAbF9ER",
        "outputId": "12ed791b-aa90-4c80-9bd5-d9c4fd0f8b6b"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fde38881ac8b4035b0e95755374f4479",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from peft import PeftModel, PeftConfig\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import torch\n",
        "\n",
        "_id = save_step*4\n",
        "\n",
        "peft_model_id = f\"{output_dir}/checkpoint-{_id}\"\n",
        "\n",
        "config = PeftConfig.from_pretrained(peft_model_id)\n",
        "\n",
        "# bnb_config = BitsAndBytesConfig(\n",
        "#     load_in_4bit=True,\n",
        "#     bnb_4bit_use_double_quant=False,\n",
        "#     bnb_4bit_quant_type=\"nf4\",\n",
        "#     bnb_4bit_compute_dtype=torch.float16,\n",
        "# )\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    modelpath,\n",
        "    device_map=\"auto\",\n",
        "    #torch_dtype=torch.float16,\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    #quantization_config=bnb_config,\n",
        "    attn_implementation=\"flash_attention_2\",\n",
        "    trust_remote_code=True,\n",
        "    token = 'YOUR TOKEN HERE'\n",
        ")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(f\"{output_dir}/checkpoint-{_id}\",\n",
        "                                          trust_remote_code=True,\n",
        "                                          padding_side='left',\n",
        "                                          token='YOUR TOKEN HERE')\n",
        "\n",
        "# Load the Lora model\n",
        "model = PeftModel.from_pretrained(model, peft_model_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hR26uLqFF9ER"
      },
      "outputs": [],
      "source": [
        "def create_prompt(input_, output_):\n",
        "    output_ = 'A. Positive' if output_ == 'positive' else 'B. Neutral' if output_ == 'neutral' else 'C. Negative'\n",
        "        #text = f\"### Question: {input__}\\n ### Answer: {example['output'][i]}\"\n",
        "    text = f'''{input_}\n",
        "A. Positive\n",
        "B. Neutral\n",
        "C. Negative\n",
        "\n",
        "The correct answer is'''\n",
        "\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V4smx8GlF9ES",
        "outputId": "7dd0cc4d-e098-4cdb-8cb3-745cb451df5e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The sentiment of this comment: \"m√≥n ƒÉn r·∫•t ngon\" is\n",
            "A. Positive\n",
            "B. Neutral\n",
            "C. Negative\n",
            "\n",
            "The correct answer is\n"
          ]
        }
      ],
      "source": [
        "sentence = 'm√≥n ƒÉn r·∫•t ngon'\n",
        "input_ = f'''The sentiment of this comment: \"{sentence}\" is'''\n",
        "prompt = create_prompt(input_, \"\")\n",
        "print(prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SgnA3NyTF9ES",
        "outputId": "4464299e-031f-4daf-c762-cca68b99feed"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[     2,    651,  25627,    576,    736,   4986, 235292,    664,  92020,\n",
              "          28644,  31085,  60774, 235281,    603,    108, 235280, 235265,  40695,\n",
              "            108, 235305, 235265,  62407,    108, 235288, 235265,  48314,    109,\n",
              "            651,   5112,   3448,    603]])"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "inputs = torch.tensor([tokenizer.encode(prompt)])\n",
        "inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9c9Zu5MOF9ES"
      },
      "outputs": [],
      "source": [
        "tokens = model.generate(\n",
        "    inputs.to(model.device),\n",
        "    max_new_tokens=50,\n",
        "    temperature=0.1,\n",
        "    do_sample=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ddDlR7FjF9EU",
        "outputId": "b7af3581-8d44-45a1-be4f-19bbad166a6c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<bos>The sentiment of this comment: \"m√≥n ƒÉn r·∫•t ngon\" is\n",
            "A. Positive\n",
            "B. Neutral\n",
            "C. Negative\n",
            "\n",
            "The correct answer is B. Neutral.\n",
            "\n",
            "Neutral is a neutral tone that is neither positive nor negative. Neutral is often used to indicate that a statement is not a fact or a claim.<eos>\n"
          ]
        }
      ],
      "source": [
        "print(tokenizer.decode(tokens[0], skip_special_tokens=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bHSN4bE1F9EU",
        "outputId": "44314145-477b-44cc-80df-07b4763cce7f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<bos>The sentiment of this comment: \"m√≥n ƒÉn r·∫•t ngon\" is\n",
            "A. Positive\n",
            "B. Neutral\n",
            "C. Negative\n",
            "\n",
            "The correct answer is B. Neutral\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:540: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "tokens = model.generate(\n",
        "    inputs.to(model.device),\n",
        "    max_new_tokens=3,\n",
        "    temperature=0.1,\n",
        "    do_sample=False\n",
        ")\n",
        "print(tokenizer.decode(tokens[0], skip_special_tokens=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nWv94usoF9EU",
        "outputId": "367932d2-5bea-4f63-aa04-701eda81eb91"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 100.0 0:00:00.077170 0:00:00.077172\n",
            "100 87.12871287128714 0:00:07.690365 0:00:00.076142\n",
            "200 86.56716417910447 0:00:15.376521 0:00:00.076500\n",
            "300 85.71428571428571 0:00:22.959424 0:00:00.076277\n",
            "400 85.785536159601 0:00:30.582669 0:00:00.076266\n",
            "500 86.02794411177645 0:00:38.193031 0:00:00.076234\n",
            "600 86.35607321131448 0:00:45.769709 0:00:00.076156\n",
            "700 86.16262482168331 0:00:53.328889 0:00:00.076075\n",
            "800 86.51685393258427 0:01:00.944671 0:00:00.076086\n",
            "900 87.12541620421753 0:01:08.518870 0:00:00.076048\n",
            "1000 87.21278721278722 0:01:16.138717 0:00:00.076063\n",
            "1100 87.19346049046321 0:01:23.717418 0:00:00.076038\n",
            "1200 86.59450457951708 0:01:31.285913 0:00:00.076008\n",
            "1300 86.70253651037663 0:01:38.897066 0:00:00.076016\n",
            "1400 86.79514632405426 0:01:46.516628 0:00:00.076029\n",
            "1500 86.47568287808129 0:01:54.073709 0:00:00.075998\n",
            "1600 86.57089319175515 0:02:01.638044 0:00:00.075976\n",
            "1700 86.71369782480893 0:02:09.197713 0:00:00.075954\n",
            "1800 86.89616879511382 0:02:16.784352 0:00:00.075949\n",
            "1900 86.90163072067332 0:02:24.293360 0:00:00.075904\n",
            "2000 87.05647176411794 0:02:31.851176 0:00:00.075888\n"
          ]
        }
      ],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "start = datetime.now()\n",
        "\n",
        "prediction = []\n",
        "response = []\n",
        "accuracy = []\n",
        "labels = []\n",
        "\n",
        "for i, x in df_test.iterrows():\n",
        "    sentence = x['sentence']\n",
        "    label = x['sentiment']\n",
        "    input_ = f'''The sentiment of this comment: \"{sentence}\" is'''\n",
        "    prompt = create_prompt(input_, label)\n",
        "\n",
        "    inputs = tokenizer.encode(\n",
        "        prompt,\n",
        "        # add_generation_prompt=True,\n",
        "        return_tensors='pt'\n",
        "    )\n",
        "\n",
        "    tokens = model.generate(\n",
        "        inputs.to(model.device),\n",
        "        max_new_tokens=3,\n",
        "        temperature=0.1,\n",
        "        do_sample=False,\n",
        "        pad_token_id=tokenizer.eos_token_id\n",
        "    )\n",
        "    #break\n",
        "\n",
        "    answer = tokenizer.decode(tokens[0], skip_special_tokens=False).split(\"The correct answer is \")[-1]\n",
        "    answer = 'positive' if 'positive' in answer.lower() else 'negative' if 'negative' in answer.lower() else 'neutral'\n",
        "    prediction.append(answer.lower())\n",
        "    response.append(tokenizer.decode(tokens[0], skip_special_tokens=False))\n",
        "\n",
        "    accuracy.append(prediction[-1] == label)\n",
        "    labels.append(label)\n",
        "\n",
        "    if i % 100 == 0:\n",
        "        print(i, np.array(accuracy).sum()/len(prediction)*100, datetime.now() - start, (datetime.now() - start)/len(prediction))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DJlgh58KF9EU",
        "outputId": "6e2da368-654d-4e5e-9dfe-1d8e50eb0f44"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative     0.9854    0.9869    0.9862       686\n",
            "     neutral     0.8325    0.7567    0.7928       670\n",
            "    positive     0.7905    0.8603    0.8239       680\n",
            "\n",
            "    accuracy                         0.8689      2036\n",
            "   macro avg     0.8695    0.8680    0.8676      2036\n",
            "weighted avg     0.8700    0.8689    0.8684      2036\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report, f1_score\n",
        "import sklearn\n",
        "\n",
        "print(sklearn.metrics.classification_report(labels, prediction, digits=4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4kR-uACF9EU"
      },
      "source": [
        "# Check results\n",
        "- I print all sentences have wrong prediction and see that almost cases is bug.\n",
        "- Conclusion, dataset is not clean than finetune LLM can't better than finetune roberta (~89..90%), because roberta will overfit even in test dataset.\n",
        "- In additionally, when I print example: \"m√≥n ƒÉn n√†y r·∫•t ngon\", we can see that model before finetune work better. Model after finetune only think about school (because finetune dataset is about school) and it don't know about food review. Than I think we only need finetune for special cases and finetune dataset need be clean and large enough."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OZlWXMkeF9EV"
      },
      "outputs": [],
      "source": [
        "df_test['predict'] = prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RNF3ztmyF9EV",
        "outputId": "a7ec3302-de8d-41ed-fb06-b4177f0f8986"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Gi·∫£ng vi√™n lu√¥n ƒë·ªìng h√†nh v·ªõi sinh vi√™n tr√™n qu√° tr√¨nh h·ªçc t·∫≠p. positive neutral\n",
            "T√¥i c√≥ th·ªÉ ·ª©ng d·ª•ng c√°c ki·∫øn th·ª©c c√≥ ƒë∆∞·ª£c t·ª´ ch∆∞∆°ng tr√¨nh ƒë√†o t·∫°o v√†o c√¥ng vi·ªác c·ªßa m√¨nh. neutral positive\n",
            "Gi·∫£ng vi√™n r·∫•t t√†i nƒÉng v√† c√≥ nhi·ªÅu kinh nghi·ªám trong c√¥ng t√°c gi·∫£ng d·∫°y. positive neutral\n",
            "ƒê∆∞·ª£c h·ªçc t·∫≠p v·ªõi c√°c gi√°o vi√™n gi√†u kinh nghi·ªám v√† th·ª±c ti·ªÖn. positive neutral\n",
            "Nh√† h√†ng v√† c√°c c·ª≠a h√†ng ti·ªán l·ª£i ·ªü g·∫ßn tr∆∞·ªùng r·∫•t ƒëa d·∫°ng v√† phong ph√∫. neutral positive\n",
            "Ch·ªã ·∫•y r·∫•t gi·ªèi qu·∫£n l√Ω th·ªùi gian v√† lu√¥n ho√†n th√†nh c√¥ng vi·ªác ƒë√∫ng ti·∫øn ƒë·ªô. positive neutral\n",
            "C√¥ ·∫•y l√† m·ªôt gi√°o vi√™n r·∫•t th√¥ng minh v√† chuy√™n nghi·ªáp. neutral positive\n",
            "Anh ·∫•y c√≥ m·ªôt t·∫ßm nh√¨n ƒë·ªânh cao v√† kh·∫£ nƒÉng gi·∫£i quy·∫øt v·∫•n ƒë·ªÅ t·ªët. positive neutral\n",
            "Tr∆∞·ªùng ƒë·∫°i h·ªçc n√†y ƒë√≥ng g√≥p m·ªôt ph·∫ßn quan tr·ªçng trong vi·ªác ph√°t tri·ªÉn kinh t·∫ø v√† x√£ h·ªôi ƒë·ªãa ph∆∞∆°ng. positive neutral\n",
            "C√≥ nhi·ªÅu ho·∫°t ƒë·ªông ngo·∫°i kh√≥a v√† phong ph√∫ cho sinh vi√™n. neutral positive\n",
            "Khu v·ª±c ƒë·∫∑t m√°y b√°n th·ª©c u·ªëng r·∫•t ti·ªán l·ª£i cho sinh vi√™n. neutral positive\n",
            "S√¢n c·ªè c·ªßa tr∆∞·ªùng ƒë∆∞·ª£c tu b·ªï v√† ƒë·ªãnh h∆∞·ªõng ri√™ng cho c√°c ho·∫°t ƒë·ªông th·ªÉ thao. positive neutral\n",
            "Ph√≤ng h·ªçc ƒë∆∞·ª£c trang b·ªã ƒë·∫ßy ƒë·ªß ti·ªán nghi gi√∫p sinh vi√™n lu√¥n d·ªÖ d√†ng ti·∫øp c·∫≠n t√†i li·ªáu v√† th√¥ng tin li√™n quan. positive neutral\n",
            "Th·∫ßy d·∫°y r·∫•t chuy√™n nghi·ªáp v√† nhi·ªát t√¨nh. neutral positive\n",
            "C√°c ph√≤ng th√≠ nghi·ªám ƒë∆∞·ª£c trang b·ªã ƒë·∫ßy ƒë·ªß c√°c thi·∫øt b·ªã c·∫ßn thi·∫øt. positive neutral\n",
            "Khu v·ª±c h·ªçc t·∫≠p t·∫°i th∆∞ vi·ªán r·∫•t y√™n tƒ©nh v√† tho·∫£i m√°i. neutral positive\n",
            "Th·∫ßy/c√¥ ƒë√°nh gi√° v√† ƒë·ªÅ xu·∫•t nh·ªØng √Ω ki·∫øn x√¢y d·ª±ng t√≠ch c·ª±c gi√∫p sinh vi√™n ph√°t tri·ªÉn h∆°n. neutral positive\n",
            "Gi·∫£ng vi√™n r·∫•t ch√¢n th√†nh v√† nhi·ªát t√¨nh. neutral positive\n",
            "H·ªá th·ªëng th∆∞ vi·ªán v√† t√†i nguy√™n h·ªçc t·∫≠p r·∫•t ƒë·∫ßy ƒë·ªß v√† ti·ªán l·ª£i. positive neutral\n",
            "Ch∆∞∆°ng tr√¨nh ƒë√†o t·∫°o c√≥ nhi·ªÅu t√≠nh ·ª©ng d·ª•ng gi√∫p sinh vi√™n t·ª± tin v√† th√†nh c√¥ng trong c√¥ng vi·ªác. neutral positive\n",
            "Tr∆∞·ªùng c·∫ßn c√≥ ch√≠nh s√°ch h·ªó tr·ª£ chi ph√≠ h·ªçc t·∫≠p ph√π h·ª£p cho sinh vi√™n. neutral negative\n",
            "Th·∫ßy cho h·ªçc sinh m·ªôt c√°i nh√¨n t·ªïng quan v·ªÅ chuy√™n ng√†nh c·ªßa m√¨nh. neutral positive\n",
            "Gi√°o tr√¨nh l√† m·ªôt s·ª± k·∫øt h·ª£p gi·ªØa l√Ω thuy·∫øt v√† th·ª±c t·∫ø r·∫•t ƒë·ªìng b·ªô. positive neutral\n",
            "C√°c ph√≤ng h·ªçc ƒë∆∞·ª£c trang b·ªã ƒë·∫ßy ƒë·ªß ti·ªán nghi v√† thi·∫øt b·ªã. positive neutral\n",
            "Ch∆∞∆°ng tr√¨nh ƒë√†o t·∫°o r·∫•t ƒëa d·∫°ng v·ªÅ c·∫£ n·ªôi dung l·∫´n h√¨nh th·ª©c ƒë√†o t·∫°o. neutral positive\n",
            "Tr∆∞·ªùng ƒë·∫°i h·ªçc cung c·∫•p nhi·ªÅu ch∆∞∆°ng tr√¨nh h·ªçc b·ªïng h·ªó tr·ª£ cho sinh vi√™n kh√≥ khƒÉn kinh t·∫ø. neutral positive\n",
            "Khu v·ª±c s·ªëng ƒë·ªông c·ªßa tr∆∞·ªùng r·∫•t th√∫ v·ªã cho sinh vi√™n. positive neutral\n",
            "Th∆∞ vi·ªán c·ªßa tr∆∞·ªùng c√≥ nhi·ªÅu t√†i li·ªáu b·ªï √≠ch v√† ƒëa d·∫°ng. positive neutral\n",
            "Gi·∫£ng vi√™n r·∫•t am hi·ªÉu v√† t·ª´ng b∆∞·ªõc h∆∞·ªõng d·∫´n sinh vi√™n ƒëi ƒë·∫øn th√†nh c√¥ng. positive neutral\n",
            "H·ªá th·ªëng an ninh t·∫°i tr∆∞·ªùng r·∫•t ch·∫∑t ch·∫Ω v√† ƒë·∫£m b·∫£o an to√†n cho sinh vi√™n. neutral positive\n",
            "Th·∫ßy gi·∫£i th√≠ch c·∫∑n k·∫Ω v√† d·ªÖ hi·ªÉu. neutral positive\n",
            "Th·∫ßy c√¥ gi·∫£ng d·∫°y ƒë·ªÅu r·∫•t nhi·ªát t√¨nh v√† c√≥ kinh nghi·ªám trong lƒ©nh v·ª±c ƒëang gi·∫£ng d·∫°y. neutral positive\n",
            "C√≥ r·∫•t nhi·ªÅu ph√≤ng h·ªçc t·∫°i tr∆∞·ªùng ƒë·ªÉ sinh vi√™n c√≥ th·ªÉ l·ª±a ch·ªçn v√† s·ª≠ d·ª•ng. neutral positive\n",
            "T√¥i r·∫•t ·∫•n t∆∞·ª£ng v·ªõi s·ª± trang tr√≠ trong tr∆∞·ªùng, ch√∫ng t·∫°o c·∫£m gi√°c tho·∫£i m√°i v√† th∆∞ gi√£n cho sinh vi√™n. positive neutral\n",
            "L·ªõp h·ªçc ƒë∆∞·ª£c t·ªï ch·ª©c ng·∫Øn g·ªçn, th·ª±c t·∫ø v√† c√≥ t√≠nh ·ª©ng d·ª•ng cao. positive neutral\n",
            "C∆° s·ªü h·∫° t·∫ßng ·ªü ƒë√¢y r·∫•t ƒë√°p ·ª©ng nhu c·∫ßu h·ªçc t·∫≠p c·ªßa sinh vi√™n. positive neutral\n",
            "Tr∆∞·ªùng c√≥ h·ªá th·ªëng th√¥ng tin qu·∫£n l√Ω hi·ªán ƒë·∫°i v√† ƒë√°p ·ª©ng ƒë∆∞·ª£c c√°c y√™u c·∫ßu c·ªßa sinh vi√™n. positive neutral\n",
            "Th·∫ßy s·ª≠ d·ª•ng ph∆∞∆°ng ph√°p ƒë·ªïi m·ªõi v√† kƒ© thu·∫≠t s·ªë ƒë·ªÉ tƒÉng c∆∞·ªùng hi·ªáu qu·∫£ h·ªçc t·∫≠p. positive neutral\n",
            "Anh ·∫•y r·∫•t l·ªãch s·ª± v√† t√¥n tr·ªçng ng∆∞·ªùi kh√°c. positive neutral\n",
            "Gi·∫£ng vi√™n ƒë∆∞a ra nh·ªØng c√¢u h·ªèi th√∫ v·ªã v√† kh√≥ gi·∫£i quy·∫øt, gi√∫p sinh vi√™n r√®n luy·ªán k·ªπ nƒÉng suy lu·∫≠n v√† ph√¢n t√≠ch. positive neutral\n",
            "Khu v·ª±c ƒÉn u·ªëng c·ªßa tr∆∞·ªùng c√≥ nhi·ªÅu m√≥n ƒÉn ngon v√† ƒëa d·∫°ng. neutral positive\n",
            "C√¥ ·∫•y lu√¥n th·ªÉ hi·ªán s·ª± nghi√™m t√∫c v√† t√¢m huy·∫øt trong vi·ªác h·ªçc t·∫≠p v√† gi·∫£ng d·∫°y. positive neutral\n",
            "C√¥ n√†y l√† ng∆∞·ªùi chƒÉm ch·ªâ v√† c√≥ tinh th·∫ßn tr√°ch nhi·ªám cao. positive neutral\n",
            "B·∫°n c·ªßa em l√† ng∆∞·ªùi d·ªÖ th∆∞∆°ng v√† tr·∫ª trung. positive neutral\n",
            "Ch·ªã ·∫•y l√† ng∆∞·ªùi th·∫≠t s·ª± t·∫≠n t√¢m v√† d√†nh tr·ªçn t√¢m huy·∫øt cho c√¥ng vi·ªác. positive neutral\n",
            "C√¥ ·∫•y r·∫•t s√°ng t·∫°o v√† ngh·ªá thu·∫≠t. positive neutral\n",
            "Gi√°o vi√™n c·ªßa t√¥i d·∫°y l√≠ thuy·∫øt v√† th·ª±c h√†nh v·ªÅ quy·ªÅn s·ªü h·ªØu tr√≠ tu·ªá v√† b·∫£o v·ªá nh√£n hi·ªáu. neutral positive\n",
            "N√†ng c√≥ s·ª± t·∫≠p trung cao ƒë·ªô v√† lu√¥n ƒë·∫°t ƒë∆∞·ª£c nh·ªØng th√†nh t√≠ch t·ªët. positive neutral\n",
            "Ph√≤ng h·ªçc ƒë∆∞·ª£c b·ªë tr√≠ nhi·ªÅu √°nh s√°ng t·ª± nhi√™n gi√∫p sinh vi√™n ti·∫øt ki·ªám ƒë∆∞·ª£c ƒëi·ªán trong qu√° tr√¨nh h·ªçc t·∫≠p. neutral positive\n",
            "M·ªôt s·ªë b·∫°n kh√° gi·ªèi nh∆∞ng l√∫c l√†m vi·ªác ch·∫≠m nh∆∞ r√πa neutral negative\n",
            "Anh ·∫•y l√† m·ªôt ng∆∞·ªùi h·ªçc nhanh v√† c√≥ kh·∫£ nƒÉng t√¨m ki·∫øm th√¥ng tin m·ªôt c√°ch hi·ªáu qu·∫£. positive neutral\n",
            "T√¥i r·∫•t th√≠ch k·∫øt h·ª£p c·ªßa m·ªôt s·ªë m√¥n h·ªçc c∆° b·∫£n v√† nh·ªØng ch·ªß ƒë·ªÅ th√∫ v·ªã v√† l·∫° l·∫´m. neutral positive\n",
            "Anh ta l√† m·ªôt ng∆∞·ªùi ƒë√°ng tin c·∫≠y v√† lu√¥n gi·ªØ l·ªùi h·ª©a c·ªßa m√¨nh. positive neutral\n",
            "Anh ·∫•y r·∫•t th·∫•u hi·ªÉu v√† gi√∫p ƒë·ª° nh·ªØng ng∆∞·ªùi g·∫∑p kh√≥ khƒÉn. positive neutral\n",
            "Gi·∫£ng vi√™n c√≥ th·ªÉ s·ª≠ d·ª•ng nhi·ªÅu ph∆∞∆°ng ph√°p gi·∫£ng d·∫°y kh√°c nhau ƒë·ªÉ thu h√∫t sinh vi√™n h·ªçc t·∫≠p. neutral positive\n",
            "Th·∫ßy gi√∫p ƒë·ª° sinh vi√™n ƒë·ªãnh h∆∞·ªõng ngh·ªÅ nghi·ªáp v√† ph√°t tri·ªÉn b·∫£n th√¢n. positive neutral\n",
            "C√°c ph√≤ng h·ªçc ƒë∆∞·ª£c trang b·ªã ƒë·∫ßy ƒë·ªß v·∫≠t d·ª•ng v√† thi·∫øt b·ªã ƒë·ªÉ ƒë√°p ·ª©ng nhu c·∫ßu h·ªçc t·∫≠p. positive neutral\n",
            "Khu√¥n vi√™n c√≥ ƒë·ªß ch·ªó ng·ªìi ngh·ªâ ng∆°i v√† th∆∞ gi√£n. positive neutral\n",
            "T√¥i r·∫•t th√≠ch l·ªëi thi·∫øt k·∫ø v√† trang tr√≠ c·ªßa tr∆∞·ªùng, n√≥ c·ª±c k·ª≥ ·∫•n t∆∞·ª£ng v√† s√°ng t·∫°o. positive neutral\n",
            "L·ªõp h·ªçc ƒë∆∞·ª£c ƒë∆∞a ra m·ªôt c√°ch sinh ƒë·ªông, h·∫•p d·∫´n v√† ƒë·∫ßy ƒë·ªß ki·∫øn th·ª©c chuy√™n m√¥n. positive neutral\n",
            "Gi·∫£ng vi√™n h∆∞·ªõng d·∫´n gi·ªèi v·ªõi l∆∞·ª£ng kinh nghi·ªám th·ª±c ti·ªÖn phong ph√∫. neutral positive\n",
            "Em th·∫•y b·∫°n c·ªßa m√¨nh r·∫•t nhanh nh·∫πn v√† chƒÉm ch·ªâ h·ªçc. positive neutral\n",
            "Khu v·ª±c sinh ho·∫°t c·ªßa sinh vi√™n ƒë∆∞·ª£c qu·∫£n l√Ω t·ªët, an ninh. neutral positive\n",
            "C∆° h·ªôi ƒë·ªÉ th·ª±c t·∫≠p trong m·ªôt m√¥i tr∆∞·ªùng th·ª±c t·∫ø. neutral positive\n",
            "Ch∆∞∆°ng tr√¨nh h·ªçc r·∫•t th√∫ v·ªã v√† ƒëa d·∫°ng. neutral positive\n",
            "C√°ch ƒë√°nh gi√° v√† ph∆∞∆°ng ph√°p gi·∫£ng d·∫°y c·ªßa tr∆∞·ªùng r·∫•t khuy·∫øn kh√≠ch v√† t·∫°o ƒë·ªông l·ª±c cho h·ªçc sinh. neutral positive\n",
            "Th·∫ßy gi·∫£ng d·∫°y r·∫•t chu ƒë√°o v√† chuy√™n nghi·ªáp. neutral positive\n",
            "Gi√°o vi√™n r·∫•t nhi·ªát t√¨nh v√† gi√∫p ƒë·ª° sinh vi√™n trong qu√° tr√¨nh h·ªçc t·∫≠p. positive neutral\n",
            "B·∫°n c·ªßa t√¥i l√† ng∆∞·ªùi r·∫•t duy√™n d√°ng v√† s√†nh ƒëi·ªáu. positive neutral\n",
            "M√¥n h·ªçc trong ch∆∞∆°ng tr√¨nh ƒë√†o t·∫°o ƒë∆∞·ª£c gi·∫£ng d·∫°y b·ªüi nh·ªØng gi√°o vi√™n gi·ªèi v√† c√≥ chuy√™n m√¥n cao. positive neutral\n",
            "Anh ·∫•y l√† m·ªôt ng∆∞·ªùi h·ªçc t·∫≠p t√≠ch c·ª±c v√† ƒëam m√™ trong vi·ªác t√¨m hi·ªÉu ki·∫øn th·ª©c m·ªõi. positive neutral\n",
            "C∆° s·ªü v·∫≠t ch·∫•t c·ªßa tr∆∞·ªùng ƒë∆∞·ª£c trang b·ªã hi·ªán ƒë·∫°i v√† ch·∫•t l∆∞·ª£ng. positive neutral\n",
            "Anh ·∫•y lu√¥n c√≥ nh·ªØng √Ω t∆∞·ªüng kh√°c bi·ªát v·ªõi nh·ªØng ng∆∞·ªùi kh√°c trong nh√≥m. neutral negative\n",
            "B·∫°n c·ªßa t√¥i r·∫•t chƒÉm ch·ªâ v√† lu√¥n ƒë√∫ng gi·ªù. positive neutral\n",
            "Nh·ªØng b√†i ki·ªÉm tra v√† ƒë√°nh gi√° ƒë·∫ßy th·ª≠ th√°ch trong ch∆∞∆°ng tr√¨nh ƒë√†o t·∫°o gi√∫p t√¥i tr·ªü n√™n chuy√™n nghi·ªáp h∆°n. neutral positive\n",
            "C√¥ ·∫•y r·∫•t nƒÉng ƒë·ªông v√† th√¢n thi·ªán ƒë·ªëi v·ªõi m·ªçi ng∆∞·ªùi trong l·ªõp. positive neutral\n",
            "Anh ·∫•y l√† m·ªôt ng∆∞·ªùi gi·ªèi v·ªÅ c√¥ng ngh·ªá v√† c√≥ kh·∫£ nƒÉng gi·∫£i quy·∫øt v·∫•n ƒë·ªÅ k·ªπ thu·∫≠t. positive neutral\n",
            "Anh b·∫°n c√πng l·ªõp r·∫•t h√≤a ƒë·ªìng v√† d·ªÖ g·∫ßn. positive neutral\n",
            "Ch∆∞∆°ng tr√¨nh ƒë√†o t·∫°o gi√∫p t√¥i trang b·ªã nh·ªØng k·ªπ nƒÉng m·ªÅm c·∫ßn thi·∫øt ƒë·ªÉ th√†nh c√¥ng trong t∆∞∆°ng lai. positive neutral\n",
            "C√°c khu v·ª±c ti·∫øp kh√°ch c·ªßa tr∆∞·ªùng ƒë∆∞·ª£c b·ªë tr√≠ th√¥ng tho√°ng v√† chuy√™n nghi·ªáp. neutral positive\n",
            "C√¥ng ngh·ªá v√† trang thi·∫øt b·ªã c·ªßa ƒë·∫°i h·ªçc t·ªët h∆°n so v·ªõi nhi·ªÅu tr∆∞·ªùng kh√°c. positive neutral\n",
            "Gi·∫£ng vi√™n n√†y d·∫°y r·∫•t t·ªët v√† truy·ªÅn c·∫£m h·ª©ng cho h·ªçc sinh. neutral positive\n",
            "Th·∫ßy t·∫°o ra m√¥i tr∆∞·ªùng h·ªçc t·∫≠p vui v·∫ª v√† ·∫•m c√∫ng. positive neutral\n",
            "Tr∆∞·ªùng lu√¥n gi·ªØ g√¨n s·∫°ch s·∫Ω v√† d·ªÖ d√†ng b·∫£o tr√¨ h∆°n nh·ªù v√†o c√°c thi·∫øt b·ªã trang tr√≠ v√† c∆° s·ªü v·∫≠t ch·∫•t. positive neutral\n",
            "ƒê·ªôi ng≈© k·ªπ thu·∫≠t c·ªßa tr∆∞·ªùng lu√¥n c√≥ m·∫∑t ƒë·ªÉ gi√∫p ƒë·ª° v√† gi·∫£i quy·∫øt c√°c v·∫•n ƒë·ªÅ k·ªπ thu·∫≠t cho sinh vi√™n. positive neutral\n",
            "ƒê·ªôi ng≈© nh√¢n vi√™n c·ªßa tr∆∞·ªùng r·∫•t th√¢n thi·ªán v√† h·ªó tr·ª£ t·∫≠n t√¨nh. neutral positive\n",
            "Ch∆∞∆°ng tr√¨nh gi·∫£ng d·∫°y r·∫•t ph√π h·ª£p v·ªõi nhu c·∫ßu c·ªßa sinh vi√™n. neutral positive\n",
            "C√¥ ·∫•y r·∫•t nh·∫°y c·∫£m v√† t√¢m l√Ω trong gi·∫£ng d·∫°y. positive neutral\n",
            "Th·∫ßy c√¥ ƒë·ªÅ cao c√°c tr·∫ª em tr√™n h·∫øt v√† mang ƒë·∫øn cho ch√∫ng ta m·ªôt m√¥i tr∆∞·ªùng h·ªçc t·∫≠p khuy·∫øn kh√≠ch v√† th√¢n thi·ªán. positive neutral\n",
            "Khu v·ª±c cho sinh vi√™n t·ª± h·ªçc kh√° tho·∫£i m√°i v√† ti·ªán nghi. neutral positive\n",
            "C√°c khu v·ª±c ƒë·∫∑t t·ªß h·ªì s∆° c·ªßa tr∆∞·ªùng ƒë∆∞·ª£c b·∫£o qu·∫£n an to√†n v√† ch√≠n chu. neutral positive\n",
            "T√¥i c·∫£m th·∫•y r·∫•t ·∫•m √°p v√† tho·∫£i m√°i khi s·ª≠ d·ª•ng ph√≤ng sinh ho·∫°t chung. positive neutral\n",
            "Gi·∫£ng vi√™n c·∫≠p nh·∫≠t th√¥ng tin nhanh ch√≥ng v√† c√≥ hi·ªÉu bi·∫øt s√¢u v·ªÅ th·ª±c t·∫ø c·ªßa ng√†nh h·ªçc. positive neutral\n",
            "C·∫≠u ·∫•y r·∫•t c·∫©n th·∫≠n v√† t·ªâ m·ªâ trong c√¥ng vi·ªác. positive neutral\n",
            "B·∫°n c·ªßa t√¥i r·∫•t y√™u th√≠ch nh·ªØng tr·∫£i nghi·ªám m·ªõi. positive neutral\n",
            "Kh√¥ng gian n·ªôi th·∫•t c·ªßa ph√≤ng h·ªçc r·∫•t t·ªët, ƒë∆∞·ª£c thi·∫øt k·∫ø ƒë·ªÉ gi√∫p tƒÉng s·ª± t·∫≠p trung c·ªßa sinh vi√™n. positive neutral\n",
            "T√¥i c·∫£m th·∫•y r·∫•t c·∫£m k√≠ch v√¨ gi·∫£ng vi√™n c·ªßa m√¨nh lu√¥n s·∫µn s√†ng gi√∫p ƒë·ª° sinh vi√™n trong b·∫•t c·ª© l√∫c n√†o. positive neutral\n",
            "T√¥i r·∫•t h√†i l√≤ng v·ªõi c√°c ph√≤ng h·ªçc ·ªü ƒë√¢y. positive neutral\n",
            "Gi·∫£ng vi√™n gi√∫p sinh vi√™n h√¨nh th√†nh ph∆∞∆°ng ph√°p h·ªçc t·∫≠p hi·ªáu qu·∫£. positive neutral\n",
            "T√¥i h√†i l√≤ng v·ªõi ch∆∞∆°ng tr√¨nh ƒë√†o t·∫°o v√¨ ƒë√£ gi√∫p t√¥i hi·ªÉu r√µ h∆°n v·ªÅ c√°c ph∆∞∆°ng th·ª©c h·ªçc t·∫≠p kh√°c nhau. neutral positive\n",
            "Th√¥ng tin tr∆∞·ªùng ƒë∆∞·ª£c ƒëƒÉng t·∫£i ƒë·∫ßy ƒë·ªß v√† chi ti·∫øt. neutral positive\n",
            "Ph√≤ng th·ª±c h√†nh c√≥ trang thi·∫øt b·ªã v√† c√¥ng c·ª• hi·ªán ƒë·∫°i. positive neutral\n",
            "C√°c ph√≤ng th√≠ nghi·ªám c·ªßa tr∆∞·ªùng ƒë∆∞·ª£c trang b·ªã ƒë·∫ßy ƒë·ªß thi·∫øt b·ªã v√† c√¥ng ngh·ªá hi·ªán ƒë·∫°i. positive neutral\n",
            "T√¥i th·∫≠t s·ª± ƒë√°nh gi√° cao c∆° s·ªü v·∫≠t ch·∫•t c·ªßa tr∆∞·ªùng, n√≥ ƒë√°p ·ª©ng t·ªët nhu c·∫ßu h·ªçc t·∫≠p v√† gi·∫£i tr√≠ c·ªßa sinh vi√™n. positive neutral\n",
            "T√¥i c·∫£m th·∫•y h·ªçc ph√≠ h·ª£p l√≠ v·ªõi ch·∫•t l∆∞·ª£ng ƒë√†o t·∫°o c·ªßa tr∆∞·ªùng. neutral positive\n",
            "C∆° h·ªôi ƒë·ªÉ ƒëi du h·ªçc v√† tham gia c√°c ch∆∞∆°ng tr√¨nh trao ƒë·ªïi v·ªõi c√°c tr∆∞·ªùng ƒë·∫°i h·ªçc n∆∞·ªõc ngo√†i. neutral positive\n",
            "Ch∆∞∆°ng tr√¨nh ƒë√†o t·∫°o gi√∫p t√¥i ph√°t tri·ªÉn nh·ªØng k·ªπ nƒÉng m√† t√¥i c·∫ßn. positive neutral\n",
            "M√¥n h·ªçc t·∫≠p trung v√†o vi·ªác th·ª±c h√†nh v√† ·ª©ng d·ª•ng ki·∫øn th·ª©c v√†o th·ª±c t·∫ø. positive neutral\n",
            "C√°c khu v·ª±c l∆∞u tr√∫ c·ªßa tr∆∞·ªùng ƒë∆∞·ª£c trang b·ªã ƒë·∫ßy ƒë·ªß ti·ªán nghi ƒë·ªÉ ƒë·∫£m b·∫£o s·ª± tho·∫£i m√°i cho sinh vi√™n. positive neutral\n",
            "M√¥n h·ªçc gi√∫p sinh vi√™n ph√°t tri·ªÉn t∆∞ duy ph√°n ƒëo√°n v√† x·ª≠ l√Ω t√¨nh hu·ªëng trong c√¥ng vi·ªác. positive neutral\n",
            "Tr∆∞·ªùng c√≥ nhi·ªÅu ch∆∞∆°ng tr√¨nh h·ªó tr·ª£ cho sinh vi√™n ƒë·∫°t th√†nh t√≠ch cao. neutral positive\n",
            "Anh ta l√† m·ªôt ng∆∞·ªùi vui t√≠nh v√† d·ªÖ g·∫ßn. positive neutral\n",
            "Th·∫ßy ƒë√£ gi√∫p t√¥i c√≥ ƒë∆∞·ª£c nhi·ªÅu ki·∫øn th·ª©c quan tr·ªçng v√† k·ªπ nƒÉng c·∫ßn thi·∫øt trong c√¥ng vi·ªác. positive neutral\n",
            "Gi√°o tr√¨nh r·∫•t th·ª±c ti·ªÖn v√† ƒë√°p ·ª©ng ƒë∆∞·ª£c y√™u c·∫ßu c·ªßa c√¥ng vi·ªác hi·ªán nay. positive neutral\n",
            "ƒê·ªôi ng≈© nh√¢n vi√™n b·∫£o tr√¨ tr∆∞·ªùng lu√¥n h·ªó tr·ª£ v√† s·ª≠ d·ª•ng c√°c ti·ªán √≠ch t·ªët nh·∫•t. positive neutral\n",
            "Khu v·ª±c khu√¢n vi√™n quanh tr∆∞·ªùng xanh t∆∞∆°i, nh·ªØng tin t·ª©c, th√¥ng b√°o c·ªßa tr∆∞·ªùng ƒë∆∞·ª£c ph√°t tr·ª±c ti·∫øp, r√µ r√†ng, d·ªÖ ti·∫øp c·∫≠n. positive neutral\n",
            "C√¥ b·∫°n n√†y r·∫•t hi·ªÅn l√†nh v√† t·ªët b·ª•ng. positive neutral\n",
            "Gi·∫£ng vi√™n th∆∞·ªùng ƒë∆∞a ra nh·ªØng c√¢u h·ªèi kh√≥ ƒë·ªÉ th√∫c ƒë·∫©y h·ªçc sinh nghi√™n c·ª©u th√™m. negative neutral\n",
            "C√°c b√†i gi·∫£ng d·ªÖ hi·ªÉu v√† h·ªó tr·ª£ h·ªçc t·∫≠p t·ªët. positive neutral\n",
            "Ch∆∞∆°ng tr√¨nh ƒë√†o t·∫°o gi√∫p sinh vi√™n ph√°t tri·ªÉn k·ªπ nƒÉng qu·∫£n l√Ω th·ªùi gian v√† t·ª± ch·ªß trong h·ªçc t·∫≠p. positive neutral\n",
            "Th·∫ßy lu√¥n c·∫≠p nh·∫≠t ki·∫øn th·ª©c m·ªõi nh·∫•t ƒë·ªÉ gi·∫£ng d·∫°y cho sinh vi√™n. positive neutral\n",
            "Gi√°o vi√™n n√†y kh√¥ng t∆∞∆°ng t√°c v·ªõi sinh vi√™n nhi·ªÅu l·∫Øm trong l·ªõp h·ªçc. neutral negative\n",
            "Gi·∫£ng vi√™n n√†y lu√¥n ki·ªÉm tra nh·ªØng b√†i t·∫≠p t·ª± l√†m c·ªßa sinh vi√™n. neutral negative\n",
            "Ch∆∞∆°ng tr√¨nh gi·∫£ng d·∫°y k·∫øt h·ª£p gi·ªØa l√Ω thuy·∫øt v√† th·ª±c h√†nh t·ªët. neutral positive\n",
            "Th·∫ßy d·∫°y cho sinh vi√™n c√°ch suy nghƒ© ƒëa chi·ªÅu v√† ph√¢n t√≠ch d·ªØ li·ªáu m·ªôt c√°ch n√¢ng cao. positive neutral\n",
            "Th·∫ßy ƒë∆∞a ra nh·ªØng t√†i li·ªáu v√† th√≠ nghi·ªám th·ª±c t·∫ø ƒë·ªÉ gi√∫p h·ªçc sinh h·ªçc t·∫≠p t·ªët h∆°n. neutral positive\n",
            "Thi·∫øt b·ªã v√† ph∆∞∆°ng ti·ªán gi·∫£ng d·∫°y c·ªßa tr∆∞·ªùng c·∫ßn ƒë∆∞·ª£c n√¢ng c·∫•p. neutral negative\n",
            "Gi·∫£ng vi√™n n√†y quan t√¢m ƒë·∫øn s·ª± ti·∫øn b·ªô c·ªßa h·ªçc sinh v√† s·∫µn s√†ng gi·∫£i ƒë√°p m·ªçi th·∫Øc m·∫Øc c·ªßa h·ªç. positive neutral\n",
            "Gi·∫£ng vi√™n r·∫•t d·ªÖ ti·∫øp c·∫≠n v√† th√¢n thi·ªán, d·ªÖ t·∫°o ƒë∆∞·ª£c m√¥i tr∆∞·ªùng h·ªçc t·∫≠p t√≠ch c·ª±c. positive neutral\n",
            "C√¥ b·∫°n n√†y r·∫•t l·ªãch s·ª± v√† t·∫ø nh·ªã. positive neutral\n",
            "Anh ta l√† ng∆∞·ªùi r·∫•t nƒÉng ƒë·ªông v√† lu√¥n t·∫°o ƒë·ªông l·ª±c cho ng∆∞·ªùi kh√°c. positive neutral\n",
            "Anh ta l√† m·ªôt ng∆∞·ªùi th√¢n thi·ªán v√† lu√¥n l·∫Øng nghe ng∆∞·ªùi kh√°c. positive neutral\n",
            "C√°c ho·∫°t ƒë·ªông ƒë·ªëi ngo·∫°i c·ªßa tr∆∞·ªùng ƒëa d·∫°ng v√† h·∫•p d·∫´n cho sinh vi√™n. neutral positive\n",
            "Gi·∫£ng ƒë∆∞·ªùng r·ªông r√£i v√† s·∫°ch s·∫Ω. neutral positive\n",
            "C√¥ gi√°o c·ªßa t√¥i l√† ng∆∞·ªùi r·∫•t th√¥ng th√°i v√† gi√†u kinh nghi·ªám. positive neutral\n",
            "ƒê·∫°i h·ªçc t√¥i c√≥ nhi·ªÅu c√¥ng tr√¨nh ki·∫øn tr√∫c ƒë·∫πp v√† ·∫•n t∆∞·ª£ng. positive neutral\n",
            "C√°c khu v·ª±c ph·ª•c v·ª• sinh vi√™n ƒë∆∞·ª£c ph·ªß s√≥ng wifi gi√∫p cho sinh vi√™n c√≥ th·ªÉ ra ngo√†i ƒë·ªÉ h·ªçc t·∫≠p ho·∫∑c gi·∫£i tr√≠. neutral positive\n",
            "Anh ·∫•y l√† ng∆∞·ªùi lu√¥n d√†nh th·ªùi gian cho s·ª± nghi·ªáp v√† h·ªçc t·∫≠p c·ªßa m√¨nh. positive neutral\n",
            "T√¥i r·∫•t ng∆∞·ª°ng m·ªô kh·∫£ nƒÉng l√†m vi·ªác c·ªßa anh ·∫•y. positive neutral\n",
            "Gi·∫£ng vi√™n r·∫•t th√¥ng minh v√† c√≥ ki·∫øn th·ª©c s√¢u r·ªông. positive neutral\n",
            "T√¥i c·∫£m th·∫•y gi·∫£ng vi√™n n√†y lu√¥n ƒë·∫∑t s·ª± c·∫ßn thƒÉm d√≤ tr∆∞·ªõc khi ƒë∆∞a ra quy·∫øt ƒë·ªãnh trong b√†i gi·∫£ng. negative neutral\n",
            "Anh ·∫•y l√† m·ªôt ng∆∞·ªùi r·∫•t ƒë√°ng tin c·∫≠y, lu√¥n lu√¥n gi·ªØ l·ªùi h·ª©a. positive neutral\n",
            "Th·∫ßy d·∫°y r·∫•t th√¥ng minh v√† t·∫≠p trung v√†o vi·ªác gi·∫£ng d·∫°y cho h·ªçc sinh hi·ªÉu b√†i h·ªçc. neutral positive\n",
            "Th∆∞ vi·ªán tr∆∞·ªùng c√≥ nhi·ªÅu ch·ªß ƒë·ªÅ kh√°c nhau gi√∫p sinh vi√™n t√¨m ƒë∆∞·ª£c ngu·ªìn t√†i li·ªáu ph√π h·ª£p v·ªõi nhu c·∫ßu h·ªçc t·∫≠p c·ªßa m√¨nh. neutral positive\n",
            "T√¥i r·∫•t h√†i l√≤ng v·ªõi c√°c d·ªãch v·ª• h·ªó tr·ª£ c·ªßa tr∆∞·ªùng, ƒë·∫∑c bi·ªát l√† c√°c d·ªãch v·ª• t∆∞ v·∫•n v√† t√†i ch√≠nh. positive neutral\n",
            "Th·∫ßy cung c·∫•p cho sinh vi√™n c√°c t√†i nguy√™n v√† c√¥ng c·ª• h·ªó tr·ª£ gi·∫£ng d·∫°y hi·ªáu qu·∫£. neutral positive\n",
            "Th·∫ßy l√† ng∆∞·ªùi gi·∫£ng d·∫°y gi·ªèi nh·∫•t m√† t√¥i t·ª´ng g·∫∑p. positive neutral\n",
            "Tr∆∞·ªùng cung c·∫•p ƒë·∫ßy ƒë·ªß c√°c th√¥ng tin v√† t√†i li·ªáu cho sinh vi√™n ƒë·ªÉ gi√∫p t√¥i h·ªçc t·∫≠p m·ªôt c√°ch hi·ªáu qu·∫£. neutral positive\n",
            "Tr∆∞·ªùng c√≥ cung c·∫•p wifi mi·ªÖn ph√≠ cho sinh vi√™n, gi√∫p c√°c em ti·ªán l·ª£i h∆°n trong vi·ªác truy c·∫≠p internet. positive neutral\n",
            "Th·∫ßy d·∫°y r·∫•t t√¢m huy·∫øt v√† c√≥ nhi·ªÅu ƒë√≥ng g√≥p cho s·ª± ph√°t tri·ªÉn c·ªßa sinh vi√™n. positive neutral\n",
            "Khu v·ª±c ng·ªìi ch·ªù ƒë·ª£i ƒë∆∞·ª£c trang b·ªã ƒë·∫ßy ƒë·ªß gh·∫ø v√† trang thi·∫øt b·ªã gi√∫p sinh vi√™n ch·ªù ƒë·ª£i m·ªôt c√°ch tho·∫£i m√°i. positive neutral\n",
            "Gi·∫£ng vi√™n n√†y ƒë∆∞a ra nh·ªØng b√†i gi·∫£ng r√µ r√†ng v√† h·∫•p d·∫´n, gi√∫p cho h·ªçc sinh hi·ªÉu b√†i h·ªçc d·ªÖ d√†ng h∆°n. neutral positive\n",
            "C√¥ b·∫°n n√†y l√† m·ªôt gi·∫£ng vi√™n tuy·ªát v·ªùi, lu√¥n h·ªó tr·ª£ v√† gi√∫p ƒë·ª° sinh vi√™n. positive neutral\n",
            "C√°c ph√≤ng h·ªçc ƒë∆∞·ª£c trang b·ªã m√°y chi·∫øu v√† b·∫£ng tr·∫Øng gi√∫p gi·∫£ng vi√™n gi·∫£ng d·∫°y t·ªët h∆°n. positive neutral\n",
            "T√¥i r·∫•t th√≠ch c√°ch m√† ch∆∞∆°ng tr√¨nh ƒë√†o t·∫°o ƒë∆∞·ª£c t·ªï ch·ª©c v√† qu·∫£n l√Ω. positive neutral\n",
            "H·ªá th·ªëng wifi mi·ªÖn ph√≠ s·ª≠ d·ª•ng thu·∫≠n ti·ªán. positive neutral\n",
            "C√¥ ·∫•y l√† m·ªôt ng∆∞·ªùi r·∫•t gi·ªèi trong vi·ªác gi·∫£ng d·∫°y v√† r·∫•t nhi·ªát t√¨nh. positive neutral\n",
            "K√Ω t√∫c x√° c·ªßa tr∆∞·ªùng r·∫•t ti·ªán nghi v√† s·∫°ch s·∫Ω. positive neutral\n",
            "C√¥ n√†y l√† ng∆∞·ªùi r·∫•t chuy√™n nghi·ªáp v√† c√≥ kinh nghi·ªám gi·∫£ng d·∫°y l√¢u nƒÉm. positive neutral\n",
            "Gi·∫£ng vi√™n lu√¥n t·∫°o ƒëi·ªÅu ki·ªán ƒë·ªÉ sinh vi√™n c√≥ th·ªÉ t·ª± t√¨m hi·ªÉu v√† t·ªët h∆°n trong h·ªçc t·∫≠p. neutral positive\n",
            "Ch∆∞∆°ng tr√¨nh h·ªçc t·∫≠p ƒë√°p ·ª©ng ƒë∆∞·ª£c nh·ªØng y√™u c·∫ßu c·ªßa ngh·ªÅ nghi·ªáp. neutral positive\n",
            "H·ªá th·ªëng camera an ninh ho·∫°t ƒë·ªông t·ªët v√† ƒë·∫£m b·∫£o an to√†n cho sinh vi√™n. positive neutral\n",
            "C√≥ nhi·ªÅu v·∫•n ƒë·ªÅ v·ªÅ thi·∫øt b·ªã v√† h·ªá th·ªëng m·∫°ng trong c√°c ph√≤ng h·ªçc. negative neutral\n",
            "B·∫°n c·ªßa t√¥i l√† ng∆∞·ªùi r·∫•t nƒÉng ƒë·ªông v√† lu√¥n c√≥ nh·ªØng √Ω t∆∞·ªüng m·ªõi l·∫°. positive neutral\n",
            "Th·∫ßy r·∫•t nhi·ªát t√¨nh v·ªõi c√°c c√¢u h·ªèi c·ªßa sinh vi√™n. neutral positive\n",
            "Tr∆∞·ªùng ƒë·∫°i h·ªçc n√†y l√† n∆°i l√Ω t∆∞·ªüng ƒë·ªÉ giao l∆∞u v√† k·∫øt n·ªëi v·ªõi nh·ªØng ng∆∞·ªùi b·∫°n m·ªõi. positive neutral\n",
            "Tr∆∞·ªùng h·ªó tr·ª£ sinh vi√™n ƒëƒÉng k√Ω tham gia c√°c k·ª≥ thi ch·ª©ng ch·ªâ v√† ƒë√†o t·∫°o kh√°c. neutral positive\n",
            "M√¥n h·ªçc kh√¥ng ph√π h·ª£p v·ªõi chuy√™n ng√†nh c·ª• th·ªÉ v√† ƒë·ªô kh√≥ qu√° cao. negative neutral\n",
            "C√¥ ·∫•y th√¥ng minh v√† c√≥ kh·∫£ nƒÉng t∆∞ duy ph·∫£n bi·ªán. positive neutral\n",
            "ƒê·ªìng nghi·ªáp c·ªßa t√¥i r·∫•t h·ªó tr·ª£ v√† ƒë·ªìng c·∫£m. neutral positive\n",
            "Anh ·∫•y c√≥ tr√≠ th√¥ng minh s√°ng su·ªët v√† s·ª± nghi·ªáp c·ªßa anh ·∫•y tuy·ªát v·ªùi. positive neutral\n",
            "S·ª± ƒëa d·∫°ng c·ªßa ch∆∞∆°ng tr√¨nh ƒë√†o t·∫°o gi√∫p tƒÉng t√≠nh linh ho·∫°t cho sinh vi√™n. neutral positive\n",
            "Th·∫ßy c√≥ kh·∫£ nƒÉng d·∫°y h·ªçc ƒëa d·∫°ng ƒë·ªÉ ph√π h·ª£p v·ªõi c√°c h·ªçc sinh c√≥ n·ªÅn t·∫£ng k√©m. neutral positive\n",
            "Th·∫ßy th∆∞·ªùng t·∫°o ra c√°c ho·∫°t ƒë·ªông nh√≥m ƒë·ªÉ tƒÉng c∆∞·ªùng t∆∞∆°ng t√°c gi·ªØa h·ªçc vi√™n v√† h·ªçc vi√™n. neutral positive\n",
            "B·∫°n s·∫Ω kh√¥ng th·ªÉ t√¨m th·∫•y m·ªôt gi·∫£ng vi√™n t·ªët h∆°n ·ªü b·∫•t k·ª≥ n∆°i n√†o kh√°c. negative positive\n",
            "Th·∫ßy c√≥ ph·∫ßn n√†o gi·ªëng nh∆∞ ng∆∞·ªùi b·∫°n ƒë·ªìng h√†nh trong h√†nh tr√¨nh h·ªçc t·∫≠p c·ªßa sinh vi√™n. positive neutral\n",
            "Gi·∫£ng vi√™n r·∫•t th√¥ng minh v√† am hi·ªÉu chuy√™n ng√†nh. positive neutral\n",
            "C·∫≠u ·∫•y r·∫•t quan t√¢m ƒë·∫øn vi·ªác h·ªçc t·∫≠p v√† ph√°t tri·ªÉn b·∫£n th√¢n. positive neutral\n",
            "C√°c ph√≤ng h·ªçc v√† ph√≤ng th√≠ nghi·ªám trong tr∆∞·ªùng ƒë∆∞·ª£c trang b·ªã ƒë·∫ßy ƒë·ªß thi·∫øt b·ªã ƒë·ªÉ ƒë·∫£m b·∫£o ch·∫•t l∆∞·ª£ng h·ªçc t·∫≠p. positive neutral\n",
            "Gi·∫£ng vi√™n l√† m·ªôt ng∆∞·ªùi c√≥ t√°c phong v√† phong c√°ch gi·∫£ng d·∫°y r·∫•t chuy√™n nghi·ªáp. neutral positive\n",
            "Th·∫ßy c√¥ gi·∫£ng d·∫°y ƒë·ªÅu r·∫•t h√≤a nh√£ v√† th√¢n thi·ªán, gi√∫p t√¥i c·∫£m th·∫•y tho·∫£i m√°i h∆°n trong l·ªõp h·ªçc. neutral positive\n",
            "C√°c d·ªãch v·ª• th∆∞ vi·ªán c·ªßa tr∆∞·ªùng r·∫•t t·ªët v√† ƒë∆∞·ª£c c·∫≠p nh·∫≠t th∆∞·ªùng xuy√™n. positive neutral\n",
            "Gi·∫£ng vi√™n r·∫•t trung th√†nh v·ªõi vai tr√≤ c·ªßa m√¨nh v√† gi·∫£ng d·∫°y r·∫•t ch√≠nh x√°c. neutral positive\n",
            "Gi·∫£ng vi√™n d·∫°y r·∫•t ch·∫•t l∆∞·ª£ng v√† hi·ªáu qu·∫£. neutral positive\n",
            "T√¥i hi v·ªçng tr∆∞·ªùng t√¥i s·∫Ω d√†nh nhi·ªÅu th·ªùi gian h∆°n ƒë·ªÉ c·∫£i thi·ªán c∆° s·ªü v·∫≠t ch·∫•t v√† n√¢ng cao ch·∫•t l∆∞·ª£ng gi·∫£ng d·∫°y. neutral negative\n",
            "Ch∆∞∆°ng tr√¨nh ƒë√†o t·∫°o r·∫•t chuy√™n nghi·ªáp. neutral positive\n",
            "Gi·∫£ng vi√™n n√†y c√≥ kh·∫£ nƒÉng ƒë·ªìng c·∫£m v√† hi·ªÉu ƒë∆∞·ª£c nh·ªØng kh√≥ khƒÉn sinh vi√™n ƒëang g·∫∑p ph·∫£i. positive neutral\n",
            "Sau khi t·ªët nghi·ªáp, sinh vi√™n c√≥ th·ªÉ c√≥ nhi·ªÅu c∆° h·ªôi vi·ªác l√†m t·ªët trong lƒ©nh v·ª±c c·ªßa m√¨nh. neutral positive\n",
            "T√¥i mong ƒë·ª£i gi·∫£ng vi√™n s·∫Ω s·ª≠a ngay l·∫≠p t·ª©c nh·ªØng sai s√≥t trong b√†i gi·∫£ng ƒë·ªÉ tr√°nh nh·∫ßm l·∫´n. negative neutral\n",
            "Kh√¥ng gi·ªõi h·∫°n v·ªÅ th·ªùi gian h·ªçc t·∫≠p. neutral positive\n",
            "Gi·∫£ng vi√™n r·∫•t l·ªãch s·ª± v√† t√¥n tr·ªçng sinh vi√™n. positive neutral\n",
            "T√¥i c·∫£m th·∫•y ki·∫øn th·ª©c ƒë∆∞·ª£c truy·ªÅn ƒë·∫°t s√¢u s·∫Øc v√† c√≥ t√≠nh ·ª©ng d·ª•ng cao. positive neutral\n",
            "B·∫°n c·ªßa t√¥i r·∫•t t·ªâ m·ªâ v√† l∆∞u √Ω ƒë·∫øn chi ti·∫øt. positive neutral\n",
            "Ch∆∞∆°ng tr√¨nh h·ªçc ph√π h·ª£p v·ªõi y√™u c·∫ßu c·ªßa th·ªã tr∆∞·ªùng v√† ƒë√°p ·ª©ng ƒë∆∞·ª£c nhu c·∫ßu c·ªßa h·ªçc vi√™n. neutral positive\n",
            "Khu√¥n vi√™n tr∆∞·ªùng r·ªông l·ªõn v√† ƒë∆∞·ª£c b·ªë tr√≠ h·ª£p l√≠. neutral positive\n",
            "Tr∆∞·ªùng c√≥ c√°c ch∆∞∆°ng tr√¨nh h·ªçc b·ªïng v√† t√†i tr·ª£ gi√∫p ƒë·ª° nh·ªØng sinh vi√™n c√≥ th√†nh t√≠ch h·ªçc t·∫≠p cao. positive neutral\n",
            "C√°c cƒÉn tin ·ªü ƒë√¢y r·∫•t ngon v√† gi√° c·∫£ ph·∫£i chƒÉng. positive neutral\n",
            "T√¥i c·∫£m th·∫•y ch∆∞∆°ng tr√¨nh h·ªçc kh√¥ng th·ª±c s·ª± ƒë√°p ·ª©ng ƒë∆∞·ª£c nhu c·∫ßu ng√†nh ngh·ªÅ hi·ªán t·∫°i. neutral negative\n",
            "Th·∫ßy n√†y t·ªï ch·ª©c v√† qu·∫£n l√Ω gi·∫£ng d·∫°y r·∫•t t·ªët. neutral positive\n",
            "Gi·∫£ng vi√™n n√†y qu√° ƒë√≤i h·ªèi cao v·ªÅ ƒëi·ªÉm s·ªë v√† ƒë√¥i khi l√†m kh√≥ h·ªçc sinh. negative neutral\n",
            "T√¥i r·∫•t y√™u th√≠ch kh√¥ng gian c·ªßa th∆∞ vi·ªán v√† c√°c d·ªãch v·ª• b·ªï tr·ª£ t·∫°i ƒë√¢y. positive neutral\n",
            "C√°c ph√≤ng h·ªçc ƒë∆∞·ª£c trang b·ªã ti·ªán nghi v√† ƒë·∫ßy ƒë·ªß thi·∫øt b·ªã. positive neutral\n",
            "Ch∆∞∆°ng tr√¨nh h·ªçc r·∫•t linh ho·∫°t v√† c√≥ th·ªÉ ph√π h·ª£p v·ªõi nhu c·∫ßu c·ªßa t·ª´ng sinh vi√™n. neutral positive\n",
            "Th·∫ßy n√†y l·∫Øng nghe h·ªçc sinh r·∫•t chu ƒë√°o. neutral positive\n",
            "Gi·∫£ng vi√™n n√†y kh√¥ng gi√∫p ƒë∆∞·ª£c h·ªçc sinh ƒë·∫°t ƒë∆∞·ª£c nh·ªØng m·ª•c ti√™u c·ªßa h·ªç. negative neutral\n",
            "K√Ω t√∫c x√° c·ªßa tr∆∞·ªùng c√≥ c√°c d·ªãch v·ª• ti·ªán √≠ch nh∆∞ t·∫≠p gym v√† qu·∫ßy c√† ph√™. neutral positive\n",
            "Tr∆∞·ªùng ƒë·∫∑t nhi·ªÅu ∆∞u ti√™n cho s·ª± ph√°t tri·ªÉn to√†n di·ªán c·ªßa sinh vi√™n. positive neutral\n",
            "ƒê·ªôi ng≈© nh√¢n vi√™n ·ªü ƒë√¢y lu√¥n h·ªó tr·ª£ v√† ƒë√°p ·ª©ng m·ªçi nhu c·∫ßu c·ªßa sinh vi√™n. positive neutral\n",
            "T√¥i h∆∞·ªõng ƒë·∫øn m·ª•c ti√™u c·ªßa b·∫£n th√¢n v·ªõi s·ª± gi√∫p ƒë·ª° c·ªßa gi·∫£ng vi√™n. neutral positive\n",
            "Ph√≤ng th√≠ nghi·ªám ·ªü tr∆∞·ªùng ƒë∆∞·ª£c trang b·ªã ƒë·∫ßy ƒë·ªß thi·∫øt b·ªã v√† m√°y m√≥c. positive neutral\n",
            "ƒê·ªôi ng≈© gi√°o vi√™n c√≥ nhi·ªÅu tri th·ª©c v√† kinh nghi·ªám gi√∫p sinh vi√™n n·∫Øm v·ªØng ki·∫øn th·ª©c chuy√™n m√¥n. neutral positive\n",
            "C√°c ph√≤ng h·ªçc ƒë∆∞·ª£c ƒë√°nh gi√° l√† kh√¥ng gian r·ªông r√£i v√† tho·∫£i m√°i. neutral positive\n",
            "Tr∆∞·ªùng ƒë·∫°i h·ªçc n√†y lu√¥n gi·ªØ v·ªá sinh v√† s·ª≠a ch·ªØa t·ªët h·ªá th·ªëng c∆° s·ªü v·∫≠t ch·∫•t. positive neutral\n",
            "B·∫°n c·ªßa t√¥i r·∫•t c·ªüi m·ªü v√† d·ªÖ th∆∞∆°ng v·ªõi m·ªçi ng∆∞·ªùi. positive neutral\n",
            "B√£i ƒë·ªó xe c·ªßa tr∆∞·ªùng r·ªông r√£i v√† an to√†n. positive neutral\n",
            "Gi·∫£ng vi√™n gi√∫p sinh vi√™n ph√°t tri·ªÉn v√† r√®n luy·ªán k·ªπ nƒÉng s√°ng t·∫°o. positive neutral\n",
            "Th·∫ßy l√† m·ªôt gi·∫£ng vi√™n r·∫•t th√¢n thi·ªán v√† lu√¥n s·∫µn s√†ng tr·ª£ gi√∫p sinh vi√™n. neutral positive\n",
            "Gi·∫£ng vi√™n n√†y l√† ng∆∞·ªùi r·∫•t chu ƒë√°o v√† nhi·ªát t√¨nh. positive neutral\n",
            "Ph√≤ng h·ªçc ƒë∆∞·ª£c trang b·ªã s·∫£n ph·∫©m ƒë√°nh gi√° nh∆∞ m√°y chi·∫øu, m√°y t√≠nh, tivi, loa, ƒë·ªám ng·ªìi, ... positive neutral\n",
            "C√°c ho·∫°t ƒë·ªông gi√°o d·ª•c kh√° ƒëa d·∫°ng v√† phong ph√∫. neutral positive\n",
            "C√°c b√†i ki·ªÉm tra ƒë∆∞·ª£c thi·∫øt k·∫ø t·ªët v√† c√¥ng b·∫±ng. neutral positive\n",
            "Th·∫ßy lu√¥n d·∫°y sinh vi√™n c√°ch t∆∞ duy v√† ph√°t tri·ªÉn k·ªπ nƒÉng. positive neutral\n",
            "T·∫•t c·∫£ sinh vi√™n ƒë∆∞·ª£c ƒë√≥n ti·∫øp v·ªõi c√°ch th·ª©c tr·ªã nh·∫π nh√†ng v√† d·ªÖ d√†ng. positive neutral\n",
            "Gi·∫£ng vi√™n n√†y ƒë√¥i l√∫c qu√™n chuy·ªán ch√≠nh ƒë·ªÉ gi·∫£i th√≠ch nh·ªØng chi ti·∫øt kh√¥ng quan tr·ªçng. negative neutral\n",
            "L·ªõp h·ªçc ƒë∆∞·ª£c t·ªï ch·ª©c khoa h·ªçc, h·ªó tr·ª£ sinh vi√™n kh√¥ng ch·ªâ gi√∫p h·ªçc m√† c√≤n gi√∫p sinh vi√™n r√®n luy·ªán k·ªπ nƒÉng qu·∫£n l√Ω th·ªùi gian. positive neutral\n",
            "B·∫°n c·ªßa t√¥i r·∫•t gi·ªèi qu·∫£n l√Ω th·ªùi gian. positive neutral\n",
            "Tr∆∞·ªùng cung c·∫•p r·∫•t nhi·ªÅu thi·∫øt b·ªã v√† ph·∫ßn m·ªÅm h·ªØu √≠ch cho vi·ªác h·ªçc t·∫≠p v√† nghi√™n c·ª©u. neutral positive\n",
            "C√¥ ·∫•y c√≥ kh·∫£ nƒÉng ƒë∆∞a ra quy·∫øt ƒë·ªãnh m·ªôt c√°ch ƒë√∫ng ƒë·∫Øn v√† hi·ªáu qu·∫£. neutral positive\n",
            "C√°c gi·∫£ng vi√™n ƒë·ªÅu r·∫•t am hi·ªÉu trong lƒ©nh v·ª±c c·ªßa m√¨nh. neutral positive\n",
            "Gi√°o tr√¨nh r·∫•t th√∫ v·ªã v√† ƒë·ªôc ƒë√°o, gi√∫p t√¥i h·ªçc ƒë∆∞·ª£c nhi·ªÅu th·ª© m·ªõi l·∫°. positive neutral\n",
            "Khu√¥n vi√™n ƒë·∫•t n·ªÅn r·ªông r√£i v√† kh√° y√™n tƒ©nh. neutral positive\n",
            "Nhi·ªÅu c∆° h·ªôi ƒë∆∞·ª£c th·ª±c t·∫≠p t·ª´ c√°c doanh nghi·ªáp n·ªïi ti·∫øng. neutral positive\n",
            "Gi√°o vi√™n r·∫•t nhi·ªát t√¨nh v√† c√≥ tr√°ch nhi·ªám trong qu√° tr√¨nh gi·∫£ng d·∫°y. positive neutral\n",
            "Gi·∫£ng vi√™n n√†y ƒë∆∞a ra nh·ªØng gi·∫£i ph√°p ƒë·ªôt ph√° v√† s√°ng t·∫°o cho vi·ªác h·ªçc t·∫≠p. neutral positive\n",
            "Th·∫ßy truy·ªÅn c·∫£m h·ª©ng v√† ƒë·ªông vi√™n c√°c sinh vi√™n c√≥ ho√†n c·∫£nh kh√≥ khƒÉn. positive neutral\n",
            "C√¥ ·∫•y r·∫•t tho·∫£i m√°i v√† t·ª± tin trong giao ti·∫øp ƒëa d·∫°ng v·ªõi ng∆∞·ªùi kh√°c gi·ªõi. positive neutral\n",
            "S·ª± ƒëa d·∫°ng v·ªÅ c√°c m√¥n h·ªçc gi√∫p m√¨nh l·ª±a ch·ªçn v√† c·∫≠p nh·∫≠t ki·∫øn th·ª©c m·ªõi. neutral positive\n",
            "Gi·∫£ng vi√™n h∆∞·ªõng d·∫´n sinh vi√™n t·∫°o ra m·ªôt m·ª•c ti√™u cho b·∫£n th√¢n v√† ƒë·∫°t ƒë∆∞·ª£c n√≥. positive neutral\n",
            "Gi·∫£ng vi√™n n√†y ƒë∆∞a ra c√°c v√≠ d·ª• r·∫•t th·ª±c t·∫ø v√† h·ªØu √≠ch ƒë·ªÉ gi√∫p t√¥i hi·ªÉu b√†i h·ªçc. neutral positive\n",
            "C·∫£m ∆°n gi·∫£ng vi√™n ƒë√£ gi√∫p t√¥i c√≥ nh·ªØng b∆∞·ªõc ti·∫øn th·∫≠t l·ªõn trong qu√° tr√¨nh h·ªçc t·∫≠p. neutral positive\n",
            "Gi·∫£ng vi√™n r·∫•t th√¢n thi·ªán v√† t·∫°o kh√¥ng kh√≠ h·ªçc t·∫≠p t√≠ch c·ª±c cho sinh vi√™n. positive neutral\n",
            "Gi√°o vi√™n lu√¥n gi·∫£i ƒë√°p th·∫Øc m·∫Øc c·ªßa sinh vi√™n r√µ r√†ng v√† chi ti·∫øt. positive neutral\n",
            "C√¥ ·∫•y c√≥ t√†i giao ti·∫øp t·ªët v√† th√¢n thi·ªán v·ªõi nh·ªØng ng∆∞·ªùi xung quanh. positive neutral\n",
            "T√¥i r·∫•t h√†i l√≤ng v·ªõi ch∆∞∆°ng tr√¨nh h·ªçc n∆°i ƒë√¢y. positive neutral\n",
            "B·∫°n c·ªßa em l√† ng∆∞·ªùi r·∫•t c√° t√≠nh v√† kh√¥ng s·ª£ th·ªÉ hi·ªán b·∫£n th√¢n. positive neutral\n",
            "C√¥ ·∫•y c√≥ phong c√°ch d·∫°y h·ªçc v√¥ c√πng s√°ng t·∫°o v√† th√∫ v·ªã. positive neutral\n",
            "C√≥ r·∫•t nhi·ªÅu ngu·ªìn t√†i nguy√™n h·ªó tr·ª£ h·ªçc vi√™n trong qu√° tr√¨nh h·ªçc t·∫≠p. neutral positive\n",
            "Anh ta lu√¥n c√≥ tinh th·∫ßn h·ªçc h·ªèi v√† m·ªü ƒë·∫ßu v·ªõi nh·ªØng ki·∫øn th·ª©c m·ªõi. positive neutral\n",
            "C√°c bu·ªïi h·ªçc ƒë∆∞·ª£c t·ªï ch·ª©c ch·∫∑t ch·∫Ω v√† c√≥ s·ª± chu·∫©n b·ªã k·ªπ l∆∞·ª°ng. neutral positive\n",
            "Ph√≤ng h·ªçc ƒë∆∞·ª£c b·ªë tr√≠ ƒë·ªìng nh·∫•t v√† g·ªçn g√†ng, gi√∫p cho sinh vi√™n h·ªçc t·∫≠p t·∫≠p trung h∆°n. positive neutral\n",
            "C√≥ r·∫•t nhi·ªÅu b·∫°n h·ªçc t·ªët v√† t√≠ch c·ª±c tham gia v√†o c√°c ho·∫°t ƒë·ªông c·ªßa tr∆∞·ªùng. positive neutral\n",
            "Anh ta l√† m·ªôt gi·∫£ng vi√™n r·∫•t t·∫≠n t√¢m v√† s√°ng t·∫°o. neutral positive\n",
            "Ch∆∞∆°ng tr√¨nh h·ªçc c·ªßa tr∆∞·ªùng gi√∫p t√¥i c√≥ c∆° h·ªôi h·ªçc t·∫≠p v√† nghi√™n c·ª©u v·ªõi nh·ªØng gi·∫£ng vi√™n h√†ng ƒë·∫ßu trong ng√†nh c·ªßa m√¨nh. positive neutral\n",
            "Gi·∫£ng vi√™n r·∫•t ƒë√°ng k√≠nh v√† ƒë∆∞·ª£c sinh vi√™n y√™u m·∫øn ƒë·∫∑c bi·ªát. positive neutral\n",
            "Th·∫ßy r·∫•t nƒÉng ƒë·ªông, gi√∫p sinh vi√™n t·∫≠p trung v√†o h·ªçc t·∫≠p m·ªôt c√°ch hi·ªáu qu·∫£. positive neutral\n",
            "M√¥n h·ªçc gi√∫p sinh vi√™n hi·ªÉu r√µ h∆°n v·ªÅ quy tr√¨nh v√† chi·∫øn l∆∞·ª£c ph√°t tri·ªÉn kinh doanh. positive neutral\n",
            "Gi·∫£ng vi√™n mang l·∫°i kinh nghi·ªám th·ª±c t·∫ø cho h·ªçc sinh. neutral positive\n",
            "H·ªá th·ªëng r·∫°p chi·∫øu phim v√† trung t√¢m gi·∫£i tr√≠ n√¢ng cao sinh ho·∫°t vƒÉn h√≥a cho sinh vi√™n. positive neutral\n",
            "Ph∆∞∆°ng ph√°p d·∫°y h·ªçc thi·∫øt th·ª±c v√† c√≥ t√≠nh ·ª©ng d·ª•ng cao. neutral positive\n",
            "C√°c ph√≤ng th√≠ nghi·ªám ƒë∆∞·ª£c trang b·ªã h·ªá th·ªëng gi√°m s√°t ho·∫°t ƒë·ªông t·ªët. positive neutral\n",
            "Nh√¢n vi√™n ph·ª•c v·ª• tr∆∞·ªùng lu√¥n s√°ng su·ªët, vui v·∫ª, nhi·ªát t√¨nh h·ªó tr·ª£ sinh vi√™n m·ªçi khi c·∫ßn thi·∫øt positive neutral\n",
            "T√†i li·ªáu h·ªçc t·∫≠p nhi·ªát t√¨nh v√† ƒë·∫ßy tr·∫£i nghi·ªám th·ª±c t·∫ø. positive neutral\n",
            "C√°c b√†i h·ªçc ƒë∆∞·ª£c thi·∫øt k·∫ø t·ªëi ∆∞u cho vi·ªác h·ªçc tr·ª±c tuy·∫øn. neutral positive\n",
            "C√°c khu v·ª±c c·∫•m h√∫t thu·ªëc ƒë∆∞·ª£c thi·∫øt k·∫ø v√† b·ªë tr√≠ ƒë·ªÉ ƒë·∫£m b·∫£o kh√¥ng kh√≠ trong l√†nh. neutral positive\n",
            "T√¥i c·∫£m th·∫•y r·∫•t ti·∫øc khi th·ªùi gian h·ªçc t·∫≠p t·∫°i tr∆∞·ªùng c·ªßa t√¥i k·∫øt th√∫c. negative positive\n",
            "C·∫≠u ·∫•y r·∫•t c√≥ k·ªπ nƒÉng v·ªÅ s√°ng t·∫°o v√† ngh·ªá thu·∫≠t. positive neutral\n",
            "Gi·∫£ng vi√™n n√†y kh√¥ng nh√†m ch√°n. neutral negative\n"
          ]
        }
      ],
      "source": [
        "for i, row in df_test.iterrows():\n",
        "    if row['predict'] != row['sentiment']:\n",
        "        print(row['sentence'], row['predict'], row['sentiment'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zxttyK-MF9EV"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7E7s3WMOF9EV"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "datasetId": 3052448,
          "sourceId": 5245967,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30733,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}