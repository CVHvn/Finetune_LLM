{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "id": "1cQcmlAKIyHF"
      },
      "source": [
        "# Install library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dgl4LnndIyHG",
        "outputId": "6ef0989d-7f7e-4170-b52d-745aac15557b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -q datasets==2.16.0\n",
        "!pip install -q bitsandbytes\n",
        "!pip install -q tiktoken\n",
        "!pip install -q peft\n",
        "!pip install -q trl\n",
        "!pip install -q transformers\n",
        "!pip install -q openpyxl\n",
        "!pip install -q pandas\n",
        "!pip install -q scikit-learn\n",
        "!pip install -q flash-attn\n",
        "#pip install -q transformers==4.38.1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sLUduw7xIyHI"
      },
      "source": [
        "# Import library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yxa0x2IeIyHI"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
        "import torch\n",
        "from accelerate import PartialState\n",
        "from peft import LoraConfig, PeftModel, prepare_model_for_kbit_training, get_peft_model\n",
        "from trl import SFTTrainer\n",
        "from peft import prepare_model_for_kbit_training\n",
        "from transformers import TrainingArguments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_fczAxFNIyHI"
      },
      "source": [
        "# Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N_vsxC6vIyHI"
      },
      "outputs": [],
      "source": [
        "modelpath = \"microsoft/Phi-3-mini-4k-instruct\"\n",
        "lr=2e-4      # learning rate\n",
        "bs=8            # batch size\n",
        "bs_eval=8      # batch size for evals\n",
        "ga_steps=2     # gradient acc. steps\n",
        "epochs=4\n",
        "max_length=128      # max. sample length with 24GB VRAM\n",
        "output_dir=\"out\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V8_AKI1cIyHI"
      },
      "source": [
        "# Remove old model\n",
        "Because of limited storage, we can't save all models, we need to delete all models in cache by the following code:\n",
        "- rm -r out: delete out folder (because I save finetuned model in out folder), you can change folder name like (rm -r output_folder). If you doesn't have out folder, this commend do not thing.\n",
        "- all pretrained huggingface models will auto save in transformers.TRANSFORMERS_CACHE. I use shutil.rmtree to delete them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dECc5nJWIyHJ"
      },
      "outputs": [],
      "source": [
        "!rm -r out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DH5yjS4QIyHJ"
      },
      "outputs": [],
      "source": [
        "# from transformers import TRANSFORMERS_CACHE\n",
        "# print(TRANSFORMERS_CACHE)\n",
        "\n",
        "# import shutil\n",
        "# shutil.rmtree(TRANSFORMERS_CACHE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z64dnKY-IyHJ"
      },
      "source": [
        "# Create Dataset\n",
        "Download dataset from [kaggle synthetic-vietnamese-students-feedback-corpus](https://www.kaggle.com/datasets/toreleon/synthetic-vietnamese-students-feedback-corpus/data)\n",
        "\n",
        "We need convert DataFrame to json line (jsonl)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tgju4mCRIyHJ"
      },
      "outputs": [],
      "source": [
        "df_train = pd.read_csv(\"synthetic_train.csv\")\n",
        "df_test = pd.read_csv(\"synthetic_val.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tpt-dZZcIyHJ",
        "outputId": "f628c7ea-d76a-42e7-c42a-8b03d2456669"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>topic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ƒê·ªôi ng≈© b·∫£o tr√¨ qu√° th∆∞a th·ªõt d·∫´n ƒë·∫øn kh√¥ng ƒë·∫£...</td>\n",
              "      <td>negative</td>\n",
              "      <td>facility</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The university's musical and artistic faciliti...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>facility</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Ph∆∞∆°ng ph√°p gi·∫£ng d·∫°y ph√π h·ª£p v·ªõi c√°c ƒë·ªëi t∆∞·ª£n...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>curriculum</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Ch∆∞∆°ng tr√¨nh h·ªçc gi√∫p t√¥i tr·ªü th√†nh m·ªôt chuy√™n...</td>\n",
              "      <td>positive</td>\n",
              "      <td>curriculum</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>T√¥i nghƒ© r·∫±ng ch∆∞∆°ng tr√¨nh ƒë√†o t·∫°o c√≥ th·ªÉ c√≥ t...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>curriculum</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            sentence sentiment       topic\n",
              "0  ƒê·ªôi ng≈© b·∫£o tr√¨ qu√° th∆∞a th·ªõt d·∫´n ƒë·∫øn kh√¥ng ƒë·∫£...  negative    facility\n",
              "1  The university's musical and artistic faciliti...   neutral    facility\n",
              "2  Ph∆∞∆°ng ph√°p gi·∫£ng d·∫°y ph√π h·ª£p v·ªõi c√°c ƒë·ªëi t∆∞·ª£n...   neutral  curriculum\n",
              "3  Ch∆∞∆°ng tr√¨nh h·ªçc gi√∫p t√¥i tr·ªü th√†nh m·ªôt chuy√™n...  positive  curriculum\n",
              "4  T√¥i nghƒ© r·∫±ng ch∆∞∆°ng tr√¨nh ƒë√†o t·∫°o c√≥ th·ªÉ c√≥ t...   neutral  curriculum"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RCIRHu5IIyHJ",
        "outputId": "94cafab5-f3f2-4245-c2a9-9307f2dd355d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>topic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Ch·∫•t l∆∞·ª£ng v·∫≠t ch·∫•t k√©m.</td>\n",
              "      <td>negative</td>\n",
              "      <td>facility</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Ph·∫ßn m·ªÅm h·ªçc t·∫≠p qu√° kh√≥ s·ª≠ d·ª•ng, khi·∫øn sinh v...</td>\n",
              "      <td>negative</td>\n",
              "      <td>facility</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Tr∆∞·ªùng t√¥i thi·∫øu nh·ªØng ti·ªán √≠ch c∆° b·∫£n nh∆∞ m√°y...</td>\n",
              "      <td>negative</td>\n",
              "      <td>facility</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>C·∫ßn t·∫°o th√™m c√°c ho·∫°t ƒë·ªông g·∫Øn k·∫øt gi·ªØa sinh v...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>curriculum</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>H·ªç r·∫•t khoan dung v√† l∆∞·ª£ng gi√°c trong quan ƒëi·ªÉ...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>others</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            sentence sentiment       topic\n",
              "0                           Ch·∫•t l∆∞·ª£ng v·∫≠t ch·∫•t k√©m.  negative    facility\n",
              "1  Ph·∫ßn m·ªÅm h·ªçc t·∫≠p qu√° kh√≥ s·ª≠ d·ª•ng, khi·∫øn sinh v...  negative    facility\n",
              "2  Tr∆∞·ªùng t√¥i thi·∫øu nh·ªØng ti·ªán √≠ch c∆° b·∫£n nh∆∞ m√°y...  negative    facility\n",
              "3  C·∫ßn t·∫°o th√™m c√°c ho·∫°t ƒë·ªông g·∫Øn k·∫øt gi·ªØa sinh v...   neutral  curriculum\n",
              "4  H·ªç r·∫•t khoan dung v√† l∆∞·ª£ng gi√°c trong quan ƒëi·ªÉ...   neutral      others"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_test.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ci7toWvpIyHJ",
        "outputId": "f0ce7574-dfca-42c3-a099-b2da757cad03"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "sentiment\n",
              "neutral     2724\n",
              "negative    2711\n",
              "positive    2709\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train.sentiment.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7gHmccqLIyHK",
        "outputId": "59e54c80-560a-4687-cc73-f2a0969d3705"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "sentiment\n",
              "negative    686\n",
              "positive    680\n",
              "neutral     670\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_test.sentiment.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CqHKMOnOIyHK"
      },
      "outputs": [],
      "source": [
        "df_train['len'] = df_train.sentence.apply(lambda x: len(str(x).split()))\n",
        "df_test['len'] = df_test.sentence.apply(lambda x: len(str(x).split()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NUIDNX_9IyHK",
        "outputId": "44d37fbb-36ac-4954-eb10-30ff8dc84e3a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "count    8144.000000\n",
              "mean       15.549730\n",
              "std         5.018764\n",
              "min         3.000000\n",
              "25%        12.000000\n",
              "50%        15.000000\n",
              "75%        18.000000\n",
              "max        43.000000\n",
              "Name: len, dtype: float64"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train['len'].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TaBwx9b9IyHK",
        "outputId": "3d775819-2c5f-4f45-ee7b-4212b70f6b13"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "count    2036.000000\n",
              "mean       15.694990\n",
              "std         5.185957\n",
              "min         2.000000\n",
              "25%        12.000000\n",
              "50%        15.000000\n",
              "75%        19.000000\n",
              "max        48.000000\n",
              "Name: len, dtype: float64"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_test['len'].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sWonupw9IyHK"
      },
      "outputs": [],
      "source": [
        "with open('train.jsonl', 'w') as outfile:\n",
        "    for i, x in df_train.iterrows():\n",
        "        comment = x['sentence']\n",
        "        label = x['sentiment']\n",
        "        #label = 'yes' if label == 'relevance' else 'no'\n",
        "        data = {\n",
        "            \"input\": f'''The sentiment of this comment \"{comment}\" is''',\n",
        "            \"output\": f\"{label}\"\n",
        "        }\n",
        "        json.dump(data, outfile)\n",
        "        outfile.write('\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7DuGwx2bIyHK"
      },
      "outputs": [],
      "source": [
        "with open('test.jsonl', 'w') as outfile:\n",
        "    for i, x in df_test.iterrows():\n",
        "        comment = x['sentence']\n",
        "        label = x['sentiment']\n",
        "        #label = 'yes' if label == 'relevance' else 'no'\n",
        "        data = {\n",
        "            \"input\": f'''The sentiment of this comment \"{comment}\" is''',\n",
        "            \"output\": f\"{label}\"\n",
        "        }\n",
        "        json.dump(data, outfile)\n",
        "        outfile.write('\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "3e725dda10294bb4a4524c97a87b703d",
            "27a150e15941408583f8a904b0a393c8"
          ]
        },
        "id": "CfpZ440BIyHL",
        "outputId": "62d17db5-c867-4d15-a754-70f6a3f996d3"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3e725dda10294bb4a4524c97a87b703d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "27a150e15941408583f8a904b0a393c8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating validation split: 0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "data_files = {\n",
        "    \"train\": \"train.jsonl\",\n",
        "    \"validation\": \"test.jsonl\",\n",
        "}\n",
        "\n",
        "dataset = load_dataset(\"json\", data_files=data_files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rnywuFQ0IyHL",
        "outputId": "da2b0116-74e6-416b-e5a7-2e6186933407"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['input', 'output'],\n",
              "        num_rows: 8144\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['input', 'output'],\n",
              "        num_rows: 2036\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5t18myx9IyHL"
      },
      "source": [
        "# Create prompt format\n",
        "Load tokenizer by AutoTokenizer.from_pretrained:\n",
        "- We need create and copy YOUR TOKEN from [huggingface](https://huggingface.co/settings/tokens)\n",
        "- We need use padding_side = 'right' because training library need padding_side = 'right' when training. You can use left padding but you need to make sure the library is not corrupted and check whether performance is affected by left padding!\n",
        "- If you have 1 prompt like \"test th·ª≠ m√¥ h√¨nh\" and want to tokenize it, just you tokenizer(prompt, return_tensors=\"pt\"). You can see output of tokenizer in cell below (output includes input_ids (list index of each token in prompt) and attention mask)\n",
        "- We can use tokenizer.batch_decode to see how tokenizer restore string from token tensor. You can see that it automatically adds the start token \"<bos>\" at the beginning of the string.\n",
        "- To train llm, we only need to pass 1 sentence to llm (including input and desired output) without specifying which is the input and which is the output.\n",
        "- I wrote the function formatting_prompts_func to convert input and output to prompt and tested this function, you can see below.\n",
        "- When predicting, remove the output part to let the model predict itself. See the predict section below later.\n",
        "- we only need to predict some next tokens like A. positive, and B. neutral. We don't care what the model says after sentiment. Then we do not need to add <eos token>. If you fine-tune the model with other tasks, maybe you need to add <eos token> at the end of the prompt:\n",
        "  - use tokenizer.eos_token, tokenizer.eos_token_id to see eos_token of your model and correspond id\n",
        "  - for ex: eos_token is \"<|im_end|>\". You need edit prompt like:\n",
        "    - '''...The correct answer is {output_}.''' --> '''...The correct answer is {output_}. <|im_end|>'''\n",
        "  - for ex: eos_token is \"end_token__\". You need edit prompt like:\n",
        "    - '''...The correct answer is {output_}.''' --> '''...The correct answer is {output_}. end_token__'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5MphHgspIyHL",
        "outputId": "6bff3807-ebf2-4d2d-8cce-704c7958ac0b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    modelpath,\n",
        "    padding_side=\"right\",\n",
        "    # add_eos_token=True,\n",
        "    # add_bos_token=True,\n",
        "    trust_remote_code=True,\n",
        "    token = 'YOUR TOKEN HERE'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HP3SFmUNIyHL",
        "outputId": "64651c94-3bb7-44be-9d35-3a3eb128a54a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_ids': tensor([[    1,  1243,   266,   228,   190,   176,   286, 30069,   298, 30097,\n",
            "         29876, 29882]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['<s>', 'test', 'th', 'ÔøΩ', 'ÔøΩ', 'ÔøΩ', 'm', '√¥', 'h', '√¨', 'n', 'h']"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prompt = \"test th·ª≠ m√¥ h√¨nh\"\n",
        "tokens = tokenizer(prompt, return_tensors=\"pt\")\n",
        "print(tokens)\n",
        "tokenizer.batch_decode(tokenizer.encode(prompt))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ZWJInjcIyHL"
      },
      "outputs": [],
      "source": [
        "def formatting_prompts_func(example):\n",
        "    output_texts = []\n",
        "    for i in range(len(example['input'])):\n",
        "        input_ = example['input'][i]\n",
        "        output_ = example['output'][i]\n",
        "        output_ = 'A. Positive' if output_ == 'positive' else 'B. Neutral' if output_ == 'neutral' else 'C. Negative'\n",
        "        #text = f\"### Question: {input__}\\n ### Answer: {example['output'][i]}\"\n",
        "        text = f'''{input_}\n",
        "A. Positive\n",
        "B. Neutral\n",
        "C. Negative\n",
        "\n",
        "The correct answer is {output_}.'''\n",
        "\n",
        "        output_texts.append(text)\n",
        "    return output_texts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gu9Mggy-IyHL",
        "outputId": "bf914d1e-bade-4357-9eb7-a2024ff0847f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('The sentiment of this comment \"Ch·∫•t l∆∞·ª£ng v·∫≠t ch·∫•t k√©m.\" is', 'negative')"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset[\"validation\"]['input'][0], dataset[\"validation\"]['output'][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k9Rcx5nqIyHM",
        "outputId": "5d658629-0bef-4d5e-9619-8a5193b9832e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['The sentiment of this comment \"Ch·∫•t l∆∞·ª£ng v·∫≠t ch·∫•t k√©m.\" is\\nA. Positive\\nB. Neutral\\nC. Negative\\n\\nThe correct answer is C. Negative.']"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "formatting_prompts_func({'input': [dataset[\"validation\"]['input'][0]],\n",
        "                         'output': [dataset[\"validation\"]['output'][0]]})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ct1oktBFIyHM",
        "outputId": "c8aacea8-f538-4e76-9166-3566ee4d6f34"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The sentiment of this comment \"Ch·∫•t l∆∞·ª£ng v·∫≠t ch·∫•t k√©m.\" is\n",
            "A. Positive\n",
            "B. Neutral\n",
            "C. Negative\n",
            "\n",
            "The correct answer is C. Negative.\n"
          ]
        }
      ],
      "source": [
        "print(formatting_prompts_func({'input': [dataset[\"validation\"]['input'][0]],\n",
        "                         'output': [dataset[\"validation\"]['output'][0]]})[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNFMj3HAIyHM"
      },
      "source": [
        "# Create model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MTRykggoIyHM"
      },
      "source": [
        "## Load model\n",
        "We use AutoModelForCausalLM.from_pretrained to load model:\n",
        "- device_map = 'auto': auto active gpu.\n",
        "- torch_dtype: use bfloat16, if your gpu don't support bfloat16, set it to float32\n",
        "- attn_implementation: you can use 'flash_attention_2', if you meet bug, maybe your gpu doesn't support it, you need delete this line.\n",
        "- token: you huggingface token like tokenizer above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "c394e9209080492dac9ce358b4d92d41"
          ]
        },
        "id": "E1swkGDEIyHM",
        "outputId": "b15e1e74-e011-46e2-90c9-6d468ac3e6ed"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c394e9209080492dac9ce358b4d92d41",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# bnb_config = BitsAndBytesConfig(\n",
        "#     load_in_4bit=True,\n",
        "#     bnb_4bit_use_double_quant=True,\n",
        "#     bnb_4bit_quant_type=\"nf4\",\n",
        "#     bnb_4bit_compute_dtype=torch.bfloat16,\n",
        "# )\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    modelpath,\n",
        "    device_map=\"auto\",\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    #torch_dtype=torch.float32,\n",
        "    #quantization_config=bnb_config,\n",
        "    #attn_implementation=\"flash_attention_2\",\n",
        "    trust_remote_code=True,\n",
        "    token = 'YOUR TOKEN HERE'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7h9Zxw8jIyHM",
        "outputId": "747302b9-be77-470a-a893-bb752fc68f7c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Phi3ForCausalLM(\n",
              "  (model): Phi3Model(\n",
              "    (embed_tokens): Embedding(32064, 3072, padding_idx=32000)\n",
              "    (embed_dropout): Dropout(p=0.0, inplace=False)\n",
              "    (layers): ModuleList(\n",
              "      (0-31): 32 x Phi3DecoderLayer(\n",
              "        (self_attn): Phi3Attention(\n",
              "          (o_proj): Linear(in_features=3072, out_features=3072, bias=False)\n",
              "          (qkv_proj): Linear(in_features=3072, out_features=9216, bias=False)\n",
              "          (rotary_emb): Phi3RotaryEmbedding()\n",
              "        )\n",
              "        (mlp): Phi3MLP(\n",
              "          (gate_up_proj): Linear(in_features=3072, out_features=16384, bias=False)\n",
              "          (down_proj): Linear(in_features=8192, out_features=3072, bias=False)\n",
              "          (activation_fn): SiLU()\n",
              "        )\n",
              "        (input_layernorm): Phi3RMSNorm()\n",
              "        (resid_attn_dropout): Dropout(p=0.0, inplace=False)\n",
              "        (resid_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
              "        (post_attention_layernorm): Phi3RMSNorm()\n",
              "      )\n",
              "    )\n",
              "    (norm): Phi3RMSNorm()\n",
              "  )\n",
              "  (lm_head): Linear(in_features=3072, out_features=32064, bias=False)\n",
              ")"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hgniEpz_IyHM"
      },
      "outputs": [],
      "source": [
        "# from peft import prepare_model_for_kbit_training\n",
        "\n",
        "# model = prepare_model_for_kbit_training(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l42mCdsHIyHN"
      },
      "source": [
        "## Eval model before training\n",
        "We use create_prompt function to generate prompt (without output), our model will predict output. We will eval model before finetune. You can see some predict below.\n",
        "\n",
        "You can see that pretrained model has poor performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rk8rQdQrIyHN",
        "outputId": "4c29093c-84cc-465e-84d8-8d4bfc563675"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:540: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "The attention mask is not set and cannot be inferred from input because pad token is same as eos token.As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "The `seen_tokens` attribute is deprecated and will be removed in v4.41. Use the `cache_position` model input instead.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The sentiment of this comment: \"m√≥n ƒÉn r·∫•t ngon\" is\n",
            "A. Positive\n",
            "B. Neutral\n",
            "C. Negative\n",
            "\n",
            "The correct answer is\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "You are not running the flash-attention implementation, expect numerical differences.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<s> The sentiment of this comment: \"m√≥n ƒÉn r·∫•t ngon\" is\n",
            "A. Positive\n",
            "B. Neutral\n",
            "C. Negative\n",
            "\n",
            "The correct answer is:\n",
            "A. Positive\n",
            "\n",
            "In Vietnamese, \"m√≥n ƒÉn r·∫•t ngon\" translates to \"the food is very delicious\" in English. The word \"ngon\" (delicious) conve\n"
          ]
        }
      ],
      "source": [
        "def create_prompt(input_, output_):\n",
        "    output_ = 'A. Positive' if output_ == 'positive' else 'B. Neutral' if output_ == 'neutral' else 'C. Negative'\n",
        "        #text = f\"### Question: {input__}\\n ### Answer: {example['output'][i]}\"\n",
        "    text = f'''{input_}\n",
        "A. Positive\n",
        "B. Neutral\n",
        "C. Negative\n",
        "\n",
        "The correct answer is'''\n",
        "\n",
        "    return text\n",
        "\n",
        "sentence = 'm√≥n ƒÉn r·∫•t ngon'\n",
        "input_ = f'''The sentiment of this comment: \"{sentence}\" is'''\n",
        "prompt = create_prompt(input_, \"\")\n",
        "print(prompt)\n",
        "\n",
        "inputs = torch.tensor([tokenizer.encode(prompt)])\n",
        "\n",
        "tokens = model.generate(\n",
        "    inputs.to(model.device),\n",
        "    max_new_tokens=50,\n",
        "    temperature=0.1,\n",
        "    do_sample=False\n",
        ")\n",
        "print(tokenizer.decode(tokens[0], skip_special_tokens=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YS5JGGTjIyHN",
        "outputId": "ac8e53e9-26c2-474e-9bba-f56394d3e22d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 0.0 0:00:00.133112 0:00:00.133115\n",
            "100 39.603960396039604 0:00:12.657178 0:00:00.125319\n",
            "200 44.27860696517413 0:00:25.104341 0:00:00.124897\n",
            "300 42.857142857142854 0:00:37.515966 0:00:00.124638\n",
            "400 42.8927680798005 0:00:49.847339 0:00:00.124308\n",
            "500 42.51497005988024 0:01:02.228128 0:00:00.124208\n",
            "600 41.43094841930117 0:01:14.670952 0:00:00.124245\n",
            "700 40.798858773181166 0:01:27.137105 0:00:00.124304\n",
            "800 41.07365792759051 0:01:39.664338 0:00:00.124425\n",
            "900 41.06548279689235 0:01:52.168834 0:00:00.124494\n",
            "1000 41.35864135864136 0:02:04.708219 0:00:00.124584\n",
            "1100 40.32697547683924 0:02:17.236723 0:00:00.124647\n",
            "1200 40.38301415487094 0:02:29.578600 0:00:00.124545\n",
            "1300 40.430438124519604 0:02:42.076432 0:00:00.124578\n",
            "1400 40.18558172733761 0:02:54.372631 0:00:00.124463\n",
            "1500 40.37308461025983 0:03:06.820666 0:00:00.124464\n",
            "1600 40.28732042473454 0:03:19.363464 0:00:00.124524\n",
            "1700 39.623750734861844 0:03:31.811416 0:00:00.124522\n",
            "1800 39.922265408106604 0:03:44.272585 0:00:00.124527\n",
            "1900 40.084166228300894 0:03:56.640560 0:00:00.124482\n",
            "2000 39.78010994502748 0:04:09.132630 0:00:00.124504\n"
          ]
        }
      ],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "start = datetime.now()\n",
        "\n",
        "prediction = []\n",
        "response = []\n",
        "accuracy = []\n",
        "labels = []\n",
        "\n",
        "for i, x in df_test.iterrows():\n",
        "    sentence = x['sentence']\n",
        "    label = x['sentiment']\n",
        "    input_ = f'''The sentiment of this comment: \"{sentence}\" is'''\n",
        "    prompt = create_prompt(input_, label)\n",
        "\n",
        "    inputs = tokenizer.encode(\n",
        "        prompt,\n",
        "        # add_generation_prompt=True,\n",
        "        return_tensors='pt'\n",
        "    )\n",
        "\n",
        "    tokens = model.generate(\n",
        "        inputs.to(model.device),\n",
        "        max_new_tokens=5,\n",
        "        temperature=0.1,\n",
        "        do_sample=False,\n",
        "        pad_token_id=tokenizer.eos_token_id\n",
        "    )\n",
        "    #break\n",
        "\n",
        "    answer = tokenizer.decode(tokens[0], skip_special_tokens=False).split(\"The correct answer is \")[-1]\n",
        "    answer = 'positive' if 'positive' in answer.lower() else 'negative' if 'negative' in answer.lower() else 'neutral'\n",
        "    prediction.append(answer.lower())\n",
        "    response.append(tokenizer.decode(tokens[0], skip_special_tokens=False))\n",
        "\n",
        "    accuracy.append(prediction[-1] == label)\n",
        "    labels.append(label)\n",
        "\n",
        "    if i % 100 == 0:\n",
        "        print(i, np.array(accuracy).sum()/len(prediction)*100, datetime.now() - start, (datetime.now() - start)/len(prediction))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zZezmVUjIyHN",
        "outputId": "c3d6dbf7-5e98-4879-e2bb-fdc8f879b8b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative     0.7699    0.1268    0.2178       686\n",
            "     neutral     0.6364    0.1254    0.2095       670\n",
            "    positive     0.3540    0.9324    0.5132       680\n",
            "\n",
            "    accuracy                         0.3954      2036\n",
            "   macro avg     0.5868    0.3948    0.3135      2036\n",
            "weighted avg     0.5871    0.3954    0.3137      2036\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report, f1_score\n",
        "import sklearn\n",
        "\n",
        "print(sklearn.metrics.classification_report(labels, prediction, digits=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mm3PimTWIyHN",
        "outputId": "c71ce6c9-62f5-4070-f4b6-7d2b9f7c5dfd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<s> The sentiment of this comment: \"The facilities of the university are versatile and helpful.\" is\n",
            "A. Positive\n",
            "B. Neutral\n",
            "C. Negative\n",
            "\n",
            "The correct answer is: A. Positive\n",
            "\n",
            "\n",
            "<s> The sentiment of this comment: \"M·∫•y b·∫°n ƒë√≥ hay ƒë√≤i h·ªèi nh∆∞ng kh√¥ng bao gi·ªù gi√∫p ƒë·ª° ng∆∞·ªùi kh√°c.\" is\n",
            "A. Positive\n",
            "B. Neutral\n",
            "C. Negative\n",
            "\n",
            "The correct answer is:\n",
            "C. Neg\n",
            "\n",
            "\n",
            "<s> The sentiment of this comment: \"C·∫≠u ·∫•y r·∫•t c√≥ k·ªπ nƒÉng v·ªÅ s√°ng t·∫°o v√† ngh·ªá thu·∫≠t.\" is\n",
            "A. Positive\n",
            "B. Neutral\n",
            "C. Negative\n",
            "\n",
            "The correct answer is:\n",
            "A. Pos\n",
            "\n",
            "\n",
            "<s> The sentiment of this comment: \"Gi·∫£ng vi√™n n√†y kh√¥ng nh√†m ch√°n.\" is\n",
            "A. Positive\n",
            "B. Neutral\n",
            "C. Negative\n",
            "\n",
            "The correct answer is C. Negative.\n",
            "\n",
            "\n",
            "<s> The sentiment of this comment: \"Anh ta l√† m·ªôt ng∆∞·ªùi r·∫•t t·ªâ m·ªâ v√† c·∫©n th·∫≠n.\" is\n",
            "A. Positive\n",
            "B. Neutral\n",
            "C. Negative\n",
            "\n",
            "The correct answer is A. Positive.\n",
            "\n",
            "\n",
            "<s> The sentiment of this comment: \"Gi√°o vi√™n ƒë∆∞a ra c√°c ph∆∞∆°ng ti·ªán h·ªó tr·ª£ gi·∫£ng d·∫°y r·∫•t t·ªët v√† hi·ªáu qu·∫£.\" is\n",
            "A. Positive\n",
            "B. Neutral\n",
            "C. Negative\n",
            "\n",
            "The correct answer is:\n",
            "A. Pos\n",
            "\n",
            "\n",
            "<s> The sentiment of this comment: \"The university's computer facilities are up-to-date and well-maintained.\" is\n",
            "A. Positive\n",
            "B. Neutral\n",
            "C. Negative\n",
            "\n",
            "The correct answer is: A. Positive\n",
            "\n",
            "\n",
            "<s> The sentiment of this comment: \"Thi·∫øu t√≠nh linh ho·∫°t trong h√¨nh th·ª©c gi·∫£ng d·∫°y v√† ƒë√°nh gi√° k·∫øt qu·∫£ h·ªçc t·∫≠p.\" is\n",
            "A. Positive\n",
            "B. Neutral\n",
            "C. Negative\n",
            "\n",
            "The correct answer is:\n",
            "C. Neg\n",
            "\n",
            "\n",
            "<s> The sentiment of this comment: \"C√¥ ·∫•y r·∫•t s·∫Øc s·∫£o v√† c√≥ kh·∫£ nƒÉng ph√¢n t√≠ch chi ti·∫øt r·∫•t t·ªët.\" is\n",
            "A. Positive\n",
            "B. Neutral\n",
            "C. Negative\n",
            "\n",
            "The correct answer is:\n",
            "A. Pos\n",
            "\n",
            "\n",
            "<s> The sentiment of this comment: \"Anh ·∫•y c√≥ t√†i nƒÉng v·ªÅ √¢m nh·∫°c v√† lu√¥n t√¨m c√°ch t·∫°o ra c√°c b·∫£n nh·∫°c m·ªõi, gi√∫p nh√≥m th√™m ho√†n h·∫£o v√† ƒëa d·∫°ng h∆°n.\" is\n",
            "A. Positive\n",
            "B. Neutral\n",
            "C. Negative\n",
            "\n",
            "The correct answer is:\n",
            "\n",
            "A.\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for x in response[-10:]:\n",
        "    print(x)\n",
        "    print(\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create peft\n",
        "For lora training, we need create LoraConfig:\n",
        "  - lora_alpha, r, dropout is basic hyperarameter.\n",
        "  - almost LLM use bias = 'none' when finetune then we set is to None\n",
        "  - target_modules are list of layer we want to finetune, I set it to 'all-linear', then all linear layers will be finetuned. If you just finetune some layers like q_proj, k_proj, you can pass list ['q_proj', 'k_proj'].\n",
        "  - modules_to_save is other layers we want to finetune (but don't use lora), in my experience, finetune all embedding layers will make model work betters than I set modules_to_save as list of all embedding layers."
      ],
      "metadata": {
        "id": "Gq61EuwNJNd3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PRikvXKjIyHQ",
        "outputId": "3676c760-4edb-4b73-da93-6ae7d3a4858f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trainable params: 111,083,520 || all params: 3,932,163,072 || trainable%: 2.8250\n"
          ]
        }
      ],
      "source": [
        "peft_config = LoraConfig(\n",
        "    lora_alpha=32,\n",
        "    lora_dropout=0.1,\n",
        "    r=8,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\",\n",
        "    target_modules = 'all-linear',\n",
        "#     target_modules=[\"q_proj\",\n",
        "#         \"k_proj\",\n",
        "#         \"v_proj\",\n",
        "#         \"o_proj\",\n",
        "#         \"gate_proj\",\n",
        "#         \"up_proj\",\n",
        "#         \"down_proj\",\n",
        "#         \"lm_head\",],\n",
        "    modules_to_save=[\"embed_tokens\", \"rotary_emb\"]\n",
        "                     #\"input_layernorm\", \"post_attention_layernorm\", \"norm\"]\n",
        ")\n",
        "model = get_peft_model(model, peft_config)\n",
        "\n",
        "model.print_trainable_parameters() #"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_h4EnOJIyHQ"
      },
      "source": [
        "## Create TrainingArguments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OpQKtzmIIyHR",
        "outputId": "4ce32bad-9250-4302-87aa-c2066750e60a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "509\n"
          ]
        }
      ],
      "source": [
        "print(len(df_train)//bs//ga_steps*epochs//4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OBZmBhx7IyHR",
        "outputId": "2558d22f-accc-41ad-d275-bce48218b4bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "509\n"
          ]
        }
      ],
      "source": [
        "save_step = len(df_train)//bs//ga_steps*epochs//4\n",
        "print(save_step)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fVsihVR1IyHR",
        "outputId": "a934fbd5-d9b1-4b7b-aa17-fa358a88913a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "training_arguments = TrainingArguments(\n",
        "    output_dir=output_dir,\n",
        "    num_train_epochs=epochs,\n",
        "    per_device_train_batch_size=bs,\n",
        "    per_device_eval_batch_size=bs_eval,\n",
        "    evaluation_strategy=\"steps\",\n",
        "    eval_steps=save_step,\n",
        "    gradient_accumulation_steps=ga_steps,\n",
        "    optim=\"paged_adamw_32bit\",\n",
        "    save_steps=save_step,\n",
        "    save_strategy=\"steps\",\n",
        "    logging_steps=save_step,\n",
        "    learning_rate=lr,\n",
        "    weight_decay=0.001,\n",
        "    fp16=False,\n",
        "    bf16=True,\n",
        "    max_grad_norm=0.3,\n",
        "    max_steps=-1,\n",
        "    warmup_ratio=0.03,\n",
        "    group_by_length=True,\n",
        "    lr_scheduler_type=\"constant\",\n",
        "    report_to=\"none\",\n",
        "    save_total_limit=1,\n",
        "    #load_best_model_at_end=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lpDFiyjaIyHR"
      },
      "source": [
        "## Create trainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "42492bdfa24a4117b7f11c75270b5767",
            "0dc003619c514ba99a073a6dc726c753"
          ]
        },
        "id": "vA-CgnK8IyHR",
        "outputId": "70be2e7b-0b55-4f42-aed5-3e908cc06219"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': max_seq_length. Will not be supported from version '1.0.0'.\n",
            "\n",
            "Deprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n",
            "  warnings.warn(message, FutureWarning)\n",
            "/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1961: FutureWarning: `--push_to_hub_token` is deprecated and will be removed in version 5 of ü§ó Transformers. Use `--hub_token` instead.\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:269: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "42492bdfa24a4117b7f11c75270b5767",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/8144 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0dc003619c514ba99a073a6dc726c753",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/2036 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
          ]
        }
      ],
      "source": [
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    train_dataset=dataset[\"train\"],\n",
        "    eval_dataset=dataset[\"validation\"],\n",
        "    peft_config=peft_config,\n",
        "    max_seq_length= 128,\n",
        "    #dataset_text_field=[\"input\", \"output\"],\n",
        "    tokenizer=tokenizer,\n",
        "    args=training_arguments,\n",
        "    packing= False,\n",
        "    formatting_func = formatting_prompts_func,\n",
        "    #data_collator=collator\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SbKeEL3MIyHR"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "55lp38jJIyHR",
        "outputId": "ba39d0df-8d0d-4dfd-e8a9-dd6e94bb3347"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2036' max='2036' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2036/2036 10:49, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>509</td>\n",
              "      <td>0.602900</td>\n",
              "      <td>0.541972</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1018</td>\n",
              "      <td>0.479900</td>\n",
              "      <td>0.508893</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1527</td>\n",
              "      <td>0.414700</td>\n",
              "      <td>0.507738</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2036</td>\n",
              "      <td>0.359800</td>\n",
              "      <td>0.519350</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=2036, training_loss=0.46430372676587056, metrics={'train_runtime': 649.7591, 'train_samples_per_second': 50.136, 'train_steps_per_second': 3.133, 'total_flos': 5.89094787280896e+16, 'train_loss': 0.46430372676587056, 'epoch': 4.0})"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O3pjrgOMIyHS"
      },
      "source": [
        "# Eval\n",
        "- If you save the model to the output_dir folder, the training code above will automatically save the model to output_dir/checkpoint-{save_step} (in my case: out/checkpoint-2036). We will load the model from this folder:\n",
        "  - I calculate _id = save_step * num_epoch = 509 * 4 = 2036\n",
        "  - My model will saved at \"{output_dir}/checkpoint-{_id}\"\n",
        "- I use del model, gc.collect() and torch.cuda.empty_cache() to release trained model (save gpu memory).\n",
        "- We use PeftConfig.from_pretrained to lead peft config (this is the same as peft config at training)\n",
        "- we load pretrained model like before.\n",
        "- We load the tokenizer in this folder by passing the saved folder to AutoTokenizer.from_pretrained()\n",
        "- We use PeftModel.from_pretrained(model, peft_model_id) to merge pre-trained model with finetuned lora model (note that when we use peft lora, training code only saves lora model, this saves our storage and saving time)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f6afZigtIyHS",
        "outputId": "cba45cd3-9160-407f-df4b-f88e63764f78"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "509\n"
          ]
        }
      ],
      "source": [
        "save_step = len(df_train)//bs//ga_steps*epochs//4\n",
        "print(save_step)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JUtzk-S6IyHS"
      },
      "outputs": [],
      "source": [
        "import gc\n",
        "\n",
        "del model\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "0f1c4797eedf4a0c84d79f845e5b02b2"
          ]
        },
        "id": "ELYwk1ugIyHS",
        "outputId": "1df7a238-8323-4ad9-a457-27dc47299aca"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0f1c4797eedf4a0c84d79f845e5b02b2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ],
      "source": [
        "from peft import PeftModel, PeftConfig\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import torch\n",
        "\n",
        "_id = save_step*4\n",
        "\n",
        "peft_model_id = f\"{output_dir}/checkpoint-{_id}\"\n",
        "\n",
        "config = PeftConfig.from_pretrained(peft_model_id)\n",
        "\n",
        "# bnb_config = BitsAndBytesConfig(\n",
        "#     load_in_4bit=True,\n",
        "#     bnb_4bit_use_double_quant=False,\n",
        "#     bnb_4bit_quant_type=\"nf4\",\n",
        "#     bnb_4bit_compute_dtype=torch.float16,\n",
        "# )\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    modelpath,\n",
        "    device_map=\"auto\",\n",
        "    #torch_dtype=torch.float16,\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    #quantization_config=bnb_config,\n",
        "    attn_implementation=\"flash_attention_2\",\n",
        "    trust_remote_code=True,\n",
        "    token = 'YOUR TOKEN HERE'\n",
        ")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(f\"{output_dir}/checkpoint-{_id}\",\n",
        "                                          trust_remote_code=True,\n",
        "                                          padding_side='left',\n",
        "                                          token='YOUR TOKEN HERE')\n",
        "\n",
        "# Load the Lora model\n",
        "model = PeftModel.from_pretrained(model, peft_model_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ihcSnZD_IyHS"
      },
      "outputs": [],
      "source": [
        "def create_prompt(input_, output_):\n",
        "    output_ = 'A. Positive' if output_ == 'positive' else 'B. Neutral' if output_ == 'neutral' else 'C. Negative'\n",
        "        #text = f\"### Question: {input__}\\n ### Answer: {example['output'][i]}\"\n",
        "    text = f'''{input_}\n",
        "A. Positive\n",
        "B. Neutral\n",
        "C. Negative\n",
        "\n",
        "The correct answer is'''\n",
        "\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nTV9Zfo2IyHS",
        "outputId": "87d20d57-2af7-4295-dcf9-a2c28fb7d763"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The sentiment of this comment: \"m√≥n ƒÉn r·∫•t ngon\" is\n",
            "A. Positive\n",
            "B. Neutral\n",
            "C. Negative\n",
            "\n",
            "The correct answer is\n"
          ]
        }
      ],
      "source": [
        "sentence = 'm√≥n ƒÉn r·∫•t ngon'\n",
        "input_ = f'''The sentiment of this comment: \"{sentence}\" is'''\n",
        "prompt = create_prompt(input_, \"\")\n",
        "print(prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yEX2ldieIyHS",
        "outputId": "06776938-1b2b-435e-fb14-2bb9aae6a79b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[    1,   450, 19688,   310,   445,  3440, 29901,   376, 29885,   888,\n",
              "         29871, 30035, 29876,   364, 31145, 29873,  8736,   265, 29908,   338,\n",
              "            13, 29909, 29889, 10321,  3321,    13, 29933, 29889,  2448,   329,\n",
              "          1705,    13, 29907, 29889, 12610,  1230,    13,    13,  1576,  1959,\n",
              "          1234,   338]])"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "inputs = torch.tensor([tokenizer.encode(prompt)])\n",
        "inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1PH94ChIIyHT"
      },
      "outputs": [],
      "source": [
        "tokens = model.generate(\n",
        "    inputs.to(model.device),\n",
        "    max_new_tokens=50,\n",
        "    temperature=0.1,\n",
        "    do_sample=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FGQBveZaIyHT",
        "outputId": "49bdc786-6eb0-4271-8f8a-98187956b4aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<s> The sentiment of this comment: \"m√≥n ƒÉn r·∫•t ngon\" is\n",
            "A. Positive\n",
            "B. Neutral\n",
            "C. Negative\n",
            "\n",
            "The correct answer is B. Neutral.\n",
            "\n",
            "The comment \"Th·∫ßy r·∫•t t·∫≠n t√¢m v√† nhi·ªát t√¨nh gi·∫£ng d·∫°y.\" is\n",
            "A. Positive\n",
            "B. Ne\n"
          ]
        }
      ],
      "source": [
        "print(tokenizer.decode(tokens[0], skip_special_tokens=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "15mj7h2SIyHT",
        "outputId": "3cfd9b97-7f9e-406b-9424-315733184ec4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<s> The sentiment of this comment: \"m√≥n ƒÉn r·∫•t ngon\" is\n",
            "A. Positive\n",
            "B. Neutral\n",
            "C. Negative\n",
            "\n",
            "The correct answer is B. Neutral\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:540: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "tokens = model.generate(\n",
        "    inputs.to(model.device),\n",
        "    max_new_tokens=5,\n",
        "    temperature=0.1,\n",
        "    do_sample=False\n",
        ")\n",
        "print(tokenizer.decode(tokens[0], skip_special_tokens=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8xNdDTXhIyHT",
        "outputId": "4e0de4e7-4274-4319-dc4a-06e64f37ad4c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 100.0 0:00:00.175634 0:00:00.175636\n",
            "100 90.0990099009901 0:00:17.732860 0:00:00.175573\n",
            "200 86.06965174129353 0:00:35.411545 0:00:00.176177\n",
            "300 85.38205980066445 0:00:52.919201 0:00:00.175811\n",
            "400 83.54114713216958 0:01:10.508683 0:00:00.175832\n",
            "500 84.63073852295409 0:01:28.156922 0:00:00.175962\n",
            "600 84.8585690515807 0:01:45.914910 0:00:00.176231\n",
            "700 84.59343794579172 0:02:03.466465 0:00:00.176129\n",
            "800 84.76903870162296 0:02:21.004927 0:00:00.176036\n",
            "900 85.23862375138734 0:02:38.580991 0:00:00.176006\n",
            "1000 85.21478521478521 0:02:56.346342 0:00:00.176170\n",
            "1100 85.1952770208901 0:03:13.941590 0:00:00.176150\n",
            "1200 84.17985012489592 0:03:31.588979 0:00:00.176177\n",
            "1300 84.78093774019985 0:03:49.275507 0:00:00.176230\n",
            "1400 84.86795146324054 0:04:06.862447 0:00:00.176204\n",
            "1500 84.94337108594272 0:04:24.444146 0:00:00.176179\n",
            "1600 84.57214241099314 0:04:41.961426 0:00:00.176116\n",
            "1700 84.77366255144034 0:04:59.660889 0:00:00.176167\n",
            "1800 84.95280399777901 0:05:17.301308 0:00:00.176181\n",
            "1900 84.9026827985271 0:05:34.885396 0:00:00.176163\n",
            "2000 84.55772113943029 0:05:52.521781 0:00:00.176173\n"
          ]
        }
      ],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "start = datetime.now()\n",
        "\n",
        "prediction = []\n",
        "response = []\n",
        "accuracy = []\n",
        "labels = []\n",
        "\n",
        "for i, x in df_test.iterrows():\n",
        "    sentence = x['sentence']\n",
        "    label = x['sentiment']\n",
        "    input_ = f'''The sentiment of this comment: \"{sentence}\" is'''\n",
        "    prompt = create_prompt(input_, label)\n",
        "\n",
        "    inputs = tokenizer.encode(\n",
        "        prompt,\n",
        "        # add_generation_prompt=True,\n",
        "        return_tensors='pt'\n",
        "    )\n",
        "\n",
        "    tokens = model.generate(\n",
        "        inputs.to(model.device),\n",
        "        max_new_tokens=5,\n",
        "        temperature=0.1,\n",
        "        do_sample=False,\n",
        "        pad_token_id=tokenizer.eos_token_id\n",
        "    )\n",
        "    #break\n",
        "\n",
        "    answer = tokenizer.decode(tokens[0], skip_special_tokens=False).split(\"The correct answer is \")[-1]\n",
        "    answer = 'positive' if 'positive' in answer.lower() else 'negative' if 'negative' in answer.lower() else 'neutral'\n",
        "    prediction.append(answer.lower())\n",
        "    response.append(tokenizer.decode(tokens[0], skip_special_tokens=False))\n",
        "\n",
        "    accuracy.append(prediction[-1] == label)\n",
        "    labels.append(label)\n",
        "\n",
        "    if i % 100 == 0:\n",
        "        print(i, np.array(accuracy).sum()/len(prediction)*100, datetime.now() - start, (datetime.now() - start)/len(prediction))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7zrTmpH4IyHT",
        "outputId": "ec0c76b1-59cb-4e05-c761-d349190fccb3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative     0.9809    0.9738    0.9773       686\n",
            "     neutral     0.8193    0.6836    0.7453       670\n",
            "    positive     0.7450    0.8721    0.8035       680\n",
            "\n",
            "    accuracy                         0.8443      2036\n",
            "   macro avg     0.8484    0.8431    0.8421      2036\n",
            "weighted avg     0.8489    0.8443    0.8429      2036\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report, f1_score\n",
        "import sklearn\n",
        "\n",
        "print(sklearn.metrics.classification_report(labels, prediction, digits=4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aaxlk9VAIyHT"
      },
      "source": [
        "# Check results\n",
        "- I print all sentences have wrong prediction and see that almost cases is bug.\n",
        "- Conclusion, dataset is not clean than finetune LLM can't better than finetune roberta (~89..90%), because roberta will overfit even in test dataset.\n",
        "- In additionally, when I print example: \"m√≥n ƒÉn n√†y r·∫•t ngon\", we can see that model before finetune work better. Model after finetune only think about school (because finetune dataset is about school) and it don't know about food review. Than I think we only need finetune for special cases and finetune dataset need be clean and large enough."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f_iC8oEzIyHU"
      },
      "outputs": [],
      "source": [
        "df_test['predict'] = prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cy2eyv0qIyHU",
        "outputId": "171743e5-2af5-489e-8a8a-048cdb985f2d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Gi·∫£ng vi√™n r·∫•t t√†i nƒÉng v√† c√≥ nhi·ªÅu kinh nghi·ªám trong c√¥ng t√°c gi·∫£ng d·∫°y. positive neutral\n",
            "ƒê∆∞·ª£c h·ªçc t·∫≠p v·ªõi c√°c gi√°o vi√™n gi√†u kinh nghi·ªám v√† th·ª±c ti·ªÖn. positive neutral\n",
            "H·ªá th·ªëng h·ªó tr·ª£ h·ªçc t·∫≠p tr·ª±c tuy·∫øn r·∫•t t·ªët. positive neutral\n",
            "Ch·ªã ·∫•y r·∫•t gi·ªèi qu·∫£n l√Ω th·ªùi gian v√† lu√¥n ho√†n th√†nh c√¥ng vi·ªác ƒë√∫ng ti·∫øn ƒë·ªô. positive neutral\n",
            "Anh ·∫•y c√≥ m·ªôt t·∫ßm nh√¨n ƒë·ªânh cao v√† kh·∫£ nƒÉng gi·∫£i quy·∫øt v·∫•n ƒë·ªÅ t·ªët. positive neutral\n",
            "C√°c c·ª≠a h√†ng ti·ªán l·ª£i g·∫ßn ƒë√≥ th∆∞·ªùng xuy√™n ƒë∆∞·ª£c m·ªü c·ª≠a cho sinh vi√™n. positive neutral\n",
            "C√≥ nhi·ªÅu ho·∫°t ƒë·ªông ngo·∫°i kh√≥a v√† phong ph√∫ cho sinh vi√™n. neutral positive\n",
            "S√¢n c·ªè c·ªßa tr∆∞·ªùng ƒë∆∞·ª£c tu b·ªï v√† ƒë·ªãnh h∆∞·ªõng ri√™ng cho c√°c ho·∫°t ƒë·ªông th·ªÉ thao. positive neutral\n",
            "C·∫≠u b·∫°n n√†y r·∫•t t·∫≠p trung v√† c·∫©n tr·ªçng. positive neutral\n",
            "Ph√≤ng h·ªçc ƒë∆∞·ª£c trang b·ªã ƒë·∫ßy ƒë·ªß ti·ªán nghi gi√∫p sinh vi√™n lu√¥n d·ªÖ d√†ng ti·∫øp c·∫≠n t√†i li·ªáu v√† th√¥ng tin li√™n quan. positive neutral\n",
            "Th·∫ßy d·∫°y r·∫•t chuy√™n nghi·ªáp v√† nhi·ªát t√¨nh. neutral positive\n",
            "ƒê·∫°i h·ªçc n√†y c√≥ nhi·ªÅu h·ªôi th·∫£o v√† kh√≥a t·∫≠p hu·∫•n gi√∫p sinh vi√™n trau d·ªìi ki·∫øn th·ª©c v√† k·ªπ nƒÉng. neutral positive\n",
            "C√°c khu v·ª±c ƒë·ªÉ t·∫≠p th·ªÉ d·ª•c trong tr∆∞·ªùng r·∫•t ƒëa d·∫°ng v√† thu·∫≠n ti·ªán. positive neutral\n",
            "Th·∫ßy/c√¥ gi·∫£ng c·∫©n th·∫≠n, ƒë·∫ßy ƒë·ªß ki·∫øn th·ª©c v√† kinh nghi·ªám. positive neutral\n",
            "C√°c ph√≤ng th√≠ nghi·ªám ƒë∆∞·ª£c trang b·ªã ƒë·∫ßy ƒë·ªß c√°c thi·∫øt b·ªã c·∫ßn thi·∫øt. positive neutral\n",
            "C√¥ ·∫•y l√† m·ªôt ng∆∞·ªùi r·∫•t ch·ªß ƒë·ªông v√† nƒÉng ƒë·ªông. positive neutral\n",
            "Th·∫ßy/c√¥ ƒë√°nh gi√° v√† ƒë·ªÅ xu·∫•t nh·ªØng √Ω ki·∫øn x√¢y d·ª±ng t√≠ch c·ª±c gi√∫p sinh vi√™n ph√°t tri·ªÉn h∆°n. neutral positive\n",
            "Gi·∫£ng vi√™n n√†y c√≥ t√¢m huy·∫øt c√¥ng vi·ªác v√† ƒëam m√™ v·ªõi ngh·ªÅ gi·∫£ng d·∫°y. neutral positive\n",
            "H·ªá th·ªëng th∆∞ vi·ªán v√† t√†i nguy√™n h·ªçc t·∫≠p r·∫•t ƒë·∫ßy ƒë·ªß v√† ti·ªán l·ª£i. positive neutral\n",
            "Ch∆∞∆°ng tr√¨nh ƒë√†o t·∫°o c√≥ nhi·ªÅu t√≠nh ·ª©ng d·ª•ng gi√∫p sinh vi√™n t·ª± tin v√† th√†nh c√¥ng trong c√¥ng vi·ªác. neutral positive\n",
            "Kh√¥ng gian h·ªçc t·∫≠p chuy√™n nghi·ªáp negative neutral\n",
            "Tr∆∞·ªùng c·∫ßn c√≥ ch√≠nh s√°ch h·ªó tr·ª£ chi ph√≠ h·ªçc t·∫≠p ph√π h·ª£p cho sinh vi√™n. neutral negative\n",
            "Sinh vi√™n ƒë∆∞·ª£c khuy·∫øn kh√≠ch tham gia c√°c ho·∫°t ƒë·ªông tr∆∞·ªùng ƒëo·∫£n c√∫ v√† h·ªôi th·∫£o. positive neutral\n",
            "Ch∆∞∆°ng tr√¨nh ƒë√†o t·∫°o r·∫•t ƒëa d·∫°ng v·ªÅ c·∫£ n·ªôi dung l·∫´n h√¨nh th·ª©c ƒë√†o t·∫°o. neutral positive\n",
            "Tr∆∞·ªùng cung c·∫•p cho t√¥i nhi·ªÅu c∆° h·ªôi h·ªçc t·∫≠p tr·ª±c tuy·∫øn v√† gi√∫p t√¥i ti·∫øt ki·ªám th·ªùi gian. positive neutral\n",
            "M√¥i tr∆∞·ªùng h·ªçc t·∫≠p √¥ nhi·ªÖm, kh√¥ng c√≥ kh√¥ng kh√≠ trong l√†nh. positive negative\n",
            "Tr∆∞·ªùng ƒë·∫°i h·ªçc cung c·∫•p nhi·ªÅu ch∆∞∆°ng tr√¨nh h·ªçc b·ªïng h·ªó tr·ª£ cho sinh vi√™n kh√≥ khƒÉn kinh t·∫ø. neutral positive\n",
            "Khu v·ª±c s·ªëng ƒë·ªông c·ªßa tr∆∞·ªùng r·∫•t th√∫ v·ªã cho sinh vi√™n. positive neutral\n",
            "Th∆∞ vi·ªán c·ªßa tr∆∞·ªùng c√≥ nhi·ªÅu t√†i li·ªáu b·ªï √≠ch v√† ƒëa d·∫°ng. positive neutral\n",
            "Gi·∫£ng vi√™n r·∫•t am hi·ªÉu v√† t·ª´ng b∆∞·ªõc h∆∞·ªõng d·∫´n sinh vi√™n ƒëi ƒë·∫øn th√†nh c√¥ng. positive neutral\n",
            "Th·∫ßy gi·∫£i th√≠ch c·∫∑n k·∫Ω v√† d·ªÖ hi·ªÉu. neutral positive\n",
            "Th·∫ßy c√¥ gi·∫£ng d·∫°y ƒë·ªÅu r·∫•t nhi·ªát t√¨nh v√† c√≥ kinh nghi·ªám trong lƒ©nh v·ª±c ƒëang gi·∫£ng d·∫°y. neutral positive\n",
            "C√≥ r·∫•t nhi·ªÅu ph√≤ng h·ªçc t·∫°i tr∆∞·ªùng ƒë·ªÉ sinh vi√™n c√≥ th·ªÉ l·ª±a ch·ªçn v√† s·ª≠ d·ª•ng. neutral positive\n",
            "T√¥i th√≠ch nh·ªØng khu v·ª±c xanh t·ªët cho s·ª©c kh·ªèe trong tr∆∞·ªùng c·ªßa m√¨nh. positive neutral\n",
            "C·∫≠u ·∫•y r·∫•t nh·∫°y b√©n v√† c√≥ s·ª©c ph√¢n t√≠ch t·ªët trong nh·ªØng v·∫•n ƒë·ªÅ ph·ª©c t·∫°p. neutral positive\n",
            "T√¥i r·∫•t ·∫•n t∆∞·ª£ng v·ªõi s·ª± trang tr√≠ trong tr∆∞·ªùng, ch√∫ng t·∫°o c·∫£m gi√°c tho·∫£i m√°i v√† th∆∞ gi√£n cho sinh vi√™n. positive neutral\n",
            "L·ªõp h·ªçc ƒë∆∞·ª£c t·ªï ch·ª©c ng·∫Øn g·ªçn, th·ª±c t·∫ø v√† c√≥ t√≠nh ·ª©ng d·ª•ng cao. positive neutral\n",
            "C√¥ ·∫•y lu√¥n s·∫µn s√†ng gi√∫p ƒë·ª° v√† h·ªó tr·ª£ ng∆∞·ªùi kh√°c. positive neutral\n",
            "C√¥ b·∫°n n√†y r·∫•t t·ª± l·∫≠p v√† ƒë·ªôc l·∫≠p. positive neutral\n",
            "T·ª± do ƒë·ªÉ qu·∫£n l√Ω th·ªùi gian h·ªçc t·∫≠p. positive neutral\n",
            "C∆° s·ªü h·∫° t·∫ßng ·ªü ƒë√¢y r·∫•t ƒë√°p ·ª©ng nhu c·∫ßu h·ªçc t·∫≠p c·ªßa sinh vi√™n. positive neutral\n",
            "Anh ·∫•y r·∫•t l·ªãch s·ª± v√† t√¥n tr·ªçng ng∆∞·ªùi kh√°c. positive neutral\n",
            "C√¥ ·∫•y lu√¥n th·ªÉ hi·ªán s·ª± nghi√™m t√∫c v√† t√¢m huy·∫øt trong vi·ªác h·ªçc t·∫≠p v√† gi·∫£ng d·∫°y. positive neutral\n",
            "C√¥ n√†y l√† ng∆∞·ªùi chƒÉm ch·ªâ v√† c√≥ tinh th·∫ßn tr√°ch nhi·ªám cao. positive neutral\n",
            "B·∫°n c·ªßa em l√† ng∆∞·ªùi d·ªÖ th∆∞∆°ng v√† tr·∫ª trung. positive neutral\n",
            "Ch·ªã ·∫•y l√† ng∆∞·ªùi th·∫≠t s·ª± t·∫≠n t√¢m v√† d√†nh tr·ªçn t√¢m huy·∫øt cho c√¥ng vi·ªác. positive neutral\n",
            "C√¥ ·∫•y r·∫•t s√°ng t·∫°o v√† ngh·ªá thu·∫≠t. positive neutral\n",
            "Gi√°o vi√™n c·ªßa t√¥i d·∫°y l√≠ thuy·∫øt v√† th·ª±c h√†nh v·ªÅ quy·ªÅn s·ªü h·ªØu tr√≠ tu·ªá v√† b·∫£o v·ªá nh√£n hi·ªáu. neutral positive\n",
            "Ch∆∞∆°ng tr√¨nh ƒë√†o t·∫°o gi√∫p t√¥i ph√°t tri·ªÉn m·ªëi quan h·ªá v·ªõi c√°c sinh vi√™n kh√°c v√† c√°c gi·∫£ng vi√™n. neutral positive\n",
            "T√¥i r·∫•t th√≠ch nh·ªØng khu v·ª±c xanh trong tr∆∞·ªùng, ch√∫ng t·∫°o c·∫£m gi√°c tho·∫£i m√°i v√† g·∫ßn g≈©i v·ªõi thi√™n nhi√™n. positive neutral\n",
            "N√†ng c√≥ s·ª± t·∫≠p trung cao ƒë·ªô v√† lu√¥n ƒë·∫°t ƒë∆∞·ª£c nh·ªØng th√†nh t√≠ch t·ªët. positive neutral\n",
            "Gi·∫£ng vi√™n lu√¥n truy·ªÅn ƒë·∫°t nh·ªØng c√¢u h·ªèi ƒë·ªÉ sinh vi√™n c·∫£m th·∫•y t√≤ m√≤ v√† quan t√¢m ƒë·∫øn b·∫£n th√¢n. positive neutral\n",
            "M·ªôt s·ªë b·∫°n kh√° gi·ªèi nh∆∞ng l√∫c l√†m vi·ªác ch·∫≠m nh∆∞ r√πa neutral negative\n",
            "C√°c khu v·ª±c sinh ho·∫°t c·ªßa tr∆∞·ªùng c·∫ßn ƒë∆∞·ª£c x√¢y d·ª±ng l·∫°i ƒë·ªÉ ƒë√°p ·ª©ng nhu c·∫ßu c·ªßa sinh vi√™n. negative neutral\n",
            "Anh ·∫•y l√† m·ªôt ng∆∞·ªùi h·ªçc nhanh v√† c√≥ kh·∫£ nƒÉng t√¨m ki·∫øm th√¥ng tin m·ªôt c√°ch hi·ªáu qu·∫£. positive neutral\n",
            "Th∆∞ vi·ªán ƒë·∫ßy ƒë·ªß s√°ch v·ªü c·∫ßn thi·∫øt. neutral positive\n",
            "T√¥i r·∫•t h√†i l√≤ng v·ªõi ch∆∞∆°ng tr√¨nh ƒë√†o t·∫°o v√¨ c√≥ c·∫£ c√°c m√¥n h·ªçc ng·∫Øn h·∫°n cho sinh vi√™n. neutral positive\n",
            "Khu v·ª±c b·∫Øn ph√°o hoa v√† m·ª´ng l·ªÖ qu√° g·∫ßn tr∆∞·ªùng, ƒë·∫∑c bi·ªát v√†o d·ªãp T·∫øt Nguy√™n ƒê√°n, d·∫´n ƒë·∫øn ·∫£nh h∆∞·ªüng nghi√™m tr·ªçng ƒë·∫øn vi·ªác h·ªçc c·ªßa sinh vi√™n. positive negative\n",
            "C√°c m√¥n h·ªçc gi√∫p sinh vi√™n ph√°t tri·ªÉn t∆∞ duy ph·∫£n bi·ªán v√† ƒë·ªôc l·∫≠p trong t∆∞ duy. neutral positive\n",
            "T√¥i r·∫•t c·∫£m k√≠ch v√¨ s·ª± h·ªó tr·ª£ c·ªßa anh ·∫•y. positive neutral\n",
            "Anh ta l√† m·ªôt ng∆∞·ªùi ƒë√°ng tin c·∫≠y v√† lu√¥n gi·ªØ l·ªùi h·ª©a c·ªßa m√¨nh. positive neutral\n",
            "Anh ·∫•y r·∫•t th·∫•u hi·ªÉu v√† gi√∫p ƒë·ª° nh·ªØng ng∆∞·ªùi g·∫∑p kh√≥ khƒÉn. positive neutral\n",
            "Gi·∫£ng vi√™n c√≥ th·ªÉ s·ª≠ d·ª•ng nhi·ªÅu ph∆∞∆°ng ph√°p gi·∫£ng d·∫°y kh√°c nhau ƒë·ªÉ thu h√∫t sinh vi√™n h·ªçc t·∫≠p. neutral positive\n",
            "Gi·∫£ng vi√™n nh·∫≠n x√©t ƒë√°nh gi√° c·ªßa t√¥i l√† ch∆∞a ƒë·ªß chi ti·∫øt khi t√¥i ƒë√£ c·ªë g·∫Øng l√†m h·∫øt. neutral negative\n",
            "Th·∫ßy gi√∫p ƒë·ª° sinh vi√™n ƒë·ªãnh h∆∞·ªõng ngh·ªÅ nghi·ªáp v√† ph√°t tri·ªÉn b·∫£n th√¢n. positive neutral\n",
            "C√¥ ·∫•y lu√¥n t·ªè ra th√¢n thi·ªán v√† t·∫°o ra kh√¥ng kh√≠ l√†m vi·ªác t·ªët trong nh√≥m. positive neutral\n",
            "Vi·ªác thi·∫øu gi·∫£ng vi√™n chuy√™n nghi·ªáp t·∫°i m·ªôt s·ªë v√πng ƒë·∫•t c√≥ th·ªÉ l√† m·ªôt nh∆∞·ª£c ƒëi·ªÉm c·ªßa ch∆∞∆°ng tr√¨nh. negative neutral\n",
            "T√¥i r·∫•t th√≠ch l·ªëi thi·∫øt k·∫ø v√† trang tr√≠ c·ªßa tr∆∞·ªùng, n√≥ c·ª±c k·ª≥ ·∫•n t∆∞·ª£ng v√† s√°ng t·∫°o. positive neutral\n",
            "L·ªõp h·ªçc ƒë∆∞·ª£c ƒë∆∞a ra m·ªôt c√°ch sinh ƒë·ªông, h·∫•p d·∫´n v√† ƒë·∫ßy ƒë·ªß ki·∫øn th·ª©c chuy√™n m√¥n. positive neutral\n",
            "Gi·∫£ng vi√™n h∆∞·ªõng d·∫´n gi·ªèi v·ªõi l∆∞·ª£ng kinh nghi·ªám th·ª±c ti·ªÖn phong ph√∫. neutral positive\n",
            "Th·∫ßy cung c·∫•p cho ch√∫ng t√¥i nhi·ªÅu t√†i li·ªáu v√† b√†i gi·∫£ng h·ªØu √≠ch. neutral positive\n",
            "Em th·∫•y b·∫°n c·ªßa m√¨nh r·∫•t nhanh nh·∫πn v√† chƒÉm ch·ªâ h·ªçc. positive neutral\n",
            "ƒê·ªôi ng≈© gi·∫£ng vi√™n chuy√™n nghi·ªáp v√† th√¢n thi·ªán. neutral positive\n",
            "C√°ch ƒë√°nh gi√° v√† ph∆∞∆°ng ph√°p gi·∫£ng d·∫°y c·ªßa tr∆∞·ªùng r·∫•t khuy·∫øn kh√≠ch v√† t·∫°o ƒë·ªông l·ª±c cho h·ªçc sinh. neutral positive\n",
            "Th·∫ßy gi·∫£ng d·∫°y r·∫•t chu ƒë√°o v√† chuy√™n nghi·ªáp. neutral positive\n",
            "Gi√°o vi√™n r·∫•t nhi·ªát t√¨nh v√† gi√∫p ƒë·ª° sinh vi√™n trong qu√° tr√¨nh h·ªçc t·∫≠p. positive neutral\n",
            "B·∫°n c·ªßa t√¥i l√† ng∆∞·ªùi r·∫•t duy√™n d√°ng v√† s√†nh ƒëi·ªáu. positive neutral\n",
            "Anh ·∫•y l√† m·ªôt ng∆∞·ªùi h·ªçc t·∫≠p t√≠ch c·ª±c v√† ƒëam m√™ trong vi·ªác t√¨m hi·ªÉu ki·∫øn th·ª©c m·ªõi. positive neutral\n",
            "H·ªçc ph√≠ tƒÉng m·ªôt c√°ch kh√¥ng ƒë√°ng k·ªÉ, kh√¥ng ƒë√°p ·ª©ng gi√° tr·ªã c·ªßa ch∆∞∆°ng tr√¨nh ƒë√†o t·∫°o. neutral negative\n",
            "C∆° s·ªü v·∫≠t ch·∫•t c·ªßa tr∆∞·ªùng ƒë∆∞·ª£c trang b·ªã hi·ªán ƒë·∫°i v√† ch·∫•t l∆∞·ª£ng. positive neutral\n",
            "Anh ·∫•y lu√¥n c√≥ nh·ªØng √Ω t∆∞·ªüng kh√°c bi·ªát v·ªõi nh·ªØng ng∆∞·ªùi kh√°c trong nh√≥m. neutral negative\n",
            "C√¥ b·∫°n n√†y r·∫•t chƒÉm ch·ªâ h·ªçc t·∫≠p. positive neutral\n",
            "Th·∫ßy l√† m·ªôt gi·∫£ng vi√™n r·∫•t gi·ªèi trong vi·ªác truy·ªÅn ƒë·∫°t ki·∫øn th·ª©c v√† k·ªπ nƒÉng cho sinh vi√™n. positive neutral\n",
            "B·∫°n c·ªßa t√¥i r·∫•t chƒÉm ch·ªâ v√† lu√¥n ƒë√∫ng gi·ªù. positive neutral\n",
            "Tr∆∞·ªùng ƒë·∫°i h·ªçc c√≥ nh·ªØng khu√¥n vi√™n xanh r·∫•t ƒë·∫πp v√† tho√°ng m√°t. positive neutral\n",
            "C√¥ ·∫•y r·∫•t nƒÉng ƒë·ªông v√† th√¢n thi·ªán ƒë·ªëi v·ªõi m·ªçi ng∆∞·ªùi trong l·ªõp. positive neutral\n",
            "Anh ·∫•y l√† m·ªôt ng∆∞·ªùi gi·ªèi v·ªÅ c√¥ng ngh·ªá v√† c√≥ kh·∫£ nƒÉng gi·∫£i quy·∫øt v·∫•n ƒë·ªÅ k·ªπ thu·∫≠t. positive neutral\n",
            "Anh b·∫°n c√πng l·ªõp r·∫•t h√≤a ƒë·ªìng v√† d·ªÖ g·∫ßn. positive neutral\n",
            "Ch∆∞∆°ng tr√¨nh ƒë√†o t·∫°o gi√∫p t√¥i trang b·ªã nh·ªØng k·ªπ nƒÉng m·ªÅm c·∫ßn thi·∫øt ƒë·ªÉ th√†nh c√¥ng trong t∆∞∆°ng lai. positive neutral\n",
            "C√¥ng ngh·ªá v√† trang thi·∫øt b·ªã c·ªßa ƒë·∫°i h·ªçc t·ªët h∆°n so v·ªõi nhi·ªÅu tr∆∞·ªùng kh√°c. positive neutral\n",
            "Gi·∫£ng vi√™n n√†y d·∫°y r·∫•t t·ªët v√† truy·ªÅn c·∫£m h·ª©ng cho h·ªçc sinh. neutral positive\n",
            "Th·∫ßy t·∫°o ra m√¥i tr∆∞·ªùng h·ªçc t·∫≠p vui v·∫ª v√† ·∫•m c√∫ng. positive neutral\n",
            "ƒê∆∞·ªùng ƒëi l·∫°i trong tr∆∞·ªùng ƒë∆∞·ª£c b·ªë tr√≠ r·∫•t h·ª£p l√Ω v√† thu·∫≠n ti·ªán cho sinh vi√™n. positive neutral\n",
            "Tr∆∞·ªùng lu√¥n gi·ªØ g√¨n s·∫°ch s·∫Ω v√† d·ªÖ d√†ng b·∫£o tr√¨ h∆°n nh·ªù v√†o c√°c thi·∫øt b·ªã trang tr√≠ v√† c∆° s·ªü v·∫≠t ch·∫•t. positive neutral\n",
            "ƒê·ªôi ng≈© k·ªπ thu·∫≠t c·ªßa tr∆∞·ªùng lu√¥n c√≥ m·∫∑t ƒë·ªÉ gi√∫p ƒë·ª° v√† gi·∫£i quy·∫øt c√°c v·∫•n ƒë·ªÅ k·ªπ thu·∫≠t cho sinh vi√™n. positive neutral\n",
            "Th·∫ßy/c√¥ c√≥ kh·∫£ nƒÉng t∆∞∆°ng t√°c t·ªët v·ªõi sinh vi√™n. positive neutral\n",
            "ƒê·ªôi ng≈© nh√¢n vi√™n c·ªßa tr∆∞·ªùng r·∫•t th√¢n thi·ªán v√† h·ªó tr·ª£ t·∫≠n t√¨nh. neutral positive\n",
            "Th·∫ßy/c√¥ t·∫°o ƒëi·ªÅu ki·ªán thu·∫≠n l·ª£i cho sinh vi√™n trao ƒë·ªïi v√† th·∫£o lu·∫≠n √Ω ki·∫øn. positive neutral\n",
            "Ch∆∞∆°ng tr√¨nh gi·∫£ng d·∫°y r·∫•t ph√π h·ª£p v·ªõi nhu c·∫ßu c·ªßa sinh vi√™n. neutral positive\n",
            "Th·∫ßy c√¥ ƒë·ªÅ cao c√°c tr·∫ª em tr√™n h·∫øt v√† mang ƒë·∫øn cho ch√∫ng ta m·ªôt m√¥i tr∆∞·ªùng h·ªçc t·∫≠p khuy·∫øn kh√≠ch v√† th√¢n thi·ªán. positive neutral\n",
            "C√°c khu v·ª±c ƒë·∫∑t t·ªß h·ªì s∆° c·ªßa tr∆∞·ªùng ƒë∆∞·ª£c b·∫£o qu·∫£n an to√†n v√† ch√≠n chu. neutral positive\n",
            "T√¥i c·∫£m th·∫•y r·∫•t ·∫•m √°p v√† tho·∫£i m√°i khi s·ª≠ d·ª•ng ph√≤ng sinh ho·∫°t chung. positive neutral\n",
            "Ch∆∞∆°ng tr√¨nh h·ªçc c·ªßa tr∆∞·ªùng gi√∫p t√¥i thi·∫øt l·∫≠p k·∫ø ho·∫°ch h·ªçc t·∫≠p c√° nh√¢n. positive neutral\n",
            "Th·∫ßy c√≥ kh·∫£ nƒÉng ph√°t hi·ªán v√† gi·∫£i quy·∫øt c√°c v·∫•n ƒë·ªÅ c·ªßa h·ªçc vi√™n trong qu√° tr√¨nh h·ªçc t·∫≠p. neutral positive\n",
            "Gi·∫£ng vi√™n c·∫≠p nh·∫≠t th√¥ng tin nhanh ch√≥ng v√† c√≥ hi·ªÉu bi·∫øt s√¢u v·ªÅ th·ª±c t·∫ø c·ªßa ng√†nh h·ªçc. positive neutral\n",
            "B·∫°n c·ªßa t√¥i r·∫•t y√™u th√≠ch nh·ªØng tr·∫£i nghi·ªám m·ªõi. positive neutral\n",
            "Kh√¥ng gian n·ªôi th·∫•t c·ªßa ph√≤ng h·ªçc r·∫•t t·ªët, ƒë∆∞·ª£c thi·∫øt k·∫ø ƒë·ªÉ gi√∫p tƒÉng s·ª± t·∫≠p trung c·ªßa sinh vi√™n. positive neutral\n",
            "T√¥i c·∫£m th·∫•y r·∫•t c·∫£m k√≠ch v√¨ gi·∫£ng vi√™n c·ªßa m√¨nh lu√¥n s·∫µn s√†ng gi√∫p ƒë·ª° sinh vi√™n trong b·∫•t c·ª© l√∫c n√†o. positive neutral\n",
            "Gi·∫£ng ƒë∆∞·ªùng c·ªßa tr∆∞·ªùng r·ªông r√£i v√† tho·∫£i m√°i cho vi·ªác h·ªçc t·∫≠p. positive neutral\n",
            "T√¥i r·∫•t h√†i l√≤ng v·ªõi c√°c ph√≤ng h·ªçc ·ªü ƒë√¢y. positive neutral\n",
            "Gi·∫£ng vi√™n gi√∫p sinh vi√™n h√¨nh th√†nh ph∆∞∆°ng ph√°p h·ªçc t·∫≠p hi·ªáu qu·∫£. positive neutral\n",
            "H·ªçc t·∫°i ƒë√¢y ƒë√≤i h·ªèi t√¥i t√≠nh k·ª∑ lu·∫≠t v√† s·ª± ƒë√≥ng g√≥p s√°ng t·∫°o. neutral positive\n",
            "Th√¥ng tin tr∆∞·ªùng ƒë∆∞·ª£c ƒëƒÉng t·∫£i ƒë·∫ßy ƒë·ªß v√† chi ti·∫øt. neutral positive\n",
            "Gi√°o tr√¨nh ƒë∆∞·ª£c c·∫≠p nh·∫≠t th∆∞·ªùng xuy√™n v√† ph√π h·ª£p v·ªõi ch∆∞∆°ng tr√¨nh h·ªçc c·ªßa tr∆∞·ªùng. neutral positive\n",
            "Ph√≤ng th·ª±c h√†nh c√≥ trang thi·∫øt b·ªã v√† c√¥ng c·ª• hi·ªán ƒë·∫°i. positive neutral\n",
            "C√≥ nhi·ªÅu t√†i li·ªáu tham kh·∫£o v√† t√†i nguy√™n h·ªçc t·∫≠p mi·ªÖn ph√≠. positive neutral\n",
            "C√°c ph√≤ng th√≠ nghi·ªám c·ªßa tr∆∞·ªùng ƒë∆∞·ª£c trang b·ªã ƒë·∫ßy ƒë·ªß thi·∫øt b·ªã v√† c√¥ng ngh·ªá hi·ªán ƒë·∫°i. positive neutral\n",
            "T√¥i th·∫≠t s·ª± ƒë√°nh gi√° cao c∆° s·ªü v·∫≠t ch·∫•t c·ªßa tr∆∞·ªùng, n√≥ ƒë√°p ·ª©ng t·ªët nhu c·∫ßu h·ªçc t·∫≠p v√† gi·∫£i tr√≠ c·ªßa sinh vi√™n. positive neutral\n",
            "T√¥i c·∫£m th·∫•y h·ªçc ph√≠ h·ª£p l√≠ v·ªõi ch·∫•t l∆∞·ª£ng ƒë√†o t·∫°o c·ªßa tr∆∞·ªùng. neutral positive\n",
            "Ch∆∞∆°ng tr√¨nh ƒë√†o t·∫°o gi√∫p t√¥i c√≥ c∆° h·ªôi h·ªçc t·∫≠p v√† trau d·ªìi kinh nghi·ªám ngo√†i l·ªõp h·ªçc. positive neutral\n",
            "Ch∆∞∆°ng tr√¨nh ƒë√†o t·∫°o gi√∫p t√¥i ph√°t tri·ªÉn nh·ªØng k·ªπ nƒÉng m√† t√¥i c·∫ßn. positive neutral\n",
            "M√¥n h·ªçc t·∫≠p trung v√†o vi·ªác th·ª±c h√†nh v√† ·ª©ng d·ª•ng ki·∫øn th·ª©c v√†o th·ª±c t·∫ø. positive neutral\n",
            "Anh ta l√† m·ªôt ng∆∞·ªùi vui t√≠nh v√† d·ªÖ g·∫ßn. positive neutral\n",
            "Th·∫ßy ƒë√£ gi√∫p t√¥i c√≥ ƒë∆∞·ª£c nhi·ªÅu ki·∫øn th·ª©c quan tr·ªçng v√† k·ªπ nƒÉng c·∫ßn thi·∫øt trong c√¥ng vi·ªác. positive neutral\n",
            "Gi√°o tr√¨nh r·∫•t th·ª±c ti·ªÖn v√† ƒë√°p ·ª©ng ƒë∆∞·ª£c y√™u c·∫ßu c·ªßa c√¥ng vi·ªác hi·ªán nay. positive neutral\n",
            "Ch∆∞∆°ng tr√¨nh h·ªçc c·ªßa tr∆∞·ªùng cung c·∫•p cho t√¥i ki·∫øn th·ª©c thi·∫øt th·ª±c v√† c√≥ gi√° tr·ªã. positive neutral\n",
            "C√°c gi·∫£ng vi√™n r·∫•t t·∫≠n t√¢m v√† nhi·ªát t√¨nh trong vi·ªác gi·∫£ng d·∫°y. neutral positive\n",
            "ƒê·ªôi ng≈© nh√¢n vi√™n b·∫£o tr√¨ tr∆∞·ªùng lu√¥n h·ªó tr·ª£ v√† s·ª≠ d·ª•ng c√°c ti·ªán √≠ch t·ªët nh·∫•t. positive neutral\n",
            "Gi·∫£ng vi√™n c·ªßa t√¥i n√≥i r·∫•t r√µ v√† d·ªÖ nghe, ƒëi·ªÅu n√†y gi√∫p t√¥i hi·ªÉu ƒë∆∞·ª£c m√¥n h·ªçc c·ªßa m√¨nh nhanh h∆°n. positive neutral\n",
            "Gi·∫£ng vi√™n n√†y l√† m·ªôt ng∆∞·ªùi r·∫•t ki√™n nh·∫´n v√† quan t√¢m ƒë·∫øn s·ª± ti·∫øn b·ªô c·ªßa h·ªçc sinh. positive neutral\n",
            "Khu v·ª±c khu√¢n vi√™n quanh tr∆∞·ªùng xanh t∆∞∆°i, nh·ªØng tin t·ª©c, th√¥ng b√°o c·ªßa tr∆∞·ªùng ƒë∆∞·ª£c ph√°t tr·ª±c ti·∫øp, r√µ r√†ng, d·ªÖ ti·∫øp c·∫≠n. positive neutral\n",
            "C√°c m√¥n h·ªçc v·ªÅ ·ª©ng d·ª•ng c√¥ng ngh·ªá th√¥ng tin trong kinh doanh r·∫•t h·ªØu √≠ch. positive neutral\n",
            "B√†i gi·∫£ng r·∫•t r√µ r√†ng v√† d·ªÖ hi·ªÉu. neutral positive\n",
            "C√¥ b·∫°n n√†y r·∫•t hi·ªÅn l√†nh v√† t·ªët b·ª•ng. positive neutral\n",
            "H·ªç lu√¥n d√†nh th·ªùi gian cho sinh vi√™n n·∫øu ch√∫ng ta c√≥ b·∫•t k·ª≥ c√¢u h·ªèi n√†o. negative neutral\n",
            "Gi·ªù h·ªçc c·ªßa th·∫ßy r·∫•t hi·ªáu qu·∫£ v√† c·∫•u tr√∫c. neutral positive\n",
            "T√¥i c·∫£m th·∫•y r·∫•t vui khi h·ªçc v·ªõi gi·∫£ng vi√™n n√†y. positive neutral\n",
            "C√°c b√†i gi·∫£ng d·ªÖ hi·ªÉu v√† h·ªó tr·ª£ h·ªçc t·∫≠p t·ªët. positive neutral\n",
            "Nh·ªØng b√†i gi·∫£ng c·ªßa gi√°o vi√™n r·∫•t chi ti·∫øt v√† ƒë·∫ßy ƒë·ªß th√¥ng tin. neutral positive\n",
            "Ch∆∞∆°ng tr√¨nh h·ªçc c·ªßa tr∆∞·ªùng ƒë·∫∑t nhi·ªÅu gi√° tr·ªã v√†o ƒë·∫°o ƒë·ª©c, tinh th·∫ßn v√† gi√° tr·ªã con ng∆∞·ªùi. positive neutral\n",
            "Th·∫ßy lu√¥n c·∫≠p nh·∫≠t ki·∫øn th·ª©c m·ªõi nh·∫•t ƒë·ªÉ gi·∫£ng d·∫°y cho sinh vi√™n. positive neutral\n",
            "Gi·∫£ng vi√™n n√†y lu√¥n ki·ªÉm tra nh·ªØng b√†i t·∫≠p t·ª± l√†m c·ªßa sinh vi√™n. neutral negative\n",
            "Gi·∫£ng vi√™n r·∫•t tinh t·∫ø khi ƒë∆∞a ra c√°c b√†i gi·∫£ng s√¢u s·∫Øc. neutral positive\n",
            "Ch∆∞∆°ng tr√¨nh gi·∫£ng d·∫°y k·∫øt h·ª£p gi·ªØa l√Ω thuy·∫øt v√† th·ª±c h√†nh t·ªët. neutral positive\n",
            "C√≥ c√°c ho·∫°t ƒë·ªông th·ªÉ thao v√† ngh·ªá thu·∫≠t cho sinh vi√™n tham gia. positive neutral\n",
            "Th·∫ßy ƒë∆∞a ra nh·ªØng t√†i li·ªáu v√† th√≠ nghi·ªám th·ª±c t·∫ø ƒë·ªÉ gi√∫p h·ªçc sinh h·ªçc t·∫≠p t·ªët h∆°n. neutral positive\n",
            "Thi·∫øt b·ªã v√† ph∆∞∆°ng ti·ªán gi·∫£ng d·∫°y c·ªßa tr∆∞·ªùng c·∫ßn ƒë∆∞·ª£c n√¢ng c·∫•p. neutral negative\n",
            "Gi·∫£ng vi√™n n√†y quan t√¢m ƒë·∫øn s·ª± ti·∫øn b·ªô c·ªßa h·ªçc sinh v√† s·∫µn s√†ng gi·∫£i ƒë√°p m·ªçi th·∫Øc m·∫Øc c·ªßa h·ªç. positive neutral\n",
            "Gi·∫£ng vi√™n r·∫•t d·ªÖ ti·∫øp c·∫≠n v√† th√¢n thi·ªán, d·ªÖ t·∫°o ƒë∆∞·ª£c m√¥i tr∆∞·ªùng h·ªçc t·∫≠p t√≠ch c·ª±c. positive neutral\n",
            "C√¥ b·∫°n n√†y r·∫•t l·ªãch s·ª± v√† t·∫ø nh·ªã. positive neutral\n",
            "Anh ta l√† ng∆∞·ªùi r·∫•t nƒÉng ƒë·ªông v√† lu√¥n t·∫°o ƒë·ªông l·ª±c cho ng∆∞·ªùi kh√°c. positive neutral\n",
            "C√°c ki·∫øn th·ª©c ƒë∆∞·ª£c truy·ªÅn ƒë·∫°t r√µ r√†ng v√† d·ªÖ ti·∫øp thu. positive neutral\n",
            "Anh ta l√† m·ªôt ng∆∞·ªùi th√¢n thi·ªán v√† lu√¥n l·∫Øng nghe ng∆∞·ªùi kh√°c. positive neutral\n",
            "C√¥ ·∫•y kh√° nƒÉng ƒë·ªông v√† lu√¥n c√≥ √Ω t∆∞·ªüng s√°ng t·∫°o. positive neutral\n",
            "C√¥ gi√°o c·ªßa t√¥i l√† ng∆∞·ªùi r·∫•t th√¥ng th√°i v√† gi√†u kinh nghi·ªám. positive neutral\n",
            "Gi·∫£ng vi√™n c√≥ k·ªπ nƒÉng gi·∫£ng d·∫°y t·ªët, gi√∫p sinh vi√™n t·ª± tin v√† hi·ªÉu r√µ h∆°n v·ªÅ ch·ªß ƒë·ªÅ. positive neutral\n",
            "ƒê·∫°i h·ªçc t√¥i c√≥ nhi·ªÅu c√¥ng tr√¨nh ki·∫øn tr√∫c ƒë·∫πp v√† ·∫•n t∆∞·ª£ng. positive neutral\n",
            "N·ªôi dung h·ªçc phong ph√∫, ƒëa d·∫°ng v√† c·∫≠p nh·∫≠t. positive neutral\n",
            "Anh ·∫•y l√† ng∆∞·ªùi lu√¥n d√†nh th·ªùi gian cho s·ª± nghi·ªáp v√† h·ªçc t·∫≠p c·ªßa m√¨nh. positive neutral\n",
            "T√¥i r·∫•t ng∆∞·ª°ng m·ªô kh·∫£ nƒÉng l√†m vi·ªác c·ªßa anh ·∫•y. positive neutral\n",
            "Gi·∫£ng vi√™n r·∫•t th√¥ng minh v√† c√≥ ki·∫øn th·ª©c s√¢u r·ªông. positive neutral\n",
            "Tr∆∞·ªùng ƒë·∫°i h·ªçc c·ªßa t√¥i c√≥ nhi·ªÅu khu v·ª±c sinh ho·∫°t chung ƒë·ªÉ sinh vi√™n c√≥ c∆° h·ªôi giao l∆∞u v√† h·ªçc h·ªèi. positive neutral\n",
            "Anh ·∫•y lu√¥n ƒë·∫∑t c√°c m·ª•c ti√™u v√† ho√†n th√†nh ch√∫ng m·ªôt c√°ch t·ªët ƒë·∫πp. positive neutral\n",
            "Anh ·∫•y l√† m·ªôt ng∆∞·ªùi ·ªïn ƒë·ªãnh v√† c√≥ kh·∫£ nƒÉng t·∫≠p trung v√†o m·ª•c ti√™u. positive neutral\n",
            "Anh ·∫•y l√† m·ªôt ng∆∞·ªùi r·∫•t ƒë√°ng tin c·∫≠y, lu√¥n lu√¥n gi·ªØ l·ªùi h·ª©a. positive neutral\n",
            "M√¥n h·ªçc c√≥ s·ª©c h·∫•p d·∫´n cao, t·∫°o ƒë·ªông l·ª±c cho sinh vi√™n h·ªçc t·∫≠p. positive neutral\n",
            "Gi√°o vi√™n c·ªßa t√¥i h∆∞·ªõng d·∫´n sinh vi√™n th·ª±c hi·ªán c√°c nghi√™n c·ª©u th·ªã tr∆∞·ªùng v√† ƒë√°nh gi√° s·∫£n ph·∫©m. neutral positive\n",
            "Th∆∞ vi·ªán tr∆∞·ªùng c√≥ nhi·ªÅu ch·ªß ƒë·ªÅ kh√°c nhau gi√∫p sinh vi√™n t√¨m ƒë∆∞·ª£c ngu·ªìn t√†i li·ªáu ph√π h·ª£p v·ªõi nhu c·∫ßu h·ªçc t·∫≠p c·ªßa m√¨nh. neutral positive\n",
            "T√¥i r·∫•t h√†i l√≤ng v·ªõi c√°c d·ªãch v·ª• h·ªó tr·ª£ c·ªßa tr∆∞·ªùng, ƒë·∫∑c bi·ªát l√† c√°c d·ªãch v·ª• t∆∞ v·∫•n v√† t√†i ch√≠nh. positive neutral\n",
            "Anh ta c√≥ t√≠nh c√°ch ƒëi·ªÅm ƒë·∫°m v√† kh√¥ng bao gi·ªù ho·∫£ng lo·∫°n. neutral positive\n",
            "Th·∫ßy cung c·∫•p cho sinh vi√™n c√°c t√†i nguy√™n v√† c√¥ng c·ª• h·ªó tr·ª£ gi·∫£ng d·∫°y hi·ªáu qu·∫£. neutral positive\n",
            "Th·∫ßy l√† ng∆∞·ªùi gi·∫£ng d·∫°y gi·ªèi nh·∫•t m√† t√¥i t·ª´ng g·∫∑p. positive neutral\n",
            "Tr∆∞·ªùng cung c·∫•p ƒë·∫ßy ƒë·ªß c√°c th√¥ng tin v√† t√†i li·ªáu cho sinh vi√™n ƒë·ªÉ gi√∫p t√¥i h·ªçc t·∫≠p m·ªôt c√°ch hi·ªáu qu·∫£. neutral positive\n",
            "Tr∆∞·ªùng c√≥ cung c·∫•p wifi mi·ªÖn ph√≠ cho sinh vi√™n, gi√∫p c√°c em ti·ªán l·ª£i h∆°n trong vi·ªác truy c·∫≠p internet. positive neutral\n",
            "C√¥ ·∫•y c√≥ kh·∫£ nƒÉng n·∫Øm b·∫Øt ƒë∆∞·ª£c √Ω t∆∞·ªüng m·ªõi v√† th√∫c ƒë·∫©y c√°c ho·∫°t ƒë·ªông t·∫°o √Ω t∆∞·ªüng s√°ng t·∫°o. positive neutral\n",
            "Th·∫ßy d·∫°y r·∫•t t√¢m huy·∫øt v√† c√≥ nhi·ªÅu ƒë√≥ng g√≥p cho s·ª± ph√°t tri·ªÉn c·ªßa sinh vi√™n. positive neutral\n",
            "C√≥ r·∫•t nhi·ªÅu c∆° h·ªôi ƒë·ªÉ b·∫°n ph√°t tri·ªÉn nƒÉng l·ª±c kh√¥ng ch·ªâ trong l·ªõp h·ªçc m√† c√≤n ngo√†i ƒë·ªùi th·ª±c. positive neutral\n",
            "Khu v·ª±c ng·ªìi ch·ªù ƒë·ª£i ƒë∆∞·ª£c trang b·ªã ƒë·∫ßy ƒë·ªß gh·∫ø v√† trang thi·∫øt b·ªã gi√∫p sinh vi√™n ch·ªù ƒë·ª£i m·ªôt c√°ch tho·∫£i m√°i. positive neutral\n",
            "Gi·∫£ng vi√™n d·∫°y r·∫•t c√≥ t√¢m, t·∫≠n t√¨nh gi√∫p ƒë·ª° sinh vi√™n khi c·∫ßn. positive neutral\n",
            "C√¥ b·∫°n n√†y l√† m·ªôt gi·∫£ng vi√™n tuy·ªát v·ªùi, lu√¥n h·ªó tr·ª£ v√† gi√∫p ƒë·ª° sinh vi√™n. positive neutral\n",
            "T√¥i r·∫•t th√≠ch c√°ch m√† ch∆∞∆°ng tr√¨nh ƒë√†o t·∫°o ƒë∆∞·ª£c t·ªï ch·ª©c v√† qu·∫£n l√Ω. positive neutral\n",
            "Ch∆∞∆°ng tr√¨nh ti√™n ti·∫øn ch∆∞a ƒë∆∞·ª£c tri·ªÉn khai r·ªông r√£i cho sinh vi√™n. negative neutral\n",
            "H·ªá th·ªëng wifi mi·ªÖn ph√≠ s·ª≠ d·ª•ng thu·∫≠n ti·ªán. positive neutral\n",
            "C√¥ ·∫•y l√† m·ªôt ng∆∞·ªùi r·∫•t gi·ªèi trong vi·ªác gi·∫£ng d·∫°y v√† r·∫•t nhi·ªát t√¨nh. positive neutral\n",
            "Anh ·∫•y l√† m·ªôt ng∆∞·ªùi c√≥ kh·∫£ nƒÉng truy·ªÅn c·∫£m h·ª©ng v√† ƒë·ªông vi√™n ng∆∞·ªùi kh√°c. positive neutral\n",
            "Ch∆∞∆°ng tr√¨nh h·ªçc c·ªßa tr∆∞·ªùng gi√∫p t√¥i c√≥ c∆° h·ªôi tham gia c√°c ho·∫°t ƒë·ªông ngo·∫°i kh√≥a v√† th·ªÉ thao. positive neutral\n",
            "B·∫°n c·ªßa t√¥i r·∫•t th√¢n thi·ªán. positive neutral\n",
            "K√Ω t√∫c x√° c·ªßa tr∆∞·ªùng r·∫•t ti·ªán nghi v√† s·∫°ch s·∫Ω. positive neutral\n",
            "C√¥ n√†y l√† ng∆∞·ªùi r·∫•t chuy√™n nghi·ªáp v√† c√≥ kinh nghi·ªám gi·∫£ng d·∫°y l√¢u nƒÉm. positive neutral\n",
            "N∆°i ƒë√¢y c√≥ nhi·ªÅu ph√≤ng th√≠ nghi·ªám v√† trang thi·∫øt b·ªã c·∫ßn thi·∫øt ƒë·ªÉ h·ªó tr·ª£ h·ªçc vi√™n. positive neutral\n",
            "M√¥n h·ªçc c·ªß th·ªÉ ch·∫Øc ch·∫Øn s·∫Ω kh√¥ng bao gi·ªù bu·ªìn t·∫ª v·ªõi th·∫ßy. neutral positive\n",
            "C√≥ nhi·ªÅu v·∫•n ƒë·ªÅ v·ªÅ thi·∫øt b·ªã v√† h·ªá th·ªëng m·∫°ng trong c√°c ph√≤ng h·ªçc. negative neutral\n",
            "B·∫°n c·ªßa t√¥i l√† ng∆∞·ªùi r·∫•t nƒÉng ƒë·ªông v√† lu√¥n c√≥ nh·ªØng √Ω t∆∞·ªüng m·ªõi l·∫°. positive neutral\n",
            "Tr∆∞·ªùng ƒë·∫°i h·ªçc n√†y l√† n∆°i l√Ω t∆∞·ªüng ƒë·ªÉ giao l∆∞u v√† k·∫øt n·ªëi v·ªõi nh·ªØng ng∆∞·ªùi b·∫°n m·ªõi. positive neutral\n",
            "C∆° s·ªü v·∫≠t ch·∫•t t·∫°i ƒë·∫°i h·ªçc n√†y ƒë√°p ·ª©ng t·ªët nhu c·∫ßu h·ªçc t·∫≠p c·ªßa sinh vi√™n. neutral positive\n",
            "M√¥n h·ªçc kh√¥ng ph√π h·ª£p v·ªõi chuy√™n ng√†nh c·ª• th·ªÉ v√† ƒë·ªô kh√≥ qu√° cao. negative neutral\n",
            "Anh ·∫•y c√≥ tr√≠ th√¥ng minh s√°ng su·ªët v√† s·ª± nghi·ªáp c·ªßa anh ·∫•y tuy·ªát v·ªùi. positive neutral\n",
            "Th·∫ßy c√≥ kh·∫£ nƒÉng d·∫°y h·ªçc ƒëa d·∫°ng ƒë·ªÉ ph√π h·ª£p v·ªõi c√°c h·ªçc sinh c√≥ n·ªÅn t·∫£ng k√©m. neutral positive\n",
            "C√≥ nh·ªØng b·∫°n r·∫•t nƒÉng ƒë·ªông v√† th√≠ch tham gia c√°c ho·∫°t ƒë·ªông c·ªßa tr∆∞·ªùng. positive neutral\n",
            "B·∫°n s·∫Ω kh√¥ng th·ªÉ t√¨m th·∫•y m·ªôt gi·∫£ng vi√™n t·ªët h∆°n ·ªü b·∫•t k·ª≥ n∆°i n√†o kh√°c. negative positive\n",
            "C√¥ ·∫•y c√≥ t√≠nh c√°ch vui v·∫ª v√† th√¢n thi·ªán. positive neutral\n",
            "Gi·∫£ng vi√™n r·∫•t th√¥ng minh v√† am hi·ªÉu chuy√™n ng√†nh. positive neutral\n",
            "C·∫≠u ·∫•y r·∫•t quan t√¢m ƒë·∫øn vi·ªác h·ªçc t·∫≠p v√† ph√°t tri·ªÉn b·∫£n th√¢n. positive neutral\n",
            "Nh·ªØng bu·ªïi h·ªçc th·ª±c t·∫ø gi√∫p sinh vi√™n hi·ªÉu r√µ h∆°n v·ªÅ ng√†nh h·ªçc. positive neutral\n",
            "Gi·∫£ng vi√™n l√† m·ªôt ng∆∞·ªùi c√≥ t√°c phong v√† phong c√°ch gi·∫£ng d·∫°y r·∫•t chuy√™n nghi·ªáp. neutral positive\n",
            "Gi·∫£ng vi√™n n√†y th∆∞·ªùng ƒë·ªìng √Ω v·ªõi √Ω ki·∫øn c·ªßa nh·ªØng sinh vi√™n gi√†u kinh nghi·ªám. neutral negative\n",
            "Gi·∫£ng vi√™n r·∫•t trung th√†nh v·ªõi vai tr√≤ c·ªßa m√¨nh v√† gi·∫£ng d·∫°y r·∫•t ch√≠nh x√°c. neutral positive\n",
            "Gi·∫£ng vi√™n r·∫•t nhi·ªát t√¨nh trong vi·ªác trao ƒë·ªïi v√† th·∫£o lu·∫≠n ƒë·ªÉ gi·∫£i quy·∫øt nh·ªØng kh√≥ khƒÉn trong qu√° tr√¨nh h·ªçc t·∫≠p. neutral positive\n",
            "H·ªçc ph√≠ r·∫•t h·ª£p l√Ω v√† ph√π h·ª£p v·ªõi nhu c·∫ßu c·ªßa sinh vi√™n. neutral positive\n",
            "Gi·∫£ng vi√™n n√†y lu√¥n ƒë∆∞a ra c√°c v√≠ d·ª• kh√≥ nh·∫±n ƒë·ªÉ h·ªçc sinh hi·ªÉu. neutral negative\n",
            "Gi·∫£ng vi√™n d·∫°y r·∫•t ch·∫•t l∆∞·ª£ng v√† hi·ªáu qu·∫£. neutral positive\n",
            "T√¥i hi v·ªçng tr∆∞·ªùng t√¥i s·∫Ω d√†nh nhi·ªÅu th·ªùi gian h∆°n ƒë·ªÉ c·∫£i thi·ªán c∆° s·ªü v·∫≠t ch·∫•t v√† n√¢ng cao ch·∫•t l∆∞·ª£ng gi·∫£ng d·∫°y. neutral negative\n",
            "Ch∆∞∆°ng tr√¨nh ƒë√†o t·∫°o r·∫•t chuy√™n nghi·ªáp. neutral positive\n",
            "Kh√¥ng gi·ªõi h·∫°n v·ªÅ th·ªùi gian h·ªçc t·∫≠p. neutral positive\n",
            "T√¥i c·∫£m th·∫•y ki·∫øn th·ª©c ƒë∆∞·ª£c truy·ªÅn ƒë·∫°t s√¢u s·∫Øc v√† c√≥ t√≠nh ·ª©ng d·ª•ng cao. positive neutral\n",
            "B·∫°n c·ªßa t√¥i r·∫•t t·ªâ m·ªâ v√† l∆∞u √Ω ƒë·∫øn chi ti·∫øt. positive neutral\n",
            "Ch∆∞∆°ng tr√¨nh h·ªçc ph√π h·ª£p v·ªõi y√™u c·∫ßu c·ªßa th·ªã tr∆∞·ªùng v√† ƒë√°p ·ª©ng ƒë∆∞·ª£c nhu c·∫ßu c·ªßa h·ªçc vi√™n. neutral positive\n",
            "Tr∆∞·ªùng c√≥ c√°c ch∆∞∆°ng tr√¨nh h·ªçc b·ªïng v√† t√†i tr·ª£ gi√∫p ƒë·ª° nh·ªØng sinh vi√™n c√≥ th√†nh t√≠ch h·ªçc t·∫≠p cao. positive neutral\n",
            "T√¥i c·∫£m th·∫•y ch∆∞∆°ng tr√¨nh h·ªçc kh√¥ng th·ª±c s·ª± ƒë√°p ·ª©ng ƒë∆∞·ª£c nhu c·∫ßu ng√†nh ngh·ªÅ hi·ªán t·∫°i. neutral negative\n",
            "Ch∆∞∆°ng tr√¨nh ƒë√†o t·∫°o gi√∫p t√¥i c√≥ c∆° h·ªôi ti·∫øp c·∫≠n v·ªõi c√°c d·ª± √°n nghi√™n c·ª©u trong ng√†nh h·ªçc c·ªßa m√¨nh. positive neutral\n",
            "H·ªçc ph√≠ ƒë∆∞·ª£c gi·∫£m gi√° cho nh·ªØng sinh vi√™n ƒëƒÉng k√Ω s·ªõm. neutral positive\n",
            "Th·∫ßy n√†y t·ªï ch·ª©c v√† qu·∫£n l√Ω gi·∫£ng d·∫°y r·∫•t t·ªët. neutral positive\n",
            "Gi·∫£ng vi√™n n√†y qu√° ƒë√≤i h·ªèi cao v·ªÅ ƒëi·ªÉm s·ªë v√† ƒë√¥i khi l√†m kh√≥ h·ªçc sinh. negative neutral\n",
            "T√¥i r·∫•t y√™u th√≠ch kh√¥ng gian c·ªßa th∆∞ vi·ªán v√† c√°c d·ªãch v·ª• b·ªï tr·ª£ t·∫°i ƒë√¢y. positive neutral\n",
            "C√¥ng ngh·ªá ƒëang s·ª≠ d·ª•ng trong qu√° tr√¨nh gi·∫£ng d·∫°y ch∆∞a ƒë√°p ·ª©ng ƒë∆∞·ª£c nhu c·∫ßu c·ªßa th·ªùi ƒë·∫°i. neutral negative\n",
            "Ch∆∞∆°ng tr√¨nh h·ªçc r·∫•t linh ho·∫°t v√† c√≥ th·ªÉ ph√π h·ª£p v·ªõi nhu c·∫ßu c·ªßa t·ª´ng sinh vi√™n. neutral positive\n",
            "Gi√°o vi√™n r·∫•t th√¥ng minh v√† nhi·ªát t√¨nh gi·∫£ng d·∫°y. neutral positive\n",
            "Th·∫ßy n√†y l·∫Øng nghe h·ªçc sinh r·∫•t chu ƒë√°o. neutral positive\n",
            "Gi·∫£ng vi√™n n√†y kh√¥ng gi√∫p ƒë∆∞·ª£c h·ªçc sinh ƒë·∫°t ƒë∆∞·ª£c nh·ªØng m·ª•c ti√™u c·ªßa h·ªç. negative neutral\n",
            "Tr∆∞·ªùng ƒë·∫∑t nhi·ªÅu ∆∞u ti√™n cho s·ª± ph√°t tri·ªÉn to√†n di·ªán c·ªßa sinh vi√™n. positive neutral\n",
            "C√°c gi·∫£ng vi√™n c·ªßa tr∆∞·ªùng r·∫•t c√≥ kinh nghi·ªám v√† gi·ªèi chuy√™n m√¥n. neutral positive\n",
            "S·ªë l∆∞·ª£ng b√†i t·∫≠p v√† b√†i ki·ªÉm tra qu√° nhi·ªÅu so v·ªõi kh·∫£ nƒÉng c·ªßa sinh vi√™n. neutral negative\n",
            "ƒê·ªôi ng≈© nh√¢n vi√™n ·ªü ƒë√¢y lu√¥n h·ªó tr·ª£ v√† ƒë√°p ·ª©ng m·ªçi nhu c·∫ßu c·ªßa sinh vi√™n. positive neutral\n",
            "T√¥i ƒë√£ ƒë∆∞·ª£c trang b·ªã ƒë·∫ßy ƒë·ªß c√°c t√†i li·ªáu th∆∞ vi·ªán c·∫ßn thi·∫øt ƒë·ªÉ h·ªçc t·∫≠p v√† l√†m b√†i t·∫≠p. positive neutral\n",
            "Ph√≤ng th√≠ nghi·ªám ·ªü tr∆∞·ªùng ƒë∆∞·ª£c trang b·ªã ƒë·∫ßy ƒë·ªß thi·∫øt b·ªã v√† m√°y m√≥c. positive neutral\n",
            "Th·∫ßy lu√¥n ƒë∆∞a ra c√°c g·ª£i √Ω ƒë·ªÉ sinh vi√™n c√≥ th·ªÉ n√¢ng cao nƒÉng l·ª±c h·ªçc t·∫≠p c·ªßa m√¨nh. positive neutral\n",
            "Gi·∫£ng vi√™n n√†y bi·∫øt c√°ch t·∫°o ra m·ªôt s·ª± t∆∞∆°ng t√°c t√≠ch c·ª±c l√†m cho b√†i gi·∫£ng c·ªßa m√¨nh tr·ªü n√™n ƒë·∫ßy h·ª©ng th√∫. positive neutral\n",
            "Th·∫ßy gi·∫£ng d·∫°y r·∫•t t·∫≠p trung v√†o kh·∫£ nƒÉng ph√°t tri·ªÉn c·ªßa sinh vi√™n h∆°n l√† ch·ªâ h∆∞·ªõng d·∫´n ki·∫øn th·ª©c. positive neutral\n",
            "ƒê·ªôi ng≈© gi√°o vi√™n c√≥ nhi·ªÅu tri th·ª©c v√† kinh nghi·ªám gi√∫p sinh vi√™n n·∫Øm v·ªØng ki·∫øn th·ª©c chuy√™n m√¥n. neutral positive\n",
            "C√°c ph√≤ng h·ªçc ƒë∆∞·ª£c ƒë√°nh gi√° l√† kh√¥ng gian r·ªông r√£i v√† tho·∫£i m√°i. neutral positive\n",
            "Tr∆∞·ªùng ƒë·∫°i h·ªçc n√†y lu√¥n gi·ªØ v·ªá sinh v√† s·ª≠a ch·ªØa t·ªët h·ªá th·ªëng c∆° s·ªü v·∫≠t ch·∫•t. positive neutral\n",
            "Nh·ªØng ki·∫øn th·ª©c t√¥i h·ªçc ƒë∆∞·ª£c trong ch∆∞∆°ng tr√¨nh h·ªçc r·∫•t b·ªï √≠ch cho c√¥ng vi·ªác c·ªßa t√¥i sau n√†y. positive neutral\n",
            "Gi√°o vi√™n chuy√™n ƒë·ªÉ √Ω ƒë·∫øn nh·ªØng sinh vi√™n xu·∫•t s·∫Øc, b·ªè qu√™n nh·ªØng sinh vi√™n y·∫øu k√©m. neutral negative\n",
            "Th·∫ßy c√¥ lu√¥n g·∫ßn g≈©i v√† d·ªÖ ti·∫øp c·∫≠n v·ªõi c√°c sinh vi√™n. positive neutral\n",
            "B·∫°n c·ªßa t√¥i r·∫•t c·ªüi m·ªü v√† d·ªÖ th∆∞∆°ng v·ªõi m·ªçi ng∆∞·ªùi. positive neutral\n",
            "T√¥i c·∫£m th·∫•y tr∆∞·ªùng ƒëang ph√°t tri·ªÉn v√† ƒëi theo xu h∆∞·ªõng m·ªõi nh·∫•t trong gi√°o d·ª•c. neutral positive\n",
            "B√£i ƒë·ªó xe c·ªßa tr∆∞·ªùng r·ªông r√£i v√† an to√†n. positive neutral\n",
            "Gi·∫£ng vi√™n gi√∫p sinh vi√™n ph√°t tri·ªÉn v√† r√®n luy·ªán k·ªπ nƒÉng s√°ng t·∫°o. positive neutral\n",
            "Gi·∫£ng vi√™n n√†y l√† ng∆∞·ªùi r·∫•t chu ƒë√°o v√† nhi·ªát t√¨nh. positive neutral\n",
            "C√°c khu v·ª±c ƒë·ªÉ gi·∫£i tr√≠ trong tr∆∞·ªùng r·∫•t ƒëa d·∫°ng v√† phong ph√∫. positive neutral\n",
            "Ph√≤ng h·ªçc ƒë∆∞·ª£c trang b·ªã s·∫£n ph·∫©m ƒë√°nh gi√° nh∆∞ m√°y chi·∫øu, m√°y t√≠nh, tivi, loa, ƒë·ªám ng·ªìi, ... positive neutral\n",
            "C√°c ho·∫°t ƒë·ªông gi√°o d·ª•c kh√° ƒëa d·∫°ng v√† phong ph√∫. neutral positive\n",
            "Tr∆∞·ªùng lu√¥n ƒë·∫£m b·∫£o r·∫±ng c√°c c∆° s·ªü v·∫≠t ch·∫•t v√† trang thi·∫øt b·ªã c·ªßa tr∆∞·ªùng lu√¥n ph√π h·ª£p v·ªõi nhu c·∫ßu h·ªçc t·∫≠p c·ªßa sinh vi√™n. neutral positive\n",
            "C√°c b√†i ki·ªÉm tra ƒë∆∞·ª£c thi·∫øt k·∫ø t·ªët v√† c√¥ng b·∫±ng. neutral positive\n",
            "Th·∫ßy lu√¥n d·∫°y sinh vi√™n c√°ch t∆∞ duy v√† ph√°t tri·ªÉn k·ªπ nƒÉng. positive neutral\n",
            "T·∫•t c·∫£ sinh vi√™n ƒë∆∞·ª£c ƒë√≥n ti·∫øp v·ªõi c√°ch th·ª©c tr·ªã nh·∫π nh√†ng v√† d·ªÖ d√†ng. positive neutral\n",
            "Gi·∫£ng vi√™n n√†y ƒë√¥i l√∫c qu√™n chuy·ªán ch√≠nh ƒë·ªÉ gi·∫£i th√≠ch nh·ªØng chi ti·∫øt kh√¥ng quan tr·ªçng. negative neutral\n",
            "L·ªõp h·ªçc ƒë∆∞·ª£c t·ªï ch·ª©c khoa h·ªçc, h·ªó tr·ª£ sinh vi√™n kh√¥ng ch·ªâ gi√∫p h·ªçc m√† c√≤n gi√∫p sinh vi√™n r√®n luy·ªán k·ªπ nƒÉng qu·∫£n l√Ω th·ªùi gian. positive neutral\n",
            "B·∫°n c·ªßa t√¥i r·∫•t gi·ªèi qu·∫£n l√Ω th·ªùi gian. positive neutral\n",
            "C√°c gi·∫£ng vi√™n c·ªßa tr∆∞·ªùng r·∫•t d·ªÖ ti·∫øp c·∫≠n v√† h·ªó tr·ª£ cho sinh vi√™n trong qu√° tr√¨nh h·ªçc t·∫≠p. neutral positive\n",
            "Tr∆∞·ªùng cung c·∫•p r·∫•t nhi·ªÅu thi·∫øt b·ªã v√† ph·∫ßn m·ªÅm h·ªØu √≠ch cho vi·ªác h·ªçc t·∫≠p v√† nghi√™n c·ª©u. neutral positive\n",
            "Gi·∫£ng vi√™n r·∫•t th√¢n thi·ªán v√† c√≥ t∆∞ duy ph·∫£n bi·ªán cao. neutral positive\n",
            "C√¥ ·∫•y c√≥ kh·∫£ nƒÉng ƒë∆∞a ra quy·∫øt ƒë·ªãnh m·ªôt c√°ch ƒë√∫ng ƒë·∫Øn v√† hi·ªáu qu·∫£. neutral positive\n",
            "C√¥ gi·∫£ng vi√™n r·∫•t ·ªßng h·ªô v√† khuy·∫øn kh√≠ch sinh vi√™n ph√°t tri·ªÉn t√†i nƒÉng. positive neutral\n",
            "C√°c gi·∫£ng vi√™n ƒë·ªÅu r·∫•t am hi·ªÉu trong lƒ©nh v·ª±c c·ªßa m√¨nh. neutral positive\n",
            "C√≥ s·ª± t∆∞ v·∫•n v√† h·ªó tr·ª£ ƒë·ªÉ chu·∫©n b·ªã cho th·ª±c t·∫≠p, t√¨m ki·∫øm vi·ªác l√†m sau khi t·ªët nghi·ªáp. positive neutral\n",
            "Gi√°o tr√¨nh r·∫•t th√∫ v·ªã v√† ƒë·ªôc ƒë√°o, gi√∫p t√¥i h·ªçc ƒë∆∞·ª£c nhi·ªÅu th·ª© m·ªõi l·∫°. positive neutral\n",
            "Khu√¥n vi√™n ƒë·∫•t n·ªÅn r·ªông r√£i v√† kh√° y√™n tƒ©nh. neutral positive\n",
            "Th·∫ßy d·∫°y r·∫•t c·∫©n th·∫≠n v√† t·ªâ m·ªâ, lu√¥n ch√∫ √Ω t·ª´ng chi ti·∫øt. positive neutral\n",
            "Th·∫ßy truy·ªÅn c·∫£m h·ª©ng v√† ƒë·ªông vi√™n c√°c sinh vi√™n c√≥ ho√†n c·∫£nh kh√≥ khƒÉn. positive neutral\n",
            "C√¥ ·∫•y r·∫•t tho·∫£i m√°i v√† t·ª± tin trong giao ti·∫øp ƒëa d·∫°ng v·ªõi ng∆∞·ªùi kh√°c gi·ªõi. positive neutral\n",
            "Anh ·∫•y c√≥ tinh th·∫ßn l·∫°c quan v√† lu√¥n gi·ªØ v·ªØng ni·ªÅm tin v√†o b·∫£n th√¢n. positive neutral\n",
            "C√°c ph√≤ng h·ªçc ƒë∆∞·ª£c trang b·ªã m√°y chi·∫øu ƒë·∫ßy ƒë·ªß gi√∫p gi·∫£ng vi√™n gi·∫£ng d·∫°y t·ªët h∆°n. neutral positive\n",
            "Gi·∫£ng vi√™n n√†y ƒë∆∞a ra c√°c v√≠ d·ª• r·∫•t th·ª±c t·∫ø v√† h·ªØu √≠ch ƒë·ªÉ gi√∫p t√¥i hi·ªÉu b√†i h·ªçc. neutral positive\n",
            "Anh ·∫•y l√† ng∆∞·ªùi h·ªó tr·ª£ r·∫•t t·ªët cho c√°c b·∫°n trong l·ªõp. positive neutral\n",
            "T√¥i th·∫•y anh ch√†ng n√†y r·∫•t t√¢m l√Ω v√† ch√∫ √Ω ƒë·∫øn t√¨nh h√¨nh xung quanh. positive neutral\n",
            "Gi·∫£ng vi√™n n√†y r·∫•t th√≠ch h·ª£p trong vi·ªác gi·∫£ng d·∫°y cho h·ªçc sinh ƒëam m√™ chuy√™n m√¥n n√†y. positive neutral\n",
            "Gi·∫£ng vi√™n r·∫•t th√¢n thi·ªán v√† t·∫°o kh√¥ng kh√≠ h·ªçc t·∫≠p t√≠ch c·ª±c cho sinh vi√™n. positive neutral\n",
            "Th·∫ßy ƒë∆∞a ra nh·ªØng ph∆∞∆°ng ph√°p d·∫°y h·ªçc hi·ªáu qu·∫£ v√† h·ªØu √≠ch cho sinh vi√™n. neutral positive\n",
            "C√¥ ·∫•y c√≥ t√†i giao ti·∫øp t·ªët v√† th√¢n thi·ªán v·ªõi nh·ªØng ng∆∞·ªùi xung quanh. positive neutral\n",
            "T√¥i r·∫•t h√†i l√≤ng v·ªõi ch∆∞∆°ng tr√¨nh h·ªçc n∆°i ƒë√¢y. positive neutral\n",
            "B·∫°n c·ªßa em l√† ng∆∞·ªùi r·∫•t c√° t√≠nh v√† kh√¥ng s·ª£ th·ªÉ hi·ªán b·∫£n th√¢n. positive neutral\n",
            "C√¥ ·∫•y c√≥ phong c√°ch d·∫°y h·ªçc v√¥ c√πng s√°ng t·∫°o v√† th√∫ v·ªã. positive neutral\n",
            "Anh ta lu√¥n c√≥ tinh th·∫ßn h·ªçc h·ªèi v√† m·ªü ƒë·∫ßu v·ªõi nh·ªØng ki·∫øn th·ª©c m·ªõi. positive neutral\n",
            "C√°c bu·ªïi h·ªçc ƒë∆∞·ª£c t·ªï ch·ª©c ch·∫∑t ch·∫Ω v√† c√≥ s·ª± chu·∫©n b·ªã k·ªπ l∆∞·ª°ng. neutral positive\n",
            "N√†ng c√≥ tinh th·∫ßn c·ªüi m·ªü v√† ƒë·ªìng c·∫£m v·ªõi ng∆∞·ªùi kh√°c. positive neutral\n",
            "Gi·∫£ng vi√™n d·∫°y r·∫•t hay v√† d·ªÖ hi·ªÉu. neutral positive\n",
            "C√¥ ·∫•y l√† ng∆∞·ªùi c√≥ c√° t√≠nh v√† lu√¥n s√°ng t·∫°o. positive neutral\n",
            "T√¥i kh√¥ng th·ªÉ t∆∞·ªüng t∆∞·ª£ng ƒë∆∞·ª£c m√¥i tr∆∞·ªùng h·ªçc t·∫≠p s·∫Ω nh∆∞ th·∫ø n·∫øu kh√¥ng c√≥ th·∫ßy/c√¥. negative positive\n",
            "C·∫≠u ·∫•y t√≠ch c·ª±c v√† nhi·ªát t√¨nh trong c√°c ho·∫°t ƒë·ªông ƒë·∫°i h·ªôi SV. positive neutral\n",
            "T√¥i ƒë√£ h·ªçc ƒë∆∞·ª£c k·ªπ nƒÉng c·∫ßn thi·∫øt cho s·ª± nghi·ªáp c·ªßa m√¨nh t·ª´ gi·∫£ng vi√™n n√†y. positive neutral\n",
            "Anh ·∫•y r·∫•t ti·∫øp thu ƒë∆∞·ª£c nh·ªØng ki·∫øn th·ª©c m·ªõi m·ªôt c√°ch nhanh ch√≥ng. positive neutral\n",
            "Ph√≤ng h·ªçc ƒë∆∞·ª£c b·ªë tr√≠ ƒë·ªìng nh·∫•t v√† g·ªçn g√†ng, gi√∫p cho sinh vi√™n h·ªçc t·∫≠p t·∫≠p trung h∆°n. positive neutral\n",
            "Gi·∫£ng vi√™n kh√¥ng th∆∞·ªùng xuy√™n li√™n h·ªá v·ªõi sinh vi√™n sau khi h·ªç k·∫øt th√∫c m√¥n h·ªçc. negative neutral\n",
            "C√≥ r·∫•t nhi·ªÅu b·∫°n h·ªçc t·ªët v√† t√≠ch c·ª±c tham gia v√†o c√°c ho·∫°t ƒë·ªông c·ªßa tr∆∞·ªùng. positive neutral\n",
            "T·∫•t c·∫£ nh·ªØng g√¨ h·ªç quan t√¢m ƒë·∫øn ch√≠nh l√† ti·ªÅn b·∫°c. neutral negative\n",
            "Ch∆∞∆°ng tr√¨nh h·ªçc c·ªßa tr∆∞·ªùng gi√∫p t√¥i c√≥ c∆° h·ªôi h·ªçc t·∫≠p v√† nghi√™n c·ª©u v·ªõi nh·ªØng gi·∫£ng vi√™n h√†ng ƒë·∫ßu trong ng√†nh c·ªßa m√¨nh. positive neutral\n",
            "Gi·∫£ng vi√™n r·∫•t ƒë√°ng k√≠nh v√† ƒë∆∞·ª£c sinh vi√™n y√™u m·∫øn ƒë·∫∑c bi·ªát. positive neutral\n",
            "Ch∆∞∆°ng tr√¨nh h·ªçc gi√∫p t√¥i hi·ªÉu r√µ h∆°n v·ªÅ n·ªÅn t·∫£ng c·ªßa ng√†nh ngh·ªÅ t∆∞∆°ng lai. positive neutral\n",
            "Th·∫ßy r·∫•t nƒÉng ƒë·ªông, gi√∫p sinh vi√™n t·∫≠p trung v√†o h·ªçc t·∫≠p m·ªôt c√°ch hi·ªáu qu·∫£. positive neutral\n",
            "Gi√°o vi√™n lu√¥n ƒë·∫∑t m√¨nh v√†o t√¢m tr·∫°ng v√† kh√≥ khƒÉn c·ªßa h·ªçc sinh. neutral positive\n",
            "Ch·∫•t l∆∞·ª£ng gi·∫£ng d·∫°y c·ªßa tr∆∞·ªùng t√¥i r·∫•t t·ªët trong ƒë√≥ gi√°o vi√™n l√† m·ªôt ph·∫ßn quan tr·ªçng. neutral positive\n",
            "T√¥i r·∫•t ng∆∞·ª°ng m·ªô s·ª± ki√™n tr√¨ c·ªßa b·∫°n ·∫•y. positive neutral\n",
            "Gi·∫£ng vi√™n mang l·∫°i kinh nghi·ªám th·ª±c t·∫ø cho h·ªçc sinh. neutral positive\n",
            "H·ªá th·ªëng r·∫°p chi·∫øu phim v√† trung t√¢m gi·∫£i tr√≠ n√¢ng cao sinh ho·∫°t vƒÉn h√≥a cho sinh vi√™n. positive neutral\n",
            "Tr∆∞·ªùng c√≥ c√°c khu v·ª±c gi·∫£i tr√≠, ph√≤ng ch∆°i game, th∆∞ gi√£n cho sinh vi√™n. positive neutral\n",
            "Ph∆∞∆°ng ph√°p d·∫°y h·ªçc thi·∫øt th·ª±c v√† c√≥ t√≠nh ·ª©ng d·ª•ng cao. neutral positive\n",
            "C√°c khu v·ª±c ph·ª•c v·ª• ƒÉn u·ªëng r·ªông r√£i v√† tho·∫£i m√°i cho sinh vi√™n. positive neutral\n",
            "Nhi·ªÅu b·∫°n x·ª≠ l√Ω t√¨nh hu·ªëng kh√≥ khƒÉn m·ªôt c√°ch th√¥ng minh v√† kh√©o l√©o trong l·ªõp h·ªçc. positive neutral\n",
            "Nh√¢n vi√™n ph·ª•c v·ª• tr∆∞·ªùng lu√¥n s√°ng su·ªët, vui v·∫ª, nhi·ªát t√¨nh h·ªó tr·ª£ sinh vi√™n m·ªçi khi c·∫ßn thi·∫øt positive neutral\n",
            "T√†i li·ªáu h·ªçc t·∫≠p nhi·ªát t√¨nh v√† ƒë·∫ßy tr·∫£i nghi·ªám th·ª±c t·∫ø. positive neutral\n",
            "C√°c b√†i h·ªçc ƒë∆∞·ª£c thi·∫øt k·∫ø t·ªëi ∆∞u cho vi·ªác h·ªçc tr·ª±c tuy·∫øn. neutral positive\n",
            "C√°c khu v·ª±c c·∫•m h√∫t thu·ªëc ƒë∆∞·ª£c thi·∫øt k·∫ø v√† b·ªë tr√≠ ƒë·ªÉ ƒë·∫£m b·∫£o kh√¥ng kh√≠ trong l√†nh. neutral positive\n",
            "T√¥i c·∫£m th·∫•y r·∫•t ti·∫øc khi th·ªùi gian h·ªçc t·∫≠p t·∫°i tr∆∞·ªùng c·ªßa t√¥i k·∫øt th√∫c. neutral positive\n",
            "C·∫≠u ·∫•y r·∫•t c√≥ k·ªπ nƒÉng v·ªÅ s√°ng t·∫°o v√† ngh·ªá thu·∫≠t. positive neutral\n",
            "Gi·∫£ng vi√™n n√†y kh√¥ng nh√†m ch√°n. neutral negative\n",
            "Anh ta l√† m·ªôt ng∆∞·ªùi r·∫•t t·ªâ m·ªâ v√† c·∫©n th·∫≠n. positive neutral\n"
          ]
        }
      ],
      "source": [
        "for i, row in df_test.iterrows():\n",
        "    if row['predict'] != row['sentiment']:\n",
        "        print(row['sentence'], row['predict'], row['sentiment'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C59SEWloIyHU"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0bmpm_tEIyHU"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "datasetId": 3052448,
          "sourceId": 5245967,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30733,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}