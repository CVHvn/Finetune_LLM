{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "id": "-d2IdoaaoUgf"
      },
      "source": [
        "# Install library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "carm7QjeoUgg",
        "outputId": "3c1b73a8-f7d5-4939-f29e-ef68c401ba5f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -q datasets==2.16.0\n",
        "!pip install -q bitsandbytes\n",
        "!pip install -q tiktoken\n",
        "!pip install -q peft\n",
        "!pip install -q trl\n",
        "!pip install -q transformers\n",
        "!pip install -q openpyxl\n",
        "!pip install -q pandas\n",
        "!pip install -q scikit-learn\n",
        "!pip install -q flash-attn\n",
        "#pip install -q transformers==4.38.1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X1jNRvdhoUgh"
      },
      "source": [
        "# Import library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NZZhRbaRoUgh"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
        "import torch\n",
        "from accelerate import PartialState\n",
        "from peft import LoraConfig, PeftModel, prepare_model_for_kbit_training, get_peft_model\n",
        "from trl import SFTTrainer\n",
        "from peft import prepare_model_for_kbit_training\n",
        "from transformers import TrainingArguments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nX0M39mAoUgh"
      },
      "source": [
        "# Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "obqlTDm6oUgh"
      },
      "outputs": [],
      "source": [
        "modelpath = \"microsoft/Phi-3-mini-4k-instruct\"\n",
        "lr=2e-4      # learning rate\n",
        "bs=16            # batch size\n",
        "bs_eval=16      # batch size for evals\n",
        "ga_steps=1     # gradient acc. steps\n",
        "epochs=4\n",
        "max_length=128      # max. sample length with 24GB VRAM\n",
        "output_dir=\"out\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UzNUdeQioUgh"
      },
      "source": [
        "# Remove old model\n",
        "Because of limited storage, we can't save all models, we need to delete all models in cache by the following code:\n",
        "- rm -r out: delete out folder (because I save finetuned model in out folder), you can change folder name like (rm -r output_folder). If you doesn't have out folder, this commend do not thing.\n",
        "- all pretrained huggingface models will auto save in transformers.TRANSFORMERS_CACHE. I use glob.glob to read all folders and use shutil.rmtree to delete them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FPG5l1rQoUgi"
      },
      "outputs": [],
      "source": [
        "!rm -r out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CwULUbhvoUgi"
      },
      "outputs": [],
      "source": [
        "# from transformers import TRANSFORMERS_CACHE\n",
        "# import glob\n",
        "# print(TRANSFORMERS_CACHE)\n",
        "# folders = glob.glob(f\"{TRANSFORMERS_CACHE}/*\")\n",
        "# print(folders)\n",
        "\n",
        "# import shutil\n",
        "# #shutil.rmtree(TRANSFORMERS_CACHE)\n",
        "# for folder in folders:\n",
        "#     if 'Phi-3' not in folder and '.txt' not in folder:\n",
        "#         shutil.rmtree(folder)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Wpb_1HaoUgi"
      },
      "source": [
        "# Create Dataset\n",
        "Download dataset from [kaggle synthetic-vietnamese-students-feedback-corpus](https://www.kaggle.com/datasets/toreleon/synthetic-vietnamese-students-feedback-corpus/data)\n",
        "\n",
        "We need convert DataFrame to json line (jsonl)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mvPXI3w9oUgi"
      },
      "outputs": [],
      "source": [
        "df_train = pd.read_csv(\"synthetic_train.csv\")\n",
        "df_test = pd.read_csv(\"synthetic_val.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dEGtHd5OoUgi",
        "outputId": "6dbc396a-21c6-4a20-d4b9-f1a0f2a5e6f0"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>topic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Đội ngũ bảo trì quá thưa thớt dẫn đến không đả...</td>\n",
              "      <td>negative</td>\n",
              "      <td>facility</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The university's musical and artistic faciliti...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>facility</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Phương pháp giảng dạy phù hợp với các đối tượn...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>curriculum</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Chương trình học giúp tôi trở thành một chuyên...</td>\n",
              "      <td>positive</td>\n",
              "      <td>curriculum</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Tôi nghĩ rằng chương trình đào tạo có thể có t...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>curriculum</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            sentence sentiment       topic\n",
              "0  Đội ngũ bảo trì quá thưa thớt dẫn đến không đả...  negative    facility\n",
              "1  The university's musical and artistic faciliti...   neutral    facility\n",
              "2  Phương pháp giảng dạy phù hợp với các đối tượn...   neutral  curriculum\n",
              "3  Chương trình học giúp tôi trở thành một chuyên...  positive  curriculum\n",
              "4  Tôi nghĩ rằng chương trình đào tạo có thể có t...   neutral  curriculum"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tUxY2dPYoUgi",
        "outputId": "dd4c9c9f-c8e7-4a14-b3ff-d8eb9ad12a62"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>topic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Chất lượng vật chất kém.</td>\n",
              "      <td>negative</td>\n",
              "      <td>facility</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Phần mềm học tập quá khó sử dụng, khiến sinh v...</td>\n",
              "      <td>negative</td>\n",
              "      <td>facility</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Trường tôi thiếu những tiện ích cơ bản như máy...</td>\n",
              "      <td>negative</td>\n",
              "      <td>facility</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Cần tạo thêm các hoạt động gắn kết giữa sinh v...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>curriculum</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Họ rất khoan dung và lượng giác trong quan điể...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>others</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            sentence sentiment       topic\n",
              "0                           Chất lượng vật chất kém.  negative    facility\n",
              "1  Phần mềm học tập quá khó sử dụng, khiến sinh v...  negative    facility\n",
              "2  Trường tôi thiếu những tiện ích cơ bản như máy...  negative    facility\n",
              "3  Cần tạo thêm các hoạt động gắn kết giữa sinh v...   neutral  curriculum\n",
              "4  Họ rất khoan dung và lượng giác trong quan điể...   neutral      others"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_test.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QCT90VbroUgj",
        "outputId": "5a5c6f0e-4fa0-4a0d-a538-8c7be73118e2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "sentiment\n",
              "neutral     2724\n",
              "negative    2711\n",
              "positive    2709\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train.sentiment.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T5r3ZWphoUgj",
        "outputId": "e645cfb9-439e-4a96-ed8e-78640c502590"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "sentiment\n",
              "negative    686\n",
              "positive    680\n",
              "neutral     670\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_test.sentiment.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z_3x4lYWoUgj"
      },
      "outputs": [],
      "source": [
        "df_train['len'] = df_train.sentence.apply(lambda x: len(str(x).split()))\n",
        "df_test['len'] = df_test.sentence.apply(lambda x: len(str(x).split()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w-wTedkmoUgj",
        "outputId": "efb84fc2-ebd7-4fdf-e6ea-bfd65fbd0767"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "count    8144.000000\n",
              "mean       15.549730\n",
              "std         5.018764\n",
              "min         3.000000\n",
              "25%        12.000000\n",
              "50%        15.000000\n",
              "75%        18.000000\n",
              "max        43.000000\n",
              "Name: len, dtype: float64"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train['len'].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bgs_CAPUoUgj",
        "outputId": "e46928c1-4b73-412e-b123-4275dc2b10f9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "count    2036.000000\n",
              "mean       15.694990\n",
              "std         5.185957\n",
              "min         2.000000\n",
              "25%        12.000000\n",
              "50%        15.000000\n",
              "75%        19.000000\n",
              "max        48.000000\n",
              "Name: len, dtype: float64"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_test['len'].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FgWB7yMWoUgj"
      },
      "outputs": [],
      "source": [
        "with open('train.jsonl', 'w') as outfile:\n",
        "    for i, x in df_train.iterrows():\n",
        "        comment = x['sentence']\n",
        "        label = x['sentiment']\n",
        "        #label = 'yes' if label == 'relevance' else 'no'\n",
        "        data = {\n",
        "            \"input\": f'''The sentiment of this comment \"{comment}\" is''',\n",
        "            \"output\": f\"{label}\"\n",
        "        }\n",
        "        json.dump(data, outfile)\n",
        "        outfile.write('\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BkJJBw5roUgj"
      },
      "outputs": [],
      "source": [
        "with open('test.jsonl', 'w') as outfile:\n",
        "    for i, x in df_test.iterrows():\n",
        "        comment = x['sentence']\n",
        "        label = x['sentiment']\n",
        "        #label = 'yes' if label == 'relevance' else 'no'\n",
        "        data = {\n",
        "            \"input\": f'''The sentiment of this comment \"{comment}\" is''',\n",
        "            \"output\": f\"{label}\"\n",
        "        }\n",
        "        json.dump(data, outfile)\n",
        "        outfile.write('\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "e6c65ca5a1c74617980bd475bc05f794",
            "4ea0fd58d8bb413d9efb99aabb2b0b85"
          ]
        },
        "id": "-eM5hO09oUgk",
        "outputId": "73986974-be77-4b47-d659-2e4e50c46140"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e6c65ca5a1c74617980bd475bc05f794",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4ea0fd58d8bb413d9efb99aabb2b0b85",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating validation split: 0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "data_files = {\n",
        "    \"train\": \"train.jsonl\",\n",
        "    \"validation\": \"test.jsonl\",\n",
        "}\n",
        "\n",
        "dataset = load_dataset(\"json\", data_files=data_files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tMG2fS_loUgk",
        "outputId": "73c13a67-04ab-475e-b5ed-106c8d02da43"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['input', 'output'],\n",
              "        num_rows: 8144\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['input', 'output'],\n",
              "        num_rows: 2036\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQRrrLoVoUgk"
      },
      "source": [
        "# Create prompt format\n",
        "Load tokenizer by AutoTokenizer.from_pretrained:\n",
        "- We need create and copy YOUR TOKEN from [huggingface](https://huggingface.co/settings/tokens)\n",
        "- We need use padding_side = 'right' because training library need padding_side = 'right' when training. You can use left padding but you need to make sure the library is not corrupted and check whether performance is affected by left padding!\n",
        "- If you have 1 prompt like \"test thử mô hình\" and want to tokenize it, just you tokenizer(prompt, return_tensors=\"pt\"). You can see output of tokenizer in cell below (output includes input_ids (list index of each token in prompt) and attention mask)\n",
        "- We can use tokenizer.batch_decode to see how tokenizer restore string from token tensor. You can see that it automatically adds the start token \"<bos>\" at the beginning of the string.\n",
        "- To train llm, we only need to pass 1 sentence to llm (including input and desired output) without specifying which is the input and which is the output.\n",
        "- I wrote the function formatting_prompts_func to convert input and output to prompt and tested this function, you can see below.\n",
        "- When predicting, remove the output part to let the model predict itself. See the predict section below later.\n",
        "- we only need to predict some next tokens like A. positive, and B. neutral. We don't care what the model says after sentiment. Then we do not need to add <eos token>. If you fine-tune the model with other tasks, maybe you need to add <eos token> at the end of the prompt:\n",
        "  - use tokenizer.eos_token, tokenizer.eos_token_id to see eos_token of your model and correspond id\n",
        "  - for ex: eos_token is \"<|im_end|>\". You need edit prompt like:\n",
        "    - '''...The correct answer is {output_}.''' --> '''...The correct answer is {output_}. <|im_end|>'''\n",
        "  - for ex: eos_token is \"end_token__\". You need edit prompt like:\n",
        "    - '''...The correct answer is {output_}.''' --> '''...The correct answer is {output_}. end_token__'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WjipnjysoUgk",
        "outputId": "531587ca-41c5-4bc7-9a11-d3dd3233c366"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    modelpath,\n",
        "    padding_side=\"right\",\n",
        "    # add_eos_token=True,\n",
        "    # add_bos_token=True,\n",
        "    trust_remote_code=True,\n",
        "    token = 'YOUR TOKEN HERE'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_OH92gt2oUgk",
        "outputId": "278abafa-9bcc-4341-9870-ceb6b2898af7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_ids': tensor([[    1,  1243,   266,   228,   190,   176,   286, 30069,   298, 30097,\n",
            "         29876, 29882]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['<s>', 'test', 'th', '�', '�', '�', 'm', 'ô', 'h', 'ì', 'n', 'h']"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prompt = \"test thử mô hình\"\n",
        "tokens = tokenizer(prompt, return_tensors=\"pt\")\n",
        "print(tokens)\n",
        "tokenizer.batch_decode(tokenizer.encode(prompt))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iNTvxGhqoUgp"
      },
      "outputs": [],
      "source": [
        "def formatting_prompts_func(example):\n",
        "    output_texts = []\n",
        "    for i in range(len(example['input'])):\n",
        "        input_ = example['input'][i]\n",
        "        output_ = example['output'][i]\n",
        "        output_ = 'A. Positive' if output_ == 'positive' else 'B. Neutral' if output_ == 'neutral' else 'C. Negative'\n",
        "        #text = f\"### Question: {input__}\\n ### Answer: {example['output'][i]}\"\n",
        "        text = f'''{input_}\n",
        "A. Positive\n",
        "B. Neutral\n",
        "C. Negative\n",
        "\n",
        "The correct answer is {output_}.'''\n",
        "\n",
        "        output_texts.append(text)\n",
        "    return output_texts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7KGlhnFXoUgq",
        "outputId": "bcb7826f-842d-4199-9b71-3ac2fc61563d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('The sentiment of this comment \"Chất lượng vật chất kém.\" is', 'negative')"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset[\"validation\"]['input'][0], dataset[\"validation\"]['output'][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QeuGE-a4oUgq",
        "outputId": "88bc6be2-e1bb-42cd-e296-dfc110b40df4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['The sentiment of this comment \"Chất lượng vật chất kém.\" is\\nA. Positive\\nB. Neutral\\nC. Negative\\n\\nThe correct answer is C. Negative.']"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "formatting_prompts_func({'input': [dataset[\"validation\"]['input'][0]],\n",
        "                         'output': [dataset[\"validation\"]['output'][0]]})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dz_XdmEDoUgq",
        "outputId": "3c310e34-16f3-42db-9eb0-5ec91afb1978"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The sentiment of this comment \"Chất lượng vật chất kém.\" is\n",
            "A. Positive\n",
            "B. Neutral\n",
            "C. Negative\n",
            "\n",
            "The correct answer is C. Negative.\n"
          ]
        }
      ],
      "source": [
        "print(formatting_prompts_func({'input': [dataset[\"validation\"]['input'][0]],\n",
        "                         'output': [dataset[\"validation\"]['output'][0]]})[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bPUEA7YhoUgq"
      },
      "source": [
        "# Create model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6jtAoiTXoUgq"
      },
      "source": [
        "## Load model\n",
        "Because we use 4 bit for training, we need use BitsAndBytesConfig:\n",
        "- load_in_4bit = True: we will load model with 4 bit format.\n",
        "- bnb_4bit_use_double_quant = True: use double quant (you can search how double quant work)\n",
        "- bnb_4bit_quant_type = 'nf4': nf4 is the normalized float 4 bit data type. It quantizes floats into 4 bits (you can search about this)\n",
        "- bnb_4bit_compute_dtype: dtype before quantize (we use bfloat16, if your gpu don't support bfloat16, set it to float32).\n",
        "\n",
        "We use AutoModelForCausalLM.from_pretrained to load model:\n",
        "- device_map = 'auto': auto active gpu.\n",
        "- torch_dtype: use bfloat16, if your gpu don't support bfloat16, set it to float32\n",
        "- quantization_config: config of quantization (bnb_config above)\n",
        "- attn_implementation: you can use 'flash_attention_2', if you meet bug, maybe your gpu doesn't support it, you need delete this line.\n",
        "- token: you huggingface token like tokenizer above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "3890f682c954465e941b8b9073e92031"
          ]
        },
        "id": "vfiCX7IGoUgq",
        "outputId": "ca939bcd-5c78-4830-c127-1f50536a202e"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3890f682c954465e941b8b9073e92031",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
        ")\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    modelpath,\n",
        "    device_map=\"auto\",\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    #torch_dtype=torch.float32,\n",
        "    quantization_config=bnb_config,\n",
        "    #attn_implementation=\"flash_attention_2\",\n",
        "    trust_remote_code=True,\n",
        "    token = 'YOUR TOKEN HERE'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jIPO6FouoUgr",
        "outputId": "2d5d6a08-d56c-4e58-c639-af0be41feac4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Phi3ForCausalLM(\n",
              "  (model): Phi3Model(\n",
              "    (embed_tokens): Embedding(32064, 3072, padding_idx=32000)\n",
              "    (embed_dropout): Dropout(p=0.0, inplace=False)\n",
              "    (layers): ModuleList(\n",
              "      (0-31): 32 x Phi3DecoderLayer(\n",
              "        (self_attn): Phi3Attention(\n",
              "          (o_proj): Linear4bit(in_features=3072, out_features=3072, bias=False)\n",
              "          (qkv_proj): Linear4bit(in_features=3072, out_features=9216, bias=False)\n",
              "          (rotary_emb): Phi3RotaryEmbedding()\n",
              "        )\n",
              "        (mlp): Phi3MLP(\n",
              "          (gate_up_proj): Linear4bit(in_features=3072, out_features=16384, bias=False)\n",
              "          (down_proj): Linear4bit(in_features=8192, out_features=3072, bias=False)\n",
              "          (activation_fn): SiLU()\n",
              "        )\n",
              "        (input_layernorm): Phi3RMSNorm()\n",
              "        (resid_attn_dropout): Dropout(p=0.0, inplace=False)\n",
              "        (resid_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
              "        (post_attention_layernorm): Phi3RMSNorm()\n",
              "      )\n",
              "    )\n",
              "    (norm): Phi3RMSNorm()\n",
              "  )\n",
              "  (lm_head): Linear(in_features=3072, out_features=32064, bias=False)\n",
              ")"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Eq9p_ItoUgr"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VVcFmIwboUgr"
      },
      "source": [
        "## Eval model before training\n",
        "We use create_prompt function to generate prompt (without output), our model will predict output. We will eval model before finetune. You can see some predict below.\n",
        "\n",
        "You can see that pretrained model has poor performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oaQreXoboUgr",
        "outputId": "4e68c1f7-90b0-46dc-e002-a3a47445e716"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:540: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "The attention mask is not set and cannot be inferred from input because pad token is same as eos token.As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "The `seen_tokens` attribute is deprecated and will be removed in v4.41. Use the `cache_position` model input instead.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The sentiment of this comment: \"món ăn rất ngon\" is\n",
            "A. Positive\n",
            "B. Neutral\n",
            "C. Negative\n",
            "\n",
            "The correct answer is\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "You are not running the flash-attention implementation, expect numerical differences.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<s> The sentiment of this comment: \"món ăn rất ngon\" is\n",
            "A. Positive\n",
            "B. Neutral\n",
            "C. Negative\n",
            "\n",
            "The correct answer is:\n",
            "\n",
            "A. Positive\n",
            "\n",
            "In Vietnamese, \"món ăn rất ngon\" translates to \"the food is very delicious.\" The word \"ngon\" (delicious) conveys a\n"
          ]
        }
      ],
      "source": [
        "def create_prompt(input_, output_):\n",
        "    output_ = 'A. Positive' if output_ == 'positive' else 'B. Neutral' if output_ == 'neutral' else 'C. Negative'\n",
        "        #text = f\"### Question: {input__}\\n ### Answer: {example['output'][i]}\"\n",
        "    text = f'''{input_}\n",
        "A. Positive\n",
        "B. Neutral\n",
        "C. Negative\n",
        "\n",
        "The correct answer is'''\n",
        "\n",
        "    return text\n",
        "\n",
        "sentence = 'món ăn rất ngon'\n",
        "input_ = f'''The sentiment of this comment: \"{sentence}\" is'''\n",
        "prompt = create_prompt(input_, \"\")\n",
        "print(prompt)\n",
        "\n",
        "inputs = torch.tensor([tokenizer.encode(prompt)])\n",
        "\n",
        "tokens = model.generate(\n",
        "    inputs.to(model.device),\n",
        "    max_new_tokens=50,\n",
        "    temperature=0.1,\n",
        "    do_sample=False\n",
        ")\n",
        "print(tokenizer.decode(tokens[0], skip_special_tokens=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gYGSJxa5oUgs",
        "outputId": "63b1fd6d-4fe0-4db8-e235-0b3c5d89f55e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 0.0 0:00:00.206166 0:00:00.206169\n",
            "100 43.56435643564357 0:00:20.149993 0:00:00.199505\n",
            "200 44.776119402985074 0:00:40.060527 0:00:00.199306\n",
            "300 43.18936877076412 0:01:00.073786 0:00:00.199581\n",
            "400 42.8927680798005 0:01:19.993988 0:00:00.199486\n",
            "500 42.91417165668663 0:01:40.284933 0:00:00.200170\n",
            "600 41.930116472545755 0:02:00.183485 0:00:00.199973\n",
            "700 41.08416547788873 0:02:20.109438 0:00:00.199871\n",
            "800 42.44694132334582 0:02:40.008936 0:00:00.199761\n",
            "900 42.730299667036626 0:02:59.870626 0:00:00.199634\n",
            "1000 42.857142857142854 0:03:19.649704 0:00:00.199450\n",
            "1100 41.87102633969119 0:03:39.506923 0:00:00.199371\n",
            "1200 41.63197335553705 0:03:59.386324 0:00:00.199323\n",
            "1300 41.890853189853964 0:04:19.256704 0:00:00.199275\n",
            "1400 41.89864382583869 0:04:39.037022 0:00:00.199170\n",
            "1500 42.30512991339107 0:04:58.796408 0:00:00.199065\n",
            "1600 41.66146158650843 0:05:18.728371 0:00:00.199081\n",
            "1700 41.269841269841265 0:05:38.644290 0:00:00.199085\n",
            "1800 41.97667962243198 0:05:58.490519 0:00:00.199051\n",
            "1900 42.030510257759076 0:06:18.378674 0:00:00.199042\n",
            "2000 41.92903548225887 0:06:38.258685 0:00:00.199030\n"
          ]
        }
      ],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "start = datetime.now()\n",
        "\n",
        "prediction = []\n",
        "response = []\n",
        "accuracy = []\n",
        "labels = []\n",
        "\n",
        "for i, x in df_test.iterrows():\n",
        "    sentence = x['sentence']\n",
        "    label = x['sentiment']\n",
        "    input_ = f'''The sentiment of this comment: \"{sentence}\" is'''\n",
        "    prompt = create_prompt(input_, label)\n",
        "\n",
        "    inputs = tokenizer.encode(\n",
        "        prompt,\n",
        "        # add_generation_prompt=True,\n",
        "        return_tensors='pt'\n",
        "    )\n",
        "\n",
        "    tokens = model.generate(\n",
        "        inputs.to(model.device),\n",
        "        max_new_tokens=5,\n",
        "        temperature=0.1,\n",
        "        do_sample=False,\n",
        "        pad_token_id=tokenizer.eos_token_id\n",
        "    )\n",
        "    #break\n",
        "\n",
        "    answer = tokenizer.decode(tokens[0], skip_special_tokens=False).split(\"The correct answer is \")[-1]\n",
        "    answer = 'positive' if 'positive' in answer.lower() else 'negative' if 'negative' in answer.lower() else 'neutral'\n",
        "    prediction.append(answer.lower())\n",
        "    response.append(tokenizer.decode(tokens[0], skip_special_tokens=False))\n",
        "\n",
        "    accuracy.append(prediction[-1] == label)\n",
        "    labels.append(label)\n",
        "\n",
        "    if i % 100 == 0:\n",
        "        print(i, np.array(accuracy).sum()/len(prediction)*100, datetime.now() - start, (datetime.now() - start)/len(prediction))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q7R-IinBoUgs",
        "outputId": "b701f5de-80f8-410c-af51-54a49a483686"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative     0.6914    0.1764    0.2811       686\n",
            "     neutral     0.5205    0.1701    0.2565       670\n",
            "    positive     0.3739    0.9029    0.5289       680\n",
            "\n",
            "    accuracy                         0.4170      2036\n",
            "   macro avg     0.5286    0.4165    0.3555      2036\n",
            "weighted avg     0.5292    0.4170    0.3557      2036\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report, f1_score\n",
        "import sklearn\n",
        "\n",
        "print(sklearn.metrics.classification_report(labels, prediction, digits=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qZfh9eFpoUgs",
        "outputId": "25712838-0162-482a-e853-4f75b48aa1a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<s> The sentiment of this comment: \"The facilities of the university are versatile and helpful.\" is\n",
            "A. Positive\n",
            "B. Neutral\n",
            "C. Negative\n",
            "\n",
            "The correct answer is\n",
            "\n",
            "A. Pos\n",
            "\n",
            "\n",
            "<s> The sentiment of this comment: \"Mấy bạn đó hay đòi hỏi nhưng không bao giờ giúp đỡ người khác.\" is\n",
            "A. Positive\n",
            "B. Neutral\n",
            "C. Negative\n",
            "\n",
            "The correct answer is:\n",
            "\n",
            "C\n",
            "\n",
            "\n",
            "\n",
            "<s> The sentiment of this comment: \"Cậu ấy rất có kỹ năng về sáng tạo và nghệ thuật.\" is\n",
            "A. Positive\n",
            "B. Neutral\n",
            "C. Negative\n",
            "\n",
            "The correct answer is\n",
            "\n",
            "A. Pos\n",
            "\n",
            "\n",
            "<s> The sentiment of this comment: \"Giảng viên này không nhàm chán.\" is\n",
            "A. Positive\n",
            "B. Neutral\n",
            "C. Negative\n",
            "\n",
            "The correct answer is C. Negative.\n",
            "\n",
            "\n",
            "<s> The sentiment of this comment: \"Anh ta là một người rất tỉ mỉ và cẩn thận.\" is\n",
            "A. Positive\n",
            "B. Neutral\n",
            "C. Negative\n",
            "\n",
            "The correct answer is C. Negative.\n",
            "\n",
            "\n",
            "<s> The sentiment of this comment: \"Giáo viên đưa ra các phương tiện hỗ trợ giảng dạy rất tốt và hiệu quả.\" is\n",
            "A. Positive\n",
            "B. Neutral\n",
            "C. Negative\n",
            "\n",
            "The correct answer is\n",
            "\n",
            "- Response:\n",
            "\n",
            "\n",
            "<s> The sentiment of this comment: \"The university's computer facilities are up-to-date and well-maintained.\" is\n",
            "A. Positive\n",
            "B. Neutral\n",
            "C. Negative\n",
            "\n",
            "The correct answer is\n",
            "\n",
            "A. Pos\n",
            "\n",
            "\n",
            "<s> The sentiment of this comment: \"Thiếu tính linh hoạt trong hình thức giảng dạy và đánh giá kết quả học tập.\" is\n",
            "A. Positive\n",
            "B. Neutral\n",
            "C. Negative\n",
            "\n",
            "The correct answer is\n",
            "\n",
            "C. Neg\n",
            "\n",
            "\n",
            "<s> The sentiment of this comment: \"Cô ấy rất sắc sảo và có khả năng phân tích chi tiết rất tốt.\" is\n",
            "A. Positive\n",
            "B. Neutral\n",
            "C. Negative\n",
            "\n",
            "The correct answer is\n",
            "\n",
            "- Response:\n",
            "\n",
            "\n",
            "<s> The sentiment of this comment: \"Anh ấy có tài năng về âm nhạc và luôn tìm cách tạo ra các bản nhạc mới, giúp nhóm thêm hoàn hảo và đa dạng hơn.\" is\n",
            "A. Positive\n",
            "B. Neutral\n",
            "C. Negative\n",
            "\n",
            "The correct answer is:\n",
            "\n",
            "A.\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for x in response[-10:]:\n",
        "    print(x)\n",
        "    print(\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create peft\n",
        "- To training model with 4 bit, we need you prepare_model_for_kbit_training.\n",
        "- For lora training, we need craete LoraConfig:\n",
        "  - lora_alpha, r, dropout is basic hyperarameter.\n",
        "  - almost LLM use bias = 'none' when finetune then we set is to None\n",
        "  - target_modules are list of layer we want to finetune, I set it to 'all-linear', then all linear layers will be finetuned. If you just finetune some layers like q_proj, k_proj, you can pass list ['q_proj', 'k_proj'].\n",
        "  - modules_to_save is other layers we want to finetune (but don't use lora), in my experience, finetune all embedding layers will make model work betters than I set modules_to_save as list of all embedding layers."
      ],
      "metadata": {
        "id": "DErS_BywpbVV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qk2F9z1PoUgs"
      },
      "outputs": [],
      "source": [
        "from peft import prepare_model_for_kbit_training\n",
        "\n",
        "model = prepare_model_for_kbit_training(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CksR1_cBoUgs",
        "outputId": "1038ba48-0fce-4173-e300-07b65936f820"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trainable params: 111,083,520 || all params: 3,932,163,072 || trainable%: 2.8250\n"
          ]
        }
      ],
      "source": [
        "peft_config = LoraConfig(\n",
        "    lora_alpha=32,\n",
        "    lora_dropout=0.1,\n",
        "    r=8,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\",\n",
        "    target_modules = 'all-linear',\n",
        "#     target_modules=[\"q_proj\",\n",
        "#         \"k_proj\",\n",
        "#         \"v_proj\",\n",
        "#         \"o_proj\",\n",
        "#         \"gate_proj\",\n",
        "#         \"up_proj\",\n",
        "#         \"down_proj\",\n",
        "#         \"lm_head\",],\n",
        "    modules_to_save=[\"embed_tokens\", \"rotary_emb\"]\n",
        "                     #\"input_layernorm\", \"post_attention_layernorm\", \"norm\"]\n",
        ")\n",
        "model = get_peft_model(model, peft_config)\n",
        "\n",
        "model.print_trainable_parameters() #"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTvEgh_MoUgs"
      },
      "source": [
        "## Create TrainingArguments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V3A4Q4jDoUgt",
        "outputId": "bfa681da-4a42-490b-c9b2-9baea00d8f24"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "509\n"
          ]
        }
      ],
      "source": [
        "print(len(df_train)//bs//ga_steps*epochs//4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BFkTFnuZoUgt",
        "outputId": "1d361514-b4dc-4585-df30-d2d2e4db628e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "509\n"
          ]
        }
      ],
      "source": [
        "save_step = len(df_train)//bs//ga_steps*epochs//4\n",
        "print(save_step)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "djN0VUKPoUgt",
        "outputId": "61e889bc-4337-431a-e37a-a0e28e4082f5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "training_arguments = TrainingArguments(\n",
        "    output_dir=output_dir,\n",
        "    num_train_epochs=epochs,\n",
        "    per_device_train_batch_size=bs,\n",
        "    per_device_eval_batch_size=bs_eval,\n",
        "    evaluation_strategy=\"steps\",\n",
        "    eval_steps=save_step,\n",
        "    gradient_accumulation_steps=ga_steps,\n",
        "    optim=\"paged_adamw_32bit\",\n",
        "    save_steps=save_step,\n",
        "    save_strategy=\"steps\",\n",
        "    logging_steps=save_step,\n",
        "    learning_rate=lr,\n",
        "    weight_decay=0.001,\n",
        "    fp16=False,\n",
        "    bf16=True,\n",
        "    max_grad_norm=0.3,\n",
        "    max_steps=-1,\n",
        "    warmup_ratio=0.03,\n",
        "    group_by_length=True,\n",
        "    lr_scheduler_type=\"constant\",\n",
        "    report_to=\"none\",\n",
        "    save_total_limit=1,\n",
        "    #load_best_model_at_end=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kp35sGOZoUgt"
      },
      "source": [
        "## Create trainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "9780e55caf8c4059bf4ebc2369abf1eb",
            "f658fef5a8ab41249450d161709237ed"
          ]
        },
        "id": "gAHPOha1oUgt",
        "outputId": "77049b80-6bdd-4c74-d8ee-29868e48c699"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': max_seq_length. Will not be supported from version '1.0.0'.\n",
            "\n",
            "Deprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n",
            "  warnings.warn(message, FutureWarning)\n",
            "/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1961: FutureWarning: `--push_to_hub_token` is deprecated and will be removed in version 5 of 🤗 Transformers. Use `--hub_token` instead.\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:269: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9780e55caf8c4059bf4ebc2369abf1eb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/8144 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f658fef5a8ab41249450d161709237ed",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/2036 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
          ]
        }
      ],
      "source": [
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    train_dataset=dataset[\"train\"],\n",
        "    eval_dataset=dataset[\"validation\"],\n",
        "    peft_config=peft_config,\n",
        "    max_seq_length= 128,\n",
        "    #dataset_text_field=[\"input\", \"output\"],\n",
        "    tokenizer=tokenizer,\n",
        "    args=training_arguments,\n",
        "    packing= False,\n",
        "    formatting_func = formatting_prompts_func,\n",
        "    #data_collator=collator\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OvMYNZIeoUgt"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TTSJt-8soUgt",
        "outputId": "28982dff-8ba0-4a5f-d915-71162203bf58"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
            "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2036' max='2036' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2036/2036 19:15, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>509</td>\n",
              "      <td>0.615300</td>\n",
              "      <td>0.549341</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1018</td>\n",
              "      <td>0.484500</td>\n",
              "      <td>0.513121</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1527</td>\n",
              "      <td>0.418200</td>\n",
              "      <td>0.509868</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2036</td>\n",
              "      <td>0.362300</td>\n",
              "      <td>0.524984</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=2036, training_loss=0.47006620545752625, metrics={'train_runtime': 1156.3232, 'train_samples_per_second': 28.172, 'train_steps_per_second': 1.761, 'total_flos': 5.923918893544243e+16, 'train_loss': 0.47006620545752625, 'epoch': 4.0})"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uq8wnILyoUgt"
      },
      "source": [
        "# Eval\n",
        "- If you save the model to the output_dir folder, the training code above will automatically save the model to output_dir/checkpoint-{save_step} (in my case: out/checkpoint-2036). We will load the model from this folder:\n",
        "  - I calculate _id = save_step * num_epoch = 509 * 4 = 2036\n",
        "  - My model will saved at \"{output_dir}/checkpoint-{_id}\"\n",
        "- I use del model, gc.collect() and torch.cuda.empty_cache() to release trained model (save gpu memory).\n",
        "- We use PeftConfig.from_pretrained to lead peft config (this is the same as peft config at training)\n",
        "- we load pretrained model like before.\n",
        "- We load the tokenizer in this folder by passing the saved folder to AutoTokenizer.from_pretrained()\n",
        "- We use PeftModel.from_pretrained(model, peft_model_id) to merge pre-trained model with finetuned lora model (note that when we use peft lora, training code only saves lora model, this saves our storage and saving time)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E4EyZUq_oUgt",
        "outputId": "9cb8fce3-285f-4903-f821-edaf92233579"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "509\n"
          ]
        }
      ],
      "source": [
        "save_step = len(df_train)//bs//ga_steps*epochs//4\n",
        "print(save_step)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NEVsRG33oUgt"
      },
      "outputs": [],
      "source": [
        "import gc\n",
        "\n",
        "del model\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "29bf0204f2dc4e11b38415decb6f9e54"
          ]
        },
        "id": "GEi4mADDoUgu",
        "outputId": "eca49e9b-a626-4f1d-e2e0-a01d3e7f7005"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "29bf0204f2dc4e11b38415decb6f9e54",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ],
      "source": [
        "from peft import PeftModel, PeftConfig\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import torch\n",
        "\n",
        "_id = save_step*4\n",
        "\n",
        "peft_model_id = f\"{output_dir}/checkpoint-{_id}\"\n",
        "\n",
        "config = PeftConfig.from_pretrained(peft_model_id)\n",
        "\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=False,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.float16,\n",
        ")\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    modelpath,\n",
        "    device_map=\"auto\",\n",
        "    #torch_dtype=torch.float16,\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    quantization_config=bnb_config,\n",
        "    #attn_implementation=\"flash_attention_2\",\n",
        "    trust_remote_code=True,\n",
        "    token = 'YOUR TOKEN HERE'\n",
        ")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(f\"{output_dir}/checkpoint-{_id}\",\n",
        "                                          trust_remote_code=True,\n",
        "                                          padding_side='left',\n",
        "                                          token='YOUR TOKEN HERE')\n",
        "\n",
        "# Load the Lora model\n",
        "model = PeftModel.from_pretrained(model, peft_model_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-3JIJFKtoUgu"
      },
      "outputs": [],
      "source": [
        "def create_prompt(input_, output_):\n",
        "    output_ = 'A. Positive' if output_ == 'positive' else 'B. Neutral' if output_ == 'neutral' else 'C. Negative'\n",
        "        #text = f\"### Question: {input__}\\n ### Answer: {example['output'][i]}\"\n",
        "    text = f'''{input_}\n",
        "A. Positive\n",
        "B. Neutral\n",
        "C. Negative\n",
        "\n",
        "The correct answer is'''\n",
        "\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MGFtOjCvoUgu",
        "outputId": "06d39712-7fe6-4f6c-8fd0-b59162f02aad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The sentiment of this comment: \"món ăn rất ngon\" is\n",
            "A. Positive\n",
            "B. Neutral\n",
            "C. Negative\n",
            "\n",
            "The correct answer is\n"
          ]
        }
      ],
      "source": [
        "sentence = 'món ăn rất ngon'\n",
        "input_ = f'''The sentiment of this comment: \"{sentence}\" is'''\n",
        "prompt = create_prompt(input_, \"\")\n",
        "print(prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OKgbXCL2oUgu",
        "outputId": "faf31294-48d9-43d8-f957-ae28ee93ba9f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[    1,   450, 19688,   310,   445,  3440, 29901,   376, 29885,   888,\n",
              "         29871, 30035, 29876,   364, 31145, 29873,  8736,   265, 29908,   338,\n",
              "            13, 29909, 29889, 10321,  3321,    13, 29933, 29889,  2448,   329,\n",
              "          1705,    13, 29907, 29889, 12610,  1230,    13,    13,  1576,  1959,\n",
              "          1234,   338]])"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "inputs = torch.tensor([tokenizer.encode(prompt)])\n",
        "inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4g8wYogqoUgu"
      },
      "outputs": [],
      "source": [
        "tokens = model.generate(\n",
        "    inputs.to(model.device),\n",
        "    max_new_tokens=50,\n",
        "    temperature=0.1,\n",
        "    do_sample=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "odtLv_c-oUgu",
        "outputId": "622a4a87-c8e1-4a81-c846-e156d5971ecc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<s> The sentiment of this comment: \"món ăn rất ngon\" is\n",
            "A. Positive\n",
            "B. Neutral\n",
            "C. Negative\n",
            "\n",
            "The correct answer is B. Neutral. The comment \"món ăn rất ngon\" simply describes the quality of the food as being fresh. It does not express a positive or negative sentiment.\n",
            "\n",
            "The comment \"Cô ấ\n"
          ]
        }
      ],
      "source": [
        "print(tokenizer.decode(tokens[0], skip_special_tokens=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lQ0v8e_AoUgu",
        "outputId": "a38703ae-9563-49dc-f146-e990b43573fe"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:540: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<s> The sentiment of this comment: \"món ăn rất ngon\" is\n",
            "A. Positive\n",
            "B. Neutral\n",
            "C. Negative\n",
            "\n",
            "The correct answer is B. Neutral\n"
          ]
        }
      ],
      "source": [
        "tokens = model.generate(\n",
        "    inputs.to(model.device),\n",
        "    max_new_tokens=5,\n",
        "    temperature=0.1,\n",
        "    do_sample=False\n",
        ")\n",
        "print(tokenizer.decode(tokens[0], skip_special_tokens=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YyrSS7T3oUgv",
        "outputId": "ad8987a4-20f2-4294-f959-1b2f80908732"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 100.0 0:00:00.265914 0:00:00.265918\n",
            "100 88.11881188118812 0:00:26.009463 0:00:00.257519\n",
            "200 85.07462686567165 0:00:52.076586 0:00:00.259088\n",
            "300 84.38538205980066 0:01:17.926222 0:00:00.258891\n",
            "400 84.03990024937656 0:01:43.832326 0:00:00.258933\n",
            "500 84.83033932135729 0:02:09.807534 0:00:00.259097\n",
            "600 85.19134775374376 0:02:35.450888 0:00:00.258654\n",
            "700 85.30670470756063 0:03:01.166835 0:00:00.258441\n",
            "800 85.39325842696628 0:03:26.736699 0:00:00.258098\n",
            "900 85.46059933407325 0:03:52.235391 0:00:00.257753\n",
            "1000 85.61438561438561 0:04:17.757040 0:00:00.257500\n",
            "1100 85.37693006357856 0:04:43.277785 0:00:00.257291\n",
            "1200 83.84679433805162 0:05:08.742241 0:00:00.257071\n",
            "1300 84.16602613374327 0:05:34.343910 0:00:00.256990\n",
            "1400 84.43968593861527 0:06:00.051187 0:00:00.256996\n",
            "1500 84.07728181212525 0:06:25.658588 0:00:00.256934\n",
            "1600 84.25983760149907 0:06:51.206890 0:00:00.256844\n",
            "1700 84.53850676072898 0:07:16.618919 0:00:00.256684\n",
            "1800 84.7307051637979 0:07:42.237150 0:00:00.256656\n",
            "1900 84.79747501315097 0:08:07.948038 0:00:00.256680\n",
            "2000 84.65767116441779 0:08:33.536940 0:00:00.256640\n"
          ]
        }
      ],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "start = datetime.now()\n",
        "\n",
        "prediction = []\n",
        "response = []\n",
        "accuracy = []\n",
        "labels = []\n",
        "\n",
        "for i, x in df_test.iterrows():\n",
        "    sentence = x['sentence']\n",
        "    label = x['sentiment']\n",
        "    input_ = f'''The sentiment of this comment: \"{sentence}\" is'''\n",
        "    prompt = create_prompt(input_, label)\n",
        "\n",
        "    inputs = tokenizer.encode(\n",
        "        prompt,\n",
        "        # add_generation_prompt=True,\n",
        "        return_tensors='pt'\n",
        "    )\n",
        "\n",
        "    tokens = model.generate(\n",
        "        inputs.to(model.device),\n",
        "        max_new_tokens=5,\n",
        "        temperature=0.1,\n",
        "        do_sample=False,\n",
        "        pad_token_id=tokenizer.eos_token_id\n",
        "    )\n",
        "    #break\n",
        "\n",
        "    answer = tokenizer.decode(tokens[0], skip_special_tokens=False).split(\"The correct answer is \")[-1]\n",
        "    answer = 'positive' if 'positive' in answer.lower() else 'negative' if 'negative' in answer.lower() else 'neutral'\n",
        "    prediction.append(answer.lower())\n",
        "    response.append(tokenizer.decode(tokens[0], skip_special_tokens=False))\n",
        "\n",
        "    accuracy.append(prediction[-1] == label)\n",
        "    labels.append(label)\n",
        "\n",
        "    if i % 100 == 0:\n",
        "        print(i, np.array(accuracy).sum()/len(prediction)*100, datetime.now() - start, (datetime.now() - start)/len(prediction))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LsqcpycBoUgv",
        "outputId": "c29a97b4-438b-48a0-e66d-c4c643b5e8f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative     0.9672    0.9883    0.9776       686\n",
            "     neutral     0.8324    0.6746    0.7453       670\n",
            "    positive     0.7487    0.8721    0.8057       680\n",
            "\n",
            "    accuracy                         0.8463      2036\n",
            "   macro avg     0.8494    0.8450    0.8429      2036\n",
            "weighted avg     0.8499    0.8463    0.8437      2036\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report, f1_score\n",
        "import sklearn\n",
        "\n",
        "print(sklearn.metrics.classification_report(labels, prediction, digits=4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cny1kvndoUgv"
      },
      "source": [
        "# Check results\n",
        "- I print all sentences have wrong prediction and see that almost cases is bug.\n",
        "- Conclusion, dataset is not clean than finetune LLM can't better than finetune roberta (~89..90%), because roberta will overfit even in test dataset.\n",
        "- In additionally, when I print example: \"món ăn này rất ngon\", we can see that model before finetune work better. Model after finetune only think about school (because finetune dataset is about school) and it don't know about food review. Than I think we only need finetune for special cases and finetune dataset need be clean and large enough."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SMT3hDcSoUgv"
      },
      "outputs": [],
      "source": [
        "df_test['predict'] = prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_5O5aneDoUgv",
        "outputId": "d8e61956-d76f-4962-f228-c59c32f1cebe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Giảng viên rất tài năng và có nhiều kinh nghiệm trong công tác giảng dạy. positive neutral\n",
            "Được học tập với các giáo viên giàu kinh nghiệm và thực tiễn. positive neutral\n",
            "Cậu bạn này rất có trách nhiệm và nghiêm túc. positive neutral\n",
            "Thiết bị như máy chiếu, loa, mic đầy đủ trong các phòng học. positive neutral\n",
            "Việc giảng dạy các kiến thức cơ bản có thể là quá dễ hoặc quá khó với một số sinh viên. negative neutral\n",
            "Chị ấy rất giỏi quản lý thời gian và luôn hoàn thành công việc đúng tiến độ. positive neutral\n",
            "Anh ấy có một tầm nhìn đỉnh cao và khả năng giải quyết vấn đề tốt. positive neutral\n",
            "Các cửa hàng tiện lợi gần đó thường xuyên được mở cửa cho sinh viên. negative neutral\n",
            "Trường đại học này đóng góp một phần quan trọng trong việc phát triển kinh tế và xã hội địa phương. positive neutral\n",
            "Sân cỏ của trường được tu bổ và định hướng riêng cho các hoạt động thể thao. positive neutral\n",
            "Môi trường học tập khích lệ sinh viên đề xuất, tìm kiếm và giải quyết các vấn đề thực tế. neutral positive\n",
            "Phòng học được trang bị đầy đủ tiện nghi giúp sinh viên luôn dễ dàng tiếp cận tài liệu và thông tin liên quan. positive neutral\n",
            "Thầy dạy rất chuyên nghiệp và nhiệt tình. neutral positive\n",
            "Các khu vực để tập thể dục trong trường rất đa dạng và thuận tiện. positive neutral\n",
            "Các phòng thí nghiệm được trang bị đầy đủ các thiết bị cần thiết. positive neutral\n",
            "Cô ấy là một người rất chủ động và năng động. positive neutral\n",
            "Thầy/cô đánh giá và đề xuất những ý kiến xây dựng tích cực giúp sinh viên phát triển hơn. neutral positive\n",
            "Giảng viên này có tâm huyết công việc và đam mê với nghề giảng dạy. neutral positive\n",
            "Trường có một thư viện rộng lớn với nhiều tài liệu khác nhau. positive neutral\n",
            "Hệ thống thư viện và tài nguyên học tập rất đầy đủ và tiện lợi. positive neutral\n",
            "Anh bạn đồng nghiệp rất có tinh thần trách nhiệm với công việc. positive neutral\n",
            "Chương trình đào tạo có nhiều tính ứng dụng giúp sinh viên tự tin và thành công trong công việc. neutral positive\n",
            "Thầy cho học sinh một cái nhìn tổng quan về chuyên ngành của mình. neutral positive\n",
            "Sinh viên được khuyến khích tham gia các hoạt động trường đoản cú và hội thảo. positive neutral\n",
            "Các phòng học được trang bị đầy đủ tiện nghi và thiết bị. positive neutral\n",
            "Chương trình đào tạo rất đa dạng về cả nội dung lẫn hình thức đào tạo. neutral positive\n",
            "Chương trình học giúp tôi hiểu rõ hơn về cách tập trung vào khách hàng và giúp tôi phát triển những giá trị ở phần còn lại của doanh nghiệp. neutral positive\n",
            "Trường đại học cung cấp nhiều chương trình học bổng hỗ trợ cho sinh viên khó khăn kinh tế. neutral positive\n",
            "Các dịch vụ bảo vệ trong trường rất chuyên nghiệp và đảm bảo an toàn cho sinh viên. positive neutral\n",
            "Khu vực sống động của trường rất thú vị cho sinh viên. positive neutral\n",
            "Thư viện của trường có nhiều tài liệu bổ ích và đa dạng. positive neutral\n",
            "Giảng viên rất am hiểu và từng bước hướng dẫn sinh viên đi đến thành công. positive neutral\n",
            "Thầy giải thích cặn kẽ và dễ hiểu. neutral positive\n",
            "Thầy cô giảng dạy đều rất nhiệt tình và có kinh nghiệm trong lĩnh vực đang giảng dạy. neutral positive\n",
            "Tôi thích những khu vực xanh tốt cho sức khỏe trong trường của mình. positive neutral\n",
            "Tôi rất ấn tượng với sự trang trí trong trường, chúng tạo cảm giác thoải mái và thư giãn cho sinh viên. positive neutral\n",
            "Không gian của từng phòng học đều được bố trí theo thiết kế hiện đại. positive neutral\n",
            "Lớp học được tổ chức ngắn gọn, thực tế và có tính ứng dụng cao. positive neutral\n",
            "Cô ấy luôn sẵn sàng giúp đỡ và hỗ trợ người khác. positive neutral\n",
            "Học phần khá đào tạo chuyên sâu và có kiến thức mới lạ. positive neutral\n",
            "Các khu vực giải trí của trường rất đầy đủ và thuận tiện. positive neutral\n",
            "Cơ sở hạ tầng ở đây rất đáp ứng nhu cầu học tập của sinh viên. positive neutral\n",
            "Trường có hệ thống thông tin quản lý hiện đại và đáp ứng được các yêu cầu của sinh viên. positive neutral\n",
            "Anh ấy rất lịch sự và tôn trọng người khác. positive neutral\n",
            "Giảng viên giúp tôi hiểu được vấn đề hơn và đưa ra nhiều ví dụ thực tế để áp dụng vào cuộc sống. neutral positive\n",
            "Cô ấy luôn thể hiện sự nghiêm túc và tâm huyết trong việc học tập và giảng dạy. positive neutral\n",
            "Cô này là người chăm chỉ và có tinh thần trách nhiệm cao. positive neutral\n",
            "Bạn của em là người dễ thương và trẻ trung. positive neutral\n",
            "Các trang thiết bị ảnh và âm thanh trong trường đều rất tốt và chất lượng. positive neutral\n",
            "Chị ấy là người thật sự tận tâm và dành trọn tâm huyết cho công việc. positive neutral\n",
            "Cô ấy rất sáng tạo và nghệ thuật. positive neutral\n",
            "Giáo viên của tôi dạy lí thuyết và thực hành về quyền sở hữu trí tuệ và bảo vệ nhãn hiệu. neutral positive\n",
            "Tôi rất thích những khu vực xanh trong trường, chúng tạo cảm giác thoải mái và gần gũi với thiên nhiên. positive neutral\n",
            "Nàng có sự tập trung cao độ và luôn đạt được những thành tích tốt. positive neutral\n",
            "Một số bạn khá giỏi nhưng lúc làm việc chậm như rùa neutral negative\n",
            "Anh ấy là một người học nhanh và có khả năng tìm kiếm thông tin một cách hiệu quả. positive neutral\n",
            "Chương trình giáo dục giúp tôi hiểu rõ hơn về bản thân và định hướng nghề nghiệp sau này của mình. neutral positive\n",
            "Các môn học giúp sinh viên phát triển tư duy phản biện và độc lập trong tư duy. neutral positive\n",
            "Tôi rất cảm kích vì sự hỗ trợ của anh ấy. positive neutral\n",
            "Anh ấy rất thấu hiểu và giúp đỡ những người gặp khó khăn. positive neutral\n",
            "Giảng viên có thể sử dụng nhiều phương pháp giảng dạy khác nhau để thu hút sinh viên học tập. neutral positive\n",
            "Thầy giúp đỡ sinh viên định hướng nghề nghiệp và phát triển bản thân. positive neutral\n",
            "Giảng dạy của thầy rất đặc sắc và sinh động. neutral positive\n",
            "Cô ấy luôn tỏ ra thân thiện và tạo ra không khí làm việc tốt trong nhóm. positive neutral\n",
            "Việc thiếu giảng viên chuyên nghiệp tại một số vùng đất có thể là một nhược điểm của chương trình. negative neutral\n",
            "Tôi rất thích lối thiết kế và trang trí của trường, nó cực kỳ ấn tượng và sáng tạo. positive neutral\n",
            "Lớp học được đưa ra một cách sinh động, hấp dẫn và đầy đủ kiến thức chuyên môn. positive neutral\n",
            "Giảng viên hướng dẫn giỏi với lượng kinh nghiệm thực tiễn phong phú. neutral positive\n",
            "Thầy cung cấp cho chúng tôi nhiều tài liệu và bài giảng hữu ích. neutral positive\n",
            "Em thấy bạn của mình rất nhanh nhẹn và chăm chỉ học. positive neutral\n",
            "Cách đánh giá và phương pháp giảng dạy của trường rất khuyến khích và tạo động lực cho học sinh. neutral positive\n",
            "Thầy giảng dạy rất chu đáo và chuyên nghiệp. neutral positive\n",
            "Giáo viên rất nhiệt tình và giúp đỡ sinh viên trong quá trình học tập. positive neutral\n",
            "Giảng viên luôn mong muốn sinh viên học tập có cho chính mình lợi ích. negative neutral\n",
            "Bạn của tôi là người rất duyên dáng và sành điệu. positive neutral\n",
            "Trường cung cấp nhiều điện thoại công cộng tại khuôn viên. positive neutral\n",
            "Anh ấy là một người học tập tích cực và đam mê trong việc tìm hiểu kiến thức mới. positive neutral\n",
            "Cơ sở vật chất của trường được trang bị hiện đại và chất lượng. positive neutral\n",
            "Cô bạn này rất chăm chỉ học tập. positive neutral\n",
            "Thầy là một giảng viên rất giỏi trong việc truyền đạt kiến thức và kỹ năng cho sinh viên. positive neutral\n",
            "Bạn của tôi rất chăm chỉ và luôn đúng giờ. positive neutral\n",
            "Trường đại học có những khuôn viên xanh rất đẹp và thoáng mát. positive neutral\n",
            "Cô ấy rất năng động và thân thiện đối với mọi người trong lớp. positive neutral\n",
            "Anh ấy là một người giỏi về công nghệ và có khả năng giải quyết vấn đề kỹ thuật. positive neutral\n",
            "Anh bạn cùng lớp rất hòa đồng và dễ gần. positive neutral\n",
            "Số lượng giáo viên nước ngoài được giảng dạy trong chương trình đào tạo là rất ít. negative neutral\n",
            "Tôi thấy chương trình học của trường rất hiện đại và đáp ứng được yêu cầu của thị trường lao động. positive neutral\n",
            "Công nghệ và trang thiết bị của đại học tốt hơn so với nhiều trường khác. positive neutral\n",
            "Giảng viên này dạy rất tốt và truyền cảm hứng cho học sinh. neutral positive\n",
            "Thầy tạo ra môi trường học tập vui vẻ và ấm cúng. positive neutral\n",
            "Đường đi lại trong trường được bố trí rất hợp lý và thuận tiện cho sinh viên. positive neutral\n",
            "Trường luôn giữ gìn sạch sẽ và dễ dàng bảo trì hơn nhờ vào các thiết bị trang trí và cơ sở vật chất. positive neutral\n",
            "Điểm yếu của chương trình là thiếu sự khuyến khích và hỗ trợ cho sinh viên tự học. negative neutral\n",
            "Thầy khuyến khích sinh viên nghiên cứu và khám phá những thứ mới trong lĩnh vực của mình. neutral positive\n",
            "Đội ngũ kỹ thuật của trường luôn có mặt để giúp đỡ và giải quyết các vấn đề kỹ thuật cho sinh viên. positive neutral\n",
            "Thầy/cô có khả năng tương tác tốt với sinh viên. positive neutral\n",
            "Chương trình giảng dạy rất phù hợp với nhu cầu của sinh viên. neutral positive\n",
            "Thầy cô đề cao các trẻ em trên hết và mang đến cho chúng ta một môi trường học tập khuyến khích và thân thiện. positive neutral\n",
            "Các khu vực đặt tủ hồ sơ của trường được bảo quản an toàn và chín chu. neutral positive\n",
            "Tôi cảm thấy rất ấm áp và thoải mái khi sử dụng phòng sinh hoạt chung. positive neutral\n",
            "Bạn của tôi rất yêu thích những trải nghiệm mới. positive neutral\n",
            "Không gian nội thất của phòng học rất tốt, được thiết kế để giúp tăng sự tập trung của sinh viên. positive neutral\n",
            "Tôi cảm thấy rất cảm kích vì giảng viên của mình luôn sẵn sàng giúp đỡ sinh viên trong bất cứ lúc nào. positive neutral\n",
            "Các phòng học được bố trí hợp lí và có đầy đủ máy tính. positive neutral\n",
            "Giảng đường của trường rộng rãi và thoải mái cho việc học tập. positive neutral\n",
            "Tôi rất hài lòng với các phòng học ở đây. positive neutral\n",
            "Giảng viên giúp sinh viên hình thành phương pháp học tập hiệu quả. positive neutral\n",
            "Học tại đây đòi hỏi tôi tính kỷ luật và sự đóng góp sáng tạo. neutral positive\n",
            "Thông tin trường được đăng tải đầy đủ và chi tiết. neutral positive\n",
            "Giáo trình được cập nhật thường xuyên và phù hợp với chương trình học của trường. neutral positive\n",
            "Phòng thực hành có trang thiết bị và công cụ hiện đại. positive neutral\n",
            "Có nhiều tài liệu tham khảo và tài nguyên học tập miễn phí. positive neutral\n",
            "Các phòng thí nghiệm của trường được trang bị đầy đủ thiết bị và công nghệ hiện đại. positive neutral\n",
            "Cật lực học tập của cậu ấy thực sự là một nguồn động lực cho tất cả mọi người trong lớp. neutral positive\n",
            "Tôi thật sự đánh giá cao cơ sở vật chất của trường, nó đáp ứng tốt nhu cầu học tập và giải trí của sinh viên. positive neutral\n",
            "Tôi cảm thấy học phí hợp lí với chất lượng đào tạo của trường. neutral positive\n",
            "Môn học tập trung vào việc thực hành và ứng dụng kiến thức vào thực tế. positive neutral\n",
            "Các khu vực lưu trú của trường được trang bị đầy đủ tiện nghi để đảm bảo sự thoải mái cho sinh viên. positive neutral\n",
            "Môn học giúp sinh viên phát triển tư duy phán đoán và xử lý tình huống trong công việc. positive neutral\n",
            "Nhà hàng của trường cung cấp các món ăn ngon và đa dạng. positive neutral\n",
            "Trường có nhiều chương trình hỗ trợ cho sinh viên đạt thành tích cao. neutral positive\n",
            "Anh ta là một người vui tính và dễ gần. positive neutral\n",
            "Thầy đã giúp tôi có được nhiều kiến thức quan trọng và kỹ năng cần thiết trong công việc. positive neutral\n",
            "Các giảng viên rất tận tâm và nhiệt tình trong việc giảng dạy. neutral positive\n",
            "Đội ngũ nhân viên bảo trì trường luôn hỗ trợ và sử dụng các tiện ích tốt nhất. positive neutral\n",
            "Giảng viên của tôi nói rất rõ và dễ nghe, điều này giúp tôi hiểu được môn học của mình nhanh hơn. positive neutral\n",
            "Cơ sở vật chất đầy đủ, tiên tiến. neutral positive\n",
            "Giảng viên này là một người rất kiên nhẫn và quan tâm đến sự tiến bộ của học sinh. positive neutral\n",
            "Khu vực khuân viên quanh trường xanh tươi, những tin tức, thông báo của trường được phát trực tiếp, rõ ràng, dễ tiếp cận. positive neutral\n",
            "Các môn học về ứng dụng công nghệ thông tin trong kinh doanh rất hữu ích. positive neutral\n",
            "Bài giảng rất rõ ràng và dễ hiểu. neutral positive\n",
            "Cô bạn này rất hiền lành và tốt bụng. positive neutral\n",
            "Các khu vực trên trường cần được bố trí thêm các ghế ngồi để sinh viên có nơi thư giãn và học tập. negative neutral\n",
            "Giảng viên thường đưa ra những câu hỏi khó để thúc đẩy học sinh nghiên cứu thêm. negative neutral\n",
            "Những bài giảng của giáo viên rất chi tiết và đầy đủ thông tin. neutral positive\n",
            "Có những bạn khá tàn nhẫn và thường đưa ra các ý kiến không cần thiết trong lớp học. negative neutral\n",
            "Chương trình học của trường đặt nhiều giá trị vào đạo đức, tinh thần và giá trị con người. positive neutral\n",
            "Thầy luôn cập nhật kiến thức mới nhất để giảng dạy cho sinh viên. positive neutral\n",
            "Giảng viên rất tinh tế khi đưa ra các bài giảng sâu sắc. neutral positive\n",
            "Chương trình giảng dạy kết hợp giữa lý thuyết và thực hành tốt. neutral positive\n",
            "Có các hoạt động thể thao và nghệ thuật cho sinh viên tham gia. positive neutral\n",
            "Thầy đưa ra những tài liệu và thí nghiệm thực tế để giúp học sinh học tập tốt hơn. neutral positive\n",
            "Thiết bị và phương tiện giảng dạy của trường cần được nâng cấp. neutral negative\n",
            "Giảng viên rất nhiệt tình trong việc hỗ trợ sinh viên bất kể lúc nào, ngay cả khi ngoài giờ giảng dạy. negative positive\n",
            "Giảng viên rất dễ tiếp cận và thân thiện, dễ tạo được môi trường học tập tích cực. positive neutral\n",
            "Cơ hội được học hỏi từ các giảng viên nước ngoài. positive neutral\n",
            "Anh ta là người giỏi trong việc tổ chức và quản lý thông tin. positive neutral\n",
            "Giảng viên rất thân thiện và dễ gần với sinh viên. positive neutral\n",
            "Anh ta là người rất năng động và luôn tạo động lực cho người khác. positive neutral\n",
            "Chương trình đào tạo cung cấp cho tôi những kiến thức và kĩ năng cần thiết để trở thành một cựu sinh viên thành công. neutral positive\n",
            "Anh ta là một người thân thiện và luôn lắng nghe người khác. positive neutral\n",
            "Cô ấy khá năng động và luôn có ý tưởng sáng tạo. positive neutral\n",
            "Cô giáo của tôi là người rất thông thái và giàu kinh nghiệm. positive neutral\n",
            "Giảng viên có kỹ năng giảng dạy tốt, giúp sinh viên tự tin và hiểu rõ hơn về chủ đề. positive neutral\n",
            "Đại học tôi có nhiều công trình kiến trúc đẹp và ấn tượng. positive neutral\n",
            "Nội dung học phong phú, đa dạng và cập nhật. positive neutral\n",
            "Anh ấy là người luôn dành thời gian cho sự nghiệp và học tập của mình. positive neutral\n",
            "Điểm mạnh của chương trình đào tạo là được học với giáo viên nước ngoài. positive neutral\n",
            "Tôi rất ngưỡng mộ khả năng làm việc của anh ấy. positive neutral\n",
            "Giảng viên rất thông minh và có kiến thức sâu rộng. positive neutral\n",
            "Anh ấy luôn đặt các mục tiêu và hoàn thành chúng một cách tốt đẹp. positive neutral\n",
            "Anh ấy là một người ổn định và có khả năng tập trung vào mục tiêu. positive neutral\n",
            "Anh ấy là một người rất đáng tin cậy, luôn luôn giữ lời hứa. positive neutral\n",
            "Môn học có sức hấp dẫn cao, tạo động lực cho sinh viên học tập. positive neutral\n",
            "Giáo viên của tôi hướng dẫn sinh viên thực hiện các nghiên cứu thị trường và đánh giá sản phẩm. neutral positive\n",
            "Thư viện trường có nhiều chủ đề khác nhau giúp sinh viên tìm được nguồn tài liệu phù hợp với nhu cầu học tập của mình. neutral positive\n",
            "Tôi rất hài lòng với các dịch vụ hỗ trợ của trường, đặc biệt là các dịch vụ tư vấn và tài chính. positive neutral\n",
            "Anh ta có tính cách điềm đạm và không bao giờ hoảng loạn. neutral positive\n",
            "Thầy cung cấp cho sinh viên các tài nguyên và công cụ hỗ trợ giảng dạy hiệu quả. neutral positive\n",
            "Thầy là người giảng dạy giỏi nhất mà tôi từng gặp. positive neutral\n",
            "Trường cung cấp đầy đủ các thông tin và tài liệu cho sinh viên để giúp tôi học tập một cách hiệu quả. neutral positive\n",
            "Trường có cung cấp wifi miễn phí cho sinh viên, giúp các em tiện lợi hơn trong việc truy cập internet. positive neutral\n",
            "Cô ấy có khả năng nắm bắt được ý tưởng mới và thúc đẩy các hoạt động tạo ý tưởng sáng tạo. positive neutral\n",
            "Thầy dạy rất tâm huyết và có nhiều đóng góp cho sự phát triển của sinh viên. positive neutral\n",
            "Có rất nhiều cơ hội để bạn phát triển năng lực không chỉ trong lớp học mà còn ngoài đời thực. positive neutral\n",
            "Khu vực ngồi chờ đợi được trang bị đầy đủ ghế và trang thiết bị giúp sinh viên chờ đợi một cách thoải mái. positive neutral\n",
            "Giảng viên này đưa ra những bài giảng rõ ràng và hấp dẫn, giúp cho học sinh hiểu bài học dễ dàng hơn. neutral positive\n",
            "Giảng viên dạy rất có tâm, tận tình giúp đỡ sinh viên khi cần. positive neutral\n",
            "Cô bạn này là một giảng viên tuyệt vời, luôn hỗ trợ và giúp đỡ sinh viên. positive neutral\n",
            "Trường đại học này có vị trí thuận tiện và giao thông dễ dàng. positive neutral\n",
            "Các phòng học được trang bị máy chiếu và bảng trắng giúp giảng viên giảng dạy tốt hơn. positive neutral\n",
            "Tôi rất thích cách mà chương trình đào tạo được tổ chức và quản lý. positive neutral\n",
            "Chương trình tiên tiến chưa được triển khai rộng rãi cho sinh viên. negative neutral\n",
            "Hệ thống wifi miễn phí sử dụng thuận tiện. positive neutral\n",
            "Anh ấy rất tôn trọng và quan tâm đến ý kiến của người khác. positive neutral\n",
            "Cô ấy là một người rất giỏi trong việc giảng dạy và rất nhiệt tình. positive neutral\n",
            "Anh ấy là một người có khả năng truyền cảm hứng và động viên người khác. positive neutral\n",
            "Giảng viên này thường chỉ giảng cho các sinh viên sáng gió. neutral negative\n",
            "Chương trình học của trường giúp tôi có cơ hội tham gia các hoạt động ngoại khóa và thể thao. positive neutral\n",
            "Ký túc xá của trường rất tiện nghi và sạch sẽ. positive neutral\n",
            "Cô này là người rất chuyên nghiệp và có kinh nghiệm giảng dạy lâu năm. positive neutral\n",
            "Giảng viên luôn tạo điều kiện để sinh viên có thể tự tìm hiểu và tốt hơn trong học tập. neutral positive\n",
            "Nơi đây có nhiều phòng thí nghiệm và trang thiết bị cần thiết để hỗ trợ học viên. positive neutral\n",
            "Chương trình học tập đáp ứng được những yêu cầu của nghề nghiệp. neutral positive\n",
            "Môn học củ thể chắc chắn sẽ không bao giờ buồn tẻ với thầy. neutral positive\n",
            "Có nhiều vấn đề về thiết bị và hệ thống mạng trong các phòng học. negative neutral\n",
            "Bạn của tôi là người rất năng động và luôn có những ý tưởng mới lạ. positive neutral\n",
            "Trường đại học này là nơi lý tưởng để giao lưu và kết nối với những người bạn mới. positive neutral\n",
            "Cậu ấy có thái độ chuyên nghiệp và luôn hướng đến chất lượng cao. positive neutral\n",
            "Cơ sở vật chất tại đại học này đáp ứng tốt nhu cầu học tập của sinh viên. neutral positive\n",
            "Môn học không phù hợp với chuyên ngành cụ thể và độ khó quá cao. negative neutral\n",
            "Có những sinh viên không sử dụng tối đa thời gian trong lớp học hoặc không lưu tâm đến vấn đề đang thảo luận. negative neutral\n",
            "Cô ấy thông minh và có khả năng tư duy phản biện. positive neutral\n",
            "Anh ấy có trí thông minh sáng suốt và sự nghiệp của anh ấy tuyệt vời. positive neutral\n",
            "Sự đa dạng của chương trình đào tạo giúp tăng tính linh hoạt cho sinh viên. neutral positive\n",
            "Thầy có khả năng dạy học đa dạng để phù hợp với các học sinh có nền tảng kém. neutral positive\n",
            "Có những bạn rất năng động và thích tham gia các hoạt động của trường. positive neutral\n",
            "Bạn sẽ không thể tìm thấy một giảng viên tốt hơn ở bất kỳ nơi nào khác. negative positive\n",
            "Giảng viên rất thông minh và am hiểu chuyên ngành. positive neutral\n",
            "Cậu ấy rất quan tâm đến việc học tập và phát triển bản thân. positive neutral\n",
            "Những buổi học thực tế giúp sinh viên hiểu rõ hơn về ngành học. positive neutral\n",
            "Giảng viên là một người có tác phong và phong cách giảng dạy rất chuyên nghiệp. neutral positive\n",
            "Giảng viên này thường đồng ý với ý kiến của những sinh viên giàu kinh nghiệm. neutral negative\n",
            "Các dịch vụ thư viện của trường rất tốt và được cập nhật thường xuyên. positive neutral\n",
            "Giảng viên rất nhiệt tình trong việc trao đổi và thảo luận để giải quyết những khó khăn trong quá trình học tập. neutral positive\n",
            "Giảng viên dạy rất chất lượng và hiệu quả. neutral positive\n",
            "Tôi hi vọng trường tôi sẽ dành nhiều thời gian hơn để cải thiện cơ sở vật chất và nâng cao chất lượng giảng dạy. neutral negative\n",
            "Chương trình đào tạo giúp tôi có cơ hội gặp gỡ và học hỏi từ những người có kinh nghiệm trong lĩnh vực tôi quan tâm. neutral positive\n",
            "Chương trình đào tạo giúp tôi có cái nhìn rộng hơn về thế giới và thời đại hiện nay. neutral positive\n",
            "Chương trình đào tạo rất chuyên nghiệp. neutral positive\n",
            "Giáo viên thường xuyên kiểm tra và giám sát quá trình học tập của sinh viên. negative neutral\n",
            "Tôi mong đợi giảng viên sẽ sửa ngay lập tức những sai sót trong bài giảng để tránh nhầm lẫn. negative neutral\n",
            "Không giới hạn về thời gian học tập. neutral positive\n",
            "Giảng viên thường sử dụng những phương pháp dạy học độc đáo và hiệu quả. neutral positive\n",
            "Tôi cảm thấy kiến thức được truyền đạt sâu sắc và có tính ứng dụng cao. positive neutral\n",
            "Chương trình học phù hợp với yêu cầu của thị trường và đáp ứng được nhu cầu của học viên. neutral positive\n",
            "Trường có các chương trình học bổng và tài trợ giúp đỡ những sinh viên có thành tích học tập cao. positive neutral\n",
            "Các căn tin ở đây rất ngon và giá cả phải chăng. positive neutral\n",
            "Chương trình học rất phù hợp cho sinh viên muốn tiếp cận nhanh với lĩnh vực công nghệ thông tin. positive neutral\n",
            "Giáo viên rất chuyên nghiệp và hỗ trợ tốt cho sinh viên. positive neutral\n",
            "Tôi cảm thấy chương trình học không thực sự đáp ứng được nhu cầu ngành nghề hiện tại. neutral negative\n",
            "Học phí được giảm giá cho những sinh viên đăng ký sớm. neutral positive\n",
            "Thầy này tổ chức và quản lý giảng dạy rất tốt. neutral positive\n",
            "Giảng viên này quá đòi hỏi cao về điểm số và đôi khi làm khó học sinh. negative neutral\n",
            "Tôi rất yêu thích không gian của thư viện và các dịch vụ bổ trợ tại đây. positive neutral\n",
            "Công nghệ đang sử dụng trong quá trình giảng dạy chưa đáp ứng được nhu cầu của thời đại. neutral negative\n",
            "Các phòng học được trang bị tiện nghi và đầy đủ thiết bị. positive neutral\n",
            "Thầy rất trung thực và chính trực trong giảng dạy. neutral positive\n",
            "Chương trình học rất linh hoạt và có thể phù hợp với nhu cầu của từng sinh viên. neutral positive\n",
            "Thầy này lắng nghe học sinh rất chu đáo. neutral positive\n",
            "Giảng viên này không giúp được học sinh đạt được những mục tiêu của họ. negative neutral\n",
            "Trường đặt nhiều ưu tiên cho sự phát triển toàn diện của sinh viên. positive neutral\n",
            "Đội ngũ nhân viên ở đây luôn hỗ trợ và đáp ứng mọi nhu cầu của sinh viên. positive neutral\n",
            "Tôi hướng đến mục tiêu của bản thân với sự giúp đỡ của giảng viên. neutral positive\n",
            "Tôi đã được trang bị đầy đủ các tài liệu thư viện cần thiết để học tập và làm bài tập. positive neutral\n",
            "Phòng thí nghiệm ở trường được trang bị đầy đủ thiết bị và máy móc. positive neutral\n",
            "Thầy luôn đưa ra các gợi ý để sinh viên có thể nâng cao năng lực học tập của mình. positive neutral\n",
            "Đội ngũ giáo viên có nhiều tri thức và kinh nghiệm giúp sinh viên nắm vững kiến thức chuyên môn. neutral positive\n",
            "Trường đại học này luôn giữ vệ sinh và sửa chữa tốt hệ thống cơ sở vật chất. positive neutral\n",
            "Những kiến thức tôi học được trong chương trình học rất bổ ích cho công việc của tôi sau này. positive neutral\n",
            "Bạn của tôi rất cởi mở và dễ thương với mọi người. positive neutral\n",
            "Bãi đỗ xe của trường rộng rãi và an toàn. positive neutral\n",
            "Sinh viên này rất tập trung và luôn hoàn thành tốt công việc được giao. positive neutral\n",
            "Giảng viên giúp sinh viên phát triển và rèn luyện kỹ năng sáng tạo. positive neutral\n",
            "Giảng viên tôi cung cấp cho tôi những kiến thức quan trọng mà tôi sẽ sử dụng suốt đời. neutral positive\n",
            "Các hoạt động giáo dục khá đa dạng và phong phú. neutral positive\n",
            "Các bài kiểm tra được thiết kế tốt và công bằng. neutral positive\n",
            "Thầy luôn dạy sinh viên cách tư duy và phát triển kỹ năng. positive neutral\n",
            "Tất cả sinh viên được đón tiếp với cách thức trị nhẹ nhàng và dễ dàng. positive neutral\n",
            "Các cơ sở vật chất trong trường rất phong phú và đáp ứng tốt nhu cầu sinh viên. positive neutral\n",
            "Giảng viên này đôi lúc quên chuyện chính để giải thích những chi tiết không quan trọng. negative neutral\n",
            "Lớp học được tổ chức khoa học, hỗ trợ sinh viên không chỉ giúp học mà còn giúp sinh viên rèn luyện kỹ năng quản lý thời gian. positive neutral\n",
            "Em nghĩ bạn của mình là người có khả năng làm việc nhóm tốt. positive neutral\n",
            "Giảng viên rất thân thiện và có tư duy phản biện cao. neutral positive\n",
            "Cô ấy có khả năng đưa ra quyết định một cách đúng đắn và hiệu quả. neutral positive\n",
            "Trường được trang bị đầy đủ thiết bị thông tin liên lạc giữa sinh viên và giảng viên. positive neutral\n",
            "Các giảng viên đều rất am hiểu trong lĩnh vực của mình. neutral positive\n",
            "Có sự tư vấn và hỗ trợ để chuẩn bị cho thực tập, tìm kiếm việc làm sau khi tốt nghiệp. positive neutral\n",
            "Người này là người rất năng động và luôn tìm cách tạo sự khác biệt. positive neutral\n",
            "Giáo trình rất thú vị và độc đáo, giúp tôi học được nhiều thứ mới lạ. positive neutral\n",
            "Khuôn viên đất nền rộng rãi và khá yên tĩnh. neutral positive\n",
            "Giảng viên này đưa ra những giải pháp đột phá và sáng tạo cho việc học tập. neutral positive\n",
            "Thầy truyền cảm hứng và động viên các sinh viên có hoàn cảnh khó khăn. positive neutral\n",
            "Nội dung bài học trực quan và hấp dẫn. positive neutral\n",
            "Cô ấy rất thoải mái và tự tin trong giao tiếp đa dạng với người khác giới. positive neutral\n",
            "Anh ấy có tinh thần lạc quan và luôn giữ vững niềm tin vào bản thân. positive neutral\n",
            "Giảng viên này đưa ra các ví dụ rất thực tế và hữu ích để giúp tôi hiểu bài học. neutral positive\n",
            "Anh ấy là người hỗ trợ rất tốt cho các bạn trong lớp. positive neutral\n",
            "Tôi thấy anh chàng này rất tâm lý và chú ý đến tình hình xung quanh. positive neutral\n",
            "Giảng viên rất thân thiện và tạo không khí học tập tích cực cho sinh viên. positive neutral\n",
            "Thầy đưa ra những phương pháp dạy học hiệu quả và hữu ích cho sinh viên. neutral positive\n",
            "Cô ấy có tài giao tiếp tốt và thân thiện với những người xung quanh. positive neutral\n",
            "Tôi rất hài lòng với chương trình học nơi đây. positive neutral\n",
            "Bạn của em là người rất cá tính và không sợ thể hiện bản thân. positive neutral\n",
            "Cô ấy có phong cách dạy học vô cùng sáng tạo và thú vị. positive neutral\n",
            "Anh ta luôn có tinh thần học hỏi và mở đầu với những kiến thức mới. positive neutral\n",
            "Các buổi học được tổ chức chặt chẽ và có sự chuẩn bị kỹ lưỡng. neutral positive\n",
            "Nàng có tinh thần cởi mở và đồng cảm với người khác. positive neutral\n",
            "Giảng viên dạy rất hay và dễ hiểu. neutral positive\n",
            "Cô ấy là người có cá tính và luôn sáng tạo. positive neutral\n",
            "Tôi không thể tưởng tượng được môi trường học tập sẽ như thế nếu không có thầy/cô. negative positive\n",
            "Cậu ấy tích cực và nhiệt tình trong các hoạt động đại hội SV. positive neutral\n",
            "Tôi đã học được kỹ năng cần thiết cho sự nghiệp của mình từ giảng viên này. positive neutral\n",
            "Anh ấy rất tiếp thu được những kiến thức mới một cách nhanh chóng. positive neutral\n",
            "Phòng học được bố trí đồng nhất và gọn gàng, giúp cho sinh viên học tập tập trung hơn. positive neutral\n",
            "Giảng viên không thường xuyên liên hệ với sinh viên sau khi họ kết thúc môn học. negative neutral\n",
            "Có rất nhiều bạn học tốt và tích cực tham gia vào các hoạt động của trường. positive neutral\n",
            "Giảng viên rất đáng kính và được sinh viên yêu mến đặc biệt. positive neutral\n",
            "Thầy rất năng động, giúp sinh viên tập trung vào học tập một cách hiệu quả. positive neutral\n",
            "Trường có các dịch vụ tiện ích như ngân hàng, quầy bán hàng tại khuôn viên. positive neutral\n",
            "Giáo viên luôn đặt mình vào tâm trạng và khó khăn của học sinh. negative positive\n",
            "Chất lượng giảng dạy của trường tôi rất tốt trong đó giáo viên là một phần quan trọng. neutral positive\n",
            "Tôi rất ngưỡng mộ sự kiên trì của bạn ấy. positive neutral\n",
            "Giảng viên càng ngày càng ít đưa ra các bài kiểm tra thực tế neutral negative\n",
            "Giảng viên mang lại kinh nghiệm thực tế cho học sinh. neutral positive\n",
            "Trường có các khu vực giải trí, phòng chơi game, thư giãn cho sinh viên. positive neutral\n",
            "Các khu vực phục vụ ăn uống rộng rãi và thoải mái cho sinh viên. positive neutral\n",
            "Cô ấy rất nhiệt tình trong hoạt động ngoại khóa. positive neutral\n",
            "Nhân viên phục vụ trường luôn sáng suốt, vui vẻ, nhiệt tình hỗ trợ sinh viên mọi khi cần thiết positive neutral\n",
            "Tài liệu học tập nhiệt tình và đầy trải nghiệm thực tế. positive neutral\n",
            "Các bài học được thiết kế tối ưu cho việc học trực tuyến. neutral positive\n",
            "Các khu vực cấm hút thuốc được thiết kế và bố trí để đảm bảo không khí trong lành. neutral positive\n",
            "Cậu ấy rất có kỹ năng về sáng tạo và nghệ thuật. positive neutral\n"
          ]
        }
      ],
      "source": [
        "for i, row in df_test.iterrows():\n",
        "    if row['predict'] != row['sentiment']:\n",
        "        print(row['sentence'], row['predict'], row['sentiment'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JLAcQK2-oUgv"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "asQsXpnkoUgv"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "datasetId": 3052448,
          "sourceId": 5245967,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30733,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}