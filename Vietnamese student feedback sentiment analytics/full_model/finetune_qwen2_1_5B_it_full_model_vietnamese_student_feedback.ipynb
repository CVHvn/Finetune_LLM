{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "id": "VwBhnLBWQrbT"
      },
      "source": [
        "# Install library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ER6en78aQrbU",
        "outputId": "92e2d0df-b8a1-4e01-b768-9584bea31adf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -q datasets==2.16.0\n",
        "!pip install -q bitsandbytes\n",
        "!pip install -q tiktoken\n",
        "!pip install -q peft\n",
        "!pip install -q trl\n",
        "!pip install -q transformers\n",
        "!pip install -q openpyxl\n",
        "!pip install -q pandas\n",
        "!pip install -q scikit-learn\n",
        "!pip install -q flash-attn\n",
        "#pip install -q transformers==4.38.1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OHkfqcjwQrbV"
      },
      "source": [
        "# Import library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ymrCHOhaQrbW"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
        "import torch\n",
        "from accelerate import PartialState\n",
        "from peft import LoraConfig, PeftModel, prepare_model_for_kbit_training, get_peft_model\n",
        "from trl import SFTTrainer\n",
        "from peft import prepare_model_for_kbit_training\n",
        "from transformers import TrainingArguments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3U2dA8vvQrbW"
      },
      "source": [
        "# Hyperparameters\n",
        "I use lr = 2e-4 when finetune with lora and qlora. But when finetune full model, I need to use lower lr (2e-5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7j2aeU1eQrbW"
      },
      "outputs": [],
      "source": [
        "modelpath = \"Qwen/Qwen2-1.5B-Instruct\"\n",
        "lr=2e-5      # learning rate\n",
        "bs=16            # batch size\n",
        "bs_eval=16      # batch size for evals\n",
        "ga_steps=1     # gradient acc. steps\n",
        "epochs=4\n",
        "max_length=128      # max. sample length with 24GB VRAM\n",
        "output_dir=\"out\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJfIspkkQrbW"
      },
      "source": [
        "# Remove old model\n",
        "Because of limited storage, we can't save all models, we need to delete all models in cache by the following code:\n",
        "- rm -r out: delete out folder (because I save finetuned model in out folder), you can change folder name like (rm -r output_folder). If you doesn't have out folder, this commend do not thing.\n",
        "- all pretrained huggingface models will auto save in transformers.TRANSFORMERS_CACHE. I use shutil.rmtree to delete them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hGazXzjAQrbW"
      },
      "outputs": [],
      "source": [
        "!rm -r out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sYsSfJvMQrbW"
      },
      "outputs": [],
      "source": [
        "# from transformers import TRANSFORMERS_CACHE\n",
        "# print(TRANSFORMERS_CACHE)\n",
        "\n",
        "# import shutil\n",
        "# shutil.rmtree(TRANSFORMERS_CACHE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jtwlIwVvQrbW"
      },
      "source": [
        "# Create Dataset\n",
        "Download dataset from [kaggle synthetic-vietnamese-students-feedback-corpus](https://www.kaggle.com/datasets/toreleon/synthetic-vietnamese-students-feedback-corpus/data)\n",
        "\n",
        "We need convert DataFrame to json line (jsonl)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kh0vXDieQrbX"
      },
      "outputs": [],
      "source": [
        "df_train = pd.read_csv(\"synthetic_train.csv\")\n",
        "df_test = pd.read_csv(\"synthetic_val.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nmV2_-o5QrbX",
        "outputId": "6970f64c-e0c3-4d7f-c1f4-37248501a6d9"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>topic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ƒê·ªôi ng≈© b·∫£o tr√¨ qu√° th∆∞a th·ªõt d·∫´n ƒë·∫øn kh√¥ng ƒë·∫£...</td>\n",
              "      <td>negative</td>\n",
              "      <td>facility</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The university's musical and artistic faciliti...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>facility</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Ph∆∞∆°ng ph√°p gi·∫£ng d·∫°y ph√π h·ª£p v·ªõi c√°c ƒë·ªëi t∆∞·ª£n...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>curriculum</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Ch∆∞∆°ng tr√¨nh h·ªçc gi√∫p t√¥i tr·ªü th√†nh m·ªôt chuy√™n...</td>\n",
              "      <td>positive</td>\n",
              "      <td>curriculum</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>T√¥i nghƒ© r·∫±ng ch∆∞∆°ng tr√¨nh ƒë√†o t·∫°o c√≥ th·ªÉ c√≥ t...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>curriculum</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            sentence sentiment       topic\n",
              "0  ƒê·ªôi ng≈© b·∫£o tr√¨ qu√° th∆∞a th·ªõt d·∫´n ƒë·∫øn kh√¥ng ƒë·∫£...  negative    facility\n",
              "1  The university's musical and artistic faciliti...   neutral    facility\n",
              "2  Ph∆∞∆°ng ph√°p gi·∫£ng d·∫°y ph√π h·ª£p v·ªõi c√°c ƒë·ªëi t∆∞·ª£n...   neutral  curriculum\n",
              "3  Ch∆∞∆°ng tr√¨nh h·ªçc gi√∫p t√¥i tr·ªü th√†nh m·ªôt chuy√™n...  positive  curriculum\n",
              "4  T√¥i nghƒ© r·∫±ng ch∆∞∆°ng tr√¨nh ƒë√†o t·∫°o c√≥ th·ªÉ c√≥ t...   neutral  curriculum"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WcAWMQiSQrbX",
        "outputId": "bd525f02-f5d3-4ed9-a5b1-ad0c83b51239"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>topic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Ch·∫•t l∆∞·ª£ng v·∫≠t ch·∫•t k√©m.</td>\n",
              "      <td>negative</td>\n",
              "      <td>facility</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Ph·∫ßn m·ªÅm h·ªçc t·∫≠p qu√° kh√≥ s·ª≠ d·ª•ng, khi·∫øn sinh v...</td>\n",
              "      <td>negative</td>\n",
              "      <td>facility</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Tr∆∞·ªùng t√¥i thi·∫øu nh·ªØng ti·ªán √≠ch c∆° b·∫£n nh∆∞ m√°y...</td>\n",
              "      <td>negative</td>\n",
              "      <td>facility</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>C·∫ßn t·∫°o th√™m c√°c ho·∫°t ƒë·ªông g·∫Øn k·∫øt gi·ªØa sinh v...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>curriculum</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>H·ªç r·∫•t khoan dung v√† l∆∞·ª£ng gi√°c trong quan ƒëi·ªÉ...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>others</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            sentence sentiment       topic\n",
              "0                           Ch·∫•t l∆∞·ª£ng v·∫≠t ch·∫•t k√©m.  negative    facility\n",
              "1  Ph·∫ßn m·ªÅm h·ªçc t·∫≠p qu√° kh√≥ s·ª≠ d·ª•ng, khi·∫øn sinh v...  negative    facility\n",
              "2  Tr∆∞·ªùng t√¥i thi·∫øu nh·ªØng ti·ªán √≠ch c∆° b·∫£n nh∆∞ m√°y...  negative    facility\n",
              "3  C·∫ßn t·∫°o th√™m c√°c ho·∫°t ƒë·ªông g·∫Øn k·∫øt gi·ªØa sinh v...   neutral  curriculum\n",
              "4  H·ªç r·∫•t khoan dung v√† l∆∞·ª£ng gi√°c trong quan ƒëi·ªÉ...   neutral      others"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_test.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BAGhK876QrbX",
        "outputId": "2d162202-2158-4e21-f78b-7c0a8228a408"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "sentiment\n",
              "neutral     2724\n",
              "negative    2711\n",
              "positive    2709\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train.sentiment.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7abZjD7DQrbX",
        "outputId": "809018c1-090a-4147-9892-2a255c4e3728"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "sentiment\n",
              "negative    686\n",
              "positive    680\n",
              "neutral     670\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_test.sentiment.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "owCz88kIQrbX"
      },
      "outputs": [],
      "source": [
        "df_train['len'] = df_train.sentence.apply(lambda x: len(str(x).split()))\n",
        "df_test['len'] = df_test.sentence.apply(lambda x: len(str(x).split()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Um6rLSdQrbX",
        "outputId": "5559ab4d-70fc-4aca-b51a-5d554f0ef63f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "count    8144.000000\n",
              "mean       15.549730\n",
              "std         5.018764\n",
              "min         3.000000\n",
              "25%        12.000000\n",
              "50%        15.000000\n",
              "75%        18.000000\n",
              "max        43.000000\n",
              "Name: len, dtype: float64"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train['len'].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5OpTZQbjQrbY",
        "outputId": "63ed7ff0-cc45-4d27-e593-99cb359bbe17"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "count    2036.000000\n",
              "mean       15.694990\n",
              "std         5.185957\n",
              "min         2.000000\n",
              "25%        12.000000\n",
              "50%        15.000000\n",
              "75%        19.000000\n",
              "max        48.000000\n",
              "Name: len, dtype: float64"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_test['len'].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bb3vCWqqQrbY"
      },
      "outputs": [],
      "source": [
        "with open('train.jsonl', 'w') as outfile:\n",
        "    for i, x in df_train.iterrows():\n",
        "        comment = x['sentence']\n",
        "        label = x['sentiment']\n",
        "        #label = 'yes' if label == 'relevance' else 'no'\n",
        "        data = {\n",
        "            \"input\": f'''The sentiment of this comment \"{comment}\" is''',\n",
        "            \"output\": f\"{label}\"\n",
        "        }\n",
        "        json.dump(data, outfile)\n",
        "        outfile.write('\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "30C2Ni65QrbY"
      },
      "outputs": [],
      "source": [
        "with open('test.jsonl', 'w') as outfile:\n",
        "    for i, x in df_test.iterrows():\n",
        "        comment = x['sentence']\n",
        "        label = x['sentiment']\n",
        "        #label = 'yes' if label == 'relevance' else 'no'\n",
        "        data = {\n",
        "            \"input\": f'''The sentiment of this comment \"{comment}\" is''',\n",
        "            \"output\": f\"{label}\"\n",
        "        }\n",
        "        json.dump(data, outfile)\n",
        "        outfile.write('\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "1c967d2522c74f28a0b15c92780ef767",
            "4423a386354948239208fe8aed426e7e"
          ]
        },
        "id": "1TjHt6o2QrbY",
        "outputId": "d49b17be-0124-4ee8-e09d-dd670e95567b"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1c967d2522c74f28a0b15c92780ef767",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4423a386354948239208fe8aed426e7e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating validation split: 0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "data_files = {\n",
        "    \"train\": \"train.jsonl\",\n",
        "    \"validation\": \"test.jsonl\",\n",
        "}\n",
        "\n",
        "dataset = load_dataset(\"json\", data_files=data_files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4cfH3YieQrbY",
        "outputId": "15c3ef14-f049-4e7b-a503-d75577ad62cf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['input', 'output'],\n",
              "        num_rows: 8144\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['input', 'output'],\n",
              "        num_rows: 2036\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IA0svdBnQrbY"
      },
      "source": [
        "# Create prompt format\n",
        "Load tokenizer by AutoTokenizer.from_pretrained:\n",
        "- We need create and copy YOUR TOKEN from [huggingface](https://huggingface.co/settings/tokens)\n",
        "- We need use padding_side = 'right' because training library need padding_side = 'right' when training. You can use left padding but you need to make sure the library is not corrupted and check whether performance is affected by left padding!\n",
        "- If you have 1 prompt like \"test th·ª≠ m√¥ h√¨nh\" and want to tokenize it, just you tokenizer(prompt, return_tensors=\"pt\"). You can see output of tokenizer in cell below (output includes input_ids (list index of each token in prompt) and attention mask)\n",
        "- We can use tokenizer.batch_decode to see how tokenizer restore string from token tensor. You can see that it automatically adds the start token \"<bos>\" at the beginning of the string.\n",
        "- To train llm, we only need to pass 1 sentence to llm (including input and desired output) without specifying which is the input and which is the output.\n",
        "- I wrote the function formatting_prompts_func to convert input and output to prompt and tested this function, you can see below.\n",
        "- When predicting, remove the output part to let the model predict itself. See the predict section below later.\n",
        "- we only need to predict some next tokens like A. positive, and B. neutral. We don't care what the model says after sentiment. Then we do not need to add <eos token>. If you fine-tune the model with other tasks, maybe you need to add <eos token> at the end of the prompt:\n",
        "  - use tokenizer.eos_token, tokenizer.eos_token_id to see eos_token of your model and correspond id\n",
        "  - for ex: eos_token is \"<|im_end|>\". You need edit prompt like:\n",
        "    - '''...The correct answer is {output_}.''' --> '''...The correct answer is {output_}. <|im_end|>'''\n",
        "  - for ex: eos_token is \"end_token__\". You need edit prompt like:\n",
        "    - '''...The correct answer is {output_}.''' --> '''...The correct answer is {output_}. end_token__'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TRqzDK3oQrbY",
        "outputId": "fa0bd29e-9a83-4f09-b169-7966635b7fd3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    modelpath,\n",
        "    padding_side=\"right\",\n",
        "    # add_eos_token=True,\n",
        "    # add_bos_token=True,\n",
        "    trust_remote_code=True,\n",
        "    token = 'YOUR TOKEN HERE'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cOwCgX_BQrbZ",
        "outputId": "1b9a2d1b-2277-4f58-e9f9-50caa18e6e6f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_ids': tensor([[  1944, 131885, 130179, 128338]]), 'attention_mask': tensor([[1, 1, 1, 1]])}\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['test', ' th·ª≠', ' m√¥', ' h√¨nh']"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prompt = \"test th·ª≠ m√¥ h√¨nh\"\n",
        "tokens = tokenizer(prompt, return_tensors=\"pt\")\n",
        "print(tokens)\n",
        "tokenizer.batch_decode(tokenizer.encode(prompt))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Na3lRDFOQrbZ"
      },
      "outputs": [],
      "source": [
        "def formatting_prompts_func(example):\n",
        "    output_texts = []\n",
        "    for i in range(len(example['input'])):\n",
        "        input_ = example['input'][i]\n",
        "        output_ = example['output'][i]\n",
        "        output_ = 'A. Positive' if output_ == 'positive' else 'B. Neutral' if output_ == 'neutral' else 'C. Negative'\n",
        "        #text = f\"### Question: {input__}\\n ### Answer: {example['output'][i]}\"\n",
        "        text = f'''{input_}\n",
        "A. Positive\n",
        "B. Neutral\n",
        "C. Negative\n",
        "\n",
        "The correct answer is {output_}.'''\n",
        "\n",
        "        output_texts.append(text)\n",
        "    return output_texts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8SU6co6NQrbZ",
        "outputId": "568271ad-d77b-4226-c8fa-d5fa0afd5416"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('The sentiment of this comment \"Ch·∫•t l∆∞·ª£ng v·∫≠t ch·∫•t k√©m.\" is', 'negative')"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset[\"validation\"]['input'][0], dataset[\"validation\"]['output'][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nFs2XPdGQrbZ",
        "outputId": "146838e1-47a7-4929-b99e-8d342ae75aa1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['The sentiment of this comment \"Ch·∫•t l∆∞·ª£ng v·∫≠t ch·∫•t k√©m.\" is\\nA. Positive\\nB. Neutral\\nC. Negative\\n\\nThe correct answer is C. Negative.']"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "formatting_prompts_func({'input': [dataset[\"validation\"]['input'][0]],\n",
        "                         'output': [dataset[\"validation\"]['output'][0]]})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fr4S8Aj7QrbZ",
        "outputId": "768fe542-08eb-46ca-e280-17476252a900"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The sentiment of this comment \"Ch·∫•t l∆∞·ª£ng v·∫≠t ch·∫•t k√©m.\" is\n",
            "A. Positive\n",
            "B. Neutral\n",
            "C. Negative\n",
            "\n",
            "The correct answer is C. Negative.\n"
          ]
        }
      ],
      "source": [
        "print(formatting_prompts_func({'input': [dataset[\"validation\"]['input'][0]],\n",
        "                         'output': [dataset[\"validation\"]['output'][0]]})[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qMoXHsDOQrbZ"
      },
      "source": [
        "# Create model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n1rXbdJBQrbZ"
      },
      "source": [
        "## Load model\n",
        "We use AutoModelForCausalLM.from_pretrained to load model:\n",
        "- device_map = 'auto': auto active gpu.\n",
        "- torch_dtype: use bfloat16, if your gpu don't support bfloat16, set it to float32\n",
        "- attn_implementation: you can use 'flash_attention_2', if you meet bug, maybe your gpu doesn't support it, you need delete this line.\n",
        "- token: you huggingface token like tokenizer above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "23GNpjIPQrba"
      },
      "outputs": [],
      "source": [
        "# bnb_config = BitsAndBytesConfig(\n",
        "#     load_in_4bit=True,\n",
        "#     bnb_4bit_use_double_quant=True,\n",
        "#     bnb_4bit_quant_type=\"nf4\",\n",
        "#     bnb_4bit_compute_dtype=torch.bfloat16,\n",
        "# )\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    modelpath,\n",
        "    device_map=\"auto\",\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    #torch_dtype=torch.float32,\n",
        "    #quantization_config=bnb_config,\n",
        "    attn_implementation=\"flash_attention_2\",\n",
        "    trust_remote_code=True,\n",
        "    token = 'YOUR TOKEN HERE'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IJ0qKmMVQrba",
        "outputId": "2d14b689-6130-4655-a06d-515d7573316d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Qwen2ForCausalLM(\n",
              "  (model): Qwen2Model(\n",
              "    (embed_tokens): Embedding(151936, 1536)\n",
              "    (layers): ModuleList(\n",
              "      (0-27): 28 x Qwen2DecoderLayer(\n",
              "        (self_attn): Qwen2FlashAttention2(\n",
              "          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
              "          (k_proj): Linear(in_features=1536, out_features=256, bias=True)\n",
              "          (v_proj): Linear(in_features=1536, out_features=256, bias=True)\n",
              "          (o_proj): Linear(in_features=1536, out_features=1536, bias=False)\n",
              "          (rotary_emb): Qwen2RotaryEmbedding()\n",
              "        )\n",
              "        (mlp): Qwen2MLP(\n",
              "          (gate_proj): Linear(in_features=1536, out_features=8960, bias=False)\n",
              "          (up_proj): Linear(in_features=1536, out_features=8960, bias=False)\n",
              "          (down_proj): Linear(in_features=8960, out_features=1536, bias=False)\n",
              "          (act_fn): SiLU()\n",
              "        )\n",
              "        (input_layernorm): Qwen2RMSNorm()\n",
              "        (post_attention_layernorm): Qwen2RMSNorm()\n",
              "      )\n",
              "    )\n",
              "    (norm): Qwen2RMSNorm()\n",
              "  )\n",
              "  (lm_head): Linear(in_features=1536, out_features=151936, bias=False)\n",
              ")"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Eval model before training\n",
        "We use create_prompt function to generate prompt (without output), our model will predict output. We will eval model before finetune. You can see some predict below.\n",
        "\n",
        "You can see that pretrained model has poor performance"
      ],
      "metadata": {
        "id": "bqx4JVIyRH8O"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_4hXdq4YQrbd",
        "outputId": "b0d51ba5-ccb3-4c0f-8b55-c2332c770fe2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:540: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:545: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:562: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.\n",
            "  warnings.warn(\n",
            "The attention mask is not set and cannot be inferred from input because pad token is same as eos token.As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The sentiment of this comment: \"m√≥n ƒÉn r·∫•t ngon\" is\n",
            "A. Positive\n",
            "B. Neutral\n",
            "C. Negative\n",
            "\n",
            "The correct answer is\n",
            "The sentiment of this comment: \"m√≥n ƒÉn r·∫•t ngon\" is\n",
            "A. Positive\n",
            "B. Neutral\n",
            "C. Negative\n",
            "\n",
            "The correct answer is A. Positive.\n",
            "\n",
            "The phrase \"m√≥n ƒÉn r·∫•t ngon\" translates to \"delicious food\" in English, which indicates a positive sentiment towards the food being described. The use of \"kh√¥ng\" (not) at the end of the\n"
          ]
        }
      ],
      "source": [
        "def create_prompt(input_, output_):\n",
        "    output_ = 'A. Positive' if output_ == 'positive' else 'B. Neutral' if output_ == 'neutral' else 'C. Negative'\n",
        "        #text = f\"### Question: {input__}\\n ### Answer: {example['output'][i]}\"\n",
        "    text = f'''{input_}\n",
        "A. Positive\n",
        "B. Neutral\n",
        "C. Negative\n",
        "\n",
        "The correct answer is'''\n",
        "\n",
        "    return text\n",
        "\n",
        "sentence = 'm√≥n ƒÉn r·∫•t ngon'\n",
        "input_ = f'''The sentiment of this comment: \"{sentence}\" is'''\n",
        "prompt = create_prompt(input_, \"\")\n",
        "print(prompt)\n",
        "\n",
        "inputs = torch.tensor([tokenizer.encode(prompt)])\n",
        "\n",
        "tokens = model.generate(\n",
        "    inputs.to(model.device),\n",
        "    max_new_tokens=50,\n",
        "    temperature=0.1,\n",
        "    do_sample=False\n",
        ")\n",
        "print(tokenizer.decode(tokens[0], skip_special_tokens=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rtg73bPwQrbd",
        "outputId": "99ed54fc-9450-4425-962a-e416e4b5f022"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 100.0 0:00:00.064404 0:00:00.064407\n",
            "100 69.3069306930693 0:00:06.473455 0:00:00.064094\n",
            "200 70.64676616915423 0:00:12.894337 0:00:00.064151\n",
            "300 67.77408637873754 0:00:19.263876 0:00:00.064000\n",
            "400 68.5785536159601 0:00:25.610590 0:00:00.063867\n",
            "500 69.26147704590818 0:00:31.964937 0:00:00.063802\n",
            "600 67.55407653910149 0:00:38.315419 0:00:00.063753\n",
            "700 66.76176890156918 0:00:44.635729 0:00:00.063674\n",
            "800 67.41573033707866 0:00:50.991089 0:00:00.063659\n",
            "900 66.48168701442842 0:00:57.342135 0:00:00.063643\n",
            "1000 66.53346653346654 0:01:03.701153 0:00:00.063638\n",
            "1100 66.03088101725703 0:01:10.119501 0:00:00.063687\n",
            "1200 65.69525395503747 0:01:16.472886 0:00:00.063674\n",
            "1300 66.10299769408148 0:01:22.791700 0:00:00.063637\n",
            "1400 66.38115631691649 0:01:29.149317 0:00:00.063633\n",
            "1500 66.35576282478348 0:01:35.533718 0:00:00.063647\n",
            "1600 66.70830730793254 0:01:41.860065 0:00:00.063623\n",
            "1700 66.84303350970018 0:01:48.200147 0:00:00.063610\n",
            "1800 67.01832315380344 0:01:54.599817 0:00:00.063631\n",
            "1900 66.964755391899 0:02:00.965346 0:00:00.063632\n",
            "2000 66.96651674162919 0:02:07.346895 0:00:00.063642\n"
          ]
        }
      ],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "start = datetime.now()\n",
        "\n",
        "prediction = []\n",
        "response = []\n",
        "accuracy = []\n",
        "labels = []\n",
        "\n",
        "for i, x in df_test.iterrows():\n",
        "    sentence = x['sentence']\n",
        "    label = x['sentiment']\n",
        "    input_ = f'''The sentiment of this comment: \"{sentence}\" is'''\n",
        "    prompt = create_prompt(input_, label)\n",
        "\n",
        "    inputs = tokenizer.encode(\n",
        "        prompt,\n",
        "        # add_generation_prompt=True,\n",
        "        return_tensors='pt'\n",
        "    )\n",
        "\n",
        "    tokens = model.generate(\n",
        "        inputs.to(model.device),\n",
        "        max_new_tokens=3,\n",
        "        temperature=0.1,\n",
        "        do_sample=False,\n",
        "        pad_token_id=tokenizer.eos_token_id\n",
        "    )\n",
        "    #break\n",
        "\n",
        "    answer = tokenizer.decode(tokens[0], skip_special_tokens=False).split(\"The correct answer is \")[-1]\n",
        "    answer = 'positive' if 'positive' in answer.lower() else 'negative' if 'negative' in answer.lower() else 'neutral'\n",
        "    prediction.append(answer.lower())\n",
        "    response.append(tokenizer.decode(tokens[0], skip_special_tokens=False))\n",
        "\n",
        "    accuracy.append(prediction[-1] == label)\n",
        "    labels.append(label)\n",
        "\n",
        "    if i % 100 == 0:\n",
        "        print(i, np.array(accuracy).sum()/len(prediction)*100, datetime.now() - start, (datetime.now() - start)/len(prediction))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "69a47BScQrbd",
        "outputId": "f92140ca-eb57-42dd-8f72-51146e79df5f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative     0.9503    0.9752    0.9626       686\n",
            "     neutral     0.7647    0.0194    0.0378       670\n",
            "    positive     0.5163    0.9985    0.6807       680\n",
            "\n",
            "    accuracy                         0.6685      2036\n",
            "   macro avg     0.7438    0.6644    0.5604      2036\n",
            "weighted avg     0.7443    0.6685    0.5641      2036\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report, f1_score\n",
        "import sklearn\n",
        "\n",
        "print(sklearn.metrics.classification_report(labels, prediction, digits=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mDFjF9EDQrbd",
        "outputId": "15cd6304-a81a-4f7e-fbca-4ac6766683db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The sentiment of this comment: \"The facilities of the university are versatile and helpful.\" is\n",
            "A. Positive\n",
            "B. Neutral\n",
            "C. Negative\n",
            "\n",
            "The correct answer is A. Positive\n",
            "\n",
            "\n",
            "The sentiment of this comment: \"M·∫•y b·∫°n ƒë√≥ hay ƒë√≤i h·ªèi nh∆∞ng kh√¥ng bao gi·ªù gi√∫p ƒë·ª° ng∆∞·ªùi kh√°c.\" is\n",
            "A. Positive\n",
            "B. Neutral\n",
            "C. Negative\n",
            "\n",
            "The correct answer is C. Negative\n",
            "\n",
            "\n",
            "The sentiment of this comment: \"C·∫≠u ·∫•y r·∫•t c√≥ k·ªπ nƒÉng v·ªÅ s√°ng t·∫°o v√† ngh·ªá thu·∫≠t.\" is\n",
            "A. Positive\n",
            "B. Neutral\n",
            "C. Negative\n",
            "\n",
            "The correct answer is A. Positive\n",
            "\n",
            "\n",
            "The sentiment of this comment: \"Gi·∫£ng vi√™n n√†y kh√¥ng nh√†m ch√°n.\" is\n",
            "A. Positive\n",
            "B. Neutral\n",
            "C. Negative\n",
            "\n",
            "The correct answer is A. Positive\n",
            "\n",
            "\n",
            "The sentiment of this comment: \"Anh ta l√† m·ªôt ng∆∞·ªùi r·∫•t t·ªâ m·ªâ v√† c·∫©n th·∫≠n.\" is\n",
            "A. Positive\n",
            "B. Neutral\n",
            "C. Negative\n",
            "\n",
            "The correct answer is A. Positive\n",
            "\n",
            "\n",
            "The sentiment of this comment: \"Gi√°o vi√™n ƒë∆∞a ra c√°c ph∆∞∆°ng ti·ªán h·ªó tr·ª£ gi·∫£ng d·∫°y r·∫•t t·ªët v√† hi·ªáu qu·∫£.\" is\n",
            "A. Positive\n",
            "B. Neutral\n",
            "C. Negative\n",
            "\n",
            "The correct answer is A. Positive\n",
            "\n",
            "\n",
            "The sentiment of this comment: \"The university's computer facilities are up-to-date and well-maintained.\" is\n",
            "A. Positive\n",
            "B. Neutral\n",
            "C. Negative\n",
            "\n",
            "The correct answer is A. Positive\n",
            "\n",
            "\n",
            "The sentiment of this comment: \"Thi·∫øu t√≠nh linh ho·∫°t trong h√¨nh th·ª©c gi·∫£ng d·∫°y v√† ƒë√°nh gi√° k·∫øt qu·∫£ h·ªçc t·∫≠p.\" is\n",
            "A. Positive\n",
            "B. Neutral\n",
            "C. Negative\n",
            "\n",
            "The correct answer is C. Negative\n",
            "\n",
            "\n",
            "The sentiment of this comment: \"C√¥ ·∫•y r·∫•t s·∫Øc s·∫£o v√† c√≥ kh·∫£ nƒÉng ph√¢n t√≠ch chi ti·∫øt r·∫•t t·ªët.\" is\n",
            "A. Positive\n",
            "B. Neutral\n",
            "C. Negative\n",
            "\n",
            "The correct answer is A. Positive\n",
            "\n",
            "\n",
            "The sentiment of this comment: \"Anh ·∫•y c√≥ t√†i nƒÉng v·ªÅ √¢m nh·∫°c v√† lu√¥n t√¨m c√°ch t·∫°o ra c√°c b·∫£n nh·∫°c m·ªõi, gi√∫p nh√≥m th√™m ho√†n h·∫£o v√† ƒëa d·∫°ng h∆°n.\" is\n",
            "A. Positive\n",
            "B. Neutral\n",
            "C. Negative\n",
            "\n",
            "The correct answer is A. Positive\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for x in response[-10:]:\n",
        "    print(x)\n",
        "    print(\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lUnGeM9IQrbe"
      },
      "source": [
        "## Create TrainingArguments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MWVm6G_HQrbe",
        "outputId": "36c79bc4-9aa9-4f79-99e0-60db73084ae4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "509\n"
          ]
        }
      ],
      "source": [
        "print(len(df_train)//bs//ga_steps*epochs//4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZpzctWQ0Qrbe",
        "outputId": "2b0d17c4-3186-4516-82a4-443f7884f7b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "509\n"
          ]
        }
      ],
      "source": [
        "save_step = len(df_train)//bs//ga_steps*epochs//4\n",
        "print(save_step)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d1cLldgoQrbe",
        "outputId": "16a199e5-ba49-4997-f2e0-57c767417f41"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "training_arguments = TrainingArguments(\n",
        "    output_dir=output_dir,\n",
        "    num_train_epochs=epochs,\n",
        "    per_device_train_batch_size=bs,\n",
        "    per_device_eval_batch_size=bs_eval,\n",
        "    evaluation_strategy=\"steps\",\n",
        "    eval_steps=save_step,\n",
        "    gradient_accumulation_steps=ga_steps,\n",
        "    optim=\"paged_adamw_32bit\",\n",
        "    save_steps=save_step,\n",
        "    save_strategy=\"steps\",\n",
        "    logging_steps=save_step,\n",
        "    learning_rate=lr,\n",
        "    weight_decay=0.001,\n",
        "    fp16=False,\n",
        "    bf16=True,\n",
        "    max_grad_norm=0.3,\n",
        "    max_steps=-1,\n",
        "    warmup_ratio=0.03,\n",
        "    group_by_length=True,\n",
        "    lr_scheduler_type=\"constant\",\n",
        "    report_to=\"none\",\n",
        "    save_total_limit=1,\n",
        "    #load_best_model_at_end=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dROO2MxsQrbe"
      },
      "source": [
        "## Create trainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "5f44e3b7667241f0857bd461a80086eb",
            "1a3454b0494b4994b7920a40617e3d58"
          ]
        },
        "id": "CmYHb8lsQrbe",
        "outputId": "51cc5180-e2f3-43ab-a5d4-18a2a275a1cc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': max_seq_length. Will not be supported from version '1.0.0'.\n",
            "\n",
            "Deprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n",
            "  warnings.warn(message, FutureWarning)\n",
            "/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1961: FutureWarning: `--push_to_hub_token` is deprecated and will be removed in version 5 of ü§ó Transformers. Use `--hub_token` instead.\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:269: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5f44e3b7667241f0857bd461a80086eb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/8144 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1a3454b0494b4994b7920a40617e3d58",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/2036 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
          ]
        }
      ],
      "source": [
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    train_dataset=dataset[\"train\"],\n",
        "    eval_dataset=dataset[\"validation\"],\n",
        "    #peft_config=peft_config,\n",
        "    max_seq_length= 128,\n",
        "    #dataset_text_field=[\"input\", \"output\"],\n",
        "    tokenizer=tokenizer,\n",
        "    args=training_arguments,\n",
        "    packing= False,\n",
        "    formatting_func = formatting_prompts_func,\n",
        "    #data_collator=collator\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O8aoa8DlQrbe"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mdj54yF9Qrbe",
        "outputId": "2711b00d-5279-4789-f596-08577a756272"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2036' max='2036' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2036/2036 56:12, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>509</td>\n",
              "      <td>0.758100</td>\n",
              "      <td>0.727522</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1018</td>\n",
              "      <td>0.637400</td>\n",
              "      <td>0.718333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1527</td>\n",
              "      <td>0.551700</td>\n",
              "      <td>0.744031</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2036</td>\n",
              "      <td>0.466100</td>\n",
              "      <td>0.800103</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=2036, training_loss=0.6033388074114187, metrics={'train_runtime': 3373.7402, 'train_samples_per_second': 9.656, 'train_steps_per_second': 0.603, 'total_flos': 1.2006787266527232e+16, 'train_loss': 0.6033388074114187, 'epoch': 4.0})"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1CCds3EQrbe"
      },
      "source": [
        "# Eval\n",
        "- If you save the model to the output_dir folder, the training code above will automatically save the model to output_dir/checkpoint-{save_step} (in my case: out/checkpoint-2036). We will load the model from this folder:\n",
        "  - I calculate _id = save_step * num_epoch = 509 * 4 = 2036\n",
        "  - My model will saved at \"{output_dir}/checkpoint-{_id}\"\n",
        "- I use del model, gc.collect() and torch.cuda.empty_cache() to release trained model (save gpu memory).\n",
        "- We load the tokenizer in this folder by passing the saved folder to AutoTokenizer.from_pretrained()\n",
        "- We load the model in this folder by passing the saved folder to AutoModelForCausalLM.from_pretrained"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JYsugKvTQrbf",
        "outputId": "09f5fd38-fde6-4070-d44e-f9f15d96af2f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "509\n"
          ]
        }
      ],
      "source": [
        "save_step = len(df_train)//bs//ga_steps*epochs//4\n",
        "print(save_step)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NtsONMIoQrbf"
      },
      "outputs": [],
      "source": [
        "import gc\n",
        "\n",
        "del model\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "37R4VpWaQrbf",
        "outputId": "40f2c18b-6575-4d7c-8c82-e041dbb1a9a1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ],
      "source": [
        "from peft import PeftModel, PeftConfig\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import torch\n",
        "\n",
        "_id = save_step*4\n",
        "\n",
        "peft_model_id = f\"{output_dir}/checkpoint-{_id}\"\n",
        "\n",
        "#config = PeftConfig.from_pretrained(peft_model_id)\n",
        "\n",
        "# bnb_config = BitsAndBytesConfig(\n",
        "#     load_in_4bit=True,\n",
        "#     bnb_4bit_use_double_quant=False,\n",
        "#     bnb_4bit_quant_type=\"nf4\",\n",
        "#     bnb_4bit_compute_dtype=torch.float16,\n",
        "# )\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    peft_model_id,\n",
        "    device_map=\"auto\",\n",
        "    #torch_dtype=torch.float16,\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    #quantization_config=bnb_config,\n",
        "    attn_implementation=\"flash_attention_2\",\n",
        "    trust_remote_code=True,\n",
        "    token = 'YOUR TOKEN HERE'\n",
        ")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(f\"{output_dir}/checkpoint-{_id}\",\n",
        "                                          trust_remote_code=True,\n",
        "                                          padding_side='left',\n",
        "                                          token='YOUR TOKEN HERE')\n",
        "\n",
        "# Load the Lora model\n",
        "#model = PeftModel.from_pretrained(model, peft_model_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xqtXTO1UQrbf"
      },
      "outputs": [],
      "source": [
        "def create_prompt(input_, output_):\n",
        "    output_ = 'A. Positive' if output_ == 'positive' else 'B. Neutral' if output_ == 'neutral' else 'C. Negative'\n",
        "        #text = f\"### Question: {input__}\\n ### Answer: {example['output'][i]}\"\n",
        "    text = f'''{input_}\n",
        "A. Positive\n",
        "B. Neutral\n",
        "C. Negative\n",
        "\n",
        "The correct answer is'''\n",
        "\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VEetbPAuQrbf",
        "outputId": "4bd48053-e256-40d1-cdce-4027f875fcde"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The sentiment of this comment: \"m√≥n ƒÉn r·∫•t ngon\" is\n",
            "A. Positive\n",
            "B. Neutral\n",
            "C. Negative\n",
            "\n",
            "The correct answer is\n"
          ]
        }
      ],
      "source": [
        "sentence = 'm√≥n ƒÉn r·∫•t ngon'\n",
        "input_ = f'''The sentiment of this comment: \"{sentence}\" is'''\n",
        "prompt = create_prompt(input_, \"\")\n",
        "print(prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1oX2_otHQrbf",
        "outputId": "ba28a8ef-9533-4a6f-cc7e-9e59aab5a047"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[   785,  25975,    315,    419,   3980,     25,    330,     76,   3165,\n",
              "         128442, 128323,   7777,    263,      1,    374,    198,     32,     13,\n",
              "          43903,    198,     33,     13,  58694,    198,     34,     13,  50857,\n",
              "            271,    785,   4396,   4226,    374]])"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "inputs = torch.tensor([tokenizer.encode(prompt)])\n",
        "inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MsctKuR8Qrbf"
      },
      "outputs": [],
      "source": [
        "tokens = model.generate(\n",
        "    inputs.to(model.device),\n",
        "    max_new_tokens=50,\n",
        "    temperature=0.1,\n",
        "    do_sample=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pxQ7GvpWQrbf",
        "outputId": "913faef3-6565-47c1-f690-a6bdb5c44f49"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The sentiment of this comment: \"m√≥n ƒÉn r·∫•t ngon\" is\n",
            "A. Positive\n",
            "B. Neutral\n",
            "C. Negative\n",
            "\n",
            "The correct answer is B. Neutral. The comment \"m√≥n ƒÉn r·∫•t ngon\" is neutral as it does not express a strong positive or negative opinion about the food. It simply states that the food is good.<|endoftext|>\n"
          ]
        }
      ],
      "source": [
        "print(tokenizer.decode(tokens[0], skip_special_tokens=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SyfPZmMuQrbg",
        "outputId": "831f4f65-0fc9-446d-c837-c15a42794cdd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The sentiment of this comment: \"m√≥n ƒÉn r·∫•t ngon\" is\n",
            "A. Positive\n",
            "B. Neutral\n",
            "C. Negative\n",
            "\n",
            "The correct answer is B. Neutral\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:540: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:545: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:562: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "tokens = model.generate(\n",
        "    inputs.to(model.device),\n",
        "    max_new_tokens=3,\n",
        "    temperature=0.1,\n",
        "    do_sample=False\n",
        ")\n",
        "print(tokenizer.decode(tokens[0], skip_special_tokens=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qix4EWZKQrbg",
        "outputId": "cc3035fd-193e-4378-dcd3-2963454d2d8e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 100.0 0:00:00.065272 0:00:00.065275\n",
            "100 88.11881188118812 0:00:06.678062 0:00:00.066119\n",
            "200 87.56218905472637 0:00:13.254048 0:00:00.065941\n",
            "300 88.37209302325581 0:00:19.721037 0:00:00.065518\n",
            "400 88.02992518703242 0:00:26.157722 0:00:00.065231\n",
            "500 87.62475049900199 0:00:32.637760 0:00:00.065145\n",
            "600 87.52079866888519 0:00:39.103604 0:00:00.065064\n",
            "700 87.58915834522111 0:00:45.546837 0:00:00.064974\n",
            "800 87.51560549313359 0:00:52.019800 0:00:00.064944\n",
            "900 87.90233074361821 0:00:58.481388 0:00:00.064907\n",
            "1000 87.71228771228772 0:01:04.940904 0:00:00.064876\n",
            "1100 88.10172570390554 0:01:11.405654 0:00:00.064855\n",
            "1200 87.17735220649459 0:01:17.888811 0:00:00.064853\n",
            "1300 87.16372021521906 0:01:24.359276 0:00:00.064842\n",
            "1400 87.43754461099215 0:01:30.805375 0:00:00.064815\n",
            "1500 87.00866089273818 0:01:37.253697 0:00:00.064793\n",
            "1600 87.19550281074329 0:01:43.743660 0:00:00.064799\n",
            "1700 87.24279835390946 0:01:50.235460 0:00:00.064806\n",
            "1800 87.34036646307607 0:01:56.678167 0:00:00.064785\n",
            "1900 87.37506575486586 0:02:03.142270 0:00:00.064778\n",
            "2000 87.30634682658672 0:02:09.607011 0:00:00.064771\n"
          ]
        }
      ],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "start = datetime.now()\n",
        "\n",
        "prediction = []\n",
        "response = []\n",
        "accuracy = []\n",
        "labels = []\n",
        "\n",
        "for i, x in df_test.iterrows():\n",
        "    sentence = x['sentence']\n",
        "    label = x['sentiment']\n",
        "    input_ = f'''The sentiment of this comment: \"{sentence}\" is'''\n",
        "    prompt = create_prompt(input_, label)\n",
        "\n",
        "    inputs = tokenizer.encode(\n",
        "        prompt,\n",
        "        # add_generation_prompt=True,\n",
        "        return_tensors='pt'\n",
        "    )\n",
        "\n",
        "    tokens = model.generate(\n",
        "        inputs.to(model.device),\n",
        "        max_new_tokens=3,\n",
        "        temperature=0.1,\n",
        "        do_sample=False,\n",
        "        pad_token_id=tokenizer.eos_token_id\n",
        "    )\n",
        "    #break\n",
        "\n",
        "    answer = tokenizer.decode(tokens[0], skip_special_tokens=False).split(\"The correct answer is \")[-1]\n",
        "    answer = 'positive' if 'positive' in answer.lower() else 'negative' if 'negative' in answer.lower() else 'neutral'\n",
        "    prediction.append(answer.lower())\n",
        "    response.append(tokenizer.decode(tokens[0], skip_special_tokens=False))\n",
        "\n",
        "    accuracy.append(prediction[-1] == label)\n",
        "    labels.append(label)\n",
        "\n",
        "    if i % 100 == 0:\n",
        "        print(i, np.array(accuracy).sum()/len(prediction)*100, datetime.now() - start, (datetime.now() - start)/len(prediction))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qZsrJDBnQrbg",
        "outputId": "15eff882-0e06-4060-e14f-4c93cbbfbd4b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative     0.9769    0.9883    0.9826       686\n",
            "     neutral     0.7929    0.8343    0.8131       670\n",
            "    positive     0.8477    0.7941    0.8200       680\n",
            "\n",
            "    accuracy                         0.8728      2036\n",
            "   macro avg     0.8725    0.8723    0.8719      2036\n",
            "weighted avg     0.8732    0.8728    0.8725      2036\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report, f1_score\n",
        "import sklearn\n",
        "\n",
        "print(sklearn.metrics.classification_report(labels, prediction, digits=4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ErxZDq_nQrbg"
      },
      "source": [
        "# Check results\n",
        "- I print all sentences have wrong prediction and see that almost cases is bug.\n",
        "- Conclusion, dataset is not clean than finetune LLM can't better than finetune roberta (~89..90%), because roberta will overfit even in test dataset.\n",
        "- In additionally, when I print example: \"m√≥n ƒÉn n√†y r·∫•t ngon\", we can see that model before finetune work better. Model after finetune only think about school (because finetune dataset is about school) and it don't know about food review. Than I think we only need finetune for special cases and finetune dataset need be clean and large enough."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EU0IReK9Qrbg"
      },
      "outputs": [],
      "source": [
        "df_test['predict'] = prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UB3SDkfiQrbg",
        "outputId": "8a858f73-a810-4b42-d141-21a497d4f481"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Gi·∫£ng vi√™n lu√¥n ƒë·ªìng h√†nh v·ªõi sinh vi√™n tr√™n qu√° tr√¨nh h·ªçc t·∫≠p. positive neutral\n",
            "T√¥i c√≥ th·ªÉ ·ª©ng d·ª•ng c√°c ki·∫øn th·ª©c c√≥ ƒë∆∞·ª£c t·ª´ ch∆∞∆°ng tr√¨nh ƒë√†o t·∫°o v√†o c√¥ng vi·ªác c·ªßa m√¨nh. neutral positive\n",
            "Gi·∫£ng vi√™n r·∫•t t√†i nƒÉng v√† c√≥ nhi·ªÅu kinh nghi·ªám trong c√¥ng t√°c gi·∫£ng d·∫°y. positive neutral\n",
            "ƒê∆∞·ª£c h·ªçc t·∫≠p v·ªõi c√°c gi√°o vi√™n gi√†u kinh nghi·ªám v√† th·ª±c ti·ªÖn. positive neutral\n",
            "ƒê·ªô kh√≥ c·ªßa c√°c b√†i ki·ªÉm tra kh√¥ng ph·∫£n √°nh ƒë√∫ng nƒÉng l·ª±c c·ªßa sinh vi√™n. neutral negative\n",
            "Nh√† h√†ng v√† c√°c c·ª≠a h√†ng ti·ªán l·ª£i ·ªü g·∫ßn tr∆∞·ªùng r·∫•t ƒëa d·∫°ng v√† phong ph√∫. neutral positive\n",
            "C√¥ ·∫•y l√† m·ªôt gi√°o vi√™n r·∫•t th√¥ng minh v√† chuy√™n nghi·ªáp. neutral positive\n",
            "C√≥ nhi·ªÅu ho·∫°t ƒë·ªông ngo·∫°i kh√≥a v√† phong ph√∫ cho sinh vi√™n. neutral positive\n",
            "Khu v·ª±c ƒë·∫∑t m√°y b√°n th·ª©c u·ªëng r·∫•t ti·ªán l·ª£i cho sinh vi√™n. neutral positive\n",
            "Ph√≤ng gym v√† h·ªì b∆°i ƒë·ªÅu ƒë∆∞·ª£c qu·∫£n l√Ω ƒë√†ng ho√†ng v√† lu√¥n s·∫°ch s·∫Ω. neutral positive\n",
            "C·∫≠u b·∫°n n√†y l√† m·ªôt ng∆∞·ªùi r·∫•t vui t√≠nh v√† h√†i h∆∞·ªõc. neutral positive\n",
            "Ph√≤ng h·ªçc ƒë∆∞·ª£c trang b·ªã ƒë·∫ßy ƒë·ªß ti·ªán nghi gi√∫p sinh vi√™n lu√¥n d·ªÖ d√†ng ti·∫øp c·∫≠n t√†i li·ªáu v√† th√¥ng tin li√™n quan. positive neutral\n",
            "Ch∆∞∆°ng tr√¨nh h·ªçc ƒë√°p ·ª©ng ƒë∆∞·ª£c nhu c·∫ßu c·ªßa th·ªã tr∆∞·ªùng lao ƒë·ªông hi·ªán nay, gi√∫p t√¥i c√≥ nhi·ªÅu c∆° h·ªôi vi·ªác l√†m. neutral positive\n",
            "Th·∫ßy d·∫°y r·∫•t chuy√™n nghi·ªáp v√† nhi·ªát t√¨nh. neutral positive\n",
            "Ph√≤ng h·ªçc lu√¥n s·∫°ch s·∫Ω v√† c√≥ ng∆∞·ªùi v·ªá sinh qu√©t d·ªçn ƒë·ªãnh k√¨. neutral positive\n",
            "Th·∫ßy/c√¥ ƒë√°nh gi√° v√† ƒë·ªÅ xu·∫•t nh·ªØng √Ω ki·∫øn x√¢y d·ª±ng t√≠ch c·ª±c gi√∫p sinh vi√™n ph√°t tri·ªÉn h∆°n. neutral positive\n",
            "Gi·∫£ng vi√™n r·∫•t ch√¢n th√†nh v√† nhi·ªát t√¨nh. neutral positive\n",
            "Gi·∫£ng vi√™n n√†y c√≥ t√¢m huy·∫øt c√¥ng vi·ªác v√† ƒëam m√™ v·ªõi ngh·ªÅ gi·∫£ng d·∫°y. neutral positive\n",
            "H·ªá th·ªëng th∆∞ vi·ªán v√† t√†i nguy√™n h·ªçc t·∫≠p r·∫•t ƒë·∫ßy ƒë·ªß v√† ti·ªán l·ª£i. positive neutral\n",
            "Tr∆∞·ªùng c·∫ßn c√≥ ch√≠nh s√°ch h·ªó tr·ª£ chi ph√≠ h·ªçc t·∫≠p ph√π h·ª£p cho sinh vi√™n. neutral negative\n",
            "Th·∫ßy cho h·ªçc sinh m·ªôt c√°i nh√¨n t·ªïng quan v·ªÅ chuy√™n ng√†nh c·ªßa m√¨nh. neutral positive\n",
            "C√°c ph√≤ng h·ªçc ƒë∆∞·ª£c trang b·ªã ƒë·∫ßy ƒë·ªß ti·ªán nghi v√† thi·∫øt b·ªã. positive neutral\n",
            "Ch∆∞∆°ng tr√¨nh ƒë√†o t·∫°o r·∫•t ƒëa d·∫°ng v·ªÅ c·∫£ n·ªôi dung l·∫´n h√¨nh th·ª©c ƒë√†o t·∫°o. neutral positive\n",
            "C√°c d·ªãch v·ª• b·∫£o v·ªá trong tr∆∞·ªùng r·∫•t chuy√™n nghi·ªáp v√† ƒë·∫£m b·∫£o an to√†n cho sinh vi√™n. positive neutral\n",
            "Khu v·ª±c s·ªëng ƒë·ªông c·ªßa tr∆∞·ªùng r·∫•t th√∫ v·ªã cho sinh vi√™n. positive neutral\n",
            "Th∆∞ vi·ªán c·ªßa tr∆∞·ªùng c√≥ nhi·ªÅu t√†i li·ªáu b·ªï √≠ch v√† ƒëa d·∫°ng. positive neutral\n",
            "H·ªá th·ªëng an ninh t·∫°i tr∆∞·ªùng r·∫•t ch·∫∑t ch·∫Ω v√† ƒë·∫£m b·∫£o an to√†n cho sinh vi√™n. neutral positive\n",
            "Th·∫ßy gi·∫£i th√≠ch c·∫∑n k·∫Ω v√† d·ªÖ hi·ªÉu. neutral positive\n",
            "Th·∫ßy c√¥ gi·∫£ng d·∫°y ƒë·ªÅu r·∫•t nhi·ªát t√¨nh v√† c√≥ kinh nghi·ªám trong lƒ©nh v·ª±c ƒëang gi·∫£ng d·∫°y. neutral positive\n",
            "C√≥ r·∫•t nhi·ªÅu ph√≤ng h·ªçc t·∫°i tr∆∞·ªùng ƒë·ªÉ sinh vi√™n c√≥ th·ªÉ l·ª±a ch·ªçn v√† s·ª≠ d·ª•ng. neutral positive\n",
            "T√¥i r·∫•t ·∫•n t∆∞·ª£ng v·ªõi s·ª± trang tr√≠ trong tr∆∞·ªùng, ch√∫ng t·∫°o c·∫£m gi√°c tho·∫£i m√°i v√† th∆∞ gi√£n cho sinh vi√™n. positive neutral\n",
            "Tr∆∞·ªùng c√≥ h·ªá th·ªëng th√¥ng tin qu·∫£n l√Ω hi·ªán ƒë·∫°i v√† ƒë√°p ·ª©ng ƒë∆∞·ª£c c√°c y√™u c·∫ßu c·ªßa sinh vi√™n. positive neutral\n",
            "Th·∫ßy lu√¥n khuy·∫øn kh√≠ch t√¥i c·∫£i thi·ªán kh·∫£ nƒÉng t·ªï ch·ª©c th·ªùi gian v√† ho√†n th√†nh nhi·ªám v·ª•. neutral positive\n",
            "Tr∆∞·ªùng cung c·∫•p nhi·ªÅu d·ªãch v·ª• h·ªó tr·ª£ cho sinh vi√™n nh∆∞ t∆∞ v·∫•n vi·ªác l√†m sau khi t·ªët nghi·ªáp. positive neutral\n",
            "Khu v·ª±c ƒÉn u·ªëng c·ªßa tr∆∞·ªùng c√≥ nhi·ªÅu m√≥n ƒÉn ngon v√† ƒëa d·∫°ng. neutral positive\n",
            "M√¥n h·ªçc ƒë·∫ßy ƒë·ªß v√† b√°m s√°t v·ªõi th·ª±c ti·ªÖn, gi√∫p sinh vi√™n n·∫Øm v·ªØng ki·∫øn th·ª©c chuy√™n ng√†nh. neutral positive\n",
            "Gi√°o vi√™n c·ªßa t√¥i d·∫°y l√≠ thuy·∫øt v√† th·ª±c h√†nh v·ªÅ quy·ªÅn s·ªü h·ªØu tr√≠ tu·ªá v√† b·∫£o v·ªá nh√£n hi·ªáu. neutral positive\n",
            "T√¥i r·∫•t th√≠ch nh·ªØng khu v·ª±c xanh trong tr∆∞·ªùng, ch√∫ng t·∫°o c·∫£m gi√°c tho·∫£i m√°i v√† g·∫ßn g≈©i v·ªõi thi√™n nhi√™n. positive neutral\n",
            "N√†ng c√≥ s·ª± t·∫≠p trung cao ƒë·ªô v√† lu√¥n ƒë·∫°t ƒë∆∞·ª£c nh·ªØng th√†nh t√≠ch t·ªët. positive neutral\n",
            "Anh ta l√† m·ªôt ng∆∞·ªùi nƒÉng ƒë·ªông v√† c√≥ kh·∫£ nƒÉng t·ªï ch·ª©c tuy·ªát v·ªùi. neutral positive\n",
            "C√°c khu v·ª±c sinh ho·∫°t c·ªßa tr∆∞·ªùng c·∫ßn ƒë∆∞·ª£c x√¢y d·ª±ng l·∫°i ƒë·ªÉ ƒë√°p ·ª©ng nhu c·∫ßu c·ªßa sinh vi√™n. negative neutral\n",
            "T√¥i r·∫•t ƒë√°nh gi√° cao s·ª± chu·∫©n b·ªã v√† b·ªë tr√≠ c·ªßa c√°c m√¥n h·ªçc trong ch∆∞∆°ng tr√¨nh. neutral positive\n",
            "Th∆∞ vi·ªán ƒë·∫ßy ƒë·ªß s√°ch v·ªü c·∫ßn thi·∫øt. neutral positive\n",
            "T√¥i r·∫•t th√≠ch k·∫øt h·ª£p c·ªßa m·ªôt s·ªë m√¥n h·ªçc c∆° b·∫£n v√† nh·ªØng ch·ªß ƒë·ªÅ th√∫ v·ªã v√† l·∫° l·∫´m. neutral positive\n",
            "C√°c m√¥n h·ªçc gi√∫p sinh vi√™n ph√°t tri·ªÉn t∆∞ duy ph·∫£n bi·ªán v√† ƒë·ªôc l·∫≠p trong t∆∞ duy. neutral positive\n",
            "Gi·∫£ng vi√™n c√≥ th·ªÉ s·ª≠ d·ª•ng nhi·ªÅu ph∆∞∆°ng ph√°p gi·∫£ng d·∫°y kh√°c nhau ƒë·ªÉ thu h√∫t sinh vi√™n h·ªçc t·∫≠p. neutral positive\n",
            "Gi·∫£ng vi√™n nh·∫≠n x√©t ƒë√°nh gi√° c·ªßa t√¥i l√† ch∆∞a ƒë·ªß chi ti·∫øt khi t√¥i ƒë√£ c·ªë g·∫Øng l√†m h·∫øt. neutral negative\n",
            "Th·∫ßy gi√∫p ƒë·ª° sinh vi√™n ƒë·ªãnh h∆∞·ªõng ngh·ªÅ nghi·ªáp v√† ph√°t tri·ªÉn b·∫£n th√¢n. positive neutral\n",
            "Vi·ªác thi·∫øu gi·∫£ng vi√™n chuy√™n nghi·ªáp t·∫°i m·ªôt s·ªë v√πng ƒë·∫•t c√≥ th·ªÉ l√† m·ªôt nh∆∞·ª£c ƒëi·ªÉm c·ªßa ch∆∞∆°ng tr√¨nh. negative neutral\n",
            "T√¥i r·∫•t th√≠ch l·ªëi thi·∫øt k·∫ø v√† trang tr√≠ c·ªßa tr∆∞·ªùng, n√≥ c·ª±c k·ª≥ ·∫•n t∆∞·ª£ng v√† s√°ng t·∫°o. positive neutral\n",
            "L·ªõp h·ªçc ƒë∆∞·ª£c ƒë∆∞a ra m·ªôt c√°ch sinh ƒë·ªông, h·∫•p d·∫´n v√† ƒë·∫ßy ƒë·ªß ki·∫øn th·ª©c chuy√™n m√¥n. positive neutral\n",
            "Gi·∫£ng vi√™n h∆∞·ªõng d·∫´n gi·ªèi v·ªõi l∆∞·ª£ng kinh nghi·ªám th·ª±c ti·ªÖn phong ph√∫. neutral positive\n",
            "Th·∫ßy cung c·∫•p cho ch√∫ng t√¥i nhi·ªÅu t√†i li·ªáu v√† b√†i gi·∫£ng h·ªØu √≠ch. neutral positive\n",
            "Em th·∫•y b·∫°n c·ªßa m√¨nh r·∫•t nhanh nh·∫πn v√† chƒÉm ch·ªâ h·ªçc. positive neutral\n",
            "Khu v·ª±c sinh ho·∫°t c·ªßa sinh vi√™n ƒë∆∞·ª£c qu·∫£n l√Ω t·ªët, an ninh. neutral positive\n",
            "C∆° h·ªôi ƒë·ªÉ th·ª±c t·∫≠p trong m·ªôt m√¥i tr∆∞·ªùng th·ª±c t·∫ø. neutral positive\n",
            "C√¥ b·∫°n n√†y r·∫•t chƒÉm ch·ªâ v√† c√≥ l√≤ng nhi·ªát huy·∫øt. neutral positive\n",
            "ƒê·ªôi ng≈© gi·∫£ng vi√™n chuy√™n nghi·ªáp v√† th√¢n thi·ªán. neutral positive\n",
            "C√°ch ƒë√°nh gi√° v√† ph∆∞∆°ng ph√°p gi·∫£ng d·∫°y c·ªßa tr∆∞·ªùng r·∫•t khuy·∫øn kh√≠ch v√† t·∫°o ƒë·ªông l·ª±c cho h·ªçc sinh. neutral positive\n",
            "Th·∫ßy gi·∫£ng d·∫°y r·∫•t chu ƒë√°o v√† chuy√™n nghi·ªáp. neutral positive\n",
            "Gi√°o vi√™n r·∫•t nhi·ªát t√¨nh v√† gi√∫p ƒë·ª° sinh vi√™n trong qu√° tr√¨nh h·ªçc t·∫≠p. positive neutral\n",
            "B·∫°n c·ªßa t√¥i l√† ng∆∞·ªùi r·∫•t duy√™n d√°ng v√† s√†nh ƒëi·ªáu. positive neutral\n",
            "C√°c ph√≤ng th√≠ nghi·ªám c·ªßa tr∆∞·ªùng ƒë·∫ßy ƒë·ªß c√°c thi·∫øt b·ªã c·∫ßn thi·∫øt cho vi·ªác nghi√™n c·ª©u. neutral positive\n",
            "Th·∫ßy lu√¥n ƒë∆∞a ra nh·ªØng v√≠ d·ª• c·ª• th·ªÉ v√† minh ho·∫° ƒë·ªÉ gi√∫p sinh vi√™n hi·ªÉu b√†i t·∫≠p. neutral positive\n",
            "Anh ·∫•y lu√¥n c√≥ nh·ªØng √Ω t∆∞·ªüng kh√°c bi·ªát v·ªõi nh·ªØng ng∆∞·ªùi kh√°c trong nh√≥m. neutral negative\n",
            "Th·∫ßy h∆∞·ªõng d·∫´n sinh vi√™n ƒë·ªçc hi·ªÉu v√† ph√¢n t√≠ch b√†i vƒÉn, gi√∫p sinh vi√™n n√¢ng cao kh·∫£ nƒÉng ƒë·ªçc hi·ªÉu v√† vi·∫øt t·ªët h∆°n. neutral positive\n",
            "Th·∫ßy l√† m·ªôt gi·∫£ng vi√™n r·∫•t gi·ªèi trong vi·ªác truy·ªÅn ƒë·∫°t ki·∫øn th·ª©c v√† k·ªπ nƒÉng cho sinh vi√™n. positive neutral\n",
            "B·∫°n c·ªßa t√¥i r·∫•t chƒÉm ch·ªâ v√† lu√¥n ƒë√∫ng gi·ªù. positive neutral\n",
            "C√¥ ·∫•y r·∫•t nƒÉng ƒë·ªông v√† th√¢n thi·ªán ƒë·ªëi v·ªõi m·ªçi ng∆∞·ªùi trong l·ªõp. positive neutral\n",
            "Th·ªùi gian v√† ƒë·ªãa ƒëi·ªÉm h·ªçc t·∫≠p kh√¥ng ph√π h·ª£p cho m·ªôt s·ªë sinh vi√™n. neutral negative\n",
            "S·ªë l∆∞·ª£ng gi√°o vi√™n n∆∞·ªõc ngo√†i ƒë∆∞·ª£c gi·∫£ng d·∫°y trong ch∆∞∆°ng tr√¨nh ƒë√†o t·∫°o l√† r·∫•t √≠t. negative neutral\n",
            "Ch∆∞∆°ng tr√¨nh ƒë√†o t·∫°o gi√∫p t√¥i trang b·ªã nh·ªØng k·ªπ nƒÉng m·ªÅm c·∫ßn thi·∫øt ƒë·ªÉ th√†nh c√¥ng trong t∆∞∆°ng lai. positive neutral\n",
            "Gi√°o tr√¨nh ƒë∆∞·ª£c vi·∫øt t·ªët v√† d·ªÖ hi·ªÉu, gi√∫p t√¥i ti√™u th·ª• th√¥ng tin nhanh h∆°n v√† hi·ªáu qu·∫£ h∆°n. neutral positive\n",
            "C√°c khu v·ª±c ti·∫øp kh√°ch c·ªßa tr∆∞·ªùng ƒë∆∞·ª£c b·ªë tr√≠ th√¥ng tho√°ng v√† chuy√™n nghi·ªáp. neutral positive\n",
            "Gi·∫£ng vi√™n n√†y d·∫°y r·∫•t t·ªët v√† truy·ªÅn c·∫£m h·ª©ng cho h·ªçc sinh. neutral positive\n",
            "Th·∫ßy t·∫°o ra m√¥i tr∆∞·ªùng h·ªçc t·∫≠p vui v·∫ª v√† ·∫•m c√∫ng. positive neutral\n",
            "Tr∆∞·ªùng lu√¥n gi·ªØ g√¨n s·∫°ch s·∫Ω v√† d·ªÖ d√†ng b·∫£o tr√¨ h∆°n nh·ªù v√†o c√°c thi·∫øt b·ªã trang tr√≠ v√† c∆° s·ªü v·∫≠t ch·∫•t. positive neutral\n",
            "ƒêi·ªÉm y·∫øu c·ªßa ch∆∞∆°ng tr√¨nh l√† thi·∫øu s·ª± khuy·∫øn kh√≠ch v√† h·ªó tr·ª£ cho sinh vi√™n t·ª± h·ªçc. negative neutral\n",
            "ƒê·ªôi ng≈© k·ªπ thu·∫≠t c·ªßa tr∆∞·ªùng lu√¥n c√≥ m·∫∑t ƒë·ªÉ gi√∫p ƒë·ª° v√† gi·∫£i quy·∫øt c√°c v·∫•n ƒë·ªÅ k·ªπ thu·∫≠t cho sinh vi√™n. positive neutral\n",
            "B·∫°n c·ªßa t√¥i r·∫•t h√≤a ƒë·ªìng v√† d·ªÖ g·∫ßn. neutral positive\n",
            "ƒê·ªôi ng≈© nh√¢n vi√™n c·ªßa tr∆∞·ªùng r·∫•t th√¢n thi·ªán v√† h·ªó tr·ª£ t·∫≠n t√¨nh. neutral positive\n",
            "Th·∫ßy/c√¥ t·∫°o ƒëi·ªÅu ki·ªán thu·∫≠n l·ª£i cho sinh vi√™n trao ƒë·ªïi v√† th·∫£o lu·∫≠n √Ω ki·∫øn. positive neutral\n",
            "Ch∆∞∆°ng tr√¨nh gi·∫£ng d·∫°y r·∫•t ph√π h·ª£p v·ªõi nhu c·∫ßu c·ªßa sinh vi√™n. neutral positive\n",
            "Th·∫ßy c√¥ ƒë·ªÅ cao c√°c tr·∫ª em tr√™n h·∫øt v√† mang ƒë·∫øn cho ch√∫ng ta m·ªôt m√¥i tr∆∞·ªùng h·ªçc t·∫≠p khuy·∫øn kh√≠ch v√† th√¢n thi·ªán. positive neutral\n",
            "Khu v·ª±c cho sinh vi√™n t·ª± h·ªçc kh√° tho·∫£i m√°i v√† ti·ªán nghi. neutral positive\n",
            "C√°c khu v·ª±c ƒë·∫∑t t·ªß h·ªì s∆° c·ªßa tr∆∞·ªùng ƒë∆∞·ª£c b·∫£o qu·∫£n an to√†n v√† ch√≠n chu. neutral positive\n",
            "Kh√¥ng gian n·ªôi th·∫•t c·ªßa ph√≤ng h·ªçc r·∫•t t·ªët, ƒë∆∞·ª£c thi·∫øt k·∫ø ƒë·ªÉ gi√∫p tƒÉng s·ª± t·∫≠p trung c·ªßa sinh vi√™n. positive neutral\n",
            "T√¥i r·∫•t h√†i l√≤ng v·ªõi c√°c ph√≤ng h·ªçc ·ªü ƒë√¢y. positive neutral\n",
            "Gi√∫p sinh vi√™n n·∫Øm b·∫Øt ƒë∆∞·ª£c nh·ªØng quy t·∫Øc v√† ƒë·∫°o ƒë·ª©c trong ng√†nh. neutral positive\n",
            "H·ªçc t·∫°i ƒë√¢y ƒë√≤i h·ªèi t√¥i t√≠nh k·ª∑ lu·∫≠t v√† s·ª± ƒë√≥ng g√≥p s√°ng t·∫°o. neutral positive\n",
            "Th√¥ng tin tr∆∞·ªùng ƒë∆∞·ª£c ƒëƒÉng t·∫£i ƒë·∫ßy ƒë·ªß v√† chi ti·∫øt. neutral positive\n",
            "Anh ·∫•y l√† ng∆∞·ªùi r·∫•t chu ƒë√°o v√† s·∫µn s√†ng gi√∫p ƒë·ª° ng∆∞·ªùi kh√°c. neutral positive\n",
            "C√°c h·ªôi tr∆∞·ªùng ƒë·ªÅu r·ªông r√£i v√† ƒë∆∞·ª£c trang b·ªã nh·ªØng trang thi·∫øt b·ªã hi·ªán ƒë·∫°i. positive neutral\n",
            "Gi√°o tr√¨nh ƒë∆∞·ª£c c·∫≠p nh·∫≠t th∆∞·ªùng xuy√™n v√† ph√π h·ª£p v·ªõi ch∆∞∆°ng tr√¨nh h·ªçc c·ªßa tr∆∞·ªùng. neutral positive\n",
            "C√°c ph√≤ng th√≠ nghi·ªám c·ªßa tr∆∞·ªùng ƒë∆∞·ª£c trang b·ªã ƒë·∫ßy ƒë·ªß thi·∫øt b·ªã v√† c√¥ng ngh·ªá hi·ªán ƒë·∫°i. positive neutral\n",
            "C·∫≠t l·ª±c h·ªçc t·∫≠p c·ªßa c·∫≠u ·∫•y th·ª±c s·ª± l√† m·ªôt ngu·ªìn ƒë·ªông l·ª±c cho t·∫•t c·∫£ m·ªçi ng∆∞·ªùi trong l·ªõp. neutral positive\n",
            "T√¥i c·∫£m th·∫•y h·ªçc ph√≠ h·ª£p l√≠ v·ªõi ch·∫•t l∆∞·ª£ng ƒë√†o t·∫°o c·ªßa tr∆∞·ªùng. neutral positive\n",
            "Ch∆∞∆°ng tr√¨nh ƒë√†o t·∫°o gi√∫p t√¥i c√≥ c∆° h·ªôi h·ªçc t·∫≠p v√† trau d·ªìi kinh nghi·ªám ngo√†i l·ªõp h·ªçc. positive neutral\n",
            "T·ª´ng m√¥n h·ªçc ƒë·ªÅu gi√∫p m√¨nh ph√°t tri·ªÉn k·ªπ nƒÉng v√† ki·∫øn th·ª©c m·ªõi. neutral positive\n",
            "M√¥n h·ªçc t·∫≠p trung v√†o vi·ªác th·ª±c h√†nh v√† ·ª©ng d·ª•ng ki·∫øn th·ª©c v√†o th·ª±c t·∫ø. positive neutral\n",
            "C√°c khu v·ª±c l∆∞u tr√∫ c·ªßa tr∆∞·ªùng ƒë∆∞·ª£c trang b·ªã ƒë·∫ßy ƒë·ªß ti·ªán nghi ƒë·ªÉ ƒë·∫£m b·∫£o s·ª± tho·∫£i m√°i cho sinh vi√™n. positive neutral\n",
            "C·∫≠u b·∫°n n√†y c√≥ tinh th·∫ßn ƒë·ªìng ƒë·ªôi v√† tinh th·∫ßn h·ª£p t√°c r·∫•t t·ªët. neutral positive\n",
            "Ch·ªã ·∫•y r·∫•t nƒÉng ƒë·ªông v√† c√≥ kh·∫£ nƒÉng l√£nh ƒë·∫°o t·ªët. neutral positive\n",
            "Th·∫ßy ƒë√£ gi√∫p t√¥i c√≥ ƒë∆∞·ª£c nhi·ªÅu ki·∫øn th·ª©c quan tr·ªçng v√† k·ªπ nƒÉng c·∫ßn thi·∫øt trong c√¥ng vi·ªác. positive neutral\n",
            "Gi·∫£ng vi√™n c·ªßa t√¥i n√≥i r·∫•t r√µ v√† d·ªÖ nghe, ƒëi·ªÅu n√†y gi√∫p t√¥i hi·ªÉu ƒë∆∞·ª£c m√¥n h·ªçc c·ªßa m√¨nh nhanh h∆°n. positive neutral\n",
            "C∆° s·ªü v·∫≠t ch·∫•t ƒë·∫ßy ƒë·ªß, ti√™n ti·∫øn. neutral positive\n",
            "Ph√≤ng t·∫≠p gym t·ªët v√† ƒë·∫ßy ƒë·ªß d·ª•ng c·ª•. neutral positive\n",
            "Khu v·ª±c khu√¢n vi√™n quanh tr∆∞·ªùng xanh t∆∞∆°i, nh·ªØng tin t·ª©c, th√¥ng b√°o c·ªßa tr∆∞·ªùng ƒë∆∞·ª£c ph√°t tr·ª±c ti·∫øp, r√µ r√†ng, d·ªÖ ti·∫øp c·∫≠n. positive neutral\n",
            "B√†i gi·∫£ng r·∫•t r√µ r√†ng v√† d·ªÖ hi·ªÉu. neutral positive\n",
            "C√¥ b·∫°n n√†y r·∫•t hi·ªÅn l√†nh v√† t·ªët b·ª•ng. positive neutral\n",
            "C√°c khu v·ª±c tr√™n tr∆∞·ªùng c·∫ßn ƒë∆∞·ª£c b·ªë tr√≠ th√™m c√°c gh·∫ø ng·ªìi ƒë·ªÉ sinh vi√™n c√≥ n∆°i th∆∞ gi√£n v√† h·ªçc t·∫≠p. negative neutral\n",
            "Gi·ªù h·ªçc c·ªßa th·∫ßy r·∫•t hi·ªáu qu·∫£ v√† c·∫•u tr√∫c. neutral positive\n",
            "C√°c b√†i gi·∫£ng d·ªÖ hi·ªÉu v√† h·ªó tr·ª£ h·ªçc t·∫≠p t·ªët. positive neutral\n",
            "Nh·ªØng b√†i gi·∫£ng c·ªßa gi√°o vi√™n r·∫•t chi ti·∫øt v√† ƒë·∫ßy ƒë·ªß th√¥ng tin. neutral positive\n",
            "C√≥ nh·ªØng b·∫°n kh√° t√†n nh·∫´n v√† th∆∞·ªùng ƒë∆∞a ra c√°c √Ω ki·∫øn kh√¥ng c·∫ßn thi·∫øt trong l·ªõp h·ªçc. negative neutral\n",
            "Ch∆∞∆°ng tr√¨nh h·ªçc c·ªßa tr∆∞·ªùng ƒë·∫∑t nhi·ªÅu gi√° tr·ªã v√†o ƒë·∫°o ƒë·ª©c, tinh th·∫ßn v√† gi√° tr·ªã con ng∆∞·ªùi. positive neutral\n",
            "H·ªçc vi√™n c√≥ th·ªÉ trao ƒë·ªïi v·ªõi nhau v√† chia s·∫ª ki·∫øn th·ª©c, kinh nghi·ªám h·ªçc t·∫≠p. neutral positive\n",
            "Gi·∫£ng vi√™n n√†y lu√¥n h∆∞·ªõng d·∫´n sinh vi√™n ƒë√∫ng h∆∞·ªõng v√† gi·∫£i ƒë√°p m·ªçi th·∫Øc m·∫Øc v·ªÅ ch·ªß ƒë·ªÅ. positive neutral\n",
            "Th·∫ßy lu√¥n c·∫≠p nh·∫≠t ki·∫øn th·ª©c m·ªõi nh·∫•t ƒë·ªÉ gi·∫£ng d·∫°y cho sinh vi√™n. positive neutral\n",
            "Gi·∫£ng vi√™n r·∫•t tinh t·∫ø khi ƒë∆∞a ra c√°c b√†i gi·∫£ng s√¢u s·∫Øc. neutral positive\n",
            "Ch∆∞∆°ng tr√¨nh gi·∫£ng d·∫°y k·∫øt h·ª£p gi·ªØa l√Ω thuy·∫øt v√† th·ª±c h√†nh t·ªët. neutral positive\n",
            "C√¥ ·∫•y l√† ng∆∞·ªùi r·∫•t th·∫•u hi·ªÉu v√† h·ªó tr·ª£ t·ªët cho m·ªçi ng∆∞·ªùi trong l·ªõp. neutral positive\n",
            "Gi·∫£ng vi√™n n√†y quan t√¢m ƒë·∫øn s·ª± ti·∫øn b·ªô c·ªßa h·ªçc sinh v√† s·∫µn s√†ng gi·∫£i ƒë√°p m·ªçi th·∫Øc m·∫Øc c·ªßa h·ªç. positive neutral\n",
            "Gi·∫£ng vi√™n r·∫•t d·ªÖ ti·∫øp c·∫≠n v√† th√¢n thi·ªán, d·ªÖ t·∫°o ƒë∆∞·ª£c m√¥i tr∆∞·ªùng h·ªçc t·∫≠p t√≠ch c·ª±c. positive neutral\n",
            "Gi·∫£ng vi√™n r·∫•t th√¢n thi·ªán v√† d·ªÖ g·∫ßn v·ªõi sinh vi√™n. positive neutral\n",
            "Anh ta l√† ng∆∞·ªùi r·∫•t nƒÉng ƒë·ªông v√† lu√¥n t·∫°o ƒë·ªông l·ª±c cho ng∆∞·ªùi kh√°c. positive neutral\n",
            "C√°c ho·∫°t ƒë·ªông ƒë·ªëi ngo·∫°i c·ªßa tr∆∞·ªùng ƒëa d·∫°ng v√† h·∫•p d·∫´n cho sinh vi√™n. neutral positive\n",
            "C√¥ ·∫•y r·∫•t t·∫≠n t√¢m v√† nhi·ªát t√¨nh gi√∫p ƒë·ª° c√°c b·∫°n trong l·ªõp. neutral positive\n",
            "Gi·∫£ng ƒë∆∞·ªùng r·ªông r√£i v√† s·∫°ch s·∫Ω. neutral positive\n",
            "C√¥ gi√°o c·ªßa t√¥i l√† ng∆∞·ªùi r·∫•t th√¥ng th√°i v√† gi√†u kinh nghi·ªám. positive neutral\n",
            "Gi·∫£ng vi√™n r·∫•t th√¥ng minh v√† c√≥ ki·∫øn th·ª©c s√¢u r·ªông. positive neutral\n",
            "Anh ·∫•y l√† m·ªôt ng∆∞·ªùi r·∫•t ƒë√°ng tin c·∫≠y, lu√¥n lu√¥n gi·ªØ l·ªùi h·ª©a. positive neutral\n",
            "Th·∫ßy d·∫°y r·∫•t th√¥ng minh v√† t·∫≠p trung v√†o vi·ªác gi·∫£ng d·∫°y cho h·ªçc sinh hi·ªÉu b√†i h·ªçc. neutral positive\n",
            "Gi√°o vi√™n c·ªßa t√¥i h∆∞·ªõng d·∫´n sinh vi√™n th·ª±c hi·ªán c√°c nghi√™n c·ª©u th·ªã tr∆∞·ªùng v√† ƒë√°nh gi√° s·∫£n ph·∫©m. neutral positive\n",
            "T√¥i r·∫•t h√†i l√≤ng v·ªõi c√°c d·ªãch v·ª• h·ªó tr·ª£ c·ªßa tr∆∞·ªùng, ƒë·∫∑c bi·ªát l√† c√°c d·ªãch v·ª• t∆∞ v·∫•n v√† t√†i ch√≠nh. positive neutral\n",
            "Th·∫ßy ch√∫ tr·ªçng ƒë·∫øn s·ª± ti·∫øn b·ªô c·ªßa t·ª´ng h·ªçc sinh, kh√¥ng ch·ªâ l·ªõp h·ªçc n√≥i chung. neutral positive\n",
            "Anh ta c√≥ t√≠nh c√°ch ƒëi·ªÅm ƒë·∫°m v√† kh√¥ng bao gi·ªù ho·∫£ng lo·∫°n. neutral positive\n",
            "C√°c ho·∫°t ƒë·ªông ngo·∫°i kh√≥a c·ªßa tr∆∞·ªùng ƒëa d·∫°ng v√† h·∫•p d·∫´n cho ng∆∞·ªùi tham gia. neutral positive\n",
            "Th·∫ßy cung c·∫•p cho sinh vi√™n c√°c t√†i nguy√™n v√† c√¥ng c·ª• h·ªó tr·ª£ gi·∫£ng d·∫°y hi·ªáu qu·∫£. neutral positive\n",
            "Th·∫ßy l√† ng∆∞·ªùi gi·∫£ng d·∫°y gi·ªèi nh·∫•t m√† t√¥i t·ª´ng g·∫∑p. positive neutral\n",
            "Tr∆∞·ªùng cung c·∫•p ƒë·∫ßy ƒë·ªß c√°c th√¥ng tin v√† t√†i li·ªáu cho sinh vi√™n ƒë·ªÉ gi√∫p t√¥i h·ªçc t·∫≠p m·ªôt c√°ch hi·ªáu qu·∫£. neutral positive\n",
            "Tr∆∞·ªùng c√≥ cung c·∫•p wifi mi·ªÖn ph√≠ cho sinh vi√™n, gi√∫p c√°c em ti·ªán l·ª£i h∆°n trong vi·ªác truy c·∫≠p internet. positive neutral\n",
            "Khu v·ª±c ng·ªìi ch·ªù ƒë·ª£i ƒë∆∞·ª£c trang b·ªã ƒë·∫ßy ƒë·ªß gh·∫ø v√† trang thi·∫øt b·ªã gi√∫p sinh vi√™n ch·ªù ƒë·ª£i m·ªôt c√°ch tho·∫£i m√°i. positive neutral\n",
            "Gi·∫£ng vi√™n d·∫°y r·∫•t c√≥ t√¢m, t·∫≠n t√¨nh gi√∫p ƒë·ª° sinh vi√™n khi c·∫ßn. positive neutral\n",
            "C√¥ b·∫°n n√†y l√† m·ªôt gi·∫£ng vi√™n tuy·ªát v·ªùi, lu√¥n h·ªó tr·ª£ v√† gi√∫p ƒë·ª° sinh vi√™n. positive neutral\n",
            "C√°c ph√≤ng h·ªçc ƒë∆∞·ª£c trang b·ªã m√°y chi·∫øu v√† b·∫£ng tr·∫Øng gi√∫p gi·∫£ng vi√™n gi·∫£ng d·∫°y t·ªët h∆°n. positive neutral\n",
            "T√¥i r·∫•t th√≠ch c√°ch m√† ch∆∞∆°ng tr√¨nh ƒë√†o t·∫°o ƒë∆∞·ª£c t·ªï ch·ª©c v√† qu·∫£n l√Ω. positive neutral\n",
            "Ch∆∞∆°ng tr√¨nh ti√™n ti·∫øn ch∆∞a ƒë∆∞·ª£c tri·ªÉn khai r·ªông r√£i cho sinh vi√™n. negative neutral\n",
            "H·ªá th·ªëng wifi mi·ªÖn ph√≠ s·ª≠ d·ª•ng thu·∫≠n ti·ªán. positive neutral\n",
            "K√Ω t√∫c x√° c·ªßa tr∆∞·ªùng r·∫•t ti·ªán nghi v√† s·∫°ch s·∫Ω. positive neutral\n",
            "C√¥ n√†y l√† ng∆∞·ªùi r·∫•t chuy√™n nghi·ªáp v√† c√≥ kinh nghi·ªám gi·∫£ng d·∫°y l√¢u nƒÉm. positive neutral\n",
            "Ch·ªã ·∫•y c√≥ kh·∫£ nƒÉng l√†m vi·ªác nh√≥m t·ªët v√† t·∫°o ra m·ªôt m√¥i tr∆∞·ªùng h·ª£p t√°c t·ªët nh·∫•t cho t·∫•t c·∫£ m·ªçi ng∆∞·ªùi. neutral positive\n",
            "N∆°i ƒë√¢y c√≥ nhi·ªÅu ph√≤ng th√≠ nghi·ªám v√† trang thi·∫øt b·ªã c·∫ßn thi·∫øt ƒë·ªÉ h·ªó tr·ª£ h·ªçc vi√™n. positive neutral\n",
            "Ch∆∞∆°ng tr√¨nh h·ªçc t·∫≠p ƒë√°p ·ª©ng ƒë∆∞·ª£c nh·ªØng y√™u c·∫ßu c·ªßa ngh·ªÅ nghi·ªáp. neutral positive\n",
            "Sinh vi√™n ƒë∆∞·ª£c h·ªó tr·ª£ t√¨m ki·∫øm vi·ªác l√†m sau khi t·ªët nghi·ªáp. neutral positive\n",
            "C√≥ nhi·ªÅu v·∫•n ƒë·ªÅ v·ªÅ thi·∫øt b·ªã v√† h·ªá th·ªëng m·∫°ng trong c√°c ph√≤ng h·ªçc. negative neutral\n",
            "B·∫°n c·ªßa t√¥i l√† ng∆∞·ªùi r·∫•t nƒÉng ƒë·ªông v√† lu√¥n c√≥ nh·ªØng √Ω t∆∞·ªüng m·ªõi l·∫°. positive neutral\n",
            "Th·∫ßy r·∫•t nhi·ªát t√¨nh v·ªõi c√°c c√¢u h·ªèi c·ªßa sinh vi√™n. neutral positive\n",
            "Tr∆∞·ªùng ƒë·∫°i h·ªçc n√†y l√† n∆°i l√Ω t∆∞·ªüng ƒë·ªÉ giao l∆∞u v√† k·∫øt n·ªëi v·ªõi nh·ªØng ng∆∞·ªùi b·∫°n m·ªõi. positive neutral\n",
            "Tr∆∞·ªùng h·ªó tr·ª£ sinh vi√™n ƒëƒÉng k√Ω tham gia c√°c k·ª≥ thi ch·ª©ng ch·ªâ v√† ƒë√†o t·∫°o kh√°c. neutral positive\n",
            "C∆° s·ªü v·∫≠t ch·∫•t t·∫°i ƒë·∫°i h·ªçc n√†y ƒë√°p ·ª©ng t·ªët nhu c·∫ßu h·ªçc t·∫≠p c·ªßa sinh vi√™n. neutral positive\n",
            "M√¥n h·ªçc kh√¥ng ph√π h·ª£p v·ªõi chuy√™n ng√†nh c·ª• th·ªÉ v√† ƒë·ªô kh√≥ qu√° cao. negative neutral\n",
            "ƒê·ªìng nghi·ªáp c·ªßa t√¥i r·∫•t h·ªó tr·ª£ v√† ƒë·ªìng c·∫£m. neutral positive\n",
            "Anh ·∫•y c√≥ tr√≠ th√¥ng minh s√°ng su·ªët v√† s·ª± nghi·ªáp c·ªßa anh ·∫•y tuy·ªát v·ªùi. positive neutral\n",
            "S·ª± ƒëa d·∫°ng c·ªßa ch∆∞∆°ng tr√¨nh ƒë√†o t·∫°o gi√∫p tƒÉng t√≠nh linh ho·∫°t cho sinh vi√™n. neutral positive\n",
            "Ch∆∞∆°ng tr√¨nh gi√°o d·ª•c r·∫•t th·ª±c t·∫ø, gi√∫p t√¥i l√†m quen v·ªõi nh·ªØng v·∫•n ƒë·ªÅ ƒëang x·∫£y ra v√† ƒë∆∞a ra gi·∫£i ph√°p th·ª±c ti·ªÖn. neutral positive\n",
            "Th·∫ßy c√≥ kh·∫£ nƒÉng d·∫°y h·ªçc ƒëa d·∫°ng ƒë·ªÉ ph√π h·ª£p v·ªõi c√°c h·ªçc sinh c√≥ n·ªÅn t·∫£ng k√©m. neutral positive\n",
            "Th·∫ßy th∆∞·ªùng t·∫°o ra c√°c ho·∫°t ƒë·ªông nh√≥m ƒë·ªÉ tƒÉng c∆∞·ªùng t∆∞∆°ng t√°c gi·ªØa h·ªçc vi√™n v√† h·ªçc vi√™n. neutral positive\n",
            "Anh ·∫•y r·∫•t bi·∫øt l·∫Øng nghe v√† c√≥ kh·∫£ nƒÉng truy·ªÅn ƒë·∫°t ki·∫øn th·ª©c d·ªÖ hi·ªÉu. neutral positive\n",
            "Anh ·∫•y l√† m·ªôt ng∆∞·ªùi r·∫•t t·∫≠n t√¢m v·ªõi c√¥ng vi·ªác v√† gia ƒë√¨nh. neutral positive\n",
            "C√°c ph√≤ng h·ªçc v√† ph√≤ng th√≠ nghi·ªám trong tr∆∞·ªùng ƒë∆∞·ª£c trang b·ªã ƒë·∫ßy ƒë·ªß thi·∫øt b·ªã ƒë·ªÉ ƒë·∫£m b·∫£o ch·∫•t l∆∞·ª£ng h·ªçc t·∫≠p. positive neutral\n",
            "Gi·∫£ng vi√™n l√† m·ªôt ng∆∞·ªùi c√≥ t√°c phong v√† phong c√°ch gi·∫£ng d·∫°y r·∫•t chuy√™n nghi·ªáp. neutral positive\n",
            "Th·∫ßy c√¥ gi·∫£ng d·∫°y ƒë·ªÅu r·∫•t h√≤a nh√£ v√† th√¢n thi·ªán, gi√∫p t√¥i c·∫£m th·∫•y tho·∫£i m√°i h∆°n trong l·ªõp h·ªçc. neutral positive\n",
            "Gi·∫£ng vi√™n r·∫•t trung th√†nh v·ªõi vai tr√≤ c·ªßa m√¨nh v√† gi·∫£ng d·∫°y r·∫•t ch√≠nh x√°c. neutral positive\n",
            "Gi·∫£ng vi√™n n√†y lu√¥n ƒë∆∞a ra c√°c v√≠ d·ª• kh√≥ nh·∫±n ƒë·ªÉ h·ªçc sinh hi·ªÉu. neutral negative\n",
            "Gi·∫£ng vi√™n d·∫°y r·∫•t ch·∫•t l∆∞·ª£ng v√† hi·ªáu qu·∫£. neutral positive\n",
            "Ch∆∞∆°ng tr√¨nh ƒë√†o t·∫°o r·∫•t chuy√™n nghi·ªáp. neutral positive\n",
            "Sau khi t·ªët nghi·ªáp, sinh vi√™n c√≥ th·ªÉ c√≥ nhi·ªÅu c∆° h·ªôi vi·ªác l√†m t·ªët trong lƒ©nh v·ª±c c·ªßa m√¨nh. neutral positive\n",
            "T√¥i mong ƒë·ª£i gi·∫£ng vi√™n s·∫Ω s·ª≠a ngay l·∫≠p t·ª©c nh·ªØng sai s√≥t trong b√†i gi·∫£ng ƒë·ªÉ tr√°nh nh·∫ßm l·∫´n. negative neutral\n",
            "Th·∫ßy l√† m·ªôt ng∆∞·ªùi d·∫°y r·∫•t nhi·ªát t√¨nh v√† s√°ng t·∫°o. neutral positive\n",
            "Kh√¥ng gi·ªõi h·∫°n v·ªÅ th·ªùi gian h·ªçc t·∫≠p. neutral positive\n",
            "C√°c ph√≤ng h·ªçc ƒë∆∞·ª£c c·∫£i t·∫°o ƒë·ªãnh k·ª≥ ƒë·ªÉ ƒë√°p ·ª©ng nhu c·∫ßu h·ªçc t·∫≠p c·ªßa sinh vi√™n. neutral positive\n",
            "T√¥i c·∫£m th·∫•y ki·∫øn th·ª©c ƒë∆∞·ª£c truy·ªÅn ƒë·∫°t s√¢u s·∫Øc v√† c√≥ t√≠nh ·ª©ng d·ª•ng cao. positive neutral\n",
            "B·∫°n c·ªßa t√¥i r·∫•t t·ªâ m·ªâ v√† l∆∞u √Ω ƒë·∫øn chi ti·∫øt. positive neutral\n",
            "Ch∆∞∆°ng tr√¨nh h·ªçc ph√π h·ª£p v·ªõi y√™u c·∫ßu c·ªßa th·ªã tr∆∞·ªùng v√† ƒë√°p ·ª©ng ƒë∆∞·ª£c nhu c·∫ßu c·ªßa h·ªçc vi√™n. neutral positive\n",
            "Khu√¥n vi√™n tr∆∞·ªùng r·ªông l·ªõn v√† ƒë∆∞·ª£c b·ªë tr√≠ h·ª£p l√≠. neutral positive\n",
            "Tr∆∞·ªùng c√≥ c√°c ch∆∞∆°ng tr√¨nh h·ªçc b·ªïng v√† t√†i tr·ª£ gi√∫p ƒë·ª° nh·ªØng sinh vi√™n c√≥ th√†nh t√≠ch h·ªçc t·∫≠p cao. positive neutral\n",
            "C√°c cƒÉn tin ·ªü ƒë√¢y r·∫•t ngon v√† gi√° c·∫£ ph·∫£i chƒÉng. positive neutral\n",
            "H·ªçc ph√≠ ƒë∆∞·ª£c chia theo c√°c k·ª≥ h·ªçc, gi√∫p sinh vi√™n d·ªÖ d√†ng to√†n t√¢m to√†n √Ω v·ªõi t·ª´ng k·ª≥ h·ªçc. neutral positive\n",
            "T√¥i c·∫£m th·∫•y ch∆∞∆°ng tr√¨nh h·ªçc kh√¥ng th·ª±c s·ª± ƒë√°p ·ª©ng ƒë∆∞·ª£c nhu c·∫ßu ng√†nh ngh·ªÅ hi·ªán t·∫°i. neutral negative\n",
            "H·ªçc ph√≠ ƒë∆∞·ª£c gi·∫£m gi√° cho nh·ªØng sinh vi√™n ƒëƒÉng k√Ω s·ªõm. neutral positive\n",
            "Gi·∫£ng vi√™n n√†y qu√° ƒë√≤i h·ªèi cao v·ªÅ ƒëi·ªÉm s·ªë v√† ƒë√¥i khi l√†m kh√≥ h·ªçc sinh. negative neutral\n",
            "T√¥i r·∫•t y√™u th√≠ch kh√¥ng gian c·ªßa th∆∞ vi·ªán v√† c√°c d·ªãch v·ª• b·ªï tr·ª£ t·∫°i ƒë√¢y. positive neutral\n",
            "C√°c ph√≤ng h·ªçc ƒë∆∞·ª£c trang b·ªã ti·ªán nghi v√† ƒë·∫ßy ƒë·ªß thi·∫øt b·ªã. positive neutral\n",
            "Ch∆∞∆°ng tr√¨nh h·ªçc r·∫•t linh ho·∫°t v√† c√≥ th·ªÉ ph√π h·ª£p v·ªõi nhu c·∫ßu c·ªßa t·ª´ng sinh vi√™n. neutral positive\n",
            "Gi·∫£ng vi√™n n√†y kh√¥ng gi√∫p ƒë∆∞·ª£c h·ªçc sinh ƒë·∫°t ƒë∆∞·ª£c nh·ªØng m·ª•c ti√™u c·ªßa h·ªç. negative neutral\n",
            "K√Ω t√∫c x√° c·ªßa tr∆∞·ªùng c√≥ c√°c d·ªãch v·ª• ti·ªán √≠ch nh∆∞ t·∫≠p gym v√† qu·∫ßy c√† ph√™. neutral positive\n",
            "Tr∆∞·ªùng ƒë·∫∑t nhi·ªÅu ∆∞u ti√™n cho s·ª± ph√°t tri·ªÉn to√†n di·ªán c·ªßa sinh vi√™n. positive neutral\n",
            "C√°c gi·∫£ng vi√™n c·ªßa tr∆∞·ªùng r·∫•t c√≥ kinh nghi·ªám v√† gi·ªèi chuy√™n m√¥n. neutral positive\n",
            "ƒê·ªôi ng≈© nh√¢n vi√™n ·ªü ƒë√¢y lu√¥n h·ªó tr·ª£ v√† ƒë√°p ·ª©ng m·ªçi nhu c·∫ßu c·ªßa sinh vi√™n. positive neutral\n",
            "Ph√≤ng th√≠ nghi·ªám ·ªü tr∆∞·ªùng ƒë∆∞·ª£c trang b·ªã ƒë·∫ßy ƒë·ªß thi·∫øt b·ªã v√† m√°y m√≥c. positive neutral\n",
            "ƒê·ªôi ng≈© gi√°o vi√™n c√≥ nhi·ªÅu tri th·ª©c v√† kinh nghi·ªám gi√∫p sinh vi√™n n·∫Øm v·ªØng ki·∫øn th·ª©c chuy√™n m√¥n. neutral positive\n",
            "Nh·ªØng ki·∫øn th·ª©c t√¥i h·ªçc ƒë∆∞·ª£c trong ch∆∞∆°ng tr√¨nh h·ªçc r·∫•t b·ªï √≠ch cho c√¥ng vi·ªác c·ªßa t√¥i sau n√†y. positive neutral\n",
            "B·∫°n c·ªßa t√¥i r·∫•t c·ªüi m·ªü v√† d·ªÖ th∆∞∆°ng v·ªõi m·ªçi ng∆∞·ªùi. positive neutral\n",
            "T√¥i c·∫£m th·∫•y tr∆∞·ªùng ƒëang ph√°t tri·ªÉn v√† ƒëi theo xu h∆∞·ªõng m·ªõi nh·∫•t trong gi√°o d·ª•c. neutral positive\n",
            "Gi·∫£ng vi√™n gi√∫p sinh vi√™n ph√°t tri·ªÉn v√† r√®n luy·ªán k·ªπ nƒÉng s√°ng t·∫°o. positive neutral\n",
            "Th·∫ßy c≈©ng l√† m·ªôt ng∆∞·ªùi ƒë·ªìng h√†nh v√† l·∫Øng nghe nh·ªØng kh√≥ khƒÉn c·ªßa sinh vi√™n. neutral positive\n",
            "H·ªôi tr∆∞·ªùng l·ªõn v√† ƒë∆∞·ª£c trang b·ªã ƒë·∫ßy ƒë·ªß h·ªá th·ªëng √¢m thanh v√† chi·∫øu s√°ng. neutral positive\n",
            "Gi·∫£ng vi√™n n√†y l√† ng∆∞·ªùi r·∫•t chu ƒë√°o v√† nhi·ªát t√¨nh. positive neutral\n",
            "C√¥ ·∫•y r·∫•t c·∫©n th·∫≠n v√† ch√∫ √Ω ƒë·∫øn chi ti·∫øt nh·ªè nh·∫•t. neutral positive\n",
            "Th·∫ßy c√≥ kh·∫£ nƒÉng truy·ªÅn c·∫£m h·ª©ng cho sinh vi√™n h·ªçc t·∫≠p. neutral positive\n",
            "C√°c ho·∫°t ƒë·ªông gi√°o d·ª•c kh√° ƒëa d·∫°ng v√† phong ph√∫. neutral positive\n",
            "C√°c b√†i ki·ªÉm tra ƒë∆∞·ª£c thi·∫øt k·∫ø t·ªët v√† c√¥ng b·∫±ng. neutral positive\n",
            "Th·∫ßy lu√¥n d·∫°y sinh vi√™n c√°ch t∆∞ duy v√† ph√°t tri·ªÉn k·ªπ nƒÉng. positive neutral\n",
            "C∆° s·ªü v·∫≠t ch·∫•t t·ªët v√† ƒë∆∞·ª£c c·∫≠p nh·∫≠t li√™n t·ª•c. neutral positive\n",
            "Gi·∫£ng vi√™n n√†y ƒë√¥i l√∫c qu√™n chuy·ªán ch√≠nh ƒë·ªÉ gi·∫£i th√≠ch nh·ªØng chi ti·∫øt kh√¥ng quan tr·ªçng. negative neutral\n",
            "L·ªõp h·ªçc ƒë∆∞·ª£c t·ªï ch·ª©c khoa h·ªçc, h·ªó tr·ª£ sinh vi√™n kh√¥ng ch·ªâ gi√∫p h·ªçc m√† c√≤n gi√∫p sinh vi√™n r√®n luy·ªán k·ªπ nƒÉng qu·∫£n l√Ω th·ªùi gian. positive neutral\n",
            "C√¥ ·∫•y c√≥ kh·∫£ nƒÉng ƒë∆∞a ra quy·∫øt ƒë·ªãnh m·ªôt c√°ch ƒë√∫ng ƒë·∫Øn v√† hi·ªáu qu·∫£. neutral positive\n",
            "Anh ·∫•y l√† m·ªôt ng∆∞·ªùi t√†i nƒÉng v√† c√≥ tinh th·∫ßn t·ª± th√°ch th·ª©c b·∫£n th√¢n. neutral positive\n",
            "C√°c gi·∫£ng vi√™n ƒë·ªÅu r·∫•t am hi·ªÉu trong lƒ©nh v·ª±c c·ªßa m√¨nh. neutral positive\n",
            "Gi√°o tr√¨nh r·∫•t th√∫ v·ªã v√† ƒë·ªôc ƒë√°o, gi√∫p t√¥i h·ªçc ƒë∆∞·ª£c nhi·ªÅu th·ª© m·ªõi l·∫°. positive neutral\n",
            "Khu√¥n vi√™n ƒë·∫•t n·ªÅn r·ªông r√£i v√† kh√° y√™n tƒ©nh. neutral positive\n",
            "Gi√°o vi√™n r·∫•t nhi·ªát t√¨nh v√† c√≥ tr√°ch nhi·ªám trong qu√° tr√¨nh gi·∫£ng d·∫°y. positive neutral\n",
            "Gi·∫£ng vi√™n n√†y ƒë∆∞a ra nh·ªØng gi·∫£i ph√°p ƒë·ªôt ph√° v√† s√°ng t·∫°o cho vi·ªác h·ªçc t·∫≠p. neutral positive\n",
            "Th·∫ßy d·∫°y r·∫•t c·∫©n th·∫≠n v√† t·ªâ m·ªâ, lu√¥n ch√∫ √Ω t·ª´ng chi ti·∫øt. positive neutral\n",
            "Th·∫ßy truy·ªÅn c·∫£m h·ª©ng v√† ƒë·ªông vi√™n c√°c sinh vi√™n c√≥ ho√†n c·∫£nh kh√≥ khƒÉn. positive neutral\n",
            "C√¥ ·∫•y r·∫•t tho·∫£i m√°i v√† t·ª± tin trong giao ti·∫øp ƒëa d·∫°ng v·ªõi ng∆∞·ªùi kh√°c gi·ªõi. positive neutral\n",
            "Khu v·ª±c ng·ªìi t·∫≠p trung v√† l√†m vi·ªác c·ªßa tr∆∞·ªùng r·∫•t t·ªët cho vi·ªác h·ªçc t·∫≠p t·∫≠p trung. neutral positive\n",
            "S·ª± ƒëa d·∫°ng v·ªÅ c√°c m√¥n h·ªçc gi√∫p m√¨nh l·ª±a ch·ªçn v√† c·∫≠p nh·∫≠t ki·∫øn th·ª©c m·ªõi. neutral positive\n",
            "Gi·∫£ng vi√™n n√†y ƒë∆∞a ra c√°c v√≠ d·ª• r·∫•t th·ª±c t·∫ø v√† h·ªØu √≠ch ƒë·ªÉ gi√∫p t√¥i hi·ªÉu b√†i h·ªçc. neutral positive\n",
            "Gi·∫£ng vi√™n n√†y r·∫•t th√≠ch h·ª£p trong vi·ªác gi·∫£ng d·∫°y cho h·ªçc sinh ƒëam m√™ chuy√™n m√¥n n√†y. positive neutral\n",
            "Gi·∫£ng vi√™n r·∫•t th√¢n thi·ªán v√† t·∫°o kh√¥ng kh√≠ h·ªçc t·∫≠p t√≠ch c·ª±c cho sinh vi√™n. positive neutral\n",
            "Gi√°o vi√™n lu√¥n gi·∫£i ƒë√°p th·∫Øc m·∫Øc c·ªßa sinh vi√™n r√µ r√†ng v√† chi ti·∫øt. positive neutral\n",
            "Th·∫ßy ƒë∆∞a ra nh·ªØng ph∆∞∆°ng ph√°p d·∫°y h·ªçc hi·ªáu qu·∫£ v√† h·ªØu √≠ch cho sinh vi√™n. neutral positive\n",
            "Ph√≤ng h·ªçc ƒë∆∞·ª£c trang b·ªã ƒë·∫ßy ƒë·ªß c√°c thi·∫øt b·ªã c·∫ßn thi·∫øt cho vi·ªác h·ªçc t·∫≠p. neutral positive\n",
            "T√¥i r·∫•t h√†i l√≤ng v·ªõi ch∆∞∆°ng tr√¨nh h·ªçc n∆°i ƒë√¢y. positive neutral\n",
            "B·∫°n c·ªßa em l√† ng∆∞·ªùi r·∫•t c√° t√≠nh v√† kh√¥ng s·ª£ th·ªÉ hi·ªán b·∫£n th√¢n. positive neutral\n",
            "Anh ta lu√¥n c√≥ tinh th·∫ßn h·ªçc h·ªèi v√† m·ªü ƒë·∫ßu v·ªõi nh·ªØng ki·∫øn th·ª©c m·ªõi. positive neutral\n",
            "C√°c bu·ªïi h·ªçc ƒë∆∞·ª£c t·ªï ch·ª©c ch·∫∑t ch·∫Ω v√† c√≥ s·ª± chu·∫©n b·ªã k·ªπ l∆∞·ª°ng. neutral positive\n",
            "Gi·∫£ng vi√™n r·∫•t l·∫°c quan v√† ƒë√°ng k√≠nh. neutral positive\n",
            "T√¥i kh√¥ng th·ªÉ t∆∞·ªüng t∆∞·ª£ng ƒë∆∞·ª£c m√¥i tr∆∞·ªùng h·ªçc t·∫≠p s·∫Ω nh∆∞ th·∫ø n·∫øu kh√¥ng c√≥ th·∫ßy/c√¥. negative positive\n",
            "Nh·ªØng kh√¥ng gian h·ªçc t·∫≠p ƒë∆°n l·∫≠p ho·∫∑c nh√≥m t·∫≠p th·ªÉ ƒë·ªÅu r·∫•t ti·ªán nghi v√† ƒë·∫ßy ƒë·ªß ƒë·ªÉ h·ªçc t·∫≠p v√† l√†m vi·ªác. neutral positive\n",
            "Gi·∫£ng vi√™n kh√¥ng th∆∞·ªùng xuy√™n li√™n h·ªá v·ªõi sinh vi√™n sau khi h·ªç k·∫øt th√∫c m√¥n h·ªçc. negative neutral\n",
            "Anh ta l√† m·ªôt gi·∫£ng vi√™n r·∫•t t·∫≠n t√¢m v√† s√°ng t·∫°o. neutral positive\n",
            "Ph√≤ng gi√°o vi√™n ƒë·ªß ti·ªán nghi, tho·∫£i m√°i. neutral positive\n",
            "C·∫≠u b·∫°n n√†y r·∫•t th√¢n thi·ªán v√† h√≤a ƒë·ªìng. neutral positive\n",
            "Gi·∫£ng vi√™n r·∫•t ƒë√°ng k√≠nh v√† ƒë∆∞·ª£c sinh vi√™n y√™u m·∫øn ƒë·∫∑c bi·ªát. positive neutral\n",
            "Th·∫ßy r·∫•t nƒÉng ƒë·ªông, gi√∫p sinh vi√™n t·∫≠p trung v√†o h·ªçc t·∫≠p m·ªôt c√°ch hi·ªáu qu·∫£. positive neutral\n",
            "Gi√°o vi√™n lu√¥n ƒë·∫∑t m√¨nh v√†o t√¢m tr·∫°ng v√† kh√≥ khƒÉn c·ªßa h·ªçc sinh. neutral positive\n",
            "Ch·∫•t l∆∞·ª£ng gi·∫£ng d·∫°y c·ªßa tr∆∞·ªùng t√¥i r·∫•t t·ªët trong ƒë√≥ gi√°o vi√™n l√† m·ªôt ph·∫ßn quan tr·ªçng. neutral positive\n",
            "Gi·∫£ng vi√™n mang l·∫°i kinh nghi·ªám th·ª±c t·∫ø cho h·ªçc sinh. neutral positive\n",
            "H·ªá th·ªëng r·∫°p chi·∫øu phim v√† trung t√¢m gi·∫£i tr√≠ n√¢ng cao sinh ho·∫°t vƒÉn h√≥a cho sinh vi√™n. positive neutral\n",
            "Th·∫ßy ƒë·∫øn l·ªõp ƒë·∫ßy ƒë·ªß v√† kh√¥ng bao gi·ªù b·ªè l·ª° b·∫•t k·ª≥ bu·ªïi h·ªçc n√†o. neutral positive\n",
            "Ph∆∞∆°ng ph√°p d·∫°y h·ªçc thi·∫øt th·ª±c v√† c√≥ t√≠nh ·ª©ng d·ª•ng cao. neutral positive\n",
            "Nh√¢n vi√™n ph·ª•c v·ª• tr∆∞·ªùng lu√¥n s√°ng su·ªët, vui v·∫ª, nhi·ªát t√¨nh h·ªó tr·ª£ sinh vi√™n m·ªçi khi c·∫ßn thi·∫øt positive neutral\n",
            "C√°c b√†i h·ªçc ƒë∆∞·ª£c thi·∫øt k·∫ø t·ªëi ∆∞u cho vi·ªác h·ªçc tr·ª±c tuy·∫øn. neutral positive\n",
            "C√°c khu v·ª±c c·∫•m h√∫t thu·ªëc ƒë∆∞·ª£c thi·∫øt k·∫ø v√† b·ªë tr√≠ ƒë·ªÉ ƒë·∫£m b·∫£o kh√¥ng kh√≠ trong l√†nh. neutral positive\n",
            "T√¥i c·∫£m th·∫•y r·∫•t ti·∫øc khi th·ªùi gian h·ªçc t·∫≠p t·∫°i tr∆∞·ªùng c·ªßa t√¥i k·∫øt th√∫c. negative positive\n",
            "Gi·∫£ng vi√™n n√†y kh√¥ng nh√†m ch√°n. neutral negative\n"
          ]
        }
      ],
      "source": [
        "for i, row in df_test.iterrows():\n",
        "    if row['predict'] != row['sentiment']:\n",
        "        print(row['sentence'], row['predict'], row['sentiment'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HLJBc3H1Qrbg"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dTG963HxQrbh"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "datasetId": 3052448,
          "sourceId": 5245967,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30733,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}