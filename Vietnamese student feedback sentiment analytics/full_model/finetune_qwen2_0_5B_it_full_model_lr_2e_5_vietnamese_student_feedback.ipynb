{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "id": "yU5pew3JPp92"
      },
      "source": [
        "# Install library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vfeJBfXaPp93",
        "outputId": "9387b180-3fd1-4bda-bbd2-2fe61050b351"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -q datasets==2.16.0\n",
        "!pip install -q bitsandbytes\n",
        "!pip install -q tiktoken\n",
        "!pip install -q peft\n",
        "!pip install -q trl\n",
        "!pip install -q transformers\n",
        "!pip install -q openpyxl\n",
        "!pip install -q pandas\n",
        "!pip install -q scikit-learn\n",
        "!pip install -q flash-attn\n",
        "#pip install -q transformers==4.38.1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "am10Rh0SPp94"
      },
      "source": [
        "# Import library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_QAtldoFPp94"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
        "import torch\n",
        "from accelerate import PartialState\n",
        "from peft import LoraConfig, PeftModel, prepare_model_for_kbit_training, get_peft_model\n",
        "from trl import SFTTrainer\n",
        "from peft import prepare_model_for_kbit_training\n",
        "from transformers import TrainingArguments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C7txKefVPp94"
      },
      "source": [
        "# Hyperparameters\n",
        "I use lr = 2e-4 when finetune with lora and qlora. But when finetune full model, I need to use lower lr (2e-5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kH_z1f3-Pp95"
      },
      "outputs": [],
      "source": [
        "modelpath = \"Qwen/Qwen2-0.5B-Instruct\"\n",
        "lr=2e-5      # learning rate\n",
        "bs=16            # batch size\n",
        "bs_eval=16      # batch size for evals\n",
        "ga_steps=1     # gradient acc. steps\n",
        "epochs=4\n",
        "max_length=128      # max. sample length with 24GB VRAM\n",
        "output_dir=\"out\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SHHGvL_MPp95"
      },
      "source": [
        "# Remove old model\n",
        "Because of limited storage, we can't save all models, we need to delete all models in cache by the following code:\n",
        "- rm -r out: delete out folder (because I save finetuned model in out folder), you can change folder name like (rm -r output_folder). If you doesn't have out folder, this commend do not thing.\n",
        "- all pretrained huggingface models will auto save in transformers.TRANSFORMERS_CACHE. I use shutil.rmtree to delete them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vr2eGkQ5Pp95"
      },
      "outputs": [],
      "source": [
        "!rm -r out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K-MrnwRaPp95"
      },
      "outputs": [],
      "source": [
        "# from transformers import TRANSFORMERS_CACHE\n",
        "# print(TRANSFORMERS_CACHE)\n",
        "\n",
        "# import shutil\n",
        "# shutil.rmtree(TRANSFORMERS_CACHE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7q8zxh1NPp95"
      },
      "source": [
        "# Create Dataset\n",
        "Download dataset from [kaggle synthetic-vietnamese-students-feedback-corpus](https://www.kaggle.com/datasets/toreleon/synthetic-vietnamese-students-feedback-corpus/data)\n",
        "\n",
        "We need convert DataFrame to json line (jsonl)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y2Mc8yF0Pp95"
      },
      "outputs": [],
      "source": [
        "df_train = pd.read_csv(\"synthetic_train.csv\")\n",
        "df_test = pd.read_csv(\"synthetic_val.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FVS2hClZPp96",
        "outputId": "0ed2cad2-84c1-4402-ac39-03a32608a9b1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>topic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Đội ngũ bảo trì quá thưa thớt dẫn đến không đả...</td>\n",
              "      <td>negative</td>\n",
              "      <td>facility</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The university's musical and artistic faciliti...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>facility</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Phương pháp giảng dạy phù hợp với các đối tượn...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>curriculum</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Chương trình học giúp tôi trở thành một chuyên...</td>\n",
              "      <td>positive</td>\n",
              "      <td>curriculum</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Tôi nghĩ rằng chương trình đào tạo có thể có t...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>curriculum</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            sentence sentiment       topic\n",
              "0  Đội ngũ bảo trì quá thưa thớt dẫn đến không đả...  negative    facility\n",
              "1  The university's musical and artistic faciliti...   neutral    facility\n",
              "2  Phương pháp giảng dạy phù hợp với các đối tượn...   neutral  curriculum\n",
              "3  Chương trình học giúp tôi trở thành một chuyên...  positive  curriculum\n",
              "4  Tôi nghĩ rằng chương trình đào tạo có thể có t...   neutral  curriculum"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AabWpKXiPp96",
        "outputId": "09ad5fc3-39a1-40ee-da3b-812c65f71b4b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>topic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Chất lượng vật chất kém.</td>\n",
              "      <td>negative</td>\n",
              "      <td>facility</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Phần mềm học tập quá khó sử dụng, khiến sinh v...</td>\n",
              "      <td>negative</td>\n",
              "      <td>facility</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Trường tôi thiếu những tiện ích cơ bản như máy...</td>\n",
              "      <td>negative</td>\n",
              "      <td>facility</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Cần tạo thêm các hoạt động gắn kết giữa sinh v...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>curriculum</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Họ rất khoan dung và lượng giác trong quan điể...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>others</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            sentence sentiment       topic\n",
              "0                           Chất lượng vật chất kém.  negative    facility\n",
              "1  Phần mềm học tập quá khó sử dụng, khiến sinh v...  negative    facility\n",
              "2  Trường tôi thiếu những tiện ích cơ bản như máy...  negative    facility\n",
              "3  Cần tạo thêm các hoạt động gắn kết giữa sinh v...   neutral  curriculum\n",
              "4  Họ rất khoan dung và lượng giác trong quan điể...   neutral      others"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_test.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bC32qiigPp96",
        "outputId": "01d95742-a72d-4a25-e7be-0ec50803d870"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "sentiment\n",
              "neutral     2724\n",
              "negative    2711\n",
              "positive    2709\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train.sentiment.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wSF_cH33Pp96",
        "outputId": "b001325c-a334-454f-9b3e-e915a08b09eb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "sentiment\n",
              "negative    686\n",
              "positive    680\n",
              "neutral     670\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_test.sentiment.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y5CLsiOiPp96"
      },
      "outputs": [],
      "source": [
        "df_train['len'] = df_train.sentence.apply(lambda x: len(str(x).split()))\n",
        "df_test['len'] = df_test.sentence.apply(lambda x: len(str(x).split()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0HJm2q1mPp96",
        "outputId": "a9e18199-3a1c-446f-b264-ac737054c66f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "count    8144.000000\n",
              "mean       15.549730\n",
              "std         5.018764\n",
              "min         3.000000\n",
              "25%        12.000000\n",
              "50%        15.000000\n",
              "75%        18.000000\n",
              "max        43.000000\n",
              "Name: len, dtype: float64"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train['len'].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pc8NW1fOPp97",
        "outputId": "2226aa53-e251-45c3-e656-9be55dc8b1c1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "count    2036.000000\n",
              "mean       15.694990\n",
              "std         5.185957\n",
              "min         2.000000\n",
              "25%        12.000000\n",
              "50%        15.000000\n",
              "75%        19.000000\n",
              "max        48.000000\n",
              "Name: len, dtype: float64"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_test['len'].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Kwf9AdGPp97"
      },
      "outputs": [],
      "source": [
        "with open('train.jsonl', 'w') as outfile:\n",
        "    for i, x in df_train.iterrows():\n",
        "        comment = x['sentence']\n",
        "        label = x['sentiment']\n",
        "        #label = 'yes' if label == 'relevance' else 'no'\n",
        "        data = {\n",
        "            \"input\": f'''The sentiment of this comment \"{comment}\" is''',\n",
        "            \"output\": f\"{label}\"\n",
        "        }\n",
        "        json.dump(data, outfile)\n",
        "        outfile.write('\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E7emtCskPp97"
      },
      "outputs": [],
      "source": [
        "with open('test.jsonl', 'w') as outfile:\n",
        "    for i, x in df_test.iterrows():\n",
        "        comment = x['sentence']\n",
        "        label = x['sentiment']\n",
        "        #label = 'yes' if label == 'relevance' else 'no'\n",
        "        data = {\n",
        "            \"input\": f'''The sentiment of this comment \"{comment}\" is''',\n",
        "            \"output\": f\"{label}\"\n",
        "        }\n",
        "        json.dump(data, outfile)\n",
        "        outfile.write('\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "8ca0237a02954dd89365424f5f5ae21c",
            "12ad64f581094b85a1630844f9b640ad"
          ]
        },
        "id": "VTQgkNdUPp97",
        "outputId": "b6da5aa5-fa2d-4699-b846-827949177caf"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8ca0237a02954dd89365424f5f5ae21c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "12ad64f581094b85a1630844f9b640ad",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating validation split: 0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "data_files = {\n",
        "    \"train\": \"train.jsonl\",\n",
        "    \"validation\": \"test.jsonl\",\n",
        "}\n",
        "\n",
        "dataset = load_dataset(\"json\", data_files=data_files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BAv2BtPuPp97",
        "outputId": "04e8f378-23ff-4d33-bffa-9a1a4c42906c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['input', 'output'],\n",
              "        num_rows: 8144\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['input', 'output'],\n",
              "        num_rows: 2036\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GqsLC_PUPp97"
      },
      "source": [
        "# Create prompt format\n",
        "Load tokenizer by AutoTokenizer.from_pretrained:\n",
        "- We need create and copy YOUR TOKEN from [huggingface](https://huggingface.co/settings/tokens)\n",
        "- We need use padding_side = 'right' because training library need padding_side = 'right' when training. You can use left padding but you need to make sure the library is not corrupted and check whether performance is affected by left padding!\n",
        "- If you have 1 prompt like \"test thử mô hình\" and want to tokenize it, just you tokenizer(prompt, return_tensors=\"pt\"). You can see output of tokenizer in cell below (output includes input_ids (list index of each token in prompt) and attention mask)\n",
        "- We can use tokenizer.batch_decode to see how tokenizer restore string from token tensor. You can see that it automatically adds the start token \"<bos>\" at the beginning of the string.\n",
        "- To train llm, we only need to pass 1 sentence to llm (including input and desired output) without specifying which is the input and which is the output.\n",
        "- I wrote the function formatting_prompts_func to convert input and output to prompt and tested this function, you can see below.\n",
        "- When predicting, remove the output part to let the model predict itself. See the predict section below later.\n",
        "- we only need to predict some next tokens like A. positive, and B. neutral. We don't care what the model says after sentiment. Then we do not need to add <eos token>. If you fine-tune the model with other tasks, maybe you need to add <eos token> at the end of the prompt:\n",
        "  - use tokenizer.eos_token, tokenizer.eos_token_id to see eos_token of your model and correspond id\n",
        "  - for ex: eos_token is \"<|im_end|>\". You need edit prompt like:\n",
        "    - '''...The correct answer is {output_}.''' --> '''...The correct answer is {output_}. <|im_end|>'''\n",
        "  - for ex: eos_token is \"end_token__\". You need edit prompt like:\n",
        "    - '''...The correct answer is {output_}.''' --> '''...The correct answer is {output_}. end_token__'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q_uakl-iPp97",
        "outputId": "ee316644-fb69-4016-b6e3-b2e2d125253f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    modelpath,\n",
        "    padding_side=\"right\",\n",
        "    # add_eos_token=True,\n",
        "    # add_bos_token=True,\n",
        "    trust_remote_code=True,\n",
        "    token = 'YOUR TOKEN HERE'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ECELpocPp98",
        "outputId": "3c181a90-a4ad-4958-90bd-344dff056445"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_ids': tensor([[  1944, 131885, 130179, 128338]]), 'attention_mask': tensor([[1, 1, 1, 1]])}\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['test', ' thử', ' mô', ' hình']"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prompt = \"test thử mô hình\"\n",
        "tokens = tokenizer(prompt, return_tensors=\"pt\")\n",
        "print(tokens)\n",
        "tokenizer.batch_decode(tokenizer.encode(prompt))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KXIWCL5-Pp-B"
      },
      "outputs": [],
      "source": [
        "def formatting_prompts_func(example):\n",
        "    output_texts = []\n",
        "    for i in range(len(example['input'])):\n",
        "        input_ = example['input'][i]\n",
        "        output_ = example['output'][i]\n",
        "        output_ = 'A. Positive' if output_ == 'positive' else 'B. Neutral' if output_ == 'neutral' else 'C. Negative'\n",
        "        #text = f\"### Question: {input__}\\n ### Answer: {example['output'][i]}\"\n",
        "        text = f'''{input_}\n",
        "A. Positive\n",
        "B. Neutral\n",
        "C. Negative\n",
        "\n",
        "The correct answer is {output_}.'''\n",
        "\n",
        "        output_texts.append(text)\n",
        "    return output_texts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a-sEHQDMPp-B",
        "outputId": "85c59576-0010-4962-fd13-2a2e52250ace"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('The sentiment of this comment \"Chất lượng vật chất kém.\" is', 'negative')"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset[\"validation\"]['input'][0], dataset[\"validation\"]['output'][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ts7VuIqMPp-B",
        "outputId": "37f6309d-f0bc-42b0-e6dd-404ff1438c27"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['The sentiment of this comment \"Chất lượng vật chất kém.\" is\\nA. Positive\\nB. Neutral\\nC. Negative\\n\\nThe correct answer is C. Negative.']"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "formatting_prompts_func({'input': [dataset[\"validation\"]['input'][0]],\n",
        "                         'output': [dataset[\"validation\"]['output'][0]]})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_dL-v47zPp-C",
        "outputId": "d9cc6a0a-5bf2-4225-f3dc-ea0e16fd5a41"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The sentiment of this comment \"Chất lượng vật chất kém.\" is\n",
            "A. Positive\n",
            "B. Neutral\n",
            "C. Negative\n",
            "\n",
            "The correct answer is C. Negative.\n"
          ]
        }
      ],
      "source": [
        "print(formatting_prompts_func({'input': [dataset[\"validation\"]['input'][0]],\n",
        "                         'output': [dataset[\"validation\"]['output'][0]]})[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2u5Yd0CuPp-C"
      },
      "source": [
        "# Create model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ENncIKmPp-C"
      },
      "source": [
        "## Load model\n",
        "We use AutoModelForCausalLM.from_pretrained to load model:\n",
        "- device_map = 'auto': auto active gpu.\n",
        "- torch_dtype: use bfloat16, if your gpu don't support bfloat16, set it to float32\n",
        "- attn_implementation: you can use 'flash_attention_2', if you meet bug, maybe your gpu doesn't support it, you need delete this line.\n",
        "- token: you huggingface token like tokenizer above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R88-YlykPp-C"
      },
      "outputs": [],
      "source": [
        "# bnb_config = BitsAndBytesConfig(\n",
        "#     load_in_4bit=True,\n",
        "#     bnb_4bit_use_double_quant=True,\n",
        "#     bnb_4bit_quant_type=\"nf4\",\n",
        "#     bnb_4bit_compute_dtype=torch.bfloat16,\n",
        "# )\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    modelpath,\n",
        "    device_map=\"auto\",\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    #torch_dtype=torch.float32,\n",
        "    #quantization_config=bnb_config,\n",
        "    attn_implementation=\"flash_attention_2\",\n",
        "    trust_remote_code=True,\n",
        "    token = 'YOUR TOKEN HERE'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pOGmvwLCPp-C",
        "outputId": "dc4a8961-e0c2-4579-d6f9-9f46251a0980"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Qwen2ForCausalLM(\n",
              "  (model): Qwen2Model(\n",
              "    (embed_tokens): Embedding(151936, 896)\n",
              "    (layers): ModuleList(\n",
              "      (0-23): 24 x Qwen2DecoderLayer(\n",
              "        (self_attn): Qwen2FlashAttention2(\n",
              "          (q_proj): Linear(in_features=896, out_features=896, bias=True)\n",
              "          (k_proj): Linear(in_features=896, out_features=128, bias=True)\n",
              "          (v_proj): Linear(in_features=896, out_features=128, bias=True)\n",
              "          (o_proj): Linear(in_features=896, out_features=896, bias=False)\n",
              "          (rotary_emb): Qwen2RotaryEmbedding()\n",
              "        )\n",
              "        (mlp): Qwen2MLP(\n",
              "          (gate_proj): Linear(in_features=896, out_features=4864, bias=False)\n",
              "          (up_proj): Linear(in_features=896, out_features=4864, bias=False)\n",
              "          (down_proj): Linear(in_features=4864, out_features=896, bias=False)\n",
              "          (act_fn): SiLU()\n",
              "        )\n",
              "        (input_layernorm): Qwen2RMSNorm()\n",
              "        (post_attention_layernorm): Qwen2RMSNorm()\n",
              "      )\n",
              "    )\n",
              "    (norm): Qwen2RMSNorm()\n",
              "  )\n",
              "  (lm_head): Linear(in_features=896, out_features=151936, bias=False)\n",
              ")"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Eval model before training\n",
        "We use create_prompt function to generate prompt (without output), our model will predict output. We will eval model before finetune. You can see some predict below.\n",
        "\n",
        "You can see that pretrained model has poor performance"
      ],
      "metadata": {
        "id": "ezLPfDqxQFZu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TFn30hPZPp-D",
        "outputId": "ab34b75b-955a-4175-e131-c14f9545f452"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:540: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:545: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:562: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.\n",
            "  warnings.warn(\n",
            "The attention mask is not set and cannot be inferred from input because pad token is same as eos token.As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The sentiment of this comment: \"món ăn rất ngon\" is\n",
            "A. Positive\n",
            "B. Neutral\n",
            "C. Negative\n",
            "\n",
            "The correct answer is\n",
            "The sentiment of this comment: \"món ăn rất ngon\" is\n",
            "A. Positive\n",
            "B. Neutral\n",
            "C. Negative\n",
            "\n",
            "The correct answer is A. Positive.\n",
            "\n",
            "The sentiment of the comment \"món ăn rất ngon\" can be interpreted as positive because it expresses satisfaction or approval with the food being described. The word \"ngon\" means good, delicious, or appealing in English.\n"
          ]
        }
      ],
      "source": [
        "def create_prompt(input_, output_):\n",
        "    output_ = 'A. Positive' if output_ == 'positive' else 'B. Neutral' if output_ == 'neutral' else 'C. Negative'\n",
        "        #text = f\"### Question: {input__}\\n ### Answer: {example['output'][i]}\"\n",
        "    text = f'''{input_}\n",
        "A. Positive\n",
        "B. Neutral\n",
        "C. Negative\n",
        "\n",
        "The correct answer is'''\n",
        "\n",
        "    return text\n",
        "\n",
        "sentence = 'món ăn rất ngon'\n",
        "input_ = f'''The sentiment of this comment: \"{sentence}\" is'''\n",
        "prompt = create_prompt(input_, \"\")\n",
        "print(prompt)\n",
        "\n",
        "inputs = torch.tensor([tokenizer.encode(prompt)])\n",
        "\n",
        "tokens = model.generate(\n",
        "    inputs.to(model.device),\n",
        "    max_new_tokens=50,\n",
        "    temperature=0.1,\n",
        "    do_sample=False\n",
        ")\n",
        "print(tokenizer.decode(tokens[0], skip_special_tokens=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8K67uRTiPp-D",
        "outputId": "d0e61075-d1d8-4e3e-9e09-91f3e25afe95"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 0.0 0:00:00.055361 0:00:00.055365\n",
            "100 35.64356435643564 0:00:05.428861 0:00:00.053751\n",
            "200 39.30348258706468 0:00:10.796546 0:00:00.053714\n",
            "300 37.87375415282392 0:00:16.118069 0:00:00.053548\n",
            "400 37.905236907730675 0:00:21.457360 0:00:00.053510\n",
            "500 36.92614770459082 0:00:26.829137 0:00:00.053551\n",
            "600 36.43926788685524 0:00:32.189697 0:00:00.053560\n",
            "700 35.805991440798856 0:00:37.546404 0:00:00.053561\n",
            "800 35.95505617977528 0:00:42.920933 0:00:00.053584\n",
            "900 35.18312985571587 0:00:48.350846 0:00:00.053664\n",
            "1000 35.064935064935064 0:00:53.698577 0:00:00.053645\n",
            "1100 33.96911898274296 0:00:59.023389 0:00:00.053609\n",
            "1200 33.72189841798502 0:01:04.393547 0:00:00.053617\n",
            "1300 33.89700230591852 0:01:09.739092 0:00:00.053604\n",
            "1400 33.40471092077088 0:01:15.084717 0:00:00.053594\n",
            "1500 33.84410393071286 0:01:20.435934 0:00:00.053588\n",
            "1600 33.91630231105559 0:01:25.804731 0:00:00.053594\n",
            "1700 33.39212228101117 0:01:31.191520 0:00:00.053611\n",
            "1800 33.7034980566352 0:01:36.627455 0:00:00.053652\n",
            "1900 33.824302998421885 0:01:42.025747 0:00:00.053670\n",
            "2000 33.483258370814596 0:01:47.431421 0:00:00.053689\n"
          ]
        }
      ],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "start = datetime.now()\n",
        "\n",
        "prediction = []\n",
        "response = []\n",
        "accuracy = []\n",
        "labels = []\n",
        "\n",
        "for i, x in df_test.iterrows():\n",
        "    sentence = x['sentence']\n",
        "    label = x['sentiment']\n",
        "    input_ = f'''The sentiment of this comment: \"{sentence}\" is'''\n",
        "    prompt = create_prompt(input_, label)\n",
        "\n",
        "    inputs = tokenizer.encode(\n",
        "        prompt,\n",
        "        # add_generation_prompt=True,\n",
        "        return_tensors='pt'\n",
        "    )\n",
        "\n",
        "    tokens = model.generate(\n",
        "        inputs.to(model.device),\n",
        "        max_new_tokens=3,\n",
        "        temperature=0.1,\n",
        "        do_sample=False,\n",
        "        pad_token_id=tokenizer.eos_token_id\n",
        "    )\n",
        "    #break\n",
        "\n",
        "    answer = tokenizer.decode(tokens[0], skip_special_tokens=False).split(\"The correct answer is \")[-1]\n",
        "    answer = 'positive' if 'positive' in answer.lower() else 'negative' if 'negative' in answer.lower() else 'neutral'\n",
        "    prediction.append(answer.lower())\n",
        "    response.append(tokenizer.decode(tokens[0], skip_special_tokens=False))\n",
        "\n",
        "    accuracy.append(prediction[-1] == label)\n",
        "    labels.append(label)\n",
        "\n",
        "    if i % 100 == 0:\n",
        "        print(i, np.array(accuracy).sum()/len(prediction)*100, datetime.now() - start, (datetime.now() - start)/len(prediction))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2LxIx6H8Pp-D",
        "outputId": "d0520923-ebdf-4dec-c713-9f0ee3def2aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative     1.0000    0.0015    0.0029       686\n",
            "     neutral     0.0000    0.0000    0.0000       670\n",
            "    positive     0.3342    1.0000    0.5009       680\n",
            "\n",
            "    accuracy                         0.3345      2036\n",
            "   macro avg     0.4447    0.3338    0.1679      2036\n",
            "weighted avg     0.4485    0.3345    0.1683      2036\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report, f1_score\n",
        "import sklearn\n",
        "\n",
        "print(sklearn.metrics.classification_report(labels, prediction, digits=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FY2HDVtjPp-E",
        "outputId": "d0883e2e-8bd2-49e4-85c6-44ba7ae0a6af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The sentiment of this comment: \"The facilities of the university are versatile and helpful.\" is\n",
            "A. Positive\n",
            "B. Neutral\n",
            "C. Negative\n",
            "\n",
            "The correct answer is A. Positive\n",
            "\n",
            "\n",
            "The sentiment of this comment: \"Mấy bạn đó hay đòi hỏi nhưng không bao giờ giúp đỡ người khác.\" is\n",
            "A. Positive\n",
            "B. Neutral\n",
            "C. Negative\n",
            "\n",
            "The correct answer is A. Positive\n",
            "\n",
            "\n",
            "The sentiment of this comment: \"Cậu ấy rất có kỹ năng về sáng tạo và nghệ thuật.\" is\n",
            "A. Positive\n",
            "B. Neutral\n",
            "C. Negative\n",
            "\n",
            "The correct answer is A. Positive\n",
            "\n",
            "\n",
            "The sentiment of this comment: \"Giảng viên này không nhàm chán.\" is\n",
            "A. Positive\n",
            "B. Neutral\n",
            "C. Negative\n",
            "\n",
            "The correct answer is A. Positive\n",
            "\n",
            "\n",
            "The sentiment of this comment: \"Anh ta là một người rất tỉ mỉ và cẩn thận.\" is\n",
            "A. Positive\n",
            "B. Neutral\n",
            "C. Negative\n",
            "\n",
            "The correct answer is A. Positive\n",
            "\n",
            "\n",
            "The sentiment of this comment: \"Giáo viên đưa ra các phương tiện hỗ trợ giảng dạy rất tốt và hiệu quả.\" is\n",
            "A. Positive\n",
            "B. Neutral\n",
            "C. Negative\n",
            "\n",
            "The correct answer is A. Positive\n",
            "\n",
            "\n",
            "The sentiment of this comment: \"The university's computer facilities are up-to-date and well-maintained.\" is\n",
            "A. Positive\n",
            "B. Neutral\n",
            "C. Negative\n",
            "\n",
            "The correct answer is A. Positive\n",
            "\n",
            "\n",
            "The sentiment of this comment: \"Thiếu tính linh hoạt trong hình thức giảng dạy và đánh giá kết quả học tập.\" is\n",
            "A. Positive\n",
            "B. Neutral\n",
            "C. Negative\n",
            "\n",
            "The correct answer is A. Positive\n",
            "\n",
            "\n",
            "The sentiment of this comment: \"Cô ấy rất sắc sảo và có khả năng phân tích chi tiết rất tốt.\" is\n",
            "A. Positive\n",
            "B. Neutral\n",
            "C. Negative\n",
            "\n",
            "The correct answer is A. Positive\n",
            "\n",
            "\n",
            "The sentiment of this comment: \"Anh ấy có tài năng về âm nhạc và luôn tìm cách tạo ra các bản nhạc mới, giúp nhóm thêm hoàn hảo và đa dạng hơn.\" is\n",
            "A. Positive\n",
            "B. Neutral\n",
            "C. Negative\n",
            "\n",
            "The correct answer is A. Positive\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for x in response[-10:]:\n",
        "    print(x)\n",
        "    print(\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3IPLuCzSPp-E"
      },
      "source": [
        "## Create TrainingArguments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LrgqyXcoPp-E",
        "outputId": "eadbb389-29d7-413c-8865-135de01dc589"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "509\n"
          ]
        }
      ],
      "source": [
        "print(len(df_train)//bs//ga_steps*epochs//4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oY7G4TTiPp-E",
        "outputId": "51368536-d15a-4522-f52a-4ba4746cbadd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "509\n"
          ]
        }
      ],
      "source": [
        "save_step = len(df_train)//bs//ga_steps*epochs//4\n",
        "print(save_step)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w3NONWQAPp-E",
        "outputId": "3acf8e8a-0694-4167-c519-c5e808a02696"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "training_arguments = TrainingArguments(\n",
        "    output_dir=output_dir,\n",
        "    num_train_epochs=epochs,\n",
        "    per_device_train_batch_size=bs,\n",
        "    per_device_eval_batch_size=bs_eval,\n",
        "    evaluation_strategy=\"steps\",\n",
        "    eval_steps=save_step,\n",
        "    gradient_accumulation_steps=ga_steps,\n",
        "    optim=\"paged_adamw_32bit\",\n",
        "    save_steps=save_step,\n",
        "    save_strategy=\"steps\",\n",
        "    logging_steps=save_step,\n",
        "    learning_rate=lr,\n",
        "    weight_decay=0.001,\n",
        "    fp16=False,\n",
        "    bf16=True,\n",
        "    max_grad_norm=0.3,\n",
        "    max_steps=-1,\n",
        "    warmup_ratio=0.03,\n",
        "    group_by_length=True,\n",
        "    lr_scheduler_type=\"constant\",\n",
        "    report_to=\"none\",\n",
        "    save_total_limit=1,\n",
        "    #load_best_model_at_end=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DmLghud2Pp-E"
      },
      "source": [
        "## Create trainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "21778625c18140a48986bb7bf6d29b67",
            "770aa14800344558921ee053e4081cfa"
          ]
        },
        "id": "RoCjobhbPp-E",
        "outputId": "3b3b2317-8b39-490b-c833-ed09d9bb5bc2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': max_seq_length. Will not be supported from version '1.0.0'.\n",
            "\n",
            "Deprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n",
            "  warnings.warn(message, FutureWarning)\n",
            "/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1961: FutureWarning: `--push_to_hub_token` is deprecated and will be removed in version 5 of 🤗 Transformers. Use `--hub_token` instead.\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:269: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "21778625c18140a48986bb7bf6d29b67",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/8144 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "770aa14800344558921ee053e4081cfa",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/2036 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
          ]
        }
      ],
      "source": [
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    train_dataset=dataset[\"train\"],\n",
        "    eval_dataset=dataset[\"validation\"],\n",
        "    #peft_config=peft_config,\n",
        "    max_seq_length= 128,\n",
        "    #dataset_text_field=[\"input\", \"output\"],\n",
        "    tokenizer=tokenizer,\n",
        "    args=training_arguments,\n",
        "    packing= False,\n",
        "    formatting_func = formatting_prompts_func,\n",
        "    #data_collator=collator\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AMzeJkJ5Pp-E"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YUo0KnkCPp-E",
        "outputId": "ec9c2ba7-159c-4696-a504-1c09b62542be"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2036' max='2036' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2036/2036 04:04, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>509</td>\n",
              "      <td>0.819500</td>\n",
              "      <td>0.783728</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1018</td>\n",
              "      <td>0.689800</td>\n",
              "      <td>0.763411</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1527</td>\n",
              "      <td>0.606000</td>\n",
              "      <td>0.778257</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2036</td>\n",
              "      <td>0.526800</td>\n",
              "      <td>0.815638</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=2036, training_loss=0.660542741037305, metrics={'train_runtime': 244.8804, 'train_samples_per_second': 133.028, 'train_steps_per_second': 8.314, 'total_flos': 3279457621659648.0, 'train_loss': 0.660542741037305, 'epoch': 4.0})"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SrfByNQgPp-F"
      },
      "source": [
        "# Eval\n",
        "- If you save the model to the output_dir folder, the training code above will automatically save the model to output_dir/checkpoint-{save_step} (in my case: out/checkpoint-2036). We will load the model from this folder:\n",
        "  - I calculate _id = save_step * num_epoch = 509 * 4 = 2036\n",
        "  - My model will saved at \"{output_dir}/checkpoint-{_id}\"\n",
        "- I use del model, gc.collect() and torch.cuda.empty_cache() to release trained model (save gpu memory).\n",
        "- We load the tokenizer in this folder by passing the saved folder to AutoTokenizer.from_pretrained()\n",
        "- We load the model in this folder by passing the saved folder to AutoModelForCausalLM.from_pretrained"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ev_ekAZwPp-F",
        "outputId": "50e82dd4-f1fc-4940-f797-a4b9583d3d25"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "509\n"
          ]
        }
      ],
      "source": [
        "save_step = len(df_train)//bs//ga_steps*epochs//4\n",
        "print(save_step)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kL-JM0c5Pp-F"
      },
      "outputs": [],
      "source": [
        "import gc\n",
        "\n",
        "del model\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GwtmxQwePp-F",
        "outputId": "f2a33dc1-1133-43b4-c126-8d0cbb646107"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ],
      "source": [
        "from peft import PeftModel, PeftConfig\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import torch\n",
        "\n",
        "_id = save_step*4\n",
        "\n",
        "peft_model_id = f\"{output_dir}/checkpoint-{_id}\"\n",
        "\n",
        "#config = PeftConfig.from_pretrained(peft_model_id)\n",
        "\n",
        "# bnb_config = BitsAndBytesConfig(\n",
        "#     load_in_4bit=True,\n",
        "#     bnb_4bit_use_double_quant=False,\n",
        "#     bnb_4bit_quant_type=\"nf4\",\n",
        "#     bnb_4bit_compute_dtype=torch.float16,\n",
        "# )\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    peft_model_id,\n",
        "    device_map=\"auto\",\n",
        "    #torch_dtype=torch.float16,\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    #quantization_config=bnb_config,\n",
        "    attn_implementation=\"flash_attention_2\",\n",
        "    trust_remote_code=True,\n",
        "    token = 'YOUR TOKEN HERE'\n",
        ")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(f\"{output_dir}/checkpoint-{_id}\",\n",
        "                                          trust_remote_code=True,\n",
        "                                          padding_side='left',\n",
        "                                          token='YOUR TOKEN HERE')\n",
        "\n",
        "# Load the Lora model\n",
        "#model = PeftModel.from_pretrained(model, peft_model_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OoI9aplTPp-F"
      },
      "outputs": [],
      "source": [
        "def create_prompt(input_, output_):\n",
        "    output_ = 'A. Positive' if output_ == 'positive' else 'B. Neutral' if output_ == 'neutral' else 'C. Negative'\n",
        "        #text = f\"### Question: {input__}\\n ### Answer: {example['output'][i]}\"\n",
        "    text = f'''{input_}\n",
        "A. Positive\n",
        "B. Neutral\n",
        "C. Negative\n",
        "\n",
        "The correct answer is'''\n",
        "\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5cmdh1nJPp-F",
        "outputId": "f4cf6167-7dfd-401e-d0fb-4f738eaa47e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The sentiment of this comment: \"món ăn rất ngon\" is\n",
            "A. Positive\n",
            "B. Neutral\n",
            "C. Negative\n",
            "\n",
            "The correct answer is\n"
          ]
        }
      ],
      "source": [
        "sentence = 'món ăn rất ngon'\n",
        "input_ = f'''The sentiment of this comment: \"{sentence}\" is'''\n",
        "prompt = create_prompt(input_, \"\")\n",
        "print(prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t6JCaFRpPp-F",
        "outputId": "74003e1b-e7d0-48a2-db17-2bc77247256a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[   785,  25975,    315,    419,   3980,     25,    330,     76,   3165,\n",
              "         128442, 128323,   7777,    263,      1,    374,    198,     32,     13,\n",
              "          43903,    198,     33,     13,  58694,    198,     34,     13,  50857,\n",
              "            271,    785,   4396,   4226,    374]])"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "inputs = torch.tensor([tokenizer.encode(prompt)])\n",
        "inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V2Y19mDePp-F"
      },
      "outputs": [],
      "source": [
        "tokens = model.generate(\n",
        "    inputs.to(model.device),\n",
        "    max_new_tokens=50,\n",
        "    temperature=0.1,\n",
        "    do_sample=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R_Hs1ZnMPp-F",
        "outputId": "4e88dc3f-c40e-4fdb-a9ad-5cd780872042"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The sentiment of this comment: \"món ăn rất ngon\" is\n",
            "A. Positive\n",
            "B. Neutral\n",
            "C. Negative\n",
            "\n",
            "The correct answer is B. Neutral. The sentence \"Món ăn rất ngon\" is a neutral statement that does not express any positive or negative emotion. It simply describes the taste of the food. Therefore, the correct answer is B. Neutral. The other options\n"
          ]
        }
      ],
      "source": [
        "print(tokenizer.decode(tokens[0], skip_special_tokens=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4b-HB2JoPp-G",
        "outputId": "4683ab28-cedc-4af3-cc29-be7acfd5e883"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The sentiment of this comment: \"món ăn rất ngon\" is\n",
            "A. Positive\n",
            "B. Neutral\n",
            "C. Negative\n",
            "\n",
            "The correct answer is B. Neutral\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:540: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:545: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:562: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "tokens = model.generate(\n",
        "    inputs.to(model.device),\n",
        "    max_new_tokens=3,\n",
        "    temperature=0.1,\n",
        "    do_sample=False\n",
        ")\n",
        "print(tokenizer.decode(tokens[0], skip_special_tokens=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FfCMVAa1Pp-G",
        "outputId": "203712d2-980c-46f3-cd65-bf1c0893e085"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 100.0 0:00:00.057033 0:00:00.057036\n",
            "100 83.16831683168317 0:00:05.577073 0:00:00.055219\n",
            "200 85.57213930348259 0:00:11.058303 0:00:00.055016\n",
            "300 86.37873754152824 0:00:16.540829 0:00:00.054953\n",
            "400 85.785536159601 0:00:22.017137 0:00:00.054906\n",
            "500 85.02994011976048 0:00:27.478177 0:00:00.054847\n",
            "600 85.52412645590682 0:00:32.931648 0:00:00.054795\n",
            "700 85.87731811697576 0:00:38.359632 0:00:00.054721\n",
            "800 86.3920099875156 0:00:43.798719 0:00:00.054680\n",
            "900 86.68146503884573 0:00:49.238808 0:00:00.054649\n",
            "1000 86.41358641358642 0:00:54.686381 0:00:00.054632\n",
            "1100 86.37602179836512 0:01:00.129318 0:00:00.054613\n",
            "1200 85.59533721898418 0:01:05.582372 0:00:00.054606\n",
            "1300 85.62644119907763 0:01:11.016522 0:00:00.054586\n",
            "1400 85.93861527480371 0:01:16.473572 0:00:00.054585\n",
            "1500 85.80946035976015 0:01:21.931103 0:00:00.054584\n",
            "1600 85.63397876327295 0:01:27.374241 0:00:00.054575\n",
            "1700 85.71428571428571 0:01:32.878218 0:00:00.054602\n",
            "1800 85.73014991671293 0:01:38.372731 0:00:00.054621\n",
            "1900 85.84955286691215 0:01:43.813549 0:00:00.054610\n",
            "2000 86.00699650174913 0:01:49.289242 0:00:00.054617\n"
          ]
        }
      ],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "start = datetime.now()\n",
        "\n",
        "prediction = []\n",
        "response = []\n",
        "accuracy = []\n",
        "labels = []\n",
        "\n",
        "for i, x in df_test.iterrows():\n",
        "    sentence = x['sentence']\n",
        "    label = x['sentiment']\n",
        "    input_ = f'''The sentiment of this comment: \"{sentence}\" is'''\n",
        "    prompt = create_prompt(input_, label)\n",
        "\n",
        "    inputs = tokenizer.encode(\n",
        "        prompt,\n",
        "        # add_generation_prompt=True,\n",
        "        return_tensors='pt'\n",
        "    )\n",
        "\n",
        "    tokens = model.generate(\n",
        "        inputs.to(model.device),\n",
        "        max_new_tokens=3,\n",
        "        temperature=0.1,\n",
        "        do_sample=False,\n",
        "        pad_token_id=tokenizer.eos_token_id\n",
        "    )\n",
        "    #break\n",
        "\n",
        "    answer = tokenizer.decode(tokens[0], skip_special_tokens=False).split(\"The correct answer is \")[-1]\n",
        "    answer = 'positive' if 'positive' in answer.lower() else 'negative' if 'negative' in answer.lower() else 'neutral'\n",
        "    prediction.append(answer.lower())\n",
        "    response.append(tokenizer.decode(tokens[0], skip_special_tokens=False))\n",
        "\n",
        "    accuracy.append(prediction[-1] == label)\n",
        "    labels.append(label)\n",
        "\n",
        "    if i % 100 == 0:\n",
        "        print(i, np.array(accuracy).sum()/len(prediction)*100, datetime.now() - start, (datetime.now() - start)/len(prediction))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BubnLYLTPp-G",
        "outputId": "9e294383-7164-4ddf-fd87-b81ed20b7db4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative     0.9797    0.9854    0.9826       686\n",
            "     neutral     0.7533    0.8567    0.8017       670\n",
            "    positive     0.8545    0.7338    0.7896       680\n",
            "\n",
            "    accuracy                         0.8590      2036\n",
            "   macro avg     0.8625    0.8587    0.8579      2036\n",
            "weighted avg     0.8634    0.8590    0.8586      2036\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report, f1_score\n",
        "import sklearn\n",
        "\n",
        "print(sklearn.metrics.classification_report(labels, prediction, digits=4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-2ryAWN0Pp-G"
      },
      "source": [
        "# Check results\n",
        "- I print all sentences have wrong prediction and see that almost cases is bug.\n",
        "- Conclusion, dataset is not clean than finetune LLM can't better than finetune roberta (~89..90%), because roberta will overfit even in test dataset.\n",
        "- In additionally, when I print example: \"món ăn này rất ngon\", we can see that model before finetune work better. Model after finetune only think about school (because finetune dataset is about school) and it don't know about food review. Than I think we only need finetune for special cases and finetune dataset need be clean and large enough."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bzx1V7jhPp-G"
      },
      "outputs": [],
      "source": [
        "df_test['predict'] = prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7QtI_mZxPp-G",
        "outputId": "8c790fb4-664f-4c7d-ccf4-9c13ea08e3a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Giảng viên luôn đồng hành với sinh viên trên quá trình học tập. positive neutral\n",
            "Tôi có thể ứng dụng các kiến thức có được từ chương trình đào tạo vào công việc của mình. neutral positive\n",
            "Trường này giúp tốt cho việc thực hành và phát triển kỹ năng. neutral positive\n",
            "Giảng viên rất tài năng và có nhiều kinh nghiệm trong công tác giảng dạy. positive neutral\n",
            "Được học tập với các giáo viên giàu kinh nghiệm và thực tiễn. positive neutral\n",
            "Nhà hàng và các cửa hàng tiện lợi ở gần trường rất đa dạng và phong phú. neutral positive\n",
            "Các phòng học được trang bị điều hòa giúp sinh viên học tập trong môi trường thoải mái. neutral positive\n",
            "Cô ấy là một giáo viên rất thông minh và chuyên nghiệp. neutral positive\n",
            "Cô ấy thực sự sáng tạo và luôn có ý tưởng mới để đạt được mục tiêu của mình. neutral positive\n",
            "Khu vực ăn uống tại trường cung cấp những món ăn ngon và đa dạng. neutral positive\n",
            "Trường đại học này đóng góp một phần quan trọng trong việc phát triển kinh tế và xã hội địa phương. positive neutral\n",
            "Có nhiều hoạt động ngoại khóa và phong phú cho sinh viên. neutral positive\n",
            "Khu vực đặt máy bán thức uống rất tiện lợi cho sinh viên. neutral positive\n",
            "Phòng gym và hồ bơi đều được quản lý đàng hoàng và luôn sạch sẽ. neutral positive\n",
            "Khu vực chơi game của sinh viên tại trường rất thú vị và sôi động. neutral positive\n",
            "Chương trình học giúp tôi cảm thấy mình có mục tiêu rõ ràng hơn. neutral positive\n",
            "Phòng học được trang bị đầy đủ tiện nghi giúp sinh viên luôn dễ dàng tiếp cận tài liệu và thông tin liên quan. positive neutral\n",
            "Thầy dạy rất chuyên nghiệp và nhiệt tình. neutral positive\n",
            "Đại học này có nhiều hội thảo và khóa tập huấn giúp sinh viên trau dồi kiến thức và kỹ năng. neutral positive\n",
            "Thầy/cô đánh giá và đề xuất những ý kiến xây dựng tích cực giúp sinh viên phát triển hơn. neutral positive\n",
            "Giảng viên rất chân thành và nhiệt tình. neutral positive\n",
            "Giảng viên này có tâm huyết công việc và đam mê với nghề giảng dạy. neutral positive\n",
            "Hệ thống thư viện và tài nguyên học tập rất đầy đủ và tiện lợi. positive neutral\n",
            "Chương trình đào tạo có nhiều tính ứng dụng giúp sinh viên tự tin và thành công trong công việc. neutral positive\n",
            "Trường cần có chính sách hỗ trợ chi phí học tập phù hợp cho sinh viên. neutral negative\n",
            "Thầy cho học sinh một cái nhìn tổng quan về chuyên ngành của mình. neutral positive\n",
            "Phòng sinh hoạt cộng đồng rất thuận tiện cho việc tổ chức các hoạt động sinh viên. neutral positive\n",
            "Chương trình đào tạo rất đa dạng về cả nội dung lẫn hình thức đào tạo. neutral positive\n",
            "Trường đại học cung cấp nhiều chương trình học bổng hỗ trợ cho sinh viên khó khăn kinh tế. neutral positive\n",
            "Giảng viên rất am hiểu và từng bước hướng dẫn sinh viên đi đến thành công. positive neutral\n",
            "Cậu ấy luôn sẵn sàng đóng góp ý kiến và đưa ra giải pháp cho các vấn đề khó khăn trong dự án. neutral positive\n",
            "Tôi cảm thấy học tập tại trường rất tốt cho sự phát triển của bản thân. neutral positive\n",
            "Thầy giải thích cặn kẽ và dễ hiểu. neutral positive\n",
            "Thầy cô giảng dạy đều rất nhiệt tình và có kinh nghiệm trong lĩnh vực đang giảng dạy. neutral positive\n",
            "Có rất nhiều phòng học tại trường để sinh viên có thể lựa chọn và sử dụng. neutral positive\n",
            "Tôi rất ấn tượng với sự trang trí trong trường, chúng tạo cảm giác thoải mái và thư giãn cho sinh viên. positive neutral\n",
            "Cô ấy luôn sẵn sàng giúp đỡ và hỗ trợ người khác. positive neutral\n",
            "Cô ấy là một giảng viên tuyệt vời, có sự tâm huyết và nhiệt huyết trong quá trình giảng dạy. neutral positive\n",
            "Chương trình học rất thú vị và bổ ích. neutral positive\n",
            "Giảng viên giúp tôi hiểu được vấn đề hơn và đưa ra nhiều ví dụ thực tế để áp dụng vào cuộc sống. neutral positive\n",
            "Khu vực ăn uống của trường có nhiều món ăn ngon và đa dạng. neutral positive\n",
            "Trường luôn đề cao hoạt động nghiên cứu khoa học cho sinh viên. neutral positive\n",
            "Giáo viên của tôi dạy lí thuyết và thực hành về quyền sở hữu trí tuệ và bảo vệ nhãn hiệu. neutral positive\n",
            "Chương trình đào tạo giúp tôi phát triển mối quan hệ với các sinh viên khác và các giảng viên. neutral positive\n",
            "Tôi rất thích những khu vực xanh trong trường, chúng tạo cảm giác thoải mái và gần gũi với thiên nhiên. positive neutral\n",
            "Phòng học được bố trí nhiều ánh sáng tự nhiên giúp sinh viên tiết kiệm được điện trong quá trình học tập. neutral positive\n",
            "Trường đề cao tính thời đại và công nghệ vào giáo dục, giúp tôi học được những kiến thức mới nhất. neutral positive\n",
            "Thầy rất tôn trọng quyền lợi và sở thích của học viên. neutral positive\n",
            "Tôi rất đánh giá cao sự chuẩn bị và bố trí của các môn học trong chương trình. neutral positive\n",
            "Chương trình giáo dục giúp tôi hiểu rõ hơn về bản thân và định hướng nghề nghiệp sau này của mình. neutral positive\n",
            "Thư viện đầy đủ sách vở cần thiết. neutral positive\n",
            "Tôi rất hài lòng với chương trình đào tạo vì có cả các môn học ngắn hạn cho sinh viên. neutral positive\n",
            "Các môn học giúp sinh viên phát triển tư duy phản biện và độc lập trong tư duy. neutral positive\n",
            "Anh ta là một người đáng tin cậy và luôn giữ lời hứa của mình. positive neutral\n",
            "Anh ấy rất thấu hiểu và giúp đỡ những người gặp khó khăn. positive neutral\n",
            "Giảng viên có thể sử dụng nhiều phương pháp giảng dạy khác nhau để thu hút sinh viên học tập. neutral positive\n",
            "Thầy giúp đỡ sinh viên định hướng nghề nghiệp và phát triển bản thân. positive neutral\n",
            "Các trung tâm học thuật của trường rất có chuyên môn và giúp tôi hiểu sâu hơn về ngành học của mình. neutral positive\n",
            "Tôi rất thích lối thiết kế và trang trí của trường, nó cực kỳ ấn tượng và sáng tạo. positive neutral\n",
            "Lớp học được đưa ra một cách sinh động, hấp dẫn và đầy đủ kiến thức chuyên môn. positive neutral\n",
            "Thầy cung cấp cho chúng tôi nhiều tài liệu và bài giảng hữu ích. neutral positive\n",
            "Em thấy bạn của mình rất nhanh nhẹn và chăm chỉ học. positive neutral\n",
            "Chương trình đào tạo của trường rất thực tiễn và hữu ích trong cuộc sống hàng ngày. neutral positive\n",
            "Khu vực sinh hoạt của sinh viên được quản lý tốt, an ninh. neutral positive\n",
            "Sạch sẽ negative neutral\n",
            "Cơ hội để thực tập trong một môi trường thực tế. neutral positive\n",
            "Khu giá thể hình của trường là nơi tuyệt vời để tập luyện với đầy đủ các thiết bị cần thiết. neutral positive\n",
            "Chương trình học rất thú vị và đa dạng. neutral positive\n",
            "Đội ngũ giảng viên chuyên nghiệp và thân thiện. neutral positive\n",
            "Được đánh giá công bằng và khách quan. positive neutral\n",
            "Cách đánh giá và phương pháp giảng dạy của trường rất khuyến khích và tạo động lực cho học sinh. neutral positive\n",
            "Thầy giảng dạy rất chu đáo và chuyên nghiệp. neutral positive\n",
            "Giáo viên rất nhiệt tình và giúp đỡ sinh viên trong quá trình học tập. positive neutral\n",
            "Anh ấy là người có tài năng và luôn cố gắng hoàn thành mọi việc tốt nhất. neutral positive\n",
            "Bạn của tôi là người rất duyên dáng và sành điệu. positive neutral\n",
            "Các phòng thí nghiệm của trường đầy đủ các thiết bị cần thiết cho việc nghiên cứu. neutral positive\n",
            "Thầy luôn đưa ra những ví dụ cụ thể và minh hoạ để giúp sinh viên hiểu bài tập. neutral positive\n",
            "Môn học giúp tôi học được nhiều kinh nghiệm và kỹ năng cần thiết cho công việc của mình. neutral positive\n",
            "Thầy là một giảng viên rất giỏi trong việc truyền đạt kiến thức và kỹ năng cho sinh viên. positive neutral\n",
            "Thời gian và địa điểm học tập không phù hợp cho một số sinh viên. neutral negative\n",
            "Anh bạn cùng lớp rất hòa đồng và dễ gần. positive neutral\n",
            "Số lượng giáo viên nước ngoài được giảng dạy trong chương trình đào tạo là rất ít. negative neutral\n",
            "Chương trình đào tạo giúp tôi trang bị những kỹ năng mềm cần thiết để thành công trong tương lai. positive neutral\n",
            "Các khu vực tiếp khách của trường được bố trí thông thoáng và chuyên nghiệp. neutral positive\n",
            "Em cảm thấy rất ấn tượng với bạn này vì luôn có câu trả lời chính xác. neutral positive\n",
            "Công nghệ và trang thiết bị của đại học tốt hơn so với nhiều trường khác. positive neutral\n",
            "Giảng viên này dạy rất tốt và truyền cảm hứng cho học sinh. neutral positive\n",
            "Thầy tạo ra môi trường học tập vui vẻ và ấm cúng. positive neutral\n",
            "Trường luôn giữ gìn sạch sẽ và dễ dàng bảo trì hơn nhờ vào các thiết bị trang trí và cơ sở vật chất. positive neutral\n",
            "Thầy khuyến khích sinh viên nghiên cứu và khám phá những thứ mới trong lĩnh vực của mình. neutral positive\n",
            "Cô ấy là người có tài năng đặc biệt và luôn cố gắng vượt qua giới hạn của bản thân. neutral positive\n",
            "Đội ngũ nhân viên của trường rất thân thiện và hỗ trợ tận tình. neutral positive\n",
            "Chương trình giảng dạy rất phù hợp với nhu cầu của sinh viên. neutral positive\n",
            "Thầy cô đề cao các trẻ em trên hết và mang đến cho chúng ta một môi trường học tập khuyến khích và thân thiện. positive neutral\n",
            "Khu vực cho sinh viên tự học khá thoải mái và tiện nghi. neutral positive\n",
            "Các khu vực đặt tủ hồ sơ của trường được bảo quản an toàn và chín chu. neutral positive\n",
            "Tôi cảm thấy rất ấm áp và thoải mái khi sử dụng phòng sinh hoạt chung. positive neutral\n",
            "Giảng viên cập nhật thông tin nhanh chóng và có hiểu biết sâu về thực tế của ngành học. positive neutral\n",
            "Tôi cảm thấy rất cảm kích vì giảng viên của mình luôn sẵn sàng giúp đỡ sinh viên trong bất cứ lúc nào. positive neutral\n",
            "Tôi rất hài lòng với các phòng học ở đây. positive neutral\n",
            "Trường có các phòng làm việc và học cùng các buồng tắm rất sạch sẽ và tiện nghi. neutral positive\n",
            "Giúp sinh viên nắm bắt được những quy tắc và đạo đức trong ngành. neutral positive\n",
            "Học tại đây đòi hỏi tôi tính kỷ luật và sự đóng góp sáng tạo. neutral positive\n",
            "Tôi hài lòng với chương trình đào tạo vì đã giúp tôi hiểu rõ hơn về các phương thức học tập khác nhau. neutral positive\n",
            "Thông tin trường được đăng tải đầy đủ và chi tiết. neutral positive\n",
            "Anh ấy là người rất chu đáo và sẵn sàng giúp đỡ người khác. neutral positive\n",
            "Giáo trình được cập nhật thường xuyên và phù hợp với chương trình học của trường. neutral positive\n",
            "Các phòng thí nghiệm của trường được trang bị đầy đủ thiết bị và công nghệ hiện đại. positive neutral\n",
            "Tôi cảm thấy học phí hợp lí với chất lượng đào tạo của trường. neutral positive\n",
            "Chị ấy rất năng động và có khả năng lãnh đạo tốt. neutral positive\n",
            "Trường có nhiều chương trình hỗ trợ cho sinh viên đạt thành tích cao. neutral positive\n",
            "Thầy đã giúp tôi có được nhiều kiến thức quan trọng và kỹ năng cần thiết trong công việc. positive neutral\n",
            "Giáo trình rất thực tiễn và đáp ứng được yêu cầu của công việc hiện nay. positive neutral\n",
            "Các giảng viên rất tận tâm và nhiệt tình trong việc giảng dạy. neutral positive\n",
            "Đội ngũ nhân viên bảo trì trường luôn hỗ trợ và sử dụng các tiện ích tốt nhất. positive neutral\n",
            "Giảng viên của tôi nói rất rõ và dễ nghe, điều này giúp tôi hiểu được môn học của mình nhanh hơn. positive neutral\n",
            "Cơ sở vật chất đầy đủ, tiên tiến. neutral positive\n",
            "Phòng tập gym tốt và đầy đủ dụng cụ. neutral positive\n",
            "Khu vực khuân viên quanh trường xanh tươi, những tin tức, thông báo của trường được phát trực tiếp, rõ ràng, dễ tiếp cận. positive neutral\n",
            "Bài giảng rất rõ ràng và dễ hiểu. neutral positive\n",
            "Cô bạn này rất hiền lành và tốt bụng. positive neutral\n",
            "Chương trình đào tạo rất đa dạng và đầy đủ, giúp sinh viên có thể nắm bắt được nhiều kiến thức khác nhau. neutral positive\n",
            "Giảng viên thường đưa ra những câu hỏi khó để thúc đẩy học sinh nghiên cứu thêm. negative neutral\n",
            "Giờ học của thầy rất hiệu quả và cấu trúc. neutral positive\n",
            "Các bài giảng dễ hiểu và hỗ trợ học tập tốt. positive neutral\n",
            "Những bài giảng của giáo viên rất chi tiết và đầy đủ thông tin. neutral positive\n",
            "Trang thiết bị và phòng học rất tiện nghi và hiện đại. neutral positive\n",
            "Có những bạn khá tàn nhẫn và thường đưa ra các ý kiến không cần thiết trong lớp học. negative neutral\n",
            "Thầy luôn cập nhật kiến thức mới nhất để giảng dạy cho sinh viên. positive neutral\n",
            "Giảng viên này luôn kiểm tra những bài tập tự làm của sinh viên. neutral negative\n",
            "Những trải nghiệm thực tế trong chương trình đào tạo giúp tôi có thêm kinh nghiệm và sẵn sàng cho công việc tương lai. neutral positive\n",
            "Giảng viên rất tinh tế khi đưa ra các bài giảng sâu sắc. neutral positive\n",
            "Chương trình giảng dạy kết hợp giữa lý thuyết và thực hành tốt. neutral positive\n",
            "Thầy dạy cho sinh viên cách suy nghĩ đa chiều và phân tích dữ liệu một cách nâng cao. positive neutral\n",
            "Thầy đưa ra những tài liệu và thí nghiệm thực tế để giúp học sinh học tập tốt hơn. neutral positive\n",
            "Thiết bị và phương tiện giảng dạy của trường cần được nâng cấp. neutral negative\n",
            "Thầy rất quan tâm đến sự phát triển của từng học sinh. neutral positive\n",
            "Giảng viên rất dễ tiếp cận và thân thiện, dễ tạo được môi trường học tập tích cực. positive neutral\n",
            "Trường không thường xuyên cập nhật các video giảng dạy và tài nguyên giáo dục cho sinh viên. neutral negative\n",
            "Anh ta là người rất năng động và luôn tạo động lực cho người khác. positive neutral\n",
            "Các kiến thức được truyền đạt rõ ràng và dễ tiếp thu. positive neutral\n",
            "Cô bạn này là người rất học hỏi và muốn nỗ lực để cải thiện bản thân. neutral positive\n",
            "Các hoạt động đối ngoại của trường đa dạng và hấp dẫn cho sinh viên. neutral positive\n",
            "Cô ấy rất tận tâm và nhiệt tình giúp đỡ các bạn trong lớp. neutral positive\n",
            "Giảng đường rộng rãi và sạch sẽ. neutral positive\n",
            "Cô giáo của tôi là người rất thông thái và giàu kinh nghiệm. positive neutral\n",
            "Nội dung học phong phú, đa dạng và cập nhật. positive neutral\n",
            "Các khu vực phục vụ sinh viên được phủ sóng wifi giúp cho sinh viên có thể ra ngoài để học tập hoặc giải trí. neutral positive\n",
            "Giảng viên rất thông minh và có kiến thức sâu rộng. positive neutral\n",
            "Tôi cảm thấy giảng viên này luôn đặt sự cần thăm dò trước khi đưa ra quyết định trong bài giảng. negative neutral\n",
            "Anh ấy là một người rất đáng tin cậy, luôn luôn giữ lời hứa. positive neutral\n",
            "Thầy dạy rất thông minh và tập trung vào việc giảng dạy cho học sinh hiểu bài học. neutral positive\n",
            "Giáo viên của tôi hướng dẫn sinh viên thực hiện các nghiên cứu thị trường và đánh giá sản phẩm. neutral positive\n",
            "Thư viện trường có nhiều chủ đề khác nhau giúp sinh viên tìm được nguồn tài liệu phù hợp với nhu cầu học tập của mình. neutral positive\n",
            "Tôi rất hài lòng với các dịch vụ hỗ trợ của trường, đặc biệt là các dịch vụ tư vấn và tài chính. positive neutral\n",
            "Thầy chú trọng đến sự tiến bộ của từng học sinh, không chỉ lớp học nói chung. neutral positive\n",
            "Anh ta có tính cách điềm đạm và không bao giờ hoảng loạn. negative positive\n",
            "Các hoạt động ngoại khóa của trường đa dạng và hấp dẫn cho người tham gia. neutral positive\n",
            "Thầy cung cấp cho sinh viên các tài nguyên và công cụ hỗ trợ giảng dạy hiệu quả. neutral positive\n",
            "Thầy là người giảng dạy giỏi nhất mà tôi từng gặp. positive neutral\n",
            "Sân bóng của trường rất đẹp và có sự bảo trì tốt. neutral positive\n",
            "Trường cung cấp đầy đủ các thông tin và tài liệu cho sinh viên để giúp tôi học tập một cách hiệu quả. neutral positive\n",
            "Trường có cung cấp wifi miễn phí cho sinh viên, giúp các em tiện lợi hơn trong việc truy cập internet. positive neutral\n",
            "Có rất nhiều cơ hội để bạn phát triển năng lực không chỉ trong lớp học mà còn ngoài đời thực. positive neutral\n",
            "Giảng viên này đưa ra những bài giảng rõ ràng và hấp dẫn, giúp cho học sinh hiểu bài học dễ dàng hơn. neutral positive\n",
            "Giảng viên dạy rất có tâm, tận tình giúp đỡ sinh viên khi cần. positive neutral\n",
            "Cô bạn này là một giảng viên tuyệt vời, luôn hỗ trợ và giúp đỡ sinh viên. positive neutral\n",
            "Tôi rất thích cách mà chương trình đào tạo được tổ chức và quản lý. positive neutral\n",
            "Chương trình tiên tiến chưa được triển khai rộng rãi cho sinh viên. negative neutral\n",
            "Ký túc xá của trường rất tiện nghi và sạch sẽ. positive neutral\n",
            "Giảng viên luôn tạo điều kiện để sinh viên có thể tự tìm hiểu và tốt hơn trong học tập. neutral positive\n",
            "Chị ấy có khả năng làm việc nhóm tốt và tạo ra một môi trường hợp tác tốt nhất cho tất cả mọi người. neutral positive\n",
            "Chương trình học tập đáp ứng được những yêu cầu của nghề nghiệp. neutral positive\n",
            "Sinh viên được hỗ trợ tìm kiếm việc làm sau khi tốt nghiệp. neutral positive\n",
            "Có nhiều vấn đề về thiết bị và hệ thống mạng trong các phòng học. negative neutral\n",
            "Bạn của tôi là người rất năng động và luôn có những ý tưởng mới lạ. positive neutral\n",
            "Các phòng học được trang bị đầy đủ những tiện ích cần thiết cho việc học tập của sinh viên. neutral positive\n",
            "Thầy rất nhiệt tình với các câu hỏi của sinh viên. neutral positive\n",
            "Trường đại học này là nơi lý tưởng để giao lưu và kết nối với những người bạn mới. positive neutral\n",
            "Tôi thích cách chương trình đào tạo được xây dựng để giúp sinh viên phát triển toàn diện hơn. neutral positive\n",
            "Trường hỗ trợ sinh viên đăng ký tham gia các kỳ thi chứng chỉ và đào tạo khác. neutral positive\n",
            "Cơ sở vật chất tại đại học này đáp ứng tốt nhu cầu học tập của sinh viên. neutral positive\n",
            "Sinh viên được tham gia vào các dự án nghiên cứu thực tế. neutral positive\n",
            "Môn học không phù hợp với chuyên ngành cụ thể và độ khó quá cao. negative neutral\n",
            "Anh ấy có trí thông minh sáng suốt và sự nghiệp của anh ấy tuyệt vời. positive neutral\n",
            "Sự đa dạng của chương trình đào tạo giúp tăng tính linh hoạt cho sinh viên. neutral positive\n",
            "Thầy có khả năng dạy học đa dạng để phù hợp với các học sinh có nền tảng kém. neutral positive\n",
            "Thầy thường tạo ra các hoạt động nhóm để tăng cường tương tác giữa học viên và học viên. neutral positive\n",
            "Bạn sẽ không thể tìm thấy một giảng viên tốt hơn ở bất kỳ nơi nào khác. negative positive\n",
            "Anh ấy là một người rất tận tâm với công việc và gia đình. neutral positive\n",
            "Giảng viên rất thông minh và am hiểu chuyên ngành. positive neutral\n",
            "Các phòng học và phòng thí nghiệm trong trường được trang bị đầy đủ thiết bị để đảm bảo chất lượng học tập. positive neutral\n",
            "Giảng viên là một người có tác phong và phong cách giảng dạy rất chuyên nghiệp. neutral positive\n",
            "Giảng viên này thường đồng ý với ý kiến của những sinh viên giàu kinh nghiệm. neutral negative\n",
            "Giảng viên rất trung thành với vai trò của mình và giảng dạy rất chính xác. neutral positive\n",
            "Giáo viên không thường xuyên đánh giá quá trình học tập của sinh viên. neutral negative\n",
            "Chương trình đào tạo giúp tôi có cơ hội gặp gỡ và học hỏi từ những người có kinh nghiệm trong lĩnh vực tôi quan tâm. neutral positive\n",
            "Chương trình đào tạo rất chuyên nghiệp. neutral positive\n",
            "Sau khi tốt nghiệp, sinh viên có thể có nhiều cơ hội việc làm tốt trong lĩnh vực của mình. neutral positive\n",
            "Không giới hạn về thời gian học tập. neutral positive\n",
            "Đội ngũ giảng dạy của trường là những giáo sư rất tận tình và nhiệt tình. neutral positive\n",
            "Các phòng học được cải tạo định kỳ để đáp ứng nhu cầu học tập của sinh viên. neutral positive\n",
            "Chương trình học phù hợp với yêu cầu của thị trường và đáp ứng được nhu cầu của học viên. neutral positive\n",
            "Khuôn viên trường rộng lớn và được bố trí hợp lí. neutral positive\n",
            "Các căn tin ở đây rất ngon và giá cả phải chăng. positive neutral\n",
            "Học phí được chia theo các kỳ học, giúp sinh viên dễ dàng toàn tâm toàn ý với từng kỳ học. neutral positive\n",
            "Tôi cảm thấy chương trình học không thực sự đáp ứng được nhu cầu ngành nghề hiện tại. neutral negative\n",
            "Học phí được giảm giá cho những sinh viên đăng ký sớm. neutral positive\n",
            "Thầy này tổ chức và quản lý giảng dạy rất tốt. neutral positive\n",
            "Giảng viên này quá đòi hỏi cao về điểm số và đôi khi làm khó học sinh. negative neutral\n",
            "Tôi rất yêu thích không gian của thư viện và các dịch vụ bổ trợ tại đây. positive neutral\n",
            "Thầy rất trung thực và chính trực trong giảng dạy. neutral positive\n",
            "Chương trình học rất linh hoạt và có thể phù hợp với nhu cầu của từng sinh viên. neutral positive\n",
            "Môn học giúp tôi trau dồi kiến thức chuyên môn và kinh nghiệm thực tiễn. neutral positive\n",
            "Giảng viên này không giúp được học sinh đạt được những mục tiêu của họ. negative neutral\n",
            "Ký túc xá của trường có các dịch vụ tiện ích như tập gym và quầy cà phê. neutral positive\n",
            "Các giảng viên của trường rất có kinh nghiệm và giỏi chuyên môn. neutral positive\n",
            "Thầy hỗ trợ sinh viên trong việc giải quyết các vấn đề học thuật và cá nhân. neutral positive\n",
            "Đội ngũ nhân viên ở đây luôn hỗ trợ và đáp ứng mọi nhu cầu của sinh viên. positive neutral\n",
            "Tôi hướng đến mục tiêu của bản thân với sự giúp đỡ của giảng viên. neutral positive\n",
            "Thầy luôn đưa ra những câu hỏi thú vị để khuyến khích sự tò mò của sinh viên. neutral positive\n",
            "Tôi đã được trang bị đầy đủ các tài liệu thư viện cần thiết để học tập và làm bài tập. positive neutral\n",
            "Phòng thí nghiệm ở trường được trang bị đầy đủ thiết bị và máy móc. positive neutral\n",
            "Đội ngũ giáo viên có nhiều tri thức và kinh nghiệm giúp sinh viên nắm vững kiến thức chuyên môn. neutral positive\n",
            "Các phòng học được đánh giá là không gian rộng rãi và thoải mái. neutral positive\n",
            "Những kiến thức tôi học được trong chương trình học rất bổ ích cho công việc của tôi sau này. positive neutral\n",
            "Giáo viên chuyên để ý đến những sinh viên xuất sắc, bỏ quên những sinh viên yếu kém. neutral negative\n",
            "Thầy cô luôn gần gũi và dễ tiếp cận với các sinh viên. positive neutral\n",
            "Bạn của tôi rất cởi mở và dễ thương với mọi người. positive neutral\n",
            "Thầy giúp sinh viên trau dồi kỹ năng mềm, rèn luyện kỹ năng thuyết trình và thuyết phục. neutral positive\n",
            "Giảng viên giúp sinh viên phát triển và rèn luyện kỹ năng sáng tạo. positive neutral\n",
            "Thầy là một giảng viên rất thân thiện và luôn sẵn sàng trợ giúp sinh viên. neutral positive\n",
            "Thầy cũng là một người đồng hành và lắng nghe những khó khăn của sinh viên. neutral positive\n",
            "Hội trường lớn và được trang bị đầy đủ hệ thống âm thanh và chiếu sáng. neutral positive\n",
            "Cô ấy rất cẩn thận và chú ý đến chi tiết nhỏ nhất. neutral positive\n",
            "Phòng học được trang bị sản phẩm đánh giá như máy chiếu, máy tính, tivi, loa, đệm ngồi, ... positive neutral\n",
            "Các hoạt động giáo dục khá đa dạng và phong phú. neutral positive\n",
            "Các bài kiểm tra được thiết kế tốt và công bằng. neutral positive\n",
            "Thầy luôn dạy sinh viên cách tư duy và phát triển kỹ năng. positive neutral\n",
            "Cơ sở vật chất tốt và được cập nhật liên tục. neutral positive\n",
            "Tôi rất thích khung giờ học có sắp xếp phù hợp với lịch trình của sinh viên. neutral positive\n",
            "Giảng viên này đôi lúc quên chuyện chính để giải thích những chi tiết không quan trọng. negative neutral\n",
            "Lớp học được tổ chức khoa học, hỗ trợ sinh viên không chỉ giúp học mà còn giúp sinh viên rèn luyện kỹ năng quản lý thời gian. positive neutral\n",
            "Trường cung cấp rất nhiều thiết bị và phần mềm hữu ích cho việc học tập và nghiên cứu. neutral positive\n",
            "Giảng viên rất thân thiện và có tư duy phản biện cao. neutral positive\n",
            "Cô ấy có khả năng đưa ra quyết định một cách đúng đắn và hiệu quả. neutral positive\n",
            "Anh ấy là một người tài năng và có tinh thần tự thách thức bản thân. neutral positive\n",
            "Các giảng viên đều rất am hiểu trong lĩnh vực của mình. neutral positive\n",
            "Thư viện của trường có không gian yên tĩnh, tạo cảm giác thư thái giúp sinh viên tập trung nghiên cứu. neutral positive\n",
            "Tôi rất ấn tượng với phong cách giảng dạy của giảng viên và cách anh ấy truyền đạt kiến thức. neutral positive\n",
            "Giáo trình rất thú vị và độc đáo, giúp tôi học được nhiều thứ mới lạ. positive neutral\n",
            "Khuôn viên đất nền rộng rãi và khá yên tĩnh. neutral positive\n",
            "Nhiều cơ hội được thực tập từ các doanh nghiệp nổi tiếng. neutral positive\n",
            "Giảng viên này đưa ra những giải pháp đột phá và sáng tạo cho việc học tập. neutral positive\n",
            "Thầy truyền cảm hứng và động viên các sinh viên có hoàn cảnh khó khăn. positive neutral\n",
            "Nội dung bài học trực quan và hấp dẫn. positive neutral\n",
            "Khu vực ngồi tập trung và làm việc của trường rất tốt cho việc học tập tập trung. neutral positive\n",
            "Hệ thống giáo trình hỗ trợ các sinh viên có thể tiếp cận và tìm hiểu về ngành nghề của mình một cách hiệu quả. positive neutral\n",
            "Sự đa dạng về các môn học giúp mình lựa chọn và cập nhật kiến thức mới. neutral positive\n",
            "Các phòng học được trang bị máy chiếu đầy đủ giúp giảng viên giảng dạy tốt hơn. neutral positive\n",
            "Giảng viên này đưa ra các ví dụ rất thực tế và hữu ích để giúp tôi hiểu bài học. neutral positive\n",
            "Cơ sở vật chất của trường rất tiên tiến và thích hợp cho việc học tập và nghiên cứu. neutral positive\n",
            "Giáo viên luôn giải đáp thắc mắc của sinh viên rõ ràng và chi tiết. positive neutral\n",
            "Phòng học được trang bị đầy đủ các thiết bị cần thiết cho việc học tập. neutral positive\n",
            "Tôi rất hài lòng với chương trình học nơi đây. positive neutral\n",
            "Cô ấy có phong cách dạy học vô cùng sáng tạo và thú vị. positive neutral\n",
            "Có rất nhiều nguồn tài nguyên hỗ trợ học viên trong quá trình học tập. neutral positive\n",
            "Anh ta luôn có tinh thần học hỏi và mở đầu với những kiến thức mới. positive neutral\n",
            "Các buổi học được tổ chức chặt chẽ và có sự chuẩn bị kỹ lưỡng. neutral positive\n",
            "Có rất nhiều bạn học tốt và tích cực tham gia vào các hoạt động của trường. positive neutral\n",
            "Anh ta là một giảng viên rất tận tâm và sáng tạo. neutral positive\n",
            "Phòng giáo viên đủ tiện nghi, thoải mái. neutral positive\n",
            "Cậu bạn này rất thân thiện và hòa đồng. neutral positive\n",
            "Giảng viên rất đáng kính và được sinh viên yêu mến đặc biệt. positive neutral\n",
            "Thầy rất năng động, giúp sinh viên tập trung vào học tập một cách hiệu quả. positive neutral\n",
            "Giảng viên này tạo ra một môi trường học tập vui nhộn và hấp dẫn. neutral positive\n",
            "Giáo viên luôn đặt mình vào tâm trạng và khó khăn của học sinh. neutral positive\n",
            "Chất lượng giảng dạy của trường tôi rất tốt trong đó giáo viên là một phần quan trọng. neutral positive\n",
            "Giảng viên mang lại kinh nghiệm thực tế cho học sinh. neutral positive\n",
            "Hệ thống rạp chiếu phim và trung tâm giải trí nâng cao sinh hoạt văn hóa cho sinh viên. positive neutral\n",
            "Anh ấy rất hiểu biết và luôn giữ lời hứa. neutral positive\n",
            "Tài liệu học tập nhiệt tình và đầy trải nghiệm thực tế. positive neutral\n",
            "Các bài học được thiết kế tối ưu cho việc học trực tuyến. neutral positive\n",
            "Các khu vực cấm hút thuốc được thiết kế và bố trí để đảm bảo không khí trong lành. neutral positive\n",
            "Tôi cảm thấy rất tiếc khi thời gian học tập tại trường của tôi kết thúc. negative positive\n",
            "Thầy rèn luyện cho học sinh động não và tưởng tượng. neutral positive\n",
            "Giảng viên này không nhàm chán. neutral negative\n"
          ]
        }
      ],
      "source": [
        "for i, row in df_test.iterrows():\n",
        "    if row['predict'] != row['sentiment']:\n",
        "        print(row['sentence'], row['predict'], row['sentiment'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "alPdHiviPp-G"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3JYDJHIVPp-G"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "datasetId": 3052448,
          "sourceId": 5245967,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30733,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}