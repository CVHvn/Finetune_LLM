{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "id": "yU5pew3JPp92"
      },
      "source": [
        "# Install library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vfeJBfXaPp93",
        "outputId": "9387b180-3fd1-4bda-bbd2-2fe61050b351"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -q datasets==2.16.0\n",
        "!pip install -q bitsandbytes\n",
        "!pip install -q tiktoken\n",
        "!pip install -q peft\n",
        "!pip install -q trl\n",
        "!pip install -q transformers\n",
        "!pip install -q openpyxl\n",
        "!pip install -q pandas\n",
        "!pip install -q scikit-learn\n",
        "!pip install -q flash-attn\n",
        "#pip install -q transformers==4.38.1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "am10Rh0SPp94"
      },
      "source": [
        "# Import library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_QAtldoFPp94"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
        "import torch\n",
        "from accelerate import PartialState\n",
        "from peft import LoraConfig, PeftModel, prepare_model_for_kbit_training, get_peft_model\n",
        "from trl import SFTTrainer\n",
        "from peft import prepare_model_for_kbit_training\n",
        "from transformers import TrainingArguments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C7txKefVPp94"
      },
      "source": [
        "# Hyperparameters\n",
        "I use lr = 2e-4 when finetune with lora and qlora. But when finetune full model, I need to use lower lr (2e-5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kH_z1f3-Pp95"
      },
      "outputs": [],
      "source": [
        "modelpath = \"Qwen/Qwen2-0.5B-Instruct\"\n",
        "lr=2e-5      # learning rate\n",
        "bs=16            # batch size\n",
        "bs_eval=16      # batch size for evals\n",
        "ga_steps=1     # gradient acc. steps\n",
        "epochs=4\n",
        "max_length=128      # max. sample length with 24GB VRAM\n",
        "output_dir=\"out\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SHHGvL_MPp95"
      },
      "source": [
        "# Remove old model\n",
        "Because of limited storage, we can't save all models, we need to delete all models in cache by the following code:\n",
        "- rm -r out: delete out folder (because I save finetuned model in out folder), you can change folder name like (rm -r output_folder). If you doesn't have out folder, this commend do not thing.\n",
        "- all pretrained huggingface models will auto save in transformers.TRANSFORMERS_CACHE. I use shutil.rmtree to delete them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vr2eGkQ5Pp95"
      },
      "outputs": [],
      "source": [
        "!rm -r out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K-MrnwRaPp95"
      },
      "outputs": [],
      "source": [
        "# from transformers import TRANSFORMERS_CACHE\n",
        "# print(TRANSFORMERS_CACHE)\n",
        "\n",
        "# import shutil\n",
        "# shutil.rmtree(TRANSFORMERS_CACHE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7q8zxh1NPp95"
      },
      "source": [
        "# Create Dataset\n",
        "Download dataset from [kaggle synthetic-vietnamese-students-feedback-corpus](https://www.kaggle.com/datasets/toreleon/synthetic-vietnamese-students-feedback-corpus/data)\n",
        "\n",
        "We need convert DataFrame to json line (jsonl)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y2Mc8yF0Pp95"
      },
      "outputs": [],
      "source": [
        "df_train = pd.read_csv(\"synthetic_train.csv\")\n",
        "df_test = pd.read_csv(\"synthetic_val.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FVS2hClZPp96",
        "outputId": "0ed2cad2-84c1-4402-ac39-03a32608a9b1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>topic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ƒê·ªôi ng≈© b·∫£o tr√¨ qu√° th∆∞a th·ªõt d·∫´n ƒë·∫øn kh√¥ng ƒë·∫£...</td>\n",
              "      <td>negative</td>\n",
              "      <td>facility</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The university's musical and artistic faciliti...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>facility</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Ph∆∞∆°ng ph√°p gi·∫£ng d·∫°y ph√π h·ª£p v·ªõi c√°c ƒë·ªëi t∆∞·ª£n...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>curriculum</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Ch∆∞∆°ng tr√¨nh h·ªçc gi√∫p t√¥i tr·ªü th√†nh m·ªôt chuy√™n...</td>\n",
              "      <td>positive</td>\n",
              "      <td>curriculum</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>T√¥i nghƒ© r·∫±ng ch∆∞∆°ng tr√¨nh ƒë√†o t·∫°o c√≥ th·ªÉ c√≥ t...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>curriculum</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            sentence sentiment       topic\n",
              "0  ƒê·ªôi ng≈© b·∫£o tr√¨ qu√° th∆∞a th·ªõt d·∫´n ƒë·∫øn kh√¥ng ƒë·∫£...  negative    facility\n",
              "1  The university's musical and artistic faciliti...   neutral    facility\n",
              "2  Ph∆∞∆°ng ph√°p gi·∫£ng d·∫°y ph√π h·ª£p v·ªõi c√°c ƒë·ªëi t∆∞·ª£n...   neutral  curriculum\n",
              "3  Ch∆∞∆°ng tr√¨nh h·ªçc gi√∫p t√¥i tr·ªü th√†nh m·ªôt chuy√™n...  positive  curriculum\n",
              "4  T√¥i nghƒ© r·∫±ng ch∆∞∆°ng tr√¨nh ƒë√†o t·∫°o c√≥ th·ªÉ c√≥ t...   neutral  curriculum"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AabWpKXiPp96",
        "outputId": "09ad5fc3-39a1-40ee-da3b-812c65f71b4b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>topic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Ch·∫•t l∆∞·ª£ng v·∫≠t ch·∫•t k√©m.</td>\n",
              "      <td>negative</td>\n",
              "      <td>facility</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Ph·∫ßn m·ªÅm h·ªçc t·∫≠p qu√° kh√≥ s·ª≠ d·ª•ng, khi·∫øn sinh v...</td>\n",
              "      <td>negative</td>\n",
              "      <td>facility</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Tr∆∞·ªùng t√¥i thi·∫øu nh·ªØng ti·ªán √≠ch c∆° b·∫£n nh∆∞ m√°y...</td>\n",
              "      <td>negative</td>\n",
              "      <td>facility</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>C·∫ßn t·∫°o th√™m c√°c ho·∫°t ƒë·ªông g·∫Øn k·∫øt gi·ªØa sinh v...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>curriculum</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>H·ªç r·∫•t khoan dung v√† l∆∞·ª£ng gi√°c trong quan ƒëi·ªÉ...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>others</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            sentence sentiment       topic\n",
              "0                           Ch·∫•t l∆∞·ª£ng v·∫≠t ch·∫•t k√©m.  negative    facility\n",
              "1  Ph·∫ßn m·ªÅm h·ªçc t·∫≠p qu√° kh√≥ s·ª≠ d·ª•ng, khi·∫øn sinh v...  negative    facility\n",
              "2  Tr∆∞·ªùng t√¥i thi·∫øu nh·ªØng ti·ªán √≠ch c∆° b·∫£n nh∆∞ m√°y...  negative    facility\n",
              "3  C·∫ßn t·∫°o th√™m c√°c ho·∫°t ƒë·ªông g·∫Øn k·∫øt gi·ªØa sinh v...   neutral  curriculum\n",
              "4  H·ªç r·∫•t khoan dung v√† l∆∞·ª£ng gi√°c trong quan ƒëi·ªÉ...   neutral      others"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_test.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bC32qiigPp96",
        "outputId": "01d95742-a72d-4a25-e7be-0ec50803d870"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "sentiment\n",
              "neutral     2724\n",
              "negative    2711\n",
              "positive    2709\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train.sentiment.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wSF_cH33Pp96",
        "outputId": "b001325c-a334-454f-9b3e-e915a08b09eb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "sentiment\n",
              "negative    686\n",
              "positive    680\n",
              "neutral     670\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_test.sentiment.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y5CLsiOiPp96"
      },
      "outputs": [],
      "source": [
        "df_train['len'] = df_train.sentence.apply(lambda x: len(str(x).split()))\n",
        "df_test['len'] = df_test.sentence.apply(lambda x: len(str(x).split()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0HJm2q1mPp96",
        "outputId": "a9e18199-3a1c-446f-b264-ac737054c66f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "count    8144.000000\n",
              "mean       15.549730\n",
              "std         5.018764\n",
              "min         3.000000\n",
              "25%        12.000000\n",
              "50%        15.000000\n",
              "75%        18.000000\n",
              "max        43.000000\n",
              "Name: len, dtype: float64"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train['len'].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pc8NW1fOPp97",
        "outputId": "2226aa53-e251-45c3-e656-9be55dc8b1c1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "count    2036.000000\n",
              "mean       15.694990\n",
              "std         5.185957\n",
              "min         2.000000\n",
              "25%        12.000000\n",
              "50%        15.000000\n",
              "75%        19.000000\n",
              "max        48.000000\n",
              "Name: len, dtype: float64"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_test['len'].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Kwf9AdGPp97"
      },
      "outputs": [],
      "source": [
        "with open('train.jsonl', 'w') as outfile:\n",
        "    for i, x in df_train.iterrows():\n",
        "        comment = x['sentence']\n",
        "        label = x['sentiment']\n",
        "        #label = 'yes' if label == 'relevance' else 'no'\n",
        "        data = {\n",
        "            \"input\": f'''The sentiment of this comment \"{comment}\" is''',\n",
        "            \"output\": f\"{label}\"\n",
        "        }\n",
        "        json.dump(data, outfile)\n",
        "        outfile.write('\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E7emtCskPp97"
      },
      "outputs": [],
      "source": [
        "with open('test.jsonl', 'w') as outfile:\n",
        "    for i, x in df_test.iterrows():\n",
        "        comment = x['sentence']\n",
        "        label = x['sentiment']\n",
        "        #label = 'yes' if label == 'relevance' else 'no'\n",
        "        data = {\n",
        "            \"input\": f'''The sentiment of this comment \"{comment}\" is''',\n",
        "            \"output\": f\"{label}\"\n",
        "        }\n",
        "        json.dump(data, outfile)\n",
        "        outfile.write('\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "8ca0237a02954dd89365424f5f5ae21c",
            "12ad64f581094b85a1630844f9b640ad"
          ]
        },
        "id": "VTQgkNdUPp97",
        "outputId": "b6da5aa5-fa2d-4699-b846-827949177caf"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8ca0237a02954dd89365424f5f5ae21c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "12ad64f581094b85a1630844f9b640ad",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating validation split: 0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "data_files = {\n",
        "    \"train\": \"train.jsonl\",\n",
        "    \"validation\": \"test.jsonl\",\n",
        "}\n",
        "\n",
        "dataset = load_dataset(\"json\", data_files=data_files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BAv2BtPuPp97",
        "outputId": "04e8f378-23ff-4d33-bffa-9a1a4c42906c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['input', 'output'],\n",
              "        num_rows: 8144\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['input', 'output'],\n",
              "        num_rows: 2036\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GqsLC_PUPp97"
      },
      "source": [
        "# Create prompt format\n",
        "Load tokenizer by AutoTokenizer.from_pretrained:\n",
        "- We need create and copy YOUR TOKEN from [huggingface](https://huggingface.co/settings/tokens)\n",
        "- We need use padding_side = 'right' because training library need padding_side = 'right' when training. You can use left padding but you need to make sure the library is not corrupted and check whether performance is affected by left padding!\n",
        "- If you have 1 prompt like \"test th·ª≠ m√¥ h√¨nh\" and want to tokenize it, just you tokenizer(prompt, return_tensors=\"pt\"). You can see output of tokenizer in cell below (output includes input_ids (list index of each token in prompt) and attention mask)\n",
        "- We can use tokenizer.batch_decode to see how tokenizer restore string from token tensor. You can see that it automatically adds the start token \"<bos>\" at the beginning of the string.\n",
        "- To train llm, we only need to pass 1 sentence to llm (including input and desired output) without specifying which is the input and which is the output.\n",
        "- I wrote the function formatting_prompts_func to convert input and output to prompt and tested this function, you can see below.\n",
        "- When predicting, remove the output part to let the model predict itself. See the predict section below later.\n",
        "- we only need to predict some next tokens like A. positive, and B. neutral. We don't care what the model says after sentiment. Then we do not need to add <eos token>. If you fine-tune the model with other tasks, maybe you need to add <eos token> at the end of the prompt:\n",
        "  - use tokenizer.eos_token, tokenizer.eos_token_id to see eos_token of your model and correspond id\n",
        "  - for ex: eos_token is \"<|im_end|>\". You need edit prompt like:\n",
        "    - '''...The correct answer is {output_}.''' --> '''...The correct answer is {output_}. <|im_end|>'''\n",
        "  - for ex: eos_token is \"end_token__\". You need edit prompt like:\n",
        "    - '''...The correct answer is {output_}.''' --> '''...The correct answer is {output_}. end_token__'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q_uakl-iPp97",
        "outputId": "ee316644-fb69-4016-b6e3-b2e2d125253f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    modelpath,\n",
        "    padding_side=\"right\",\n",
        "    # add_eos_token=True,\n",
        "    # add_bos_token=True,\n",
        "    trust_remote_code=True,\n",
        "    token = 'YOUR TOKEN HERE'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ECELpocPp98",
        "outputId": "3c181a90-a4ad-4958-90bd-344dff056445"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_ids': tensor([[  1944, 131885, 130179, 128338]]), 'attention_mask': tensor([[1, 1, 1, 1]])}\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['test', ' th·ª≠', ' m√¥', ' h√¨nh']"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prompt = \"test th·ª≠ m√¥ h√¨nh\"\n",
        "tokens = tokenizer(prompt, return_tensors=\"pt\")\n",
        "print(tokens)\n",
        "tokenizer.batch_decode(tokenizer.encode(prompt))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KXIWCL5-Pp-B"
      },
      "outputs": [],
      "source": [
        "def formatting_prompts_func(example):\n",
        "    output_texts = []\n",
        "    for i in range(len(example['input'])):\n",
        "        input_ = example['input'][i]\n",
        "        output_ = example['output'][i]\n",
        "        output_ = 'A. Positive' if output_ == 'positive' else 'B. Neutral' if output_ == 'neutral' else 'C. Negative'\n",
        "        #text = f\"### Question: {input__}\\n ### Answer: {example['output'][i]}\"\n",
        "        text = f'''{input_}\n",
        "A. Positive\n",
        "B. Neutral\n",
        "C. Negative\n",
        "\n",
        "The correct answer is {output_}.'''\n",
        "\n",
        "        output_texts.append(text)\n",
        "    return output_texts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a-sEHQDMPp-B",
        "outputId": "85c59576-0010-4962-fd13-2a2e52250ace"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('The sentiment of this comment \"Ch·∫•t l∆∞·ª£ng v·∫≠t ch·∫•t k√©m.\" is', 'negative')"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset[\"validation\"]['input'][0], dataset[\"validation\"]['output'][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ts7VuIqMPp-B",
        "outputId": "37f6309d-f0bc-42b0-e6dd-404ff1438c27"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['The sentiment of this comment \"Ch·∫•t l∆∞·ª£ng v·∫≠t ch·∫•t k√©m.\" is\\nA. Positive\\nB. Neutral\\nC. Negative\\n\\nThe correct answer is C. Negative.']"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "formatting_prompts_func({'input': [dataset[\"validation\"]['input'][0]],\n",
        "                         'output': [dataset[\"validation\"]['output'][0]]})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_dL-v47zPp-C",
        "outputId": "d9cc6a0a-5bf2-4225-f3dc-ea0e16fd5a41"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The sentiment of this comment \"Ch·∫•t l∆∞·ª£ng v·∫≠t ch·∫•t k√©m.\" is\n",
            "A. Positive\n",
            "B. Neutral\n",
            "C. Negative\n",
            "\n",
            "The correct answer is C. Negative.\n"
          ]
        }
      ],
      "source": [
        "print(formatting_prompts_func({'input': [dataset[\"validation\"]['input'][0]],\n",
        "                         'output': [dataset[\"validation\"]['output'][0]]})[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2u5Yd0CuPp-C"
      },
      "source": [
        "# Create model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ENncIKmPp-C"
      },
      "source": [
        "## Load model\n",
        "We use AutoModelForCausalLM.from_pretrained to load model:\n",
        "- device_map = 'auto': auto active gpu.\n",
        "- torch_dtype: use bfloat16, if your gpu don't support bfloat16, set it to float32\n",
        "- attn_implementation: you can use 'flash_attention_2', if you meet bug, maybe your gpu doesn't support it, you need delete this line.\n",
        "- token: you huggingface token like tokenizer above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R88-YlykPp-C"
      },
      "outputs": [],
      "source": [
        "# bnb_config = BitsAndBytesConfig(\n",
        "#     load_in_4bit=True,\n",
        "#     bnb_4bit_use_double_quant=True,\n",
        "#     bnb_4bit_quant_type=\"nf4\",\n",
        "#     bnb_4bit_compute_dtype=torch.bfloat16,\n",
        "# )\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    modelpath,\n",
        "    device_map=\"auto\",\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    #torch_dtype=torch.float32,\n",
        "    #quantization_config=bnb_config,\n",
        "    attn_implementation=\"flash_attention_2\",\n",
        "    trust_remote_code=True,\n",
        "    token = 'YOUR TOKEN HERE'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pOGmvwLCPp-C",
        "outputId": "dc4a8961-e0c2-4579-d6f9-9f46251a0980"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Qwen2ForCausalLM(\n",
              "  (model): Qwen2Model(\n",
              "    (embed_tokens): Embedding(151936, 896)\n",
              "    (layers): ModuleList(\n",
              "      (0-23): 24 x Qwen2DecoderLayer(\n",
              "        (self_attn): Qwen2FlashAttention2(\n",
              "          (q_proj): Linear(in_features=896, out_features=896, bias=True)\n",
              "          (k_proj): Linear(in_features=896, out_features=128, bias=True)\n",
              "          (v_proj): Linear(in_features=896, out_features=128, bias=True)\n",
              "          (o_proj): Linear(in_features=896, out_features=896, bias=False)\n",
              "          (rotary_emb): Qwen2RotaryEmbedding()\n",
              "        )\n",
              "        (mlp): Qwen2MLP(\n",
              "          (gate_proj): Linear(in_features=896, out_features=4864, bias=False)\n",
              "          (up_proj): Linear(in_features=896, out_features=4864, bias=False)\n",
              "          (down_proj): Linear(in_features=4864, out_features=896, bias=False)\n",
              "          (act_fn): SiLU()\n",
              "        )\n",
              "        (input_layernorm): Qwen2RMSNorm()\n",
              "        (post_attention_layernorm): Qwen2RMSNorm()\n",
              "      )\n",
              "    )\n",
              "    (norm): Qwen2RMSNorm()\n",
              "  )\n",
              "  (lm_head): Linear(in_features=896, out_features=151936, bias=False)\n",
              ")"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Eval model before training\n",
        "We use create_prompt function to generate prompt (without output), our model will predict output. We will eval model before finetune. You can see some predict below.\n",
        "\n",
        "You can see that pretrained model has poor performance"
      ],
      "metadata": {
        "id": "ezLPfDqxQFZu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TFn30hPZPp-D",
        "outputId": "ab34b75b-955a-4175-e131-c14f9545f452"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:540: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:545: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:562: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.\n",
            "  warnings.warn(\n",
            "The attention mask is not set and cannot be inferred from input because pad token is same as eos token.As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The sentiment of this comment: \"m√≥n ƒÉn r·∫•t ngon\" is\n",
            "A. Positive\n",
            "B. Neutral\n",
            "C. Negative\n",
            "\n",
            "The correct answer is\n",
            "The sentiment of this comment: \"m√≥n ƒÉn r·∫•t ngon\" is\n",
            "A. Positive\n",
            "B. Neutral\n",
            "C. Negative\n",
            "\n",
            "The correct answer is A. Positive.\n",
            "\n",
            "The sentiment of the comment \"m√≥n ƒÉn r·∫•t ngon\" can be interpreted as positive because it expresses satisfaction or approval with the food being described. The word \"ngon\" means good, delicious, or appealing in English.\n"
          ]
        }
      ],
      "source": [
        "def create_prompt(input_, output_):\n",
        "    output_ = 'A. Positive' if output_ == 'positive' else 'B. Neutral' if output_ == 'neutral' else 'C. Negative'\n",
        "        #text = f\"### Question: {input__}\\n ### Answer: {example['output'][i]}\"\n",
        "    text = f'''{input_}\n",
        "A. Positive\n",
        "B. Neutral\n",
        "C. Negative\n",
        "\n",
        "The correct answer is'''\n",
        "\n",
        "    return text\n",
        "\n",
        "sentence = 'm√≥n ƒÉn r·∫•t ngon'\n",
        "input_ = f'''The sentiment of this comment: \"{sentence}\" is'''\n",
        "prompt = create_prompt(input_, \"\")\n",
        "print(prompt)\n",
        "\n",
        "inputs = torch.tensor([tokenizer.encode(prompt)])\n",
        "\n",
        "tokens = model.generate(\n",
        "    inputs.to(model.device),\n",
        "    max_new_tokens=50,\n",
        "    temperature=0.1,\n",
        "    do_sample=False\n",
        ")\n",
        "print(tokenizer.decode(tokens[0], skip_special_tokens=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8K67uRTiPp-D",
        "outputId": "d0e61075-d1d8-4e3e-9e09-91f3e25afe95"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 0.0 0:00:00.055361 0:00:00.055365\n",
            "100 35.64356435643564 0:00:05.428861 0:00:00.053751\n",
            "200 39.30348258706468 0:00:10.796546 0:00:00.053714\n",
            "300 37.87375415282392 0:00:16.118069 0:00:00.053548\n",
            "400 37.905236907730675 0:00:21.457360 0:00:00.053510\n",
            "500 36.92614770459082 0:00:26.829137 0:00:00.053551\n",
            "600 36.43926788685524 0:00:32.189697 0:00:00.053560\n",
            "700 35.805991440798856 0:00:37.546404 0:00:00.053561\n",
            "800 35.95505617977528 0:00:42.920933 0:00:00.053584\n",
            "900 35.18312985571587 0:00:48.350846 0:00:00.053664\n",
            "1000 35.064935064935064 0:00:53.698577 0:00:00.053645\n",
            "1100 33.96911898274296 0:00:59.023389 0:00:00.053609\n",
            "1200 33.72189841798502 0:01:04.393547 0:00:00.053617\n",
            "1300 33.89700230591852 0:01:09.739092 0:00:00.053604\n",
            "1400 33.40471092077088 0:01:15.084717 0:00:00.053594\n",
            "1500 33.84410393071286 0:01:20.435934 0:00:00.053588\n",
            "1600 33.91630231105559 0:01:25.804731 0:00:00.053594\n",
            "1700 33.39212228101117 0:01:31.191520 0:00:00.053611\n",
            "1800 33.7034980566352 0:01:36.627455 0:00:00.053652\n",
            "1900 33.824302998421885 0:01:42.025747 0:00:00.053670\n",
            "2000 33.483258370814596 0:01:47.431421 0:00:00.053689\n"
          ]
        }
      ],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "start = datetime.now()\n",
        "\n",
        "prediction = []\n",
        "response = []\n",
        "accuracy = []\n",
        "labels = []\n",
        "\n",
        "for i, x in df_test.iterrows():\n",
        "    sentence = x['sentence']\n",
        "    label = x['sentiment']\n",
        "    input_ = f'''The sentiment of this comment: \"{sentence}\" is'''\n",
        "    prompt = create_prompt(input_, label)\n",
        "\n",
        "    inputs = tokenizer.encode(\n",
        "        prompt,\n",
        "        # add_generation_prompt=True,\n",
        "        return_tensors='pt'\n",
        "    )\n",
        "\n",
        "    tokens = model.generate(\n",
        "        inputs.to(model.device),\n",
        "        max_new_tokens=3,\n",
        "        temperature=0.1,\n",
        "        do_sample=False,\n",
        "        pad_token_id=tokenizer.eos_token_id\n",
        "    )\n",
        "    #break\n",
        "\n",
        "    answer = tokenizer.decode(tokens[0], skip_special_tokens=False).split(\"The correct answer is \")[-1]\n",
        "    answer = 'positive' if 'positive' in answer.lower() else 'negative' if 'negative' in answer.lower() else 'neutral'\n",
        "    prediction.append(answer.lower())\n",
        "    response.append(tokenizer.decode(tokens[0], skip_special_tokens=False))\n",
        "\n",
        "    accuracy.append(prediction[-1] == label)\n",
        "    labels.append(label)\n",
        "\n",
        "    if i % 100 == 0:\n",
        "        print(i, np.array(accuracy).sum()/len(prediction)*100, datetime.now() - start, (datetime.now() - start)/len(prediction))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2LxIx6H8Pp-D",
        "outputId": "d0520923-ebdf-4dec-c713-9f0ee3def2aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative     1.0000    0.0015    0.0029       686\n",
            "     neutral     0.0000    0.0000    0.0000       670\n",
            "    positive     0.3342    1.0000    0.5009       680\n",
            "\n",
            "    accuracy                         0.3345      2036\n",
            "   macro avg     0.4447    0.3338    0.1679      2036\n",
            "weighted avg     0.4485    0.3345    0.1683      2036\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report, f1_score\n",
        "import sklearn\n",
        "\n",
        "print(sklearn.metrics.classification_report(labels, prediction, digits=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FY2HDVtjPp-E",
        "outputId": "d0883e2e-8bd2-49e4-85c6-44ba7ae0a6af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The sentiment of this comment: \"The facilities of the university are versatile and helpful.\" is\n",
            "A. Positive\n",
            "B. Neutral\n",
            "C. Negative\n",
            "\n",
            "The correct answer is A. Positive\n",
            "\n",
            "\n",
            "The sentiment of this comment: \"M·∫•y b·∫°n ƒë√≥ hay ƒë√≤i h·ªèi nh∆∞ng kh√¥ng bao gi·ªù gi√∫p ƒë·ª° ng∆∞·ªùi kh√°c.\" is\n",
            "A. Positive\n",
            "B. Neutral\n",
            "C. Negative\n",
            "\n",
            "The correct answer is A. Positive\n",
            "\n",
            "\n",
            "The sentiment of this comment: \"C·∫≠u ·∫•y r·∫•t c√≥ k·ªπ nƒÉng v·ªÅ s√°ng t·∫°o v√† ngh·ªá thu·∫≠t.\" is\n",
            "A. Positive\n",
            "B. Neutral\n",
            "C. Negative\n",
            "\n",
            "The correct answer is A. Positive\n",
            "\n",
            "\n",
            "The sentiment of this comment: \"Gi·∫£ng vi√™n n√†y kh√¥ng nh√†m ch√°n.\" is\n",
            "A. Positive\n",
            "B. Neutral\n",
            "C. Negative\n",
            "\n",
            "The correct answer is A. Positive\n",
            "\n",
            "\n",
            "The sentiment of this comment: \"Anh ta l√† m·ªôt ng∆∞·ªùi r·∫•t t·ªâ m·ªâ v√† c·∫©n th·∫≠n.\" is\n",
            "A. Positive\n",
            "B. Neutral\n",
            "C. Negative\n",
            "\n",
            "The correct answer is A. Positive\n",
            "\n",
            "\n",
            "The sentiment of this comment: \"Gi√°o vi√™n ƒë∆∞a ra c√°c ph∆∞∆°ng ti·ªán h·ªó tr·ª£ gi·∫£ng d·∫°y r·∫•t t·ªët v√† hi·ªáu qu·∫£.\" is\n",
            "A. Positive\n",
            "B. Neutral\n",
            "C. Negative\n",
            "\n",
            "The correct answer is A. Positive\n",
            "\n",
            "\n",
            "The sentiment of this comment: \"The university's computer facilities are up-to-date and well-maintained.\" is\n",
            "A. Positive\n",
            "B. Neutral\n",
            "C. Negative\n",
            "\n",
            "The correct answer is A. Positive\n",
            "\n",
            "\n",
            "The sentiment of this comment: \"Thi·∫øu t√≠nh linh ho·∫°t trong h√¨nh th·ª©c gi·∫£ng d·∫°y v√† ƒë√°nh gi√° k·∫øt qu·∫£ h·ªçc t·∫≠p.\" is\n",
            "A. Positive\n",
            "B. Neutral\n",
            "C. Negative\n",
            "\n",
            "The correct answer is A. Positive\n",
            "\n",
            "\n",
            "The sentiment of this comment: \"C√¥ ·∫•y r·∫•t s·∫Øc s·∫£o v√† c√≥ kh·∫£ nƒÉng ph√¢n t√≠ch chi ti·∫øt r·∫•t t·ªët.\" is\n",
            "A. Positive\n",
            "B. Neutral\n",
            "C. Negative\n",
            "\n",
            "The correct answer is A. Positive\n",
            "\n",
            "\n",
            "The sentiment of this comment: \"Anh ·∫•y c√≥ t√†i nƒÉng v·ªÅ √¢m nh·∫°c v√† lu√¥n t√¨m c√°ch t·∫°o ra c√°c b·∫£n nh·∫°c m·ªõi, gi√∫p nh√≥m th√™m ho√†n h·∫£o v√† ƒëa d·∫°ng h∆°n.\" is\n",
            "A. Positive\n",
            "B. Neutral\n",
            "C. Negative\n",
            "\n",
            "The correct answer is A. Positive\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for x in response[-10:]:\n",
        "    print(x)\n",
        "    print(\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3IPLuCzSPp-E"
      },
      "source": [
        "## Create TrainingArguments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LrgqyXcoPp-E",
        "outputId": "eadbb389-29d7-413c-8865-135de01dc589"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "509\n"
          ]
        }
      ],
      "source": [
        "print(len(df_train)//bs//ga_steps*epochs//4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oY7G4TTiPp-E",
        "outputId": "51368536-d15a-4522-f52a-4ba4746cbadd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "509\n"
          ]
        }
      ],
      "source": [
        "save_step = len(df_train)//bs//ga_steps*epochs//4\n",
        "print(save_step)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w3NONWQAPp-E",
        "outputId": "3acf8e8a-0694-4167-c519-c5e808a02696"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "training_arguments = TrainingArguments(\n",
        "    output_dir=output_dir,\n",
        "    num_train_epochs=epochs,\n",
        "    per_device_train_batch_size=bs,\n",
        "    per_device_eval_batch_size=bs_eval,\n",
        "    evaluation_strategy=\"steps\",\n",
        "    eval_steps=save_step,\n",
        "    gradient_accumulation_steps=ga_steps,\n",
        "    optim=\"paged_adamw_32bit\",\n",
        "    save_steps=save_step,\n",
        "    save_strategy=\"steps\",\n",
        "    logging_steps=save_step,\n",
        "    learning_rate=lr,\n",
        "    weight_decay=0.001,\n",
        "    fp16=False,\n",
        "    bf16=True,\n",
        "    max_grad_norm=0.3,\n",
        "    max_steps=-1,\n",
        "    warmup_ratio=0.03,\n",
        "    group_by_length=True,\n",
        "    lr_scheduler_type=\"constant\",\n",
        "    report_to=\"none\",\n",
        "    save_total_limit=1,\n",
        "    #load_best_model_at_end=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DmLghud2Pp-E"
      },
      "source": [
        "## Create trainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "21778625c18140a48986bb7bf6d29b67",
            "770aa14800344558921ee053e4081cfa"
          ]
        },
        "id": "RoCjobhbPp-E",
        "outputId": "3b3b2317-8b39-490b-c833-ed09d9bb5bc2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': max_seq_length. Will not be supported from version '1.0.0'.\n",
            "\n",
            "Deprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n",
            "  warnings.warn(message, FutureWarning)\n",
            "/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1961: FutureWarning: `--push_to_hub_token` is deprecated and will be removed in version 5 of ü§ó Transformers. Use `--hub_token` instead.\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:269: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "21778625c18140a48986bb7bf6d29b67",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/8144 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "770aa14800344558921ee053e4081cfa",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/2036 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
          ]
        }
      ],
      "source": [
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    train_dataset=dataset[\"train\"],\n",
        "    eval_dataset=dataset[\"validation\"],\n",
        "    #peft_config=peft_config,\n",
        "    max_seq_length= 128,\n",
        "    #dataset_text_field=[\"input\", \"output\"],\n",
        "    tokenizer=tokenizer,\n",
        "    args=training_arguments,\n",
        "    packing= False,\n",
        "    formatting_func = formatting_prompts_func,\n",
        "    #data_collator=collator\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AMzeJkJ5Pp-E"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YUo0KnkCPp-E",
        "outputId": "ec9c2ba7-159c-4696-a504-1c09b62542be"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2036' max='2036' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2036/2036 04:04, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>509</td>\n",
              "      <td>0.819500</td>\n",
              "      <td>0.783728</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1018</td>\n",
              "      <td>0.689800</td>\n",
              "      <td>0.763411</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1527</td>\n",
              "      <td>0.606000</td>\n",
              "      <td>0.778257</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2036</td>\n",
              "      <td>0.526800</td>\n",
              "      <td>0.815638</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=2036, training_loss=0.660542741037305, metrics={'train_runtime': 244.8804, 'train_samples_per_second': 133.028, 'train_steps_per_second': 8.314, 'total_flos': 3279457621659648.0, 'train_loss': 0.660542741037305, 'epoch': 4.0})"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SrfByNQgPp-F"
      },
      "source": [
        "# Eval\n",
        "- If you save the model to the output_dir folder, the training code above will automatically save the model to output_dir/checkpoint-{save_step} (in my case: out/checkpoint-2036). We will load the model from this folder:\n",
        "  - I calculate _id = save_step * num_epoch = 509 * 4 = 2036\n",
        "  - My model will saved at \"{output_dir}/checkpoint-{_id}\"\n",
        "- I use del model, gc.collect() and torch.cuda.empty_cache() to release trained model (save gpu memory).\n",
        "- We load the tokenizer in this folder by passing the saved folder to AutoTokenizer.from_pretrained()\n",
        "- We load the model in this folder by passing the saved folder to AutoModelForCausalLM.from_pretrained"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ev_ekAZwPp-F",
        "outputId": "50e82dd4-f1fc-4940-f797-a4b9583d3d25"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "509\n"
          ]
        }
      ],
      "source": [
        "save_step = len(df_train)//bs//ga_steps*epochs//4\n",
        "print(save_step)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kL-JM0c5Pp-F"
      },
      "outputs": [],
      "source": [
        "import gc\n",
        "\n",
        "del model\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GwtmxQwePp-F",
        "outputId": "f2a33dc1-1133-43b4-c126-8d0cbb646107"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ],
      "source": [
        "from peft import PeftModel, PeftConfig\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import torch\n",
        "\n",
        "_id = save_step*4\n",
        "\n",
        "peft_model_id = f\"{output_dir}/checkpoint-{_id}\"\n",
        "\n",
        "#config = PeftConfig.from_pretrained(peft_model_id)\n",
        "\n",
        "# bnb_config = BitsAndBytesConfig(\n",
        "#     load_in_4bit=True,\n",
        "#     bnb_4bit_use_double_quant=False,\n",
        "#     bnb_4bit_quant_type=\"nf4\",\n",
        "#     bnb_4bit_compute_dtype=torch.float16,\n",
        "# )\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    peft_model_id,\n",
        "    device_map=\"auto\",\n",
        "    #torch_dtype=torch.float16,\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    #quantization_config=bnb_config,\n",
        "    attn_implementation=\"flash_attention_2\",\n",
        "    trust_remote_code=True,\n",
        "    token = 'YOUR TOKEN HERE'\n",
        ")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(f\"{output_dir}/checkpoint-{_id}\",\n",
        "                                          trust_remote_code=True,\n",
        "                                          padding_side='left',\n",
        "                                          token='YOUR TOKEN HERE')\n",
        "\n",
        "# Load the Lora model\n",
        "#model = PeftModel.from_pretrained(model, peft_model_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OoI9aplTPp-F"
      },
      "outputs": [],
      "source": [
        "def create_prompt(input_, output_):\n",
        "    output_ = 'A. Positive' if output_ == 'positive' else 'B. Neutral' if output_ == 'neutral' else 'C. Negative'\n",
        "        #text = f\"### Question: {input__}\\n ### Answer: {example['output'][i]}\"\n",
        "    text = f'''{input_}\n",
        "A. Positive\n",
        "B. Neutral\n",
        "C. Negative\n",
        "\n",
        "The correct answer is'''\n",
        "\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5cmdh1nJPp-F",
        "outputId": "f4cf6167-7dfd-401e-d0fb-4f738eaa47e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The sentiment of this comment: \"m√≥n ƒÉn r·∫•t ngon\" is\n",
            "A. Positive\n",
            "B. Neutral\n",
            "C. Negative\n",
            "\n",
            "The correct answer is\n"
          ]
        }
      ],
      "source": [
        "sentence = 'm√≥n ƒÉn r·∫•t ngon'\n",
        "input_ = f'''The sentiment of this comment: \"{sentence}\" is'''\n",
        "prompt = create_prompt(input_, \"\")\n",
        "print(prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t6JCaFRpPp-F",
        "outputId": "74003e1b-e7d0-48a2-db17-2bc77247256a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[   785,  25975,    315,    419,   3980,     25,    330,     76,   3165,\n",
              "         128442, 128323,   7777,    263,      1,    374,    198,     32,     13,\n",
              "          43903,    198,     33,     13,  58694,    198,     34,     13,  50857,\n",
              "            271,    785,   4396,   4226,    374]])"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "inputs = torch.tensor([tokenizer.encode(prompt)])\n",
        "inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V2Y19mDePp-F"
      },
      "outputs": [],
      "source": [
        "tokens = model.generate(\n",
        "    inputs.to(model.device),\n",
        "    max_new_tokens=50,\n",
        "    temperature=0.1,\n",
        "    do_sample=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R_Hs1ZnMPp-F",
        "outputId": "4e88dc3f-c40e-4fdb-a9ad-5cd780872042"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The sentiment of this comment: \"m√≥n ƒÉn r·∫•t ngon\" is\n",
            "A. Positive\n",
            "B. Neutral\n",
            "C. Negative\n",
            "\n",
            "The correct answer is B. Neutral. The sentence \"M√≥n ƒÉn r·∫•t ngon\" is a neutral statement that does not express any positive or negative emotion. It simply describes the taste of the food. Therefore, the correct answer is B. Neutral. The other options\n"
          ]
        }
      ],
      "source": [
        "print(tokenizer.decode(tokens[0], skip_special_tokens=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4b-HB2JoPp-G",
        "outputId": "4683ab28-cedc-4af3-cc29-be7acfd5e883"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The sentiment of this comment: \"m√≥n ƒÉn r·∫•t ngon\" is\n",
            "A. Positive\n",
            "B. Neutral\n",
            "C. Negative\n",
            "\n",
            "The correct answer is B. Neutral\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:540: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:545: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:562: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "tokens = model.generate(\n",
        "    inputs.to(model.device),\n",
        "    max_new_tokens=3,\n",
        "    temperature=0.1,\n",
        "    do_sample=False\n",
        ")\n",
        "print(tokenizer.decode(tokens[0], skip_special_tokens=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FfCMVAa1Pp-G",
        "outputId": "203712d2-980c-46f3-cd65-bf1c0893e085"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 100.0 0:00:00.057033 0:00:00.057036\n",
            "100 83.16831683168317 0:00:05.577073 0:00:00.055219\n",
            "200 85.57213930348259 0:00:11.058303 0:00:00.055016\n",
            "300 86.37873754152824 0:00:16.540829 0:00:00.054953\n",
            "400 85.785536159601 0:00:22.017137 0:00:00.054906\n",
            "500 85.02994011976048 0:00:27.478177 0:00:00.054847\n",
            "600 85.52412645590682 0:00:32.931648 0:00:00.054795\n",
            "700 85.87731811697576 0:00:38.359632 0:00:00.054721\n",
            "800 86.3920099875156 0:00:43.798719 0:00:00.054680\n",
            "900 86.68146503884573 0:00:49.238808 0:00:00.054649\n",
            "1000 86.41358641358642 0:00:54.686381 0:00:00.054632\n",
            "1100 86.37602179836512 0:01:00.129318 0:00:00.054613\n",
            "1200 85.59533721898418 0:01:05.582372 0:00:00.054606\n",
            "1300 85.62644119907763 0:01:11.016522 0:00:00.054586\n",
            "1400 85.93861527480371 0:01:16.473572 0:00:00.054585\n",
            "1500 85.80946035976015 0:01:21.931103 0:00:00.054584\n",
            "1600 85.63397876327295 0:01:27.374241 0:00:00.054575\n",
            "1700 85.71428571428571 0:01:32.878218 0:00:00.054602\n",
            "1800 85.73014991671293 0:01:38.372731 0:00:00.054621\n",
            "1900 85.84955286691215 0:01:43.813549 0:00:00.054610\n",
            "2000 86.00699650174913 0:01:49.289242 0:00:00.054617\n"
          ]
        }
      ],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "start = datetime.now()\n",
        "\n",
        "prediction = []\n",
        "response = []\n",
        "accuracy = []\n",
        "labels = []\n",
        "\n",
        "for i, x in df_test.iterrows():\n",
        "    sentence = x['sentence']\n",
        "    label = x['sentiment']\n",
        "    input_ = f'''The sentiment of this comment: \"{sentence}\" is'''\n",
        "    prompt = create_prompt(input_, label)\n",
        "\n",
        "    inputs = tokenizer.encode(\n",
        "        prompt,\n",
        "        # add_generation_prompt=True,\n",
        "        return_tensors='pt'\n",
        "    )\n",
        "\n",
        "    tokens = model.generate(\n",
        "        inputs.to(model.device),\n",
        "        max_new_tokens=3,\n",
        "        temperature=0.1,\n",
        "        do_sample=False,\n",
        "        pad_token_id=tokenizer.eos_token_id\n",
        "    )\n",
        "    #break\n",
        "\n",
        "    answer = tokenizer.decode(tokens[0], skip_special_tokens=False).split(\"The correct answer is \")[-1]\n",
        "    answer = 'positive' if 'positive' in answer.lower() else 'negative' if 'negative' in answer.lower() else 'neutral'\n",
        "    prediction.append(answer.lower())\n",
        "    response.append(tokenizer.decode(tokens[0], skip_special_tokens=False))\n",
        "\n",
        "    accuracy.append(prediction[-1] == label)\n",
        "    labels.append(label)\n",
        "\n",
        "    if i % 100 == 0:\n",
        "        print(i, np.array(accuracy).sum()/len(prediction)*100, datetime.now() - start, (datetime.now() - start)/len(prediction))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BubnLYLTPp-G",
        "outputId": "9e294383-7164-4ddf-fd87-b81ed20b7db4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative     0.9797    0.9854    0.9826       686\n",
            "     neutral     0.7533    0.8567    0.8017       670\n",
            "    positive     0.8545    0.7338    0.7896       680\n",
            "\n",
            "    accuracy                         0.8590      2036\n",
            "   macro avg     0.8625    0.8587    0.8579      2036\n",
            "weighted avg     0.8634    0.8590    0.8586      2036\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report, f1_score\n",
        "import sklearn\n",
        "\n",
        "print(sklearn.metrics.classification_report(labels, prediction, digits=4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-2ryAWN0Pp-G"
      },
      "source": [
        "# Check results\n",
        "- I print all sentences have wrong prediction and see that almost cases is bug.\n",
        "- Conclusion, dataset is not clean than finetune LLM can't better than finetune roberta (~89..90%), because roberta will overfit even in test dataset.\n",
        "- In additionally, when I print example: \"m√≥n ƒÉn n√†y r·∫•t ngon\", we can see that model before finetune work better. Model after finetune only think about school (because finetune dataset is about school) and it don't know about food review. Than I think we only need finetune for special cases and finetune dataset need be clean and large enough."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bzx1V7jhPp-G"
      },
      "outputs": [],
      "source": [
        "df_test['predict'] = prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7QtI_mZxPp-G",
        "outputId": "8c790fb4-664f-4c7d-ccf4-9c13ea08e3a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Gi·∫£ng vi√™n lu√¥n ƒë·ªìng h√†nh v·ªõi sinh vi√™n tr√™n qu√° tr√¨nh h·ªçc t·∫≠p. positive neutral\n",
            "T√¥i c√≥ th·ªÉ ·ª©ng d·ª•ng c√°c ki·∫øn th·ª©c c√≥ ƒë∆∞·ª£c t·ª´ ch∆∞∆°ng tr√¨nh ƒë√†o t·∫°o v√†o c√¥ng vi·ªác c·ªßa m√¨nh. neutral positive\n",
            "Tr∆∞·ªùng n√†y gi√∫p t·ªët cho vi·ªác th·ª±c h√†nh v√† ph√°t tri·ªÉn k·ªπ nƒÉng. neutral positive\n",
            "Gi·∫£ng vi√™n r·∫•t t√†i nƒÉng v√† c√≥ nhi·ªÅu kinh nghi·ªám trong c√¥ng t√°c gi·∫£ng d·∫°y. positive neutral\n",
            "ƒê∆∞·ª£c h·ªçc t·∫≠p v·ªõi c√°c gi√°o vi√™n gi√†u kinh nghi·ªám v√† th·ª±c ti·ªÖn. positive neutral\n",
            "Nh√† h√†ng v√† c√°c c·ª≠a h√†ng ti·ªán l·ª£i ·ªü g·∫ßn tr∆∞·ªùng r·∫•t ƒëa d·∫°ng v√† phong ph√∫. neutral positive\n",
            "C√°c ph√≤ng h·ªçc ƒë∆∞·ª£c trang b·ªã ƒëi·ªÅu h√≤a gi√∫p sinh vi√™n h·ªçc t·∫≠p trong m√¥i tr∆∞·ªùng tho·∫£i m√°i. neutral positive\n",
            "C√¥ ·∫•y l√† m·ªôt gi√°o vi√™n r·∫•t th√¥ng minh v√† chuy√™n nghi·ªáp. neutral positive\n",
            "C√¥ ·∫•y th·ª±c s·ª± s√°ng t·∫°o v√† lu√¥n c√≥ √Ω t∆∞·ªüng m·ªõi ƒë·ªÉ ƒë·∫°t ƒë∆∞·ª£c m·ª•c ti√™u c·ªßa m√¨nh. neutral positive\n",
            "Khu v·ª±c ƒÉn u·ªëng t·∫°i tr∆∞·ªùng cung c·∫•p nh·ªØng m√≥n ƒÉn ngon v√† ƒëa d·∫°ng. neutral positive\n",
            "Tr∆∞·ªùng ƒë·∫°i h·ªçc n√†y ƒë√≥ng g√≥p m·ªôt ph·∫ßn quan tr·ªçng trong vi·ªác ph√°t tri·ªÉn kinh t·∫ø v√† x√£ h·ªôi ƒë·ªãa ph∆∞∆°ng. positive neutral\n",
            "C√≥ nhi·ªÅu ho·∫°t ƒë·ªông ngo·∫°i kh√≥a v√† phong ph√∫ cho sinh vi√™n. neutral positive\n",
            "Khu v·ª±c ƒë·∫∑t m√°y b√°n th·ª©c u·ªëng r·∫•t ti·ªán l·ª£i cho sinh vi√™n. neutral positive\n",
            "Ph√≤ng gym v√† h·ªì b∆°i ƒë·ªÅu ƒë∆∞·ª£c qu·∫£n l√Ω ƒë√†ng ho√†ng v√† lu√¥n s·∫°ch s·∫Ω. neutral positive\n",
            "Khu v·ª±c ch∆°i game c·ªßa sinh vi√™n t·∫°i tr∆∞·ªùng r·∫•t th√∫ v·ªã v√† s√¥i ƒë·ªông. neutral positive\n",
            "Ch∆∞∆°ng tr√¨nh h·ªçc gi√∫p t√¥i c·∫£m th·∫•y m√¨nh c√≥ m·ª•c ti√™u r√µ r√†ng h∆°n. neutral positive\n",
            "Ph√≤ng h·ªçc ƒë∆∞·ª£c trang b·ªã ƒë·∫ßy ƒë·ªß ti·ªán nghi gi√∫p sinh vi√™n lu√¥n d·ªÖ d√†ng ti·∫øp c·∫≠n t√†i li·ªáu v√† th√¥ng tin li√™n quan. positive neutral\n",
            "Th·∫ßy d·∫°y r·∫•t chuy√™n nghi·ªáp v√† nhi·ªát t√¨nh. neutral positive\n",
            "ƒê·∫°i h·ªçc n√†y c√≥ nhi·ªÅu h·ªôi th·∫£o v√† kh√≥a t·∫≠p hu·∫•n gi√∫p sinh vi√™n trau d·ªìi ki·∫øn th·ª©c v√† k·ªπ nƒÉng. neutral positive\n",
            "Th·∫ßy/c√¥ ƒë√°nh gi√° v√† ƒë·ªÅ xu·∫•t nh·ªØng √Ω ki·∫øn x√¢y d·ª±ng t√≠ch c·ª±c gi√∫p sinh vi√™n ph√°t tri·ªÉn h∆°n. neutral positive\n",
            "Gi·∫£ng vi√™n r·∫•t ch√¢n th√†nh v√† nhi·ªát t√¨nh. neutral positive\n",
            "Gi·∫£ng vi√™n n√†y c√≥ t√¢m huy·∫øt c√¥ng vi·ªác v√† ƒëam m√™ v·ªõi ngh·ªÅ gi·∫£ng d·∫°y. neutral positive\n",
            "H·ªá th·ªëng th∆∞ vi·ªán v√† t√†i nguy√™n h·ªçc t·∫≠p r·∫•t ƒë·∫ßy ƒë·ªß v√† ti·ªán l·ª£i. positive neutral\n",
            "Ch∆∞∆°ng tr√¨nh ƒë√†o t·∫°o c√≥ nhi·ªÅu t√≠nh ·ª©ng d·ª•ng gi√∫p sinh vi√™n t·ª± tin v√† th√†nh c√¥ng trong c√¥ng vi·ªác. neutral positive\n",
            "Tr∆∞·ªùng c·∫ßn c√≥ ch√≠nh s√°ch h·ªó tr·ª£ chi ph√≠ h·ªçc t·∫≠p ph√π h·ª£p cho sinh vi√™n. neutral negative\n",
            "Th·∫ßy cho h·ªçc sinh m·ªôt c√°i nh√¨n t·ªïng quan v·ªÅ chuy√™n ng√†nh c·ªßa m√¨nh. neutral positive\n",
            "Ph√≤ng sinh ho·∫°t c·ªông ƒë·ªìng r·∫•t thu·∫≠n ti·ªán cho vi·ªác t·ªï ch·ª©c c√°c ho·∫°t ƒë·ªông sinh vi√™n. neutral positive\n",
            "Ch∆∞∆°ng tr√¨nh ƒë√†o t·∫°o r·∫•t ƒëa d·∫°ng v·ªÅ c·∫£ n·ªôi dung l·∫´n h√¨nh th·ª©c ƒë√†o t·∫°o. neutral positive\n",
            "Tr∆∞·ªùng ƒë·∫°i h·ªçc cung c·∫•p nhi·ªÅu ch∆∞∆°ng tr√¨nh h·ªçc b·ªïng h·ªó tr·ª£ cho sinh vi√™n kh√≥ khƒÉn kinh t·∫ø. neutral positive\n",
            "Gi·∫£ng vi√™n r·∫•t am hi·ªÉu v√† t·ª´ng b∆∞·ªõc h∆∞·ªõng d·∫´n sinh vi√™n ƒëi ƒë·∫øn th√†nh c√¥ng. positive neutral\n",
            "C·∫≠u ·∫•y lu√¥n s·∫µn s√†ng ƒë√≥ng g√≥p √Ω ki·∫øn v√† ƒë∆∞a ra gi·∫£i ph√°p cho c√°c v·∫•n ƒë·ªÅ kh√≥ khƒÉn trong d·ª± √°n. neutral positive\n",
            "T√¥i c·∫£m th·∫•y h·ªçc t·∫≠p t·∫°i tr∆∞·ªùng r·∫•t t·ªët cho s·ª± ph√°t tri·ªÉn c·ªßa b·∫£n th√¢n. neutral positive\n",
            "Th·∫ßy gi·∫£i th√≠ch c·∫∑n k·∫Ω v√† d·ªÖ hi·ªÉu. neutral positive\n",
            "Th·∫ßy c√¥ gi·∫£ng d·∫°y ƒë·ªÅu r·∫•t nhi·ªát t√¨nh v√† c√≥ kinh nghi·ªám trong lƒ©nh v·ª±c ƒëang gi·∫£ng d·∫°y. neutral positive\n",
            "C√≥ r·∫•t nhi·ªÅu ph√≤ng h·ªçc t·∫°i tr∆∞·ªùng ƒë·ªÉ sinh vi√™n c√≥ th·ªÉ l·ª±a ch·ªçn v√† s·ª≠ d·ª•ng. neutral positive\n",
            "T√¥i r·∫•t ·∫•n t∆∞·ª£ng v·ªõi s·ª± trang tr√≠ trong tr∆∞·ªùng, ch√∫ng t·∫°o c·∫£m gi√°c tho·∫£i m√°i v√† th∆∞ gi√£n cho sinh vi√™n. positive neutral\n",
            "C√¥ ·∫•y lu√¥n s·∫µn s√†ng gi√∫p ƒë·ª° v√† h·ªó tr·ª£ ng∆∞·ªùi kh√°c. positive neutral\n",
            "C√¥ ·∫•y l√† m·ªôt gi·∫£ng vi√™n tuy·ªát v·ªùi, c√≥ s·ª± t√¢m huy·∫øt v√† nhi·ªát huy·∫øt trong qu√° tr√¨nh gi·∫£ng d·∫°y. neutral positive\n",
            "Ch∆∞∆°ng tr√¨nh h·ªçc r·∫•t th√∫ v·ªã v√† b·ªï √≠ch. neutral positive\n",
            "Gi·∫£ng vi√™n gi√∫p t√¥i hi·ªÉu ƒë∆∞·ª£c v·∫•n ƒë·ªÅ h∆°n v√† ƒë∆∞a ra nhi·ªÅu v√≠ d·ª• th·ª±c t·∫ø ƒë·ªÉ √°p d·ª•ng v√†o cu·ªôc s·ªëng. neutral positive\n",
            "Khu v·ª±c ƒÉn u·ªëng c·ªßa tr∆∞·ªùng c√≥ nhi·ªÅu m√≥n ƒÉn ngon v√† ƒëa d·∫°ng. neutral positive\n",
            "Tr∆∞·ªùng lu√¥n ƒë·ªÅ cao ho·∫°t ƒë·ªông nghi√™n c·ª©u khoa h·ªçc cho sinh vi√™n. neutral positive\n",
            "Gi√°o vi√™n c·ªßa t√¥i d·∫°y l√≠ thuy·∫øt v√† th·ª±c h√†nh v·ªÅ quy·ªÅn s·ªü h·ªØu tr√≠ tu·ªá v√† b·∫£o v·ªá nh√£n hi·ªáu. neutral positive\n",
            "Ch∆∞∆°ng tr√¨nh ƒë√†o t·∫°o gi√∫p t√¥i ph√°t tri·ªÉn m·ªëi quan h·ªá v·ªõi c√°c sinh vi√™n kh√°c v√† c√°c gi·∫£ng vi√™n. neutral positive\n",
            "T√¥i r·∫•t th√≠ch nh·ªØng khu v·ª±c xanh trong tr∆∞·ªùng, ch√∫ng t·∫°o c·∫£m gi√°c tho·∫£i m√°i v√† g·∫ßn g≈©i v·ªõi thi√™n nhi√™n. positive neutral\n",
            "Ph√≤ng h·ªçc ƒë∆∞·ª£c b·ªë tr√≠ nhi·ªÅu √°nh s√°ng t·ª± nhi√™n gi√∫p sinh vi√™n ti·∫øt ki·ªám ƒë∆∞·ª£c ƒëi·ªán trong qu√° tr√¨nh h·ªçc t·∫≠p. neutral positive\n",
            "Tr∆∞·ªùng ƒë·ªÅ cao t√≠nh th·ªùi ƒë·∫°i v√† c√¥ng ngh·ªá v√†o gi√°o d·ª•c, gi√∫p t√¥i h·ªçc ƒë∆∞·ª£c nh·ªØng ki·∫øn th·ª©c m·ªõi nh·∫•t. neutral positive\n",
            "Th·∫ßy r·∫•t t√¥n tr·ªçng quy·ªÅn l·ª£i v√† s·ªü th√≠ch c·ªßa h·ªçc vi√™n. neutral positive\n",
            "T√¥i r·∫•t ƒë√°nh gi√° cao s·ª± chu·∫©n b·ªã v√† b·ªë tr√≠ c·ªßa c√°c m√¥n h·ªçc trong ch∆∞∆°ng tr√¨nh. neutral positive\n",
            "Ch∆∞∆°ng tr√¨nh gi√°o d·ª•c gi√∫p t√¥i hi·ªÉu r√µ h∆°n v·ªÅ b·∫£n th√¢n v√† ƒë·ªãnh h∆∞·ªõng ngh·ªÅ nghi·ªáp sau n√†y c·ªßa m√¨nh. neutral positive\n",
            "Th∆∞ vi·ªán ƒë·∫ßy ƒë·ªß s√°ch v·ªü c·∫ßn thi·∫øt. neutral positive\n",
            "T√¥i r·∫•t h√†i l√≤ng v·ªõi ch∆∞∆°ng tr√¨nh ƒë√†o t·∫°o v√¨ c√≥ c·∫£ c√°c m√¥n h·ªçc ng·∫Øn h·∫°n cho sinh vi√™n. neutral positive\n",
            "C√°c m√¥n h·ªçc gi√∫p sinh vi√™n ph√°t tri·ªÉn t∆∞ duy ph·∫£n bi·ªán v√† ƒë·ªôc l·∫≠p trong t∆∞ duy. neutral positive\n",
            "Anh ta l√† m·ªôt ng∆∞·ªùi ƒë√°ng tin c·∫≠y v√† lu√¥n gi·ªØ l·ªùi h·ª©a c·ªßa m√¨nh. positive neutral\n",
            "Anh ·∫•y r·∫•t th·∫•u hi·ªÉu v√† gi√∫p ƒë·ª° nh·ªØng ng∆∞·ªùi g·∫∑p kh√≥ khƒÉn. positive neutral\n",
            "Gi·∫£ng vi√™n c√≥ th·ªÉ s·ª≠ d·ª•ng nhi·ªÅu ph∆∞∆°ng ph√°p gi·∫£ng d·∫°y kh√°c nhau ƒë·ªÉ thu h√∫t sinh vi√™n h·ªçc t·∫≠p. neutral positive\n",
            "Th·∫ßy gi√∫p ƒë·ª° sinh vi√™n ƒë·ªãnh h∆∞·ªõng ngh·ªÅ nghi·ªáp v√† ph√°t tri·ªÉn b·∫£n th√¢n. positive neutral\n",
            "C√°c trung t√¢m h·ªçc thu·∫≠t c·ªßa tr∆∞·ªùng r·∫•t c√≥ chuy√™n m√¥n v√† gi√∫p t√¥i hi·ªÉu s√¢u h∆°n v·ªÅ ng√†nh h·ªçc c·ªßa m√¨nh. neutral positive\n",
            "T√¥i r·∫•t th√≠ch l·ªëi thi·∫øt k·∫ø v√† trang tr√≠ c·ªßa tr∆∞·ªùng, n√≥ c·ª±c k·ª≥ ·∫•n t∆∞·ª£ng v√† s√°ng t·∫°o. positive neutral\n",
            "L·ªõp h·ªçc ƒë∆∞·ª£c ƒë∆∞a ra m·ªôt c√°ch sinh ƒë·ªông, h·∫•p d·∫´n v√† ƒë·∫ßy ƒë·ªß ki·∫øn th·ª©c chuy√™n m√¥n. positive neutral\n",
            "Th·∫ßy cung c·∫•p cho ch√∫ng t√¥i nhi·ªÅu t√†i li·ªáu v√† b√†i gi·∫£ng h·ªØu √≠ch. neutral positive\n",
            "Em th·∫•y b·∫°n c·ªßa m√¨nh r·∫•t nhanh nh·∫πn v√† chƒÉm ch·ªâ h·ªçc. positive neutral\n",
            "Ch∆∞∆°ng tr√¨nh ƒë√†o t·∫°o c·ªßa tr∆∞·ªùng r·∫•t th·ª±c ti·ªÖn v√† h·ªØu √≠ch trong cu·ªôc s·ªëng h√†ng ng√†y. neutral positive\n",
            "Khu v·ª±c sinh ho·∫°t c·ªßa sinh vi√™n ƒë∆∞·ª£c qu·∫£n l√Ω t·ªët, an ninh. neutral positive\n",
            "S·∫°ch s·∫Ω negative neutral\n",
            "C∆° h·ªôi ƒë·ªÉ th·ª±c t·∫≠p trong m·ªôt m√¥i tr∆∞·ªùng th·ª±c t·∫ø. neutral positive\n",
            "Khu gi√° th·ªÉ h√¨nh c·ªßa tr∆∞·ªùng l√† n∆°i tuy·ªát v·ªùi ƒë·ªÉ t·∫≠p luy·ªán v·ªõi ƒë·∫ßy ƒë·ªß c√°c thi·∫øt b·ªã c·∫ßn thi·∫øt. neutral positive\n",
            "Ch∆∞∆°ng tr√¨nh h·ªçc r·∫•t th√∫ v·ªã v√† ƒëa d·∫°ng. neutral positive\n",
            "ƒê·ªôi ng≈© gi·∫£ng vi√™n chuy√™n nghi·ªáp v√† th√¢n thi·ªán. neutral positive\n",
            "ƒê∆∞·ª£c ƒë√°nh gi√° c√¥ng b·∫±ng v√† kh√°ch quan. positive neutral\n",
            "C√°ch ƒë√°nh gi√° v√† ph∆∞∆°ng ph√°p gi·∫£ng d·∫°y c·ªßa tr∆∞·ªùng r·∫•t khuy·∫øn kh√≠ch v√† t·∫°o ƒë·ªông l·ª±c cho h·ªçc sinh. neutral positive\n",
            "Th·∫ßy gi·∫£ng d·∫°y r·∫•t chu ƒë√°o v√† chuy√™n nghi·ªáp. neutral positive\n",
            "Gi√°o vi√™n r·∫•t nhi·ªát t√¨nh v√† gi√∫p ƒë·ª° sinh vi√™n trong qu√° tr√¨nh h·ªçc t·∫≠p. positive neutral\n",
            "Anh ·∫•y l√† ng∆∞·ªùi c√≥ t√†i nƒÉng v√† lu√¥n c·ªë g·∫Øng ho√†n th√†nh m·ªçi vi·ªác t·ªët nh·∫•t. neutral positive\n",
            "B·∫°n c·ªßa t√¥i l√† ng∆∞·ªùi r·∫•t duy√™n d√°ng v√† s√†nh ƒëi·ªáu. positive neutral\n",
            "C√°c ph√≤ng th√≠ nghi·ªám c·ªßa tr∆∞·ªùng ƒë·∫ßy ƒë·ªß c√°c thi·∫øt b·ªã c·∫ßn thi·∫øt cho vi·ªác nghi√™n c·ª©u. neutral positive\n",
            "Th·∫ßy lu√¥n ƒë∆∞a ra nh·ªØng v√≠ d·ª• c·ª• th·ªÉ v√† minh ho·∫° ƒë·ªÉ gi√∫p sinh vi√™n hi·ªÉu b√†i t·∫≠p. neutral positive\n",
            "M√¥n h·ªçc gi√∫p t√¥i h·ªçc ƒë∆∞·ª£c nhi·ªÅu kinh nghi·ªám v√† k·ªπ nƒÉng c·∫ßn thi·∫øt cho c√¥ng vi·ªác c·ªßa m√¨nh. neutral positive\n",
            "Th·∫ßy l√† m·ªôt gi·∫£ng vi√™n r·∫•t gi·ªèi trong vi·ªác truy·ªÅn ƒë·∫°t ki·∫øn th·ª©c v√† k·ªπ nƒÉng cho sinh vi√™n. positive neutral\n",
            "Th·ªùi gian v√† ƒë·ªãa ƒëi·ªÉm h·ªçc t·∫≠p kh√¥ng ph√π h·ª£p cho m·ªôt s·ªë sinh vi√™n. neutral negative\n",
            "Anh b·∫°n c√πng l·ªõp r·∫•t h√≤a ƒë·ªìng v√† d·ªÖ g·∫ßn. positive neutral\n",
            "S·ªë l∆∞·ª£ng gi√°o vi√™n n∆∞·ªõc ngo√†i ƒë∆∞·ª£c gi·∫£ng d·∫°y trong ch∆∞∆°ng tr√¨nh ƒë√†o t·∫°o l√† r·∫•t √≠t. negative neutral\n",
            "Ch∆∞∆°ng tr√¨nh ƒë√†o t·∫°o gi√∫p t√¥i trang b·ªã nh·ªØng k·ªπ nƒÉng m·ªÅm c·∫ßn thi·∫øt ƒë·ªÉ th√†nh c√¥ng trong t∆∞∆°ng lai. positive neutral\n",
            "C√°c khu v·ª±c ti·∫øp kh√°ch c·ªßa tr∆∞·ªùng ƒë∆∞·ª£c b·ªë tr√≠ th√¥ng tho√°ng v√† chuy√™n nghi·ªáp. neutral positive\n",
            "Em c·∫£m th·∫•y r·∫•t ·∫•n t∆∞·ª£ng v·ªõi b·∫°n n√†y v√¨ lu√¥n c√≥ c√¢u tr·∫£ l·ªùi ch√≠nh x√°c. neutral positive\n",
            "C√¥ng ngh·ªá v√† trang thi·∫øt b·ªã c·ªßa ƒë·∫°i h·ªçc t·ªët h∆°n so v·ªõi nhi·ªÅu tr∆∞·ªùng kh√°c. positive neutral\n",
            "Gi·∫£ng vi√™n n√†y d·∫°y r·∫•t t·ªët v√† truy·ªÅn c·∫£m h·ª©ng cho h·ªçc sinh. neutral positive\n",
            "Th·∫ßy t·∫°o ra m√¥i tr∆∞·ªùng h·ªçc t·∫≠p vui v·∫ª v√† ·∫•m c√∫ng. positive neutral\n",
            "Tr∆∞·ªùng lu√¥n gi·ªØ g√¨n s·∫°ch s·∫Ω v√† d·ªÖ d√†ng b·∫£o tr√¨ h∆°n nh·ªù v√†o c√°c thi·∫øt b·ªã trang tr√≠ v√† c∆° s·ªü v·∫≠t ch·∫•t. positive neutral\n",
            "Th·∫ßy khuy·∫øn kh√≠ch sinh vi√™n nghi√™n c·ª©u v√† kh√°m ph√° nh·ªØng th·ª© m·ªõi trong lƒ©nh v·ª±c c·ªßa m√¨nh. neutral positive\n",
            "C√¥ ·∫•y l√† ng∆∞·ªùi c√≥ t√†i nƒÉng ƒë·∫∑c bi·ªát v√† lu√¥n c·ªë g·∫Øng v∆∞·ª£t qua gi·ªõi h·∫°n c·ªßa b·∫£n th√¢n. neutral positive\n",
            "ƒê·ªôi ng≈© nh√¢n vi√™n c·ªßa tr∆∞·ªùng r·∫•t th√¢n thi·ªán v√† h·ªó tr·ª£ t·∫≠n t√¨nh. neutral positive\n",
            "Ch∆∞∆°ng tr√¨nh gi·∫£ng d·∫°y r·∫•t ph√π h·ª£p v·ªõi nhu c·∫ßu c·ªßa sinh vi√™n. neutral positive\n",
            "Th·∫ßy c√¥ ƒë·ªÅ cao c√°c tr·∫ª em tr√™n h·∫øt v√† mang ƒë·∫øn cho ch√∫ng ta m·ªôt m√¥i tr∆∞·ªùng h·ªçc t·∫≠p khuy·∫øn kh√≠ch v√† th√¢n thi·ªán. positive neutral\n",
            "Khu v·ª±c cho sinh vi√™n t·ª± h·ªçc kh√° tho·∫£i m√°i v√† ti·ªán nghi. neutral positive\n",
            "C√°c khu v·ª±c ƒë·∫∑t t·ªß h·ªì s∆° c·ªßa tr∆∞·ªùng ƒë∆∞·ª£c b·∫£o qu·∫£n an to√†n v√† ch√≠n chu. neutral positive\n",
            "T√¥i c·∫£m th·∫•y r·∫•t ·∫•m √°p v√† tho·∫£i m√°i khi s·ª≠ d·ª•ng ph√≤ng sinh ho·∫°t chung. positive neutral\n",
            "Gi·∫£ng vi√™n c·∫≠p nh·∫≠t th√¥ng tin nhanh ch√≥ng v√† c√≥ hi·ªÉu bi·∫øt s√¢u v·ªÅ th·ª±c t·∫ø c·ªßa ng√†nh h·ªçc. positive neutral\n",
            "T√¥i c·∫£m th·∫•y r·∫•t c·∫£m k√≠ch v√¨ gi·∫£ng vi√™n c·ªßa m√¨nh lu√¥n s·∫µn s√†ng gi√∫p ƒë·ª° sinh vi√™n trong b·∫•t c·ª© l√∫c n√†o. positive neutral\n",
            "T√¥i r·∫•t h√†i l√≤ng v·ªõi c√°c ph√≤ng h·ªçc ·ªü ƒë√¢y. positive neutral\n",
            "Tr∆∞·ªùng c√≥ c√°c ph√≤ng l√†m vi·ªác v√† h·ªçc c√πng c√°c bu·ªìng t·∫Øm r·∫•t s·∫°ch s·∫Ω v√† ti·ªán nghi. neutral positive\n",
            "Gi√∫p sinh vi√™n n·∫Øm b·∫Øt ƒë∆∞·ª£c nh·ªØng quy t·∫Øc v√† ƒë·∫°o ƒë·ª©c trong ng√†nh. neutral positive\n",
            "H·ªçc t·∫°i ƒë√¢y ƒë√≤i h·ªèi t√¥i t√≠nh k·ª∑ lu·∫≠t v√† s·ª± ƒë√≥ng g√≥p s√°ng t·∫°o. neutral positive\n",
            "T√¥i h√†i l√≤ng v·ªõi ch∆∞∆°ng tr√¨nh ƒë√†o t·∫°o v√¨ ƒë√£ gi√∫p t√¥i hi·ªÉu r√µ h∆°n v·ªÅ c√°c ph∆∞∆°ng th·ª©c h·ªçc t·∫≠p kh√°c nhau. neutral positive\n",
            "Th√¥ng tin tr∆∞·ªùng ƒë∆∞·ª£c ƒëƒÉng t·∫£i ƒë·∫ßy ƒë·ªß v√† chi ti·∫øt. neutral positive\n",
            "Anh ·∫•y l√† ng∆∞·ªùi r·∫•t chu ƒë√°o v√† s·∫µn s√†ng gi√∫p ƒë·ª° ng∆∞·ªùi kh√°c. neutral positive\n",
            "Gi√°o tr√¨nh ƒë∆∞·ª£c c·∫≠p nh·∫≠t th∆∞·ªùng xuy√™n v√† ph√π h·ª£p v·ªõi ch∆∞∆°ng tr√¨nh h·ªçc c·ªßa tr∆∞·ªùng. neutral positive\n",
            "C√°c ph√≤ng th√≠ nghi·ªám c·ªßa tr∆∞·ªùng ƒë∆∞·ª£c trang b·ªã ƒë·∫ßy ƒë·ªß thi·∫øt b·ªã v√† c√¥ng ngh·ªá hi·ªán ƒë·∫°i. positive neutral\n",
            "T√¥i c·∫£m th·∫•y h·ªçc ph√≠ h·ª£p l√≠ v·ªõi ch·∫•t l∆∞·ª£ng ƒë√†o t·∫°o c·ªßa tr∆∞·ªùng. neutral positive\n",
            "Ch·ªã ·∫•y r·∫•t nƒÉng ƒë·ªông v√† c√≥ kh·∫£ nƒÉng l√£nh ƒë·∫°o t·ªët. neutral positive\n",
            "Tr∆∞·ªùng c√≥ nhi·ªÅu ch∆∞∆°ng tr√¨nh h·ªó tr·ª£ cho sinh vi√™n ƒë·∫°t th√†nh t√≠ch cao. neutral positive\n",
            "Th·∫ßy ƒë√£ gi√∫p t√¥i c√≥ ƒë∆∞·ª£c nhi·ªÅu ki·∫øn th·ª©c quan tr·ªçng v√† k·ªπ nƒÉng c·∫ßn thi·∫øt trong c√¥ng vi·ªác. positive neutral\n",
            "Gi√°o tr√¨nh r·∫•t th·ª±c ti·ªÖn v√† ƒë√°p ·ª©ng ƒë∆∞·ª£c y√™u c·∫ßu c·ªßa c√¥ng vi·ªác hi·ªán nay. positive neutral\n",
            "C√°c gi·∫£ng vi√™n r·∫•t t·∫≠n t√¢m v√† nhi·ªát t√¨nh trong vi·ªác gi·∫£ng d·∫°y. neutral positive\n",
            "ƒê·ªôi ng≈© nh√¢n vi√™n b·∫£o tr√¨ tr∆∞·ªùng lu√¥n h·ªó tr·ª£ v√† s·ª≠ d·ª•ng c√°c ti·ªán √≠ch t·ªët nh·∫•t. positive neutral\n",
            "Gi·∫£ng vi√™n c·ªßa t√¥i n√≥i r·∫•t r√µ v√† d·ªÖ nghe, ƒëi·ªÅu n√†y gi√∫p t√¥i hi·ªÉu ƒë∆∞·ª£c m√¥n h·ªçc c·ªßa m√¨nh nhanh h∆°n. positive neutral\n",
            "C∆° s·ªü v·∫≠t ch·∫•t ƒë·∫ßy ƒë·ªß, ti√™n ti·∫øn. neutral positive\n",
            "Ph√≤ng t·∫≠p gym t·ªët v√† ƒë·∫ßy ƒë·ªß d·ª•ng c·ª•. neutral positive\n",
            "Khu v·ª±c khu√¢n vi√™n quanh tr∆∞·ªùng xanh t∆∞∆°i, nh·ªØng tin t·ª©c, th√¥ng b√°o c·ªßa tr∆∞·ªùng ƒë∆∞·ª£c ph√°t tr·ª±c ti·∫øp, r√µ r√†ng, d·ªÖ ti·∫øp c·∫≠n. positive neutral\n",
            "B√†i gi·∫£ng r·∫•t r√µ r√†ng v√† d·ªÖ hi·ªÉu. neutral positive\n",
            "C√¥ b·∫°n n√†y r·∫•t hi·ªÅn l√†nh v√† t·ªët b·ª•ng. positive neutral\n",
            "Ch∆∞∆°ng tr√¨nh ƒë√†o t·∫°o r·∫•t ƒëa d·∫°ng v√† ƒë·∫ßy ƒë·ªß, gi√∫p sinh vi√™n c√≥ th·ªÉ n·∫Øm b·∫Øt ƒë∆∞·ª£c nhi·ªÅu ki·∫øn th·ª©c kh√°c nhau. neutral positive\n",
            "Gi·∫£ng vi√™n th∆∞·ªùng ƒë∆∞a ra nh·ªØng c√¢u h·ªèi kh√≥ ƒë·ªÉ th√∫c ƒë·∫©y h·ªçc sinh nghi√™n c·ª©u th√™m. negative neutral\n",
            "Gi·ªù h·ªçc c·ªßa th·∫ßy r·∫•t hi·ªáu qu·∫£ v√† c·∫•u tr√∫c. neutral positive\n",
            "C√°c b√†i gi·∫£ng d·ªÖ hi·ªÉu v√† h·ªó tr·ª£ h·ªçc t·∫≠p t·ªët. positive neutral\n",
            "Nh·ªØng b√†i gi·∫£ng c·ªßa gi√°o vi√™n r·∫•t chi ti·∫øt v√† ƒë·∫ßy ƒë·ªß th√¥ng tin. neutral positive\n",
            "Trang thi·∫øt b·ªã v√† ph√≤ng h·ªçc r·∫•t ti·ªán nghi v√† hi·ªán ƒë·∫°i. neutral positive\n",
            "C√≥ nh·ªØng b·∫°n kh√° t√†n nh·∫´n v√† th∆∞·ªùng ƒë∆∞a ra c√°c √Ω ki·∫øn kh√¥ng c·∫ßn thi·∫øt trong l·ªõp h·ªçc. negative neutral\n",
            "Th·∫ßy lu√¥n c·∫≠p nh·∫≠t ki·∫øn th·ª©c m·ªõi nh·∫•t ƒë·ªÉ gi·∫£ng d·∫°y cho sinh vi√™n. positive neutral\n",
            "Gi·∫£ng vi√™n n√†y lu√¥n ki·ªÉm tra nh·ªØng b√†i t·∫≠p t·ª± l√†m c·ªßa sinh vi√™n. neutral negative\n",
            "Nh·ªØng tr·∫£i nghi·ªám th·ª±c t·∫ø trong ch∆∞∆°ng tr√¨nh ƒë√†o t·∫°o gi√∫p t√¥i c√≥ th√™m kinh nghi·ªám v√† s·∫µn s√†ng cho c√¥ng vi·ªác t∆∞∆°ng lai. neutral positive\n",
            "Gi·∫£ng vi√™n r·∫•t tinh t·∫ø khi ƒë∆∞a ra c√°c b√†i gi·∫£ng s√¢u s·∫Øc. neutral positive\n",
            "Ch∆∞∆°ng tr√¨nh gi·∫£ng d·∫°y k·∫øt h·ª£p gi·ªØa l√Ω thuy·∫øt v√† th·ª±c h√†nh t·ªët. neutral positive\n",
            "Th·∫ßy d·∫°y cho sinh vi√™n c√°ch suy nghƒ© ƒëa chi·ªÅu v√† ph√¢n t√≠ch d·ªØ li·ªáu m·ªôt c√°ch n√¢ng cao. positive neutral\n",
            "Th·∫ßy ƒë∆∞a ra nh·ªØng t√†i li·ªáu v√† th√≠ nghi·ªám th·ª±c t·∫ø ƒë·ªÉ gi√∫p h·ªçc sinh h·ªçc t·∫≠p t·ªët h∆°n. neutral positive\n",
            "Thi·∫øt b·ªã v√† ph∆∞∆°ng ti·ªán gi·∫£ng d·∫°y c·ªßa tr∆∞·ªùng c·∫ßn ƒë∆∞·ª£c n√¢ng c·∫•p. neutral negative\n",
            "Th·∫ßy r·∫•t quan t√¢m ƒë·∫øn s·ª± ph√°t tri·ªÉn c·ªßa t·ª´ng h·ªçc sinh. neutral positive\n",
            "Gi·∫£ng vi√™n r·∫•t d·ªÖ ti·∫øp c·∫≠n v√† th√¢n thi·ªán, d·ªÖ t·∫°o ƒë∆∞·ª£c m√¥i tr∆∞·ªùng h·ªçc t·∫≠p t√≠ch c·ª±c. positive neutral\n",
            "Tr∆∞·ªùng kh√¥ng th∆∞·ªùng xuy√™n c·∫≠p nh·∫≠t c√°c video gi·∫£ng d·∫°y v√† t√†i nguy√™n gi√°o d·ª•c cho sinh vi√™n. neutral negative\n",
            "Anh ta l√† ng∆∞·ªùi r·∫•t nƒÉng ƒë·ªông v√† lu√¥n t·∫°o ƒë·ªông l·ª±c cho ng∆∞·ªùi kh√°c. positive neutral\n",
            "C√°c ki·∫øn th·ª©c ƒë∆∞·ª£c truy·ªÅn ƒë·∫°t r√µ r√†ng v√† d·ªÖ ti·∫øp thu. positive neutral\n",
            "C√¥ b·∫°n n√†y l√† ng∆∞·ªùi r·∫•t h·ªçc h·ªèi v√† mu·ªën n·ªó l·ª±c ƒë·ªÉ c·∫£i thi·ªán b·∫£n th√¢n. neutral positive\n",
            "C√°c ho·∫°t ƒë·ªông ƒë·ªëi ngo·∫°i c·ªßa tr∆∞·ªùng ƒëa d·∫°ng v√† h·∫•p d·∫´n cho sinh vi√™n. neutral positive\n",
            "C√¥ ·∫•y r·∫•t t·∫≠n t√¢m v√† nhi·ªát t√¨nh gi√∫p ƒë·ª° c√°c b·∫°n trong l·ªõp. neutral positive\n",
            "Gi·∫£ng ƒë∆∞·ªùng r·ªông r√£i v√† s·∫°ch s·∫Ω. neutral positive\n",
            "C√¥ gi√°o c·ªßa t√¥i l√† ng∆∞·ªùi r·∫•t th√¥ng th√°i v√† gi√†u kinh nghi·ªám. positive neutral\n",
            "N·ªôi dung h·ªçc phong ph√∫, ƒëa d·∫°ng v√† c·∫≠p nh·∫≠t. positive neutral\n",
            "C√°c khu v·ª±c ph·ª•c v·ª• sinh vi√™n ƒë∆∞·ª£c ph·ªß s√≥ng wifi gi√∫p cho sinh vi√™n c√≥ th·ªÉ ra ngo√†i ƒë·ªÉ h·ªçc t·∫≠p ho·∫∑c gi·∫£i tr√≠. neutral positive\n",
            "Gi·∫£ng vi√™n r·∫•t th√¥ng minh v√† c√≥ ki·∫øn th·ª©c s√¢u r·ªông. positive neutral\n",
            "T√¥i c·∫£m th·∫•y gi·∫£ng vi√™n n√†y lu√¥n ƒë·∫∑t s·ª± c·∫ßn thƒÉm d√≤ tr∆∞·ªõc khi ƒë∆∞a ra quy·∫øt ƒë·ªãnh trong b√†i gi·∫£ng. negative neutral\n",
            "Anh ·∫•y l√† m·ªôt ng∆∞·ªùi r·∫•t ƒë√°ng tin c·∫≠y, lu√¥n lu√¥n gi·ªØ l·ªùi h·ª©a. positive neutral\n",
            "Th·∫ßy d·∫°y r·∫•t th√¥ng minh v√† t·∫≠p trung v√†o vi·ªác gi·∫£ng d·∫°y cho h·ªçc sinh hi·ªÉu b√†i h·ªçc. neutral positive\n",
            "Gi√°o vi√™n c·ªßa t√¥i h∆∞·ªõng d·∫´n sinh vi√™n th·ª±c hi·ªán c√°c nghi√™n c·ª©u th·ªã tr∆∞·ªùng v√† ƒë√°nh gi√° s·∫£n ph·∫©m. neutral positive\n",
            "Th∆∞ vi·ªán tr∆∞·ªùng c√≥ nhi·ªÅu ch·ªß ƒë·ªÅ kh√°c nhau gi√∫p sinh vi√™n t√¨m ƒë∆∞·ª£c ngu·ªìn t√†i li·ªáu ph√π h·ª£p v·ªõi nhu c·∫ßu h·ªçc t·∫≠p c·ªßa m√¨nh. neutral positive\n",
            "T√¥i r·∫•t h√†i l√≤ng v·ªõi c√°c d·ªãch v·ª• h·ªó tr·ª£ c·ªßa tr∆∞·ªùng, ƒë·∫∑c bi·ªát l√† c√°c d·ªãch v·ª• t∆∞ v·∫•n v√† t√†i ch√≠nh. positive neutral\n",
            "Th·∫ßy ch√∫ tr·ªçng ƒë·∫øn s·ª± ti·∫øn b·ªô c·ªßa t·ª´ng h·ªçc sinh, kh√¥ng ch·ªâ l·ªõp h·ªçc n√≥i chung. neutral positive\n",
            "Anh ta c√≥ t√≠nh c√°ch ƒëi·ªÅm ƒë·∫°m v√† kh√¥ng bao gi·ªù ho·∫£ng lo·∫°n. negative positive\n",
            "C√°c ho·∫°t ƒë·ªông ngo·∫°i kh√≥a c·ªßa tr∆∞·ªùng ƒëa d·∫°ng v√† h·∫•p d·∫´n cho ng∆∞·ªùi tham gia. neutral positive\n",
            "Th·∫ßy cung c·∫•p cho sinh vi√™n c√°c t√†i nguy√™n v√† c√¥ng c·ª• h·ªó tr·ª£ gi·∫£ng d·∫°y hi·ªáu qu·∫£. neutral positive\n",
            "Th·∫ßy l√† ng∆∞·ªùi gi·∫£ng d·∫°y gi·ªèi nh·∫•t m√† t√¥i t·ª´ng g·∫∑p. positive neutral\n",
            "S√¢n b√≥ng c·ªßa tr∆∞·ªùng r·∫•t ƒë·∫πp v√† c√≥ s·ª± b·∫£o tr√¨ t·ªët. neutral positive\n",
            "Tr∆∞·ªùng cung c·∫•p ƒë·∫ßy ƒë·ªß c√°c th√¥ng tin v√† t√†i li·ªáu cho sinh vi√™n ƒë·ªÉ gi√∫p t√¥i h·ªçc t·∫≠p m·ªôt c√°ch hi·ªáu qu·∫£. neutral positive\n",
            "Tr∆∞·ªùng c√≥ cung c·∫•p wifi mi·ªÖn ph√≠ cho sinh vi√™n, gi√∫p c√°c em ti·ªán l·ª£i h∆°n trong vi·ªác truy c·∫≠p internet. positive neutral\n",
            "C√≥ r·∫•t nhi·ªÅu c∆° h·ªôi ƒë·ªÉ b·∫°n ph√°t tri·ªÉn nƒÉng l·ª±c kh√¥ng ch·ªâ trong l·ªõp h·ªçc m√† c√≤n ngo√†i ƒë·ªùi th·ª±c. positive neutral\n",
            "Gi·∫£ng vi√™n n√†y ƒë∆∞a ra nh·ªØng b√†i gi·∫£ng r√µ r√†ng v√† h·∫•p d·∫´n, gi√∫p cho h·ªçc sinh hi·ªÉu b√†i h·ªçc d·ªÖ d√†ng h∆°n. neutral positive\n",
            "Gi·∫£ng vi√™n d·∫°y r·∫•t c√≥ t√¢m, t·∫≠n t√¨nh gi√∫p ƒë·ª° sinh vi√™n khi c·∫ßn. positive neutral\n",
            "C√¥ b·∫°n n√†y l√† m·ªôt gi·∫£ng vi√™n tuy·ªát v·ªùi, lu√¥n h·ªó tr·ª£ v√† gi√∫p ƒë·ª° sinh vi√™n. positive neutral\n",
            "T√¥i r·∫•t th√≠ch c√°ch m√† ch∆∞∆°ng tr√¨nh ƒë√†o t·∫°o ƒë∆∞·ª£c t·ªï ch·ª©c v√† qu·∫£n l√Ω. positive neutral\n",
            "Ch∆∞∆°ng tr√¨nh ti√™n ti·∫øn ch∆∞a ƒë∆∞·ª£c tri·ªÉn khai r·ªông r√£i cho sinh vi√™n. negative neutral\n",
            "K√Ω t√∫c x√° c·ªßa tr∆∞·ªùng r·∫•t ti·ªán nghi v√† s·∫°ch s·∫Ω. positive neutral\n",
            "Gi·∫£ng vi√™n lu√¥n t·∫°o ƒëi·ªÅu ki·ªán ƒë·ªÉ sinh vi√™n c√≥ th·ªÉ t·ª± t√¨m hi·ªÉu v√† t·ªët h∆°n trong h·ªçc t·∫≠p. neutral positive\n",
            "Ch·ªã ·∫•y c√≥ kh·∫£ nƒÉng l√†m vi·ªác nh√≥m t·ªët v√† t·∫°o ra m·ªôt m√¥i tr∆∞·ªùng h·ª£p t√°c t·ªët nh·∫•t cho t·∫•t c·∫£ m·ªçi ng∆∞·ªùi. neutral positive\n",
            "Ch∆∞∆°ng tr√¨nh h·ªçc t·∫≠p ƒë√°p ·ª©ng ƒë∆∞·ª£c nh·ªØng y√™u c·∫ßu c·ªßa ngh·ªÅ nghi·ªáp. neutral positive\n",
            "Sinh vi√™n ƒë∆∞·ª£c h·ªó tr·ª£ t√¨m ki·∫øm vi·ªác l√†m sau khi t·ªët nghi·ªáp. neutral positive\n",
            "C√≥ nhi·ªÅu v·∫•n ƒë·ªÅ v·ªÅ thi·∫øt b·ªã v√† h·ªá th·ªëng m·∫°ng trong c√°c ph√≤ng h·ªçc. negative neutral\n",
            "B·∫°n c·ªßa t√¥i l√† ng∆∞·ªùi r·∫•t nƒÉng ƒë·ªông v√† lu√¥n c√≥ nh·ªØng √Ω t∆∞·ªüng m·ªõi l·∫°. positive neutral\n",
            "C√°c ph√≤ng h·ªçc ƒë∆∞·ª£c trang b·ªã ƒë·∫ßy ƒë·ªß nh·ªØng ti·ªán √≠ch c·∫ßn thi·∫øt cho vi·ªác h·ªçc t·∫≠p c·ªßa sinh vi√™n. neutral positive\n",
            "Th·∫ßy r·∫•t nhi·ªát t√¨nh v·ªõi c√°c c√¢u h·ªèi c·ªßa sinh vi√™n. neutral positive\n",
            "Tr∆∞·ªùng ƒë·∫°i h·ªçc n√†y l√† n∆°i l√Ω t∆∞·ªüng ƒë·ªÉ giao l∆∞u v√† k·∫øt n·ªëi v·ªõi nh·ªØng ng∆∞·ªùi b·∫°n m·ªõi. positive neutral\n",
            "T√¥i th√≠ch c√°ch ch∆∞∆°ng tr√¨nh ƒë√†o t·∫°o ƒë∆∞·ª£c x√¢y d·ª±ng ƒë·ªÉ gi√∫p sinh vi√™n ph√°t tri·ªÉn to√†n di·ªán h∆°n. neutral positive\n",
            "Tr∆∞·ªùng h·ªó tr·ª£ sinh vi√™n ƒëƒÉng k√Ω tham gia c√°c k·ª≥ thi ch·ª©ng ch·ªâ v√† ƒë√†o t·∫°o kh√°c. neutral positive\n",
            "C∆° s·ªü v·∫≠t ch·∫•t t·∫°i ƒë·∫°i h·ªçc n√†y ƒë√°p ·ª©ng t·ªët nhu c·∫ßu h·ªçc t·∫≠p c·ªßa sinh vi√™n. neutral positive\n",
            "Sinh vi√™n ƒë∆∞·ª£c tham gia v√†o c√°c d·ª± √°n nghi√™n c·ª©u th·ª±c t·∫ø. neutral positive\n",
            "M√¥n h·ªçc kh√¥ng ph√π h·ª£p v·ªõi chuy√™n ng√†nh c·ª• th·ªÉ v√† ƒë·ªô kh√≥ qu√° cao. negative neutral\n",
            "Anh ·∫•y c√≥ tr√≠ th√¥ng minh s√°ng su·ªët v√† s·ª± nghi·ªáp c·ªßa anh ·∫•y tuy·ªát v·ªùi. positive neutral\n",
            "S·ª± ƒëa d·∫°ng c·ªßa ch∆∞∆°ng tr√¨nh ƒë√†o t·∫°o gi√∫p tƒÉng t√≠nh linh ho·∫°t cho sinh vi√™n. neutral positive\n",
            "Th·∫ßy c√≥ kh·∫£ nƒÉng d·∫°y h·ªçc ƒëa d·∫°ng ƒë·ªÉ ph√π h·ª£p v·ªõi c√°c h·ªçc sinh c√≥ n·ªÅn t·∫£ng k√©m. neutral positive\n",
            "Th·∫ßy th∆∞·ªùng t·∫°o ra c√°c ho·∫°t ƒë·ªông nh√≥m ƒë·ªÉ tƒÉng c∆∞·ªùng t∆∞∆°ng t√°c gi·ªØa h·ªçc vi√™n v√† h·ªçc vi√™n. neutral positive\n",
            "B·∫°n s·∫Ω kh√¥ng th·ªÉ t√¨m th·∫•y m·ªôt gi·∫£ng vi√™n t·ªët h∆°n ·ªü b·∫•t k·ª≥ n∆°i n√†o kh√°c. negative positive\n",
            "Anh ·∫•y l√† m·ªôt ng∆∞·ªùi r·∫•t t·∫≠n t√¢m v·ªõi c√¥ng vi·ªác v√† gia ƒë√¨nh. neutral positive\n",
            "Gi·∫£ng vi√™n r·∫•t th√¥ng minh v√† am hi·ªÉu chuy√™n ng√†nh. positive neutral\n",
            "C√°c ph√≤ng h·ªçc v√† ph√≤ng th√≠ nghi·ªám trong tr∆∞·ªùng ƒë∆∞·ª£c trang b·ªã ƒë·∫ßy ƒë·ªß thi·∫øt b·ªã ƒë·ªÉ ƒë·∫£m b·∫£o ch·∫•t l∆∞·ª£ng h·ªçc t·∫≠p. positive neutral\n",
            "Gi·∫£ng vi√™n l√† m·ªôt ng∆∞·ªùi c√≥ t√°c phong v√† phong c√°ch gi·∫£ng d·∫°y r·∫•t chuy√™n nghi·ªáp. neutral positive\n",
            "Gi·∫£ng vi√™n n√†y th∆∞·ªùng ƒë·ªìng √Ω v·ªõi √Ω ki·∫øn c·ªßa nh·ªØng sinh vi√™n gi√†u kinh nghi·ªám. neutral negative\n",
            "Gi·∫£ng vi√™n r·∫•t trung th√†nh v·ªõi vai tr√≤ c·ªßa m√¨nh v√† gi·∫£ng d·∫°y r·∫•t ch√≠nh x√°c. neutral positive\n",
            "Gi√°o vi√™n kh√¥ng th∆∞·ªùng xuy√™n ƒë√°nh gi√° qu√° tr√¨nh h·ªçc t·∫≠p c·ªßa sinh vi√™n. neutral negative\n",
            "Ch∆∞∆°ng tr√¨nh ƒë√†o t·∫°o gi√∫p t√¥i c√≥ c∆° h·ªôi g·∫∑p g·ª° v√† h·ªçc h·ªèi t·ª´ nh·ªØng ng∆∞·ªùi c√≥ kinh nghi·ªám trong lƒ©nh v·ª±c t√¥i quan t√¢m. neutral positive\n",
            "Ch∆∞∆°ng tr√¨nh ƒë√†o t·∫°o r·∫•t chuy√™n nghi·ªáp. neutral positive\n",
            "Sau khi t·ªët nghi·ªáp, sinh vi√™n c√≥ th·ªÉ c√≥ nhi·ªÅu c∆° h·ªôi vi·ªác l√†m t·ªët trong lƒ©nh v·ª±c c·ªßa m√¨nh. neutral positive\n",
            "Kh√¥ng gi·ªõi h·∫°n v·ªÅ th·ªùi gian h·ªçc t·∫≠p. neutral positive\n",
            "ƒê·ªôi ng≈© gi·∫£ng d·∫°y c·ªßa tr∆∞·ªùng l√† nh·ªØng gi√°o s∆∞ r·∫•t t·∫≠n t√¨nh v√† nhi·ªát t√¨nh. neutral positive\n",
            "C√°c ph√≤ng h·ªçc ƒë∆∞·ª£c c·∫£i t·∫°o ƒë·ªãnh k·ª≥ ƒë·ªÉ ƒë√°p ·ª©ng nhu c·∫ßu h·ªçc t·∫≠p c·ªßa sinh vi√™n. neutral positive\n",
            "Ch∆∞∆°ng tr√¨nh h·ªçc ph√π h·ª£p v·ªõi y√™u c·∫ßu c·ªßa th·ªã tr∆∞·ªùng v√† ƒë√°p ·ª©ng ƒë∆∞·ª£c nhu c·∫ßu c·ªßa h·ªçc vi√™n. neutral positive\n",
            "Khu√¥n vi√™n tr∆∞·ªùng r·ªông l·ªõn v√† ƒë∆∞·ª£c b·ªë tr√≠ h·ª£p l√≠. neutral positive\n",
            "C√°c cƒÉn tin ·ªü ƒë√¢y r·∫•t ngon v√† gi√° c·∫£ ph·∫£i chƒÉng. positive neutral\n",
            "H·ªçc ph√≠ ƒë∆∞·ª£c chia theo c√°c k·ª≥ h·ªçc, gi√∫p sinh vi√™n d·ªÖ d√†ng to√†n t√¢m to√†n √Ω v·ªõi t·ª´ng k·ª≥ h·ªçc. neutral positive\n",
            "T√¥i c·∫£m th·∫•y ch∆∞∆°ng tr√¨nh h·ªçc kh√¥ng th·ª±c s·ª± ƒë√°p ·ª©ng ƒë∆∞·ª£c nhu c·∫ßu ng√†nh ngh·ªÅ hi·ªán t·∫°i. neutral negative\n",
            "H·ªçc ph√≠ ƒë∆∞·ª£c gi·∫£m gi√° cho nh·ªØng sinh vi√™n ƒëƒÉng k√Ω s·ªõm. neutral positive\n",
            "Th·∫ßy n√†y t·ªï ch·ª©c v√† qu·∫£n l√Ω gi·∫£ng d·∫°y r·∫•t t·ªët. neutral positive\n",
            "Gi·∫£ng vi√™n n√†y qu√° ƒë√≤i h·ªèi cao v·ªÅ ƒëi·ªÉm s·ªë v√† ƒë√¥i khi l√†m kh√≥ h·ªçc sinh. negative neutral\n",
            "T√¥i r·∫•t y√™u th√≠ch kh√¥ng gian c·ªßa th∆∞ vi·ªán v√† c√°c d·ªãch v·ª• b·ªï tr·ª£ t·∫°i ƒë√¢y. positive neutral\n",
            "Th·∫ßy r·∫•t trung th·ª±c v√† ch√≠nh tr·ª±c trong gi·∫£ng d·∫°y. neutral positive\n",
            "Ch∆∞∆°ng tr√¨nh h·ªçc r·∫•t linh ho·∫°t v√† c√≥ th·ªÉ ph√π h·ª£p v·ªõi nhu c·∫ßu c·ªßa t·ª´ng sinh vi√™n. neutral positive\n",
            "M√¥n h·ªçc gi√∫p t√¥i trau d·ªìi ki·∫øn th·ª©c chuy√™n m√¥n v√† kinh nghi·ªám th·ª±c ti·ªÖn. neutral positive\n",
            "Gi·∫£ng vi√™n n√†y kh√¥ng gi√∫p ƒë∆∞·ª£c h·ªçc sinh ƒë·∫°t ƒë∆∞·ª£c nh·ªØng m·ª•c ti√™u c·ªßa h·ªç. negative neutral\n",
            "K√Ω t√∫c x√° c·ªßa tr∆∞·ªùng c√≥ c√°c d·ªãch v·ª• ti·ªán √≠ch nh∆∞ t·∫≠p gym v√† qu·∫ßy c√† ph√™. neutral positive\n",
            "C√°c gi·∫£ng vi√™n c·ªßa tr∆∞·ªùng r·∫•t c√≥ kinh nghi·ªám v√† gi·ªèi chuy√™n m√¥n. neutral positive\n",
            "Th·∫ßy h·ªó tr·ª£ sinh vi√™n trong vi·ªác gi·∫£i quy·∫øt c√°c v·∫•n ƒë·ªÅ h·ªçc thu·∫≠t v√† c√° nh√¢n. neutral positive\n",
            "ƒê·ªôi ng≈© nh√¢n vi√™n ·ªü ƒë√¢y lu√¥n h·ªó tr·ª£ v√† ƒë√°p ·ª©ng m·ªçi nhu c·∫ßu c·ªßa sinh vi√™n. positive neutral\n",
            "T√¥i h∆∞·ªõng ƒë·∫øn m·ª•c ti√™u c·ªßa b·∫£n th√¢n v·ªõi s·ª± gi√∫p ƒë·ª° c·ªßa gi·∫£ng vi√™n. neutral positive\n",
            "Th·∫ßy lu√¥n ƒë∆∞a ra nh·ªØng c√¢u h·ªèi th√∫ v·ªã ƒë·ªÉ khuy·∫øn kh√≠ch s·ª± t√≤ m√≤ c·ªßa sinh vi√™n. neutral positive\n",
            "T√¥i ƒë√£ ƒë∆∞·ª£c trang b·ªã ƒë·∫ßy ƒë·ªß c√°c t√†i li·ªáu th∆∞ vi·ªán c·∫ßn thi·∫øt ƒë·ªÉ h·ªçc t·∫≠p v√† l√†m b√†i t·∫≠p. positive neutral\n",
            "Ph√≤ng th√≠ nghi·ªám ·ªü tr∆∞·ªùng ƒë∆∞·ª£c trang b·ªã ƒë·∫ßy ƒë·ªß thi·∫øt b·ªã v√† m√°y m√≥c. positive neutral\n",
            "ƒê·ªôi ng≈© gi√°o vi√™n c√≥ nhi·ªÅu tri th·ª©c v√† kinh nghi·ªám gi√∫p sinh vi√™n n·∫Øm v·ªØng ki·∫øn th·ª©c chuy√™n m√¥n. neutral positive\n",
            "C√°c ph√≤ng h·ªçc ƒë∆∞·ª£c ƒë√°nh gi√° l√† kh√¥ng gian r·ªông r√£i v√† tho·∫£i m√°i. neutral positive\n",
            "Nh·ªØng ki·∫øn th·ª©c t√¥i h·ªçc ƒë∆∞·ª£c trong ch∆∞∆°ng tr√¨nh h·ªçc r·∫•t b·ªï √≠ch cho c√¥ng vi·ªác c·ªßa t√¥i sau n√†y. positive neutral\n",
            "Gi√°o vi√™n chuy√™n ƒë·ªÉ √Ω ƒë·∫øn nh·ªØng sinh vi√™n xu·∫•t s·∫Øc, b·ªè qu√™n nh·ªØng sinh vi√™n y·∫øu k√©m. neutral negative\n",
            "Th·∫ßy c√¥ lu√¥n g·∫ßn g≈©i v√† d·ªÖ ti·∫øp c·∫≠n v·ªõi c√°c sinh vi√™n. positive neutral\n",
            "B·∫°n c·ªßa t√¥i r·∫•t c·ªüi m·ªü v√† d·ªÖ th∆∞∆°ng v·ªõi m·ªçi ng∆∞·ªùi. positive neutral\n",
            "Th·∫ßy gi√∫p sinh vi√™n trau d·ªìi k·ªπ nƒÉng m·ªÅm, r√®n luy·ªán k·ªπ nƒÉng thuy·∫øt tr√¨nh v√† thuy·∫øt ph·ª•c. neutral positive\n",
            "Gi·∫£ng vi√™n gi√∫p sinh vi√™n ph√°t tri·ªÉn v√† r√®n luy·ªán k·ªπ nƒÉng s√°ng t·∫°o. positive neutral\n",
            "Th·∫ßy l√† m·ªôt gi·∫£ng vi√™n r·∫•t th√¢n thi·ªán v√† lu√¥n s·∫µn s√†ng tr·ª£ gi√∫p sinh vi√™n. neutral positive\n",
            "Th·∫ßy c≈©ng l√† m·ªôt ng∆∞·ªùi ƒë·ªìng h√†nh v√† l·∫Øng nghe nh·ªØng kh√≥ khƒÉn c·ªßa sinh vi√™n. neutral positive\n",
            "H·ªôi tr∆∞·ªùng l·ªõn v√† ƒë∆∞·ª£c trang b·ªã ƒë·∫ßy ƒë·ªß h·ªá th·ªëng √¢m thanh v√† chi·∫øu s√°ng. neutral positive\n",
            "C√¥ ·∫•y r·∫•t c·∫©n th·∫≠n v√† ch√∫ √Ω ƒë·∫øn chi ti·∫øt nh·ªè nh·∫•t. neutral positive\n",
            "Ph√≤ng h·ªçc ƒë∆∞·ª£c trang b·ªã s·∫£n ph·∫©m ƒë√°nh gi√° nh∆∞ m√°y chi·∫øu, m√°y t√≠nh, tivi, loa, ƒë·ªám ng·ªìi, ... positive neutral\n",
            "C√°c ho·∫°t ƒë·ªông gi√°o d·ª•c kh√° ƒëa d·∫°ng v√† phong ph√∫. neutral positive\n",
            "C√°c b√†i ki·ªÉm tra ƒë∆∞·ª£c thi·∫øt k·∫ø t·ªët v√† c√¥ng b·∫±ng. neutral positive\n",
            "Th·∫ßy lu√¥n d·∫°y sinh vi√™n c√°ch t∆∞ duy v√† ph√°t tri·ªÉn k·ªπ nƒÉng. positive neutral\n",
            "C∆° s·ªü v·∫≠t ch·∫•t t·ªët v√† ƒë∆∞·ª£c c·∫≠p nh·∫≠t li√™n t·ª•c. neutral positive\n",
            "T√¥i r·∫•t th√≠ch khung gi·ªù h·ªçc c√≥ s·∫Øp x·∫øp ph√π h·ª£p v·ªõi l·ªãch tr√¨nh c·ªßa sinh vi√™n. neutral positive\n",
            "Gi·∫£ng vi√™n n√†y ƒë√¥i l√∫c qu√™n chuy·ªán ch√≠nh ƒë·ªÉ gi·∫£i th√≠ch nh·ªØng chi ti·∫øt kh√¥ng quan tr·ªçng. negative neutral\n",
            "L·ªõp h·ªçc ƒë∆∞·ª£c t·ªï ch·ª©c khoa h·ªçc, h·ªó tr·ª£ sinh vi√™n kh√¥ng ch·ªâ gi√∫p h·ªçc m√† c√≤n gi√∫p sinh vi√™n r√®n luy·ªán k·ªπ nƒÉng qu·∫£n l√Ω th·ªùi gian. positive neutral\n",
            "Tr∆∞·ªùng cung c·∫•p r·∫•t nhi·ªÅu thi·∫øt b·ªã v√† ph·∫ßn m·ªÅm h·ªØu √≠ch cho vi·ªác h·ªçc t·∫≠p v√† nghi√™n c·ª©u. neutral positive\n",
            "Gi·∫£ng vi√™n r·∫•t th√¢n thi·ªán v√† c√≥ t∆∞ duy ph·∫£n bi·ªán cao. neutral positive\n",
            "C√¥ ·∫•y c√≥ kh·∫£ nƒÉng ƒë∆∞a ra quy·∫øt ƒë·ªãnh m·ªôt c√°ch ƒë√∫ng ƒë·∫Øn v√† hi·ªáu qu·∫£. neutral positive\n",
            "Anh ·∫•y l√† m·ªôt ng∆∞·ªùi t√†i nƒÉng v√† c√≥ tinh th·∫ßn t·ª± th√°ch th·ª©c b·∫£n th√¢n. neutral positive\n",
            "C√°c gi·∫£ng vi√™n ƒë·ªÅu r·∫•t am hi·ªÉu trong lƒ©nh v·ª±c c·ªßa m√¨nh. neutral positive\n",
            "Th∆∞ vi·ªán c·ªßa tr∆∞·ªùng c√≥ kh√¥ng gian y√™n tƒ©nh, t·∫°o c·∫£m gi√°c th∆∞ th√°i gi√∫p sinh vi√™n t·∫≠p trung nghi√™n c·ª©u. neutral positive\n",
            "T√¥i r·∫•t ·∫•n t∆∞·ª£ng v·ªõi phong c√°ch gi·∫£ng d·∫°y c·ªßa gi·∫£ng vi√™n v√† c√°ch anh ·∫•y truy·ªÅn ƒë·∫°t ki·∫øn th·ª©c. neutral positive\n",
            "Gi√°o tr√¨nh r·∫•t th√∫ v·ªã v√† ƒë·ªôc ƒë√°o, gi√∫p t√¥i h·ªçc ƒë∆∞·ª£c nhi·ªÅu th·ª© m·ªõi l·∫°. positive neutral\n",
            "Khu√¥n vi√™n ƒë·∫•t n·ªÅn r·ªông r√£i v√† kh√° y√™n tƒ©nh. neutral positive\n",
            "Nhi·ªÅu c∆° h·ªôi ƒë∆∞·ª£c th·ª±c t·∫≠p t·ª´ c√°c doanh nghi·ªáp n·ªïi ti·∫øng. neutral positive\n",
            "Gi·∫£ng vi√™n n√†y ƒë∆∞a ra nh·ªØng gi·∫£i ph√°p ƒë·ªôt ph√° v√† s√°ng t·∫°o cho vi·ªác h·ªçc t·∫≠p. neutral positive\n",
            "Th·∫ßy truy·ªÅn c·∫£m h·ª©ng v√† ƒë·ªông vi√™n c√°c sinh vi√™n c√≥ ho√†n c·∫£nh kh√≥ khƒÉn. positive neutral\n",
            "N·ªôi dung b√†i h·ªçc tr·ª±c quan v√† h·∫•p d·∫´n. positive neutral\n",
            "Khu v·ª±c ng·ªìi t·∫≠p trung v√† l√†m vi·ªác c·ªßa tr∆∞·ªùng r·∫•t t·ªët cho vi·ªác h·ªçc t·∫≠p t·∫≠p trung. neutral positive\n",
            "H·ªá th·ªëng gi√°o tr√¨nh h·ªó tr·ª£ c√°c sinh vi√™n c√≥ th·ªÉ ti·∫øp c·∫≠n v√† t√¨m hi·ªÉu v·ªÅ ng√†nh ngh·ªÅ c·ªßa m√¨nh m·ªôt c√°ch hi·ªáu qu·∫£. positive neutral\n",
            "S·ª± ƒëa d·∫°ng v·ªÅ c√°c m√¥n h·ªçc gi√∫p m√¨nh l·ª±a ch·ªçn v√† c·∫≠p nh·∫≠t ki·∫øn th·ª©c m·ªõi. neutral positive\n",
            "C√°c ph√≤ng h·ªçc ƒë∆∞·ª£c trang b·ªã m√°y chi·∫øu ƒë·∫ßy ƒë·ªß gi√∫p gi·∫£ng vi√™n gi·∫£ng d·∫°y t·ªët h∆°n. neutral positive\n",
            "Gi·∫£ng vi√™n n√†y ƒë∆∞a ra c√°c v√≠ d·ª• r·∫•t th·ª±c t·∫ø v√† h·ªØu √≠ch ƒë·ªÉ gi√∫p t√¥i hi·ªÉu b√†i h·ªçc. neutral positive\n",
            "C∆° s·ªü v·∫≠t ch·∫•t c·ªßa tr∆∞·ªùng r·∫•t ti√™n ti·∫øn v√† th√≠ch h·ª£p cho vi·ªác h·ªçc t·∫≠p v√† nghi√™n c·ª©u. neutral positive\n",
            "Gi√°o vi√™n lu√¥n gi·∫£i ƒë√°p th·∫Øc m·∫Øc c·ªßa sinh vi√™n r√µ r√†ng v√† chi ti·∫øt. positive neutral\n",
            "Ph√≤ng h·ªçc ƒë∆∞·ª£c trang b·ªã ƒë·∫ßy ƒë·ªß c√°c thi·∫øt b·ªã c·∫ßn thi·∫øt cho vi·ªác h·ªçc t·∫≠p. neutral positive\n",
            "T√¥i r·∫•t h√†i l√≤ng v·ªõi ch∆∞∆°ng tr√¨nh h·ªçc n∆°i ƒë√¢y. positive neutral\n",
            "C√¥ ·∫•y c√≥ phong c√°ch d·∫°y h·ªçc v√¥ c√πng s√°ng t·∫°o v√† th√∫ v·ªã. positive neutral\n",
            "C√≥ r·∫•t nhi·ªÅu ngu·ªìn t√†i nguy√™n h·ªó tr·ª£ h·ªçc vi√™n trong qu√° tr√¨nh h·ªçc t·∫≠p. neutral positive\n",
            "Anh ta lu√¥n c√≥ tinh th·∫ßn h·ªçc h·ªèi v√† m·ªü ƒë·∫ßu v·ªõi nh·ªØng ki·∫øn th·ª©c m·ªõi. positive neutral\n",
            "C√°c bu·ªïi h·ªçc ƒë∆∞·ª£c t·ªï ch·ª©c ch·∫∑t ch·∫Ω v√† c√≥ s·ª± chu·∫©n b·ªã k·ªπ l∆∞·ª°ng. neutral positive\n",
            "C√≥ r·∫•t nhi·ªÅu b·∫°n h·ªçc t·ªët v√† t√≠ch c·ª±c tham gia v√†o c√°c ho·∫°t ƒë·ªông c·ªßa tr∆∞·ªùng. positive neutral\n",
            "Anh ta l√† m·ªôt gi·∫£ng vi√™n r·∫•t t·∫≠n t√¢m v√† s√°ng t·∫°o. neutral positive\n",
            "Ph√≤ng gi√°o vi√™n ƒë·ªß ti·ªán nghi, tho·∫£i m√°i. neutral positive\n",
            "C·∫≠u b·∫°n n√†y r·∫•t th√¢n thi·ªán v√† h√≤a ƒë·ªìng. neutral positive\n",
            "Gi·∫£ng vi√™n r·∫•t ƒë√°ng k√≠nh v√† ƒë∆∞·ª£c sinh vi√™n y√™u m·∫øn ƒë·∫∑c bi·ªát. positive neutral\n",
            "Th·∫ßy r·∫•t nƒÉng ƒë·ªông, gi√∫p sinh vi√™n t·∫≠p trung v√†o h·ªçc t·∫≠p m·ªôt c√°ch hi·ªáu qu·∫£. positive neutral\n",
            "Gi·∫£ng vi√™n n√†y t·∫°o ra m·ªôt m√¥i tr∆∞·ªùng h·ªçc t·∫≠p vui nh·ªôn v√† h·∫•p d·∫´n. neutral positive\n",
            "Gi√°o vi√™n lu√¥n ƒë·∫∑t m√¨nh v√†o t√¢m tr·∫°ng v√† kh√≥ khƒÉn c·ªßa h·ªçc sinh. neutral positive\n",
            "Ch·∫•t l∆∞·ª£ng gi·∫£ng d·∫°y c·ªßa tr∆∞·ªùng t√¥i r·∫•t t·ªët trong ƒë√≥ gi√°o vi√™n l√† m·ªôt ph·∫ßn quan tr·ªçng. neutral positive\n",
            "Gi·∫£ng vi√™n mang l·∫°i kinh nghi·ªám th·ª±c t·∫ø cho h·ªçc sinh. neutral positive\n",
            "H·ªá th·ªëng r·∫°p chi·∫øu phim v√† trung t√¢m gi·∫£i tr√≠ n√¢ng cao sinh ho·∫°t vƒÉn h√≥a cho sinh vi√™n. positive neutral\n",
            "Anh ·∫•y r·∫•t hi·ªÉu bi·∫øt v√† lu√¥n gi·ªØ l·ªùi h·ª©a. neutral positive\n",
            "T√†i li·ªáu h·ªçc t·∫≠p nhi·ªát t√¨nh v√† ƒë·∫ßy tr·∫£i nghi·ªám th·ª±c t·∫ø. positive neutral\n",
            "C√°c b√†i h·ªçc ƒë∆∞·ª£c thi·∫øt k·∫ø t·ªëi ∆∞u cho vi·ªác h·ªçc tr·ª±c tuy·∫øn. neutral positive\n",
            "C√°c khu v·ª±c c·∫•m h√∫t thu·ªëc ƒë∆∞·ª£c thi·∫øt k·∫ø v√† b·ªë tr√≠ ƒë·ªÉ ƒë·∫£m b·∫£o kh√¥ng kh√≠ trong l√†nh. neutral positive\n",
            "T√¥i c·∫£m th·∫•y r·∫•t ti·∫øc khi th·ªùi gian h·ªçc t·∫≠p t·∫°i tr∆∞·ªùng c·ªßa t√¥i k·∫øt th√∫c. negative positive\n",
            "Th·∫ßy r√®n luy·ªán cho h·ªçc sinh ƒë·ªông n√£o v√† t∆∞·ªüng t∆∞·ª£ng. neutral positive\n",
            "Gi·∫£ng vi√™n n√†y kh√¥ng nh√†m ch√°n. neutral negative\n"
          ]
        }
      ],
      "source": [
        "for i, row in df_test.iterrows():\n",
        "    if row['predict'] != row['sentiment']:\n",
        "        print(row['sentence'], row['predict'], row['sentiment'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "alPdHiviPp-G"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3JYDJHIVPp-G"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "datasetId": 3052448,
          "sourceId": 5245967,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30733,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}